\begin{thebibliography}{10}

\bibitem{liu_swin_2022}
Z.~Liu, H.~Hu, Y.~Lin, Z.~Yao, Z.~Xie, Y.~Wei, J.~Ning, Y.~Cao, Z.~Zhang, L.~Dong, F.~Wei, and B.~Guo, ``Swin {Transformer} {V2}: {Scaling} {Up} {Capacity} and {Resolution},'' Apr. 2022.
\newblock arXiv:2111.09883 [cs] version: 2.

\bibitem{vaswani_attention_2017}
A.~Vaswani, N.~Shazeer, N.~Parmar, J.~Uszkoreit, L.~Jones, A.~N. Gomez, L.~Kaiser, and I.~Polosukhin, ``Attention {Is} {All} {You} {Need},'' Dec. 2017.
\newblock arXiv:1706.03762 [cs].

\bibitem{oquab_is_2015}
M.~Oquab, L.~Bottou, I.~Laptev, and J.~Sivic, ``Is object localization for free? - {Weakly}-supervised learning with convolutional neural networks,'' in {\em 2015 {IEEE} {Conference} on {Computer} {Vision} and {Pattern} {Recognition} ({CVPR})}, (Boston, MA, USA), pp.~685--694, IEEE, June 2015.

\bibitem{selvaraju_grad-cam_nodate}
R.~R. Selvaraju, M.~Cogswell, A.~Das, R.~Vedantam, D.~Parikh, and D.~Batra, ``Grad-{CAM}: {Visual} {Explanations} {From} {Deep} {Networks} via {Gradient}-{Based} {Localization},'' p.~9.

\bibitem{chattopadhyay_grad-cam_2018}
A.~Chattopadhyay, A.~Sarkar, P.~Howlader, and V.~N. Balasubramanian, ``Grad-{CAM}++: {Improved} {Visual} {Explanations} for {Deep} {Convolutional} {Networks},'' in {\em 2018 {IEEE} {Winter} {Conference} on {Applications} of {Computer} {Vision} ({WACV})}, pp.~839--847, Mar. 2018.
\newblock arXiv:1710.11063 [cs].

\bibitem{lin_network_2014}
M.~Lin, Q.~Chen, and S.~Yan, ``Network {In} {Network},'' Mar. 2014.
\newblock arXiv:1312.4400 [cs] version: 3.

\bibitem{perez2017effectiveness}
L.~Perez and J.~Wang, ``The effectiveness of data augmentation in image classification using deep learning,'' {\em arXiv preprint arXiv:1712.04621}, 2017.

\bibitem{zhong2020random}
Z.~Zhong, L.~Zheng, G.~Kang, S.~Li, and Y.~Yang, ``Random erasing data augmentation,'' in {\em Proceedings of the AAAI conference on artificial intelligence}, vol.~34, pp.~13001--13008, 2020.

\bibitem{dvornik2018modeling}
N.~Dvornik, J.~Mairal, and C.~Schmid, ``Modeling visual context is key to augmenting object detection datasets,'' in {\em Proceedings of the European Conference on Computer Vision (ECCV)}, pp.~364--380, 2018.

\bibitem{devlin_bert_2019}
J.~Devlin, M.-W. Chang, K.~Lee, and K.~Toutanova, ``{BERT}: {Pre}-training of {Deep} {Bidirectional} {Transformers} for {Language} {Understanding},'' May 2019.
\newblock arXiv:1810.04805 [cs].

\bibitem{brown_language_2020}
T.~B. Brown, B.~Mann, N.~Ryder, M.~Subbiah, J.~Kaplan, P.~Dhariwal, A.~Neelakantan, P.~Shyam, G.~Sastry, A.~Askell, S.~Agarwal, A.~Herbert-Voss, G.~Krueger, T.~Henighan, R.~Child, A.~Ramesh, D.~M. Ziegler, J.~Wu, C.~Winter, C.~Hesse, M.~Chen, E.~Sigler, M.~Litwin, S.~Gray, B.~Chess, J.~Clark, C.~Berner, S.~McCandlish, A.~Radford, I.~Sutskever, and D.~Amodei, ``Language {Models} are {Few}-{Shot} {Learners},'' July 2020.
\newblock arXiv:2005.14165 [cs].

\bibitem{dosovitskiy2020image}
A.~Dosovitskiy, L.~Beyer, A.~Kolesnikov, D.~Weissenborn, X.~Zhai, T.~Unterthiner, M.~Dehghani, M.~Minderer, G.~Heigold, S.~Gelly, {\em et~al.}, ``An image is worth 16x16 words: Transformers for image recognition at scale,'' {\em arXiv preprint arXiv:2010.11929}, 2020.

\bibitem{paszke2019pytorch}
A.~Paszke, S.~Gross, F.~Massa, A.~Lerer, J.~Bradbury, G.~Chanan, T.~Killeen, Z.~Lin, N.~Gimelshein, L.~Antiga, {\em et~al.}, ``Pytorch: An imperative style, high-performance deep learning library,'' {\em Advances in neural information processing systems}, vol.~32, 2019.

\bibitem{bradski2000opencv}
G.~Bradski, ``The opencv library.,'' {\em Dr. Dobb's Journal: Software Tools for the Professional Programmer}, vol.~25, no.~11, pp.~120--123, 2000.

\bibitem{howard2018fastai}
J.~Howard {\em et~al.}, ``fastai.'' \url{https://github.com/fastai/fastai}, 2018.

\bibitem{he2016deep}
K.~He, X.~Zhang, S.~Ren, and J.~Sun, ``Deep residual learning for image recognition,'' in {\em Proceedings of the IEEE conference on computer vision and pattern recognition}, pp.~770--778, 2016.

\end{thebibliography}
