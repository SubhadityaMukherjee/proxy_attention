% $ biblatex auxiliary file $
% $ biblatex bbl format version 3.2 $
% Do not modify the above lines!
%
% This is an auxiliary file used by the 'biblatex' package.
% This file may safely be deleted. It will be recreated by
% biber as required.
%
\begingroup
\makeatletter
\@ifundefined{ver@biblatex.sty}
  {\@latex@error
     {Missing 'biblatex' package}
     {The bibliography requires the 'biblatex' package.}
      \aftergroup\endinput}
  {}
\endgroup


\refsection{0}
  \datalist[entry]{none/global//global/global}
    \entry{krizhevskyLearningMultipleLayers}{article}{}
      \name{author}{1}{}{%
        {{hash=c5e3a676e2ac1164b3afcd539c131fc9}{%
           family={Krizhevsky},
           familyi={K\bibinitperiod},
           given={Alex},
           giveni={A\bibinitperiod}}}%
      }
      \strng{namehash}{c5e3a676e2ac1164b3afcd539c131fc9}
      \strng{fullhash}{c5e3a676e2ac1164b3afcd539c131fc9}
      \strng{bibnamehash}{c5e3a676e2ac1164b3afcd539c131fc9}
      \strng{authorbibnamehash}{c5e3a676e2ac1164b3afcd539c131fc9}
      \strng{authornamehash}{c5e3a676e2ac1164b3afcd539c131fc9}
      \strng{authorfullhash}{c5e3a676e2ac1164b3afcd539c131fc9}
      \field{sortinit}{1}
      \field{sortinithash}{4f6aaa89bab872aa0999fec09ff8e98a}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{langid}{english}
      \field{title}{Learning {{Multiple Layers}} of {{Features}} from {{Tiny Images}}}
      \verb{file}
      \verb /Users/eragon/Zotero/storage/T2BXLVFU/Krizhevsky - Learning Multiple Layers of Features from Tiny Ima.pdf
      \endverb
    \endentry
    \entry{wangScoreCAMScoreWeightedVisual2020}{online}{}
      \name{author}{8}{}{%
        {{hash=2af57f63f16bd5ef869fcd7a0764dae5}{%
           family={Wang},
           familyi={W\bibinitperiod},
           given={Haofan},
           giveni={H\bibinitperiod}}}%
        {{hash=5ddb055abfa86a367168a9254a94cdfb}{%
           family={Wang},
           familyi={W\bibinitperiod},
           given={Zifan},
           giveni={Z\bibinitperiod}}}%
        {{hash=9beacda51637cbdae2180aeebe90f31c}{%
           family={Du},
           familyi={D\bibinitperiod},
           given={Mengnan},
           giveni={M\bibinitperiod}}}%
        {{hash=bac6a7a5d8c835c2ebe5288a6fe722b4}{%
           family={Yang},
           familyi={Y\bibinitperiod},
           given={Fan},
           giveni={F\bibinitperiod}}}%
        {{hash=53f90aa659ae14734c307d61aeefc1ef}{%
           family={Zhang},
           familyi={Z\bibinitperiod},
           given={Zijian},
           giveni={Z\bibinitperiod}}}%
        {{hash=5c252be48d12323ae5c070ca0b2acb8b}{%
           family={Ding},
           familyi={D\bibinitperiod},
           given={Sirui},
           giveni={S\bibinitperiod}}}%
        {{hash=36b04db0da7f3f385e92a82ac5ba3937}{%
           family={Mardziel},
           familyi={M\bibinitperiod},
           given={Piotr},
           giveni={P\bibinitperiod}}}%
        {{hash=13be76d254e7c2f65cfc92bc75bb18fd}{%
           family={Hu},
           familyi={H\bibinitperiod},
           given={Xia},
           giveni={X\bibinitperiod}}}%
      }
      \strng{namehash}{55ae1ccb8bbf87a087f74443354c001d}
      \strng{fullhash}{f53bdf3685e73e4a9d3578229d6e07a6}
      \strng{bibnamehash}{55ae1ccb8bbf87a087f74443354c001d}
      \strng{authorbibnamehash}{55ae1ccb8bbf87a087f74443354c001d}
      \strng{authornamehash}{55ae1ccb8bbf87a087f74443354c001d}
      \strng{authorfullhash}{f53bdf3685e73e4a9d3578229d6e07a6}
      \field{sortinit}{2}
      \field{sortinithash}{8b555b3791beccb63322c22f3320aa9a}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{shorttitle}
      \field{abstract}{Recently, increasing attention has been drawn to the internal mechanisms of convolutional neural networks, and the reason why the network makes specific decisions. In this paper, we develop a novel post-hoc visual explanation method called Score-CAM based on class activation mapping. Unlike previous class activation mapping based approaches, Score-CAM gets rid of the dependence on gradients by obtaining the weight of each activation map through its forward passing score on target class, the final result is obtained by a linear combination of weights and activation maps. We demonstrate that Score-CAM achieves better visual performance and fairness for interpreting the decision making process. Our approach outperforms previous methods on both recognition and localization tasks, it also passes the sanity check. We also indicate its application as debugging tools. Official code has been released.}
      \field{day}{13}
      \field{eprinttype}{arxiv}
      \field{month}{4}
      \field{number}{arXiv:1910.01279}
      \field{pubstate}{preprint}
      \field{shorttitle}{Score-{{CAM}}}
      \field{title}{Score-{{CAM}}: {{Score-Weighted Visual Explanations}} for {{Convolutional Neural Networks}}}
      \field{urlday}{16}
      \field{urlmonth}{2}
      \field{urlyear}{2023}
      \field{version}{2}
      \field{year}{2020}
      \field{dateera}{ce}
      \field{urldateera}{ce}
      \verb{eprint}
      \verb arXiv:1910.01279
      \endverb
      \verb{file}
      \verb /Users/eragon/Zotero/storage/AR2AG5TE/Wang et al. - 2020 - Score-CAM Score-Weighted Visual Explanations for .pdf
      \endverb
      \verb{urlraw}
      \verb http://arxiv.org/abs/1910.01279
      \endverb
      \verb{url}
      \verb http://arxiv.org/abs/1910.01279
      \endverb
      \keyw{Computer Science - Computer Vision and Pattern Recognition}
    \endentry
    \entry{hendrycksAugMixSimpleData2020}{online}{}
      \name{author}{6}{}{%
        {{hash=86d0b4ecd6b6066d49e7aecde6e5e630}{%
           family={Hendrycks},
           familyi={H\bibinitperiod},
           given={Dan},
           giveni={D\bibinitperiod}}}%
        {{hash=d0a09a44bc951d42ed9a586a243998cb}{%
           family={Mu},
           familyi={M\bibinitperiod},
           given={Norman},
           giveni={N\bibinitperiod}}}%
        {{hash=2fca729a4ff01c85c2e50c1fdf09b9f2}{%
           family={Cubuk},
           familyi={C\bibinitperiod},
           given={Ekin\bibnamedelima D.},
           giveni={E\bibinitperiod\bibinitdelim D\bibinitperiod}}}%
        {{hash=91aafc93e68e8c6a55e8cd804c2acaf2}{%
           family={Zoph},
           familyi={Z\bibinitperiod},
           given={Barret},
           giveni={B\bibinitperiod}}}%
        {{hash=4f550339f0337905aa634f39e1ba4833}{%
           family={Gilmer},
           familyi={G\bibinitperiod},
           given={Justin},
           giveni={J\bibinitperiod}}}%
        {{hash=55c0a67ecb602e5a3063393ffee9c7fa}{%
           family={Lakshminarayanan},
           familyi={L\bibinitperiod},
           given={Balaji},
           giveni={B\bibinitperiod}}}%
      }
      \strng{namehash}{f461c117afa272374439d2db3ee67282}
      \strng{fullhash}{23ffd230c8d2d79d5036bc3e3cdb2e01}
      \strng{bibnamehash}{f461c117afa272374439d2db3ee67282}
      \strng{authorbibnamehash}{f461c117afa272374439d2db3ee67282}
      \strng{authornamehash}{f461c117afa272374439d2db3ee67282}
      \strng{authorfullhash}{23ffd230c8d2d79d5036bc3e3cdb2e01}
      \field{sortinit}{3}
      \field{sortinithash}{ad6fe7482ffbd7b9f99c9e8b5dccd3d7}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{shorttitle}
      \field{abstract}{Modern deep neural networks can achieve high accuracy when the training distribution and test distribution are identically distributed, but this assumption is frequently violated in practice. When the train and test distributions are mismatched, accuracy can plummet. Currently there are few techniques that improve robustness to unforeseen data shifts encountered during deployment. In this work, we propose a technique to improve the robustness and uncertainty estimates of image classifiers. We propose AUGMIX, a data processing technique that is simple to implement, adds limited computational overhead, and helps models withstand unforeseen corruptions. AUGMIX significantly improves robustness and uncertainty measures on challenging image classification benchmarks, closing the gap between previous methods and the best possible performance in some cases by more than half.}
      \field{day}{17}
      \field{eprinttype}{arxiv}
      \field{langid}{english}
      \field{month}{2}
      \field{number}{arXiv:1912.02781}
      \field{pubstate}{preprint}
      \field{shorttitle}{{{AugMix}}}
      \field{title}{{{AugMix}}: {{A Simple Data Processing Method}} to {{Improve Robustness}} and {{Uncertainty}}}
      \field{urlday}{16}
      \field{urlmonth}{1}
      \field{urlyear}{2023}
      \field{year}{2020}
      \field{dateera}{ce}
      \field{urldateera}{ce}
      \verb{eprint}
      \verb arXiv:1912.02781
      \endverb
      \verb{file}
      \verb /Users/eragon/Zotero/storage/W3F6Q299/Hendrycks et al. - 2020 - AugMix A Simple Data Processing Method to Improve.pdf
      \endverb
      \verb{urlraw}
      \verb http://arxiv.org/abs/1912.02781
      \endverb
      \verb{url}
      \verb http://arxiv.org/abs/1912.02781
      \endverb
      \keyw{Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning,Statistics - Machine Learning}
    \endentry
    \entry{linDivergenceMeasuresBased}{article}{}
      \name{author}{1}{}{%
        {{hash=c9ad66a38d11327f45f96280e5ece1dd}{%
           family={Lin},
           familyi={L\bibinitperiod},
           given={Jianhua},
           giveni={J\bibinitperiod}}}%
      }
      \strng{namehash}{c9ad66a38d11327f45f96280e5ece1dd}
      \strng{fullhash}{c9ad66a38d11327f45f96280e5ece1dd}
      \strng{bibnamehash}{c9ad66a38d11327f45f96280e5ece1dd}
      \strng{authorbibnamehash}{c9ad66a38d11327f45f96280e5ece1dd}
      \strng{authornamehash}{c9ad66a38d11327f45f96280e5ece1dd}
      \strng{authorfullhash}{c9ad66a38d11327f45f96280e5ece1dd}
      \field{sortinit}{4}
      \field{sortinithash}{9381316451d1b9788675a07e972a12a7}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{A new class of information-theoretic divergence measures based on the Shannon entropy is introduced. Unlike the well-known Kullback divergences, the new measures do not require the condition of absolute continuity to be satisfied by the probability distributions involved. More importantly, their close relationship with the variational distance and the probability of misclassification error are established in terms of bounds. These bounds are crucial in many applications of divergence measures. The new measures are also well characterized by the properties of nonnegativity, finiteness, semiboundedness, and boundedness.}
      \field{langid}{english}
      \field{title}{Divergence {{Measures Based}} on the {{Shannon Entropy}}}
      \verb{file}
      \verb /Users/eragon/Zotero/storage/6U26YDRA/Lin - Divergence Measures Based on the Shannon Entropy.pdf
      \endverb
    \endentry
    \entry{devriesImprovedRegularizationConvolutional2017}{online}{}
      \name{author}{2}{}{%
        {{hash=5f72faa67f3e3eeb5ab473ef067062aa}{%
           family={DeVries},
           familyi={D\bibinitperiod},
           given={Terrance},
           giveni={T\bibinitperiod}}}%
        {{hash=8c57b78bacc3da92f8aa3623167ea5de}{%
           family={Taylor},
           familyi={T\bibinitperiod},
           given={Graham\bibnamedelima W.},
           giveni={G\bibinitperiod\bibinitdelim W\bibinitperiod}}}%
      }
      \strng{namehash}{c654df171568208867bf898ab0b57ea8}
      \strng{fullhash}{c654df171568208867bf898ab0b57ea8}
      \strng{bibnamehash}{c654df171568208867bf898ab0b57ea8}
      \strng{authorbibnamehash}{c654df171568208867bf898ab0b57ea8}
      \strng{authornamehash}{c654df171568208867bf898ab0b57ea8}
      \strng{authorfullhash}{c654df171568208867bf898ab0b57ea8}
      \field{sortinit}{5}
      \field{sortinithash}{20e9b4b0b173788c5dace24730f47d8c}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Convolutional neural networks are capable of learning powerful representational spaces, which are necessary for tackling complex learning tasks. However, due to the model capacity required to capture such representations, they are often susceptible to overfitting and therefore require proper regularization in order to generalize well. In this paper, we show that the simple regularization technique of randomly masking out square regions of input during training, which we call cutout, can be used to improve the robustness and overall performance of convolutional neural networks. Not only is this method extremely easy to implement, but we also demonstrate that it can be used in conjunction with existing forms of data augmentation and other regularizers to further improve model performance. We evaluate this method by applying it to current state-of-the-art architectures on the CIFAR-10, CIFAR-100, and SVHN datasets, yielding new state-of-the-art results of 2.56\%, 15.20\%, and 1.30\% test error respectively. Code is available at https://github.com/uoguelph-mlrg/Cutout}
      \field{day}{29}
      \field{eprinttype}{arxiv}
      \field{month}{11}
      \field{number}{arXiv:1708.04552}
      \field{pubstate}{preprint}
      \field{title}{Improved {{Regularization}} of {{Convolutional Neural Networks}} with {{Cutout}}}
      \field{urlday}{27}
      \field{urlmonth}{3}
      \field{urlyear}{2023}
      \field{year}{2017}
      \field{dateera}{ce}
      \field{urldateera}{ce}
      \verb{doi}
      \verb 10.48550/arXiv.1708.04552
      \endverb
      \verb{eprint}
      \verb arXiv:1708.04552
      \endverb
      \verb{file}
      \verb /Users/eragon/Zotero/storage/6FFUVLAN/DeVries and Taylor - 2017 - Improved Regularization of Convolutional Neural Ne.pdf
      \endverb
      \verb{urlraw}
      \verb http://arxiv.org/abs/1708.04552
      \endverb
      \verb{url}
      \verb http://arxiv.org/abs/1708.04552
      \endverb
      \keyw{Computer Science - Computer Vision and Pattern Recognition}
    \endentry
    \entry{yunCutMixRegularizationStrategy2019}{inproceedings}{}
      \name{author}{6}{}{%
        {{hash=eb5683d5e1e58ddad99e436c69bb62e9}{%
           family={Yun},
           familyi={Y\bibinitperiod},
           given={Sangdoo},
           giveni={S\bibinitperiod}}}%
        {{hash=9d2ac11de77065ae48b1a2661bb6c477}{%
           family={Han},
           familyi={H\bibinitperiod},
           given={Dongyoon},
           giveni={D\bibinitperiod}}}%
        {{hash=0f548f5eee2626aa65c478015ad5770b}{%
           family={Chun},
           familyi={C\bibinitperiod},
           given={Sanghyuk},
           giveni={S\bibinitperiod}}}%
        {{hash=a8d55c6ddfbc6c08c58e478684c8f374}{%
           family={Oh},
           familyi={O\bibinitperiod},
           given={Seong\bibnamedelima Joon},
           giveni={S\bibinitperiod\bibinitdelim J\bibinitperiod}}}%
        {{hash=9dd4f82b368957654f651047565ef024}{%
           family={Yoo},
           familyi={Y\bibinitperiod},
           given={Youngjoon},
           giveni={Y\bibinitperiod}}}%
        {{hash=2229e018c11bac708e2bca90d081ada1}{%
           family={Choe},
           familyi={C\bibinitperiod},
           given={Junsuk},
           giveni={J\bibinitperiod}}}%
      }
      \list{location}{1}{%
        {Seoul, Korea (South)}%
      }
      \list{publisher}{1}{%
        {IEEE}%
      }
      \strng{namehash}{ecb5eb5d5b1aa17538b94ebea227bb51}
      \strng{fullhash}{8ebe560361d59d3619ee16e63809c449}
      \strng{bibnamehash}{ecb5eb5d5b1aa17538b94ebea227bb51}
      \strng{authorbibnamehash}{ecb5eb5d5b1aa17538b94ebea227bb51}
      \strng{authornamehash}{ecb5eb5d5b1aa17538b94ebea227bb51}
      \strng{authorfullhash}{8ebe560361d59d3619ee16e63809c449}
      \field{sortinit}{7}
      \field{sortinithash}{108d0be1b1bee9773a1173443802c0a3}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{shorttitle}
      \field{abstract}{Regional dropout strategies have been proposed to enhance the performance of convolutional neural network classifiers. They have proved to be effective for guiding the model to attend on less discriminative parts of objects (e.g. leg as opposed to head of a person), thereby letting the network generalize better and have better object localization capabilities. On the other hand, current methods for regional dropout remove informative pixels on training images by overlaying a patch of either black pixels or random noise. Such removal is not desirable because it leads to information loss and inefficiency during training. We therefore propose the CutMix augmentation strategy: patches are cut and pasted among training images where the ground truth labels are also mixed proportionally to the area of the patches. By making efficient use of training pixels and retaining the regularization effect of regional dropout, CutMix consistently outperforms the state-of-the-art augmentation strategies on CIFAR and ImageNet classification tasks, as well as on the ImageNet weakly-supervised localization task. Moreover, unlike previous augmentation methods, our CutMix-trained ImageNet classifier, when used as a pretrained model, results in consistent performance gains in Pascal detection and MS-COCO image captioning benchmarks. We also show that CutMix improves the model robustness against input corruptions and its out-of-distribution detection performances. Source code and pretrained models are available at https://github.com/clovaai/CutMix-PyTorch.}
      \field{booktitle}{2019 {{IEEE}}/{{CVF International Conference}} on {{Computer Vision}} ({{ICCV}})}
      \field{eventtitle}{2019 {{IEEE}}/{{CVF International Conference}} on {{Computer Vision}} ({{ICCV}})}
      \field{isbn}{978-1-72814-803-8}
      \field{langid}{english}
      \field{month}{10}
      \field{shorttitle}{{{CutMix}}}
      \field{title}{{{CutMix}}: {{Regularization Strategy}} to {{Train Strong Classifiers With Localizable Features}}}
      \field{urlday}{20}
      \field{urlmonth}{2}
      \field{urlyear}{2023}
      \field{year}{2019}
      \field{dateera}{ce}
      \field{urldateera}{ce}
      \field{pages}{6022\bibrangedash 6031}
      \range{pages}{10}
      \verb{doi}
      \verb 10.1109/ICCV.2019.00612
      \endverb
      \verb{file}
      \verb /Users/eragon/Zotero/storage/RI2AY5CU/Yun et al. - 2019 - CutMix Regularization Strategy to Train Strong Cl.pdf
      \endverb
      \verb{urlraw}
      \verb https://ieeexplore.ieee.org/document/9008296/
      \endverb
      \verb{url}
      \verb https://ieeexplore.ieee.org/document/9008296/
      \endverb
    \endentry
    \entry{zhangMixupEmpiricalRisk2018}{online}{}
      \name{author}{4}{}{%
        {{hash=2055fe99efa178d6f877d718047b0390}{%
           family={Zhang},
           familyi={Z\bibinitperiod},
           given={Hongyi},
           giveni={H\bibinitperiod}}}%
        {{hash=c55edd870afd5174d08d32e8560235f0}{%
           family={Cisse},
           familyi={C\bibinitperiod},
           given={Moustapha},
           giveni={M\bibinitperiod}}}%
        {{hash=ea1ca71b064fbb7ec15bd2e49e287ea9}{%
           family={Dauphin},
           familyi={D\bibinitperiod},
           given={Yann\bibnamedelima N.},
           giveni={Y\bibinitperiod\bibinitdelim N\bibinitperiod}}}%
        {{hash=47d681c0cbae75196012a538c46ccc06}{%
           family={Lopez-Paz},
           familyi={L\bibinithyphendelim P\bibinitperiod},
           given={David},
           giveni={D\bibinitperiod}}}%
      }
      \strng{namehash}{47ed15e39b226ffdc3da65f48de59b1f}
      \strng{fullhash}{99e17545100e06ee9db2c0f295e2db48}
      \strng{bibnamehash}{47ed15e39b226ffdc3da65f48de59b1f}
      \strng{authorbibnamehash}{47ed15e39b226ffdc3da65f48de59b1f}
      \strng{authornamehash}{47ed15e39b226ffdc3da65f48de59b1f}
      \strng{authorfullhash}{99e17545100e06ee9db2c0f295e2db48}
      \field{sortinit}{8}
      \field{sortinithash}{a231b008ebf0ecbe0b4d96dcc159445f}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{shorttitle}
      \field{abstract}{Large deep neural networks are powerful, but exhibit undesirable behaviors such as memorization and sensitivity to adversarial examples. In this work, we propose mixup, a simple learning principle to alleviate these issues. In essence, mixup trains a neural network on convex combinations of pairs of examples and their labels. By doing so, mixup regularizes the neural network to favor simple linear behavior in-between training examples. Our experiments on the ImageNet-2012, CIFAR-10, CIFAR-100, Google commands and UCI datasets show that mixup improves the generalization of state-of-the-art neural network architectures. We also find that mixup reduces the memorization of corrupt labels, increases the robustness to adversarial examples, and stabilizes the training of generative adversarial networks.}
      \field{day}{27}
      \field{eprinttype}{arxiv}
      \field{month}{4}
      \field{number}{arXiv:1710.09412}
      \field{pubstate}{preprint}
      \field{shorttitle}{Mixup}
      \field{title}{Mixup: {{Beyond Empirical Risk Minimization}}}
      \field{urlday}{27}
      \field{urlmonth}{3}
      \field{urlyear}{2023}
      \field{year}{2018}
      \field{dateera}{ce}
      \field{urldateera}{ce}
      \verb{doi}
      \verb 10.48550/arXiv.1710.09412
      \endverb
      \verb{eprint}
      \verb arXiv:1710.09412
      \endverb
      \verb{file}
      \verb /Users/eragon/Zotero/storage/K2UFNUHC/Zhang et al. - 2018 - mixup Beyond Empirical Risk Minimization.pdf
      \endverb
      \verb{urlraw}
      \verb http://arxiv.org/abs/1710.09412
      \endverb
      \verb{url}
      \verb http://arxiv.org/abs/1710.09412
      \endverb
      \keyw{Computer Science - Machine Learning,Statistics - Machine Learning}
    \endentry
    \entry{walawalkarAttentiveCutMixEnhanced2020}{online}{}
      \name{author}{4}{}{%
        {{hash=caefcc8c1710091cc966342d67df28cb}{%
           family={Walawalkar},
           familyi={W\bibinitperiod},
           given={Devesh},
           giveni={D\bibinitperiod}}}%
        {{hash=656a003a053913c84310e52854968608}{%
           family={Shen},
           familyi={S\bibinitperiod},
           given={Zhiqiang},
           giveni={Z\bibinitperiod}}}%
        {{hash=f7d472f100bd11b3fbb1c5f7d54960a3}{%
           family={Liu},
           familyi={L\bibinitperiod},
           given={Zechun},
           giveni={Z\bibinitperiod}}}%
        {{hash=82fa321950a025af7d68b502b217c22a}{%
           family={Savvides},
           familyi={S\bibinitperiod},
           given={Marios},
           giveni={M\bibinitperiod}}}%
      }
      \strng{namehash}{3c249e0898b4a1aec133ca4937d3674f}
      \strng{fullhash}{810f900becb1a95ad6678560f4abe1f2}
      \strng{bibnamehash}{3c249e0898b4a1aec133ca4937d3674f}
      \strng{authorbibnamehash}{3c249e0898b4a1aec133ca4937d3674f}
      \strng{authornamehash}{3c249e0898b4a1aec133ca4937d3674f}
      \strng{authorfullhash}{810f900becb1a95ad6678560f4abe1f2}
      \field{sortinit}{1}
      \field{sortinithash}{4f6aaa89bab872aa0999fec09ff8e98a}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{shorttitle}
      \field{abstract}{Convolutional neural networks (CNN) are capable of learning robust representation with different regularization methods and activations as convolutional layers are spatially correlated. Based on this property, a large variety of regional dropout strategies have been proposed, such as Cutout, DropBlock, CutMix, etc. These methods aim to promote the network to generalize better by partially occluding the discriminative parts of objects. However, all of them perform this operation randomly, without capturing the most important region(s) within an object. In this paper, we propose Attentive CutMix, a naturally enhanced augmentation strategy based on CutMix. In each training iteration, we choose the most descriptive regions based on the intermediate attention maps from a feature extractor, which enables searching for the most discriminative parts in an image. Our proposed method is simple yet effective, easy to implement and can boost the baseline significantly. Extensive experiments on CIFAR-10/100, ImageNet datasets with various CNN architectures (in a unified setting) demonstrate the effectiveness of our proposed method, which consistently outperforms the baseline CutMix and other methods by a significant margin.}
      \field{day}{5}
      \field{eprinttype}{arxiv}
      \field{month}{4}
      \field{number}{arXiv:2003.13048}
      \field{pubstate}{preprint}
      \field{shorttitle}{Attentive {{CutMix}}}
      \field{title}{Attentive {{CutMix}}: {{An Enhanced Data Augmentation Approach}} for {{Deep Learning Based Image Classification}}}
      \field{urlday}{29}
      \field{urlmonth}{3}
      \field{urlyear}{2023}
      \field{year}{2020}
      \field{dateera}{ce}
      \field{urldateera}{ce}
      \verb{doi}
      \verb 10.48550/arXiv.2003.13048
      \endverb
      \verb{eprint}
      \verb arXiv:2003.13048
      \endverb
      \verb{file}
      \verb /Users/eragon/Zotero/storage/5ZN5WF6N/Walawalkar et al. - 2020 - Attentive CutMix An Enhanced Data Augmentation Ap.pdf
      \endverb
      \verb{urlraw}
      \verb http://arxiv.org/abs/2003.13048
      \endverb
      \verb{url}
      \verb http://arxiv.org/abs/2003.13048
      \endverb
      \keyw{Computer Science - Computer Vision and Pattern Recognition}
    \endentry
    \entry{singhHideandSeekDataAugmentation2018}{online}{}
      \name{author}{5}{}{%
        {{hash=b14c1e38525e58e809557d68d6fd5df3}{%
           family={Singh},
           familyi={S\bibinitperiod},
           given={Krishna\bibnamedelima Kumar},
           giveni={K\bibinitperiod\bibinitdelim K\bibinitperiod}}}%
        {{hash=36c3a7c4b7df7f39ac811cd870a20dfa}{%
           family={Yu},
           familyi={Y\bibinitperiod},
           given={Hao},
           giveni={H\bibinitperiod}}}%
        {{hash=450831fb561ed7e96754f10f8dec62de}{%
           family={Sarmasi},
           familyi={S\bibinitperiod},
           given={Aron},
           giveni={A\bibinitperiod}}}%
        {{hash=a36125feaee54466bfd1d8e288625d05}{%
           family={Pradeep},
           familyi={P\bibinitperiod},
           given={Gautam},
           giveni={G\bibinitperiod}}}%
        {{hash=0058780d2044b7ad95d263c45e1a1b15}{%
           family={Lee},
           familyi={L\bibinitperiod},
           given={Yong\bibnamedelima Jae},
           giveni={Y\bibinitperiod\bibinitdelim J\bibinitperiod}}}%
      }
      \strng{namehash}{da7ea9661525754a9e647bc6950a9f9d}
      \strng{fullhash}{0ed6f8405cc8b34c03463bba041b9ab8}
      \strng{bibnamehash}{da7ea9661525754a9e647bc6950a9f9d}
      \strng{authorbibnamehash}{da7ea9661525754a9e647bc6950a9f9d}
      \strng{authornamehash}{da7ea9661525754a9e647bc6950a9f9d}
      \strng{authorfullhash}{0ed6f8405cc8b34c03463bba041b9ab8}
      \field{sortinit}{1}
      \field{sortinithash}{4f6aaa89bab872aa0999fec09ff8e98a}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{shorttitle}
      \field{abstract}{We propose 'Hide-and-Seek' a general purpose data augmentation technique, which is complementary to existing data augmentation techniques and is beneficial for various visual recognition tasks. The key idea is to hide patches in a training image randomly, in order to force the network to seek other relevant content when the most discriminative content is hidden. Our approach only needs to modify the input image and can work with any network to improve its performance. During testing, it does not need to hide any patches. The main advantage of Hide-and-Seek over existing data augmentation techniques is its ability to improve object localization accuracy in the weakly-supervised setting, and we therefore use this task to motivate the approach. However, Hide-and-Seek is not tied only to the image localization task, and can generalize to other forms of visual input like videos, as well as other recognition tasks like image classification, temporal action localization, semantic segmentation, emotion recognition, age/gender estimation, and person re-identification. We perform extensive experiments to showcase the advantage of Hide-and-Seek on these various visual recognition problems.}
      \field{day}{6}
      \field{eprinttype}{arxiv}
      \field{month}{11}
      \field{number}{arXiv:1811.02545}
      \field{pubstate}{preprint}
      \field{shorttitle}{Hide-and-{{Seek}}}
      \field{title}{Hide-and-{{Seek}}: {{A Data Augmentation Technique}} for {{Weakly-Supervised Localization}} and {{Beyond}}}
      \field{urlday}{27}
      \field{urlmonth}{3}
      \field{urlyear}{2023}
      \field{year}{2018}
      \field{dateera}{ce}
      \field{urldateera}{ce}
      \verb{doi}
      \verb 10.48550/arXiv.1811.02545
      \endverb
      \verb{eprint}
      \verb arXiv:1811.02545
      \endverb
      \verb{file}
      \verb /Users/eragon/Zotero/storage/LL5XKNP3/Singh et al. - 2018 - Hide-and-Seek A Data Augmentation Technique for W.pdf
      \endverb
      \verb{urlraw}
      \verb http://arxiv.org/abs/1811.02545
      \endverb
      \verb{url}
      \verb http://arxiv.org/abs/1811.02545
      \endverb
      \keyw{Computer Science - Computer Vision and Pattern Recognition}
    \endentry
    \entry{zhouLearningDeepFeatures2016}{inproceedings}{}
      \name{author}{5}{}{%
        {{hash=c7cb7aa044ac5597397cceabad3765a3}{%
           family={Zhou},
           familyi={Z\bibinitperiod},
           given={Bolei},
           giveni={B\bibinitperiod}}}%
        {{hash=c8d6add84efe17681e0d4968ebf47fdc}{%
           family={Khosla},
           familyi={K\bibinitperiod},
           given={Aditya},
           giveni={A\bibinitperiod}}}%
        {{hash=ff625fa4a3aa4372da089f7c768a77c0}{%
           family={Lapedriza},
           familyi={L\bibinitperiod},
           given={Agata},
           giveni={A\bibinitperiod}}}%
        {{hash=b7446de83b2320d904225a0730e3389a}{%
           family={Oliva},
           familyi={O\bibinitperiod},
           given={Aude},
           giveni={A\bibinitperiod}}}%
        {{hash=2a80dd1cae02059e95bfed2f2715fd0a}{%
           family={Torralba},
           familyi={T\bibinitperiod},
           given={Antonio},
           giveni={A\bibinitperiod}}}%
      }
      \list{location}{1}{%
        {Las Vegas, NV, USA}%
      }
      \list{publisher}{1}{%
        {IEEE}%
      }
      \strng{namehash}{85a01c7844076348ef51e88248410965}
      \strng{fullhash}{11813c4999ac7bb6f658ca15eb365e76}
      \strng{bibnamehash}{85a01c7844076348ef51e88248410965}
      \strng{authorbibnamehash}{85a01c7844076348ef51e88248410965}
      \strng{authornamehash}{85a01c7844076348ef51e88248410965}
      \strng{authorfullhash}{11813c4999ac7bb6f658ca15eb365e76}
      \field{sortinit}{1}
      \field{sortinithash}{4f6aaa89bab872aa0999fec09ff8e98a}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{In this work, we revisit the global average pooling layer proposed in [13], and shed light on how it explicitly enables the convolutional neural network (CNN) to have remarkable localization ability despite being trained on imagelevel labels. While this technique was previously proposed as a means for regularizing training, we find that it actually builds a generic localizable deep representation that exposes the implicit attention of CNNs on an image. Despite the apparent simplicity of global average pooling, we are able to achieve 37.1\% top-5 error for object localization on ILSVRC 2014 without training on any bounding box annotation.We demonstrate in a variety of experiments that our network is able to localize the discriminative image regions despite just being trained for solving classification task1.}
      \field{booktitle}{2016 {{IEEE Conference}} on {{Computer Vision}} and {{Pattern Recognition}} ({{CVPR}})}
      \field{eventtitle}{2016 {{IEEE Conference}} on {{Computer Vision}} and {{Pattern Recognition}} ({{CVPR}})}
      \field{isbn}{978-1-4673-8851-1}
      \field{langid}{english}
      \field{month}{6}
      \field{title}{Learning {{Deep Features}} for {{Discriminative Localization}}}
      \field{urlday}{20}
      \field{urlmonth}{2}
      \field{urlyear}{2023}
      \field{year}{2016}
      \field{dateera}{ce}
      \field{urldateera}{ce}
      \field{pages}{2921\bibrangedash 2929}
      \range{pages}{9}
      \verb{doi}
      \verb 10.1109/CVPR.2016.319
      \endverb
      \verb{file}
      \verb /Users/eragon/Zotero/storage/D46H4UWB/Zhou et al. - 2016 - Learning Deep Features for Discriminative Localiza.pdf
      \endverb
      \verb{urlraw}
      \verb http://ieeexplore.ieee.org/document/7780688/
      \endverb
      \verb{url}
      \verb http://ieeexplore.ieee.org/document/7780688/
      \endverb
    \endentry
    \entry{zhongRandomErasingData2020}{article}{}
      \name{author}{5}{}{%
        {{hash=5ffd59133d7d49ddc05ba07d2bbe8c66}{%
           family={Zhong},
           familyi={Z\bibinitperiod},
           given={Zhun},
           giveni={Z\bibinitperiod}}}%
        {{hash=7f1ed47c0c1b22e46324b0745b5b65eb}{%
           family={Zheng},
           familyi={Z\bibinitperiod},
           given={Liang},
           giveni={L\bibinitperiod}}}%
        {{hash=3c065eed66394a54f1d36a69511ea026}{%
           family={Kang},
           familyi={K\bibinitperiod},
           given={Guoliang},
           giveni={G\bibinitperiod}}}%
        {{hash=bc6feb32222eb9129e27d20dbc31167a}{%
           family={Li},
           familyi={L\bibinitperiod},
           given={Shaozi},
           giveni={S\bibinitperiod}}}%
        {{hash=446e84a6f09f26fc6cf5730853e551ba}{%
           family={Yang},
           familyi={Y\bibinitperiod},
           given={Yi},
           giveni={Y\bibinitperiod}}}%
      }
      \strng{namehash}{9beb7313dee5fea863f2a90fa266a247}
      \strng{fullhash}{aa6bb3b2b5a8e821b6e99f37d5de0376}
      \strng{bibnamehash}{9beb7313dee5fea863f2a90fa266a247}
      \strng{authorbibnamehash}{9beb7313dee5fea863f2a90fa266a247}
      \strng{authornamehash}{9beb7313dee5fea863f2a90fa266a247}
      \strng{authorfullhash}{aa6bb3b2b5a8e821b6e99f37d5de0376}
      \field{sortinit}{1}
      \field{sortinithash}{4f6aaa89bab872aa0999fec09ff8e98a}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{In this paper, we introduce Random Erasing, a new data augmentation method for training the convolutional neural network (CNN). In training, Random Erasing randomly selects a rectangle region in an image and erases its pixels with random values. In this process, training images with various levels of occlusion are generated, which reduces the risk of over-fitting and makes the model robust to occlusion. Random Erasing is parameter learning free, easy to implement, and can be integrated with most of the CNN-based recognition models. Albeit simple, Random Erasing is complementary to commonly used data augmentation techniques such as random cropping and flipping, and yields consistent improvement over strong baselines in image classification, object detection and person re-identification. Code is available at: https://github.com/zhunzhong07/Random-Erasing.}
      \field{day}{3}
      \field{issn}{2374-3468, 2159-5399}
      \field{journaltitle}{Proceedings of the AAAI Conference on Artificial Intelligence}
      \field{langid}{english}
      \field{month}{4}
      \field{number}{07}
      \field{shortjournal}{AAAI}
      \field{title}{Random {{Erasing Data Augmentation}}}
      \field{urlday}{21}
      \field{urlmonth}{10}
      \field{urlyear}{2022}
      \field{volume}{34}
      \field{year}{2020}
      \field{dateera}{ce}
      \field{urldateera}{ce}
      \field{pages}{13001\bibrangedash 13008}
      \range{pages}{8}
      \verb{doi}
      \verb 10.1609/aaai.v34i07.7000
      \endverb
      \verb{file}
      \verb /Users/eragon/Zotero/storage/H2HNNUFX/Zhong et al. - 2020 - Random Erasing Data Augmentation.pdf
      \endverb
      \verb{urlraw}
      \verb https://aaai.org/ojs/index.php/AAAI/article/view/7000
      \endverb
      \verb{url}
      \verb https://aaai.org/ojs/index.php/AAAI/article/view/7000
      \endverb
    \endentry
    \entry{qinResizeMixMixingData2020}{online}{}
      \name{author}{6}{}{%
        {{hash=2f85a6ceba865d9250bcbbc35cf70c03}{%
           family={Qin},
           familyi={Q\bibinitperiod},
           given={Jie},
           giveni={J\bibinitperiod}}}%
        {{hash=ec5ce127932e919a209dd5a9db85cee9}{%
           family={Fang},
           familyi={F\bibinitperiod},
           given={Jiemin},
           giveni={J\bibinitperiod}}}%
        {{hash=ab5652acf0de64074be2a35319b7c36a}{%
           family={Zhang},
           familyi={Z\bibinitperiod},
           given={Qian},
           giveni={Q\bibinitperiod}}}%
        {{hash=d2354226a305a694e082d0c47c299a00}{%
           family={Liu},
           familyi={L\bibinitperiod},
           given={Wenyu},
           giveni={W\bibinitperiod}}}%
        {{hash=13f130cc9092f464777eeb08a8dd109a}{%
           family={Wang},
           familyi={W\bibinitperiod},
           given={Xingang},
           giveni={X\bibinitperiod}}}%
        {{hash=1bd616b774bd66d7d77e025ac08c962d}{%
           family={Wang},
           familyi={W\bibinitperiod},
           given={Xinggang},
           giveni={X\bibinitperiod}}}%
      }
      \strng{namehash}{169327b45088329d25efe8084931ee2a}
      \strng{fullhash}{28c91cef478881ce99b3a236e6b501ef}
      \strng{bibnamehash}{169327b45088329d25efe8084931ee2a}
      \strng{authorbibnamehash}{169327b45088329d25efe8084931ee2a}
      \strng{authornamehash}{169327b45088329d25efe8084931ee2a}
      \strng{authorfullhash}{28c91cef478881ce99b3a236e6b501ef}
      \field{sortinit}{1}
      \field{sortinithash}{4f6aaa89bab872aa0999fec09ff8e98a}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{shorttitle}
      \field{abstract}{Data augmentation is a powerful technique to increase the diversity of data, which can effectively improve the generalization ability of neural networks in image recognition tasks. Recent data mixing based augmentation strategies have achieved great success. Especially, CutMix uses a simple but effective method to improve the classifiers by randomly cropping a patch from one image and pasting it on another image. To further promote the performance of CutMix, a series of works explore to use the saliency information of the image to guide the mixing. We systematically study the importance of the saliency information for mixing data, and find that the saliency information is not so necessary for promoting the augmentation performance. Furthermore, we find that the cutting based data mixing methods carry two problems of label misallocation and object information missing, which cannot be resolved simultaneously. We propose a more effective but very easily implemented method, namely ResizeMix. We mix the data by directly resizing the source image to a small patch and paste it on another image. The obtained patch preserves more substantial object information compared with conventional cut-based methods. ResizeMix shows evident advantages over CutMix and the saliency-guided methods on both image classification and object detection tasks without additional computation cost, which even outperforms most costly search-based automatic augmentation methods.}
      \field{day}{20}
      \field{eprinttype}{arxiv}
      \field{month}{12}
      \field{number}{arXiv:2012.11101}
      \field{pubstate}{preprint}
      \field{shorttitle}{{{ResizeMix}}}
      \field{title}{{{ResizeMix}}: {{Mixing Data}} with {{Preserved Object Information}} and {{True Labels}}}
      \field{urlday}{29}
      \field{urlmonth}{3}
      \field{urlyear}{2023}
      \field{year}{2020}
      \field{dateera}{ce}
      \field{urldateera}{ce}
      \verb{eprint}
      \verb arXiv:2012.11101
      \endverb
      \verb{file}
      \verb /Users/eragon/Zotero/storage/N5QGSZ8V/Qin et al. - 2020 - ResizeMix Mixing Data with Preserved Object Infor.pdf
      \endverb
      \verb{urlraw}
      \verb http://arxiv.org/abs/2012.11101
      \endverb
      \verb{url}
      \verb http://arxiv.org/abs/2012.11101
      \endverb
      \keyw{Computer Science - Computer Vision and Pattern Recognition}
    \endentry
    \entry{takahashiDataAugmentationUsing2020}{article}{}
      \name{author}{3}{}{%
        {{hash=f05c6141445ed7d02b15871c9e06e6e3}{%
           family={Takahashi},
           familyi={T\bibinitperiod},
           given={Ryo},
           giveni={R\bibinitperiod}}}%
        {{hash=5e274388763fb2deb9f78659d85341b3}{%
           family={Matsubara},
           familyi={M\bibinitperiod},
           given={Takashi},
           giveni={T\bibinitperiod}}}%
        {{hash=6a5f8c6a5957757638ac13cdd32d69a9}{%
           family={Uehara},
           familyi={U\bibinitperiod},
           given={Kuniaki},
           giveni={K\bibinitperiod}}}%
      }
      \strng{namehash}{ffff3952df718cca7646b3c73ad5598b}
      \strng{fullhash}{ffff3952df718cca7646b3c73ad5598b}
      \strng{bibnamehash}{ffff3952df718cca7646b3c73ad5598b}
      \strng{authorbibnamehash}{ffff3952df718cca7646b3c73ad5598b}
      \strng{authornamehash}{ffff3952df718cca7646b3c73ad5598b}
      \strng{authorfullhash}{ffff3952df718cca7646b3c73ad5598b}
      \field{sortinit}{1}
      \field{sortinithash}{4f6aaa89bab872aa0999fec09ff8e98a}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Deep convolutional neural networks (CNNs) have achieved remarkable results in image processing tasks. However, their high expression ability risks overfitting. Consequently, data augmentation techniques have been proposed to prevent overfitting while enriching datasets. Recent CNN architectures with more parameters are rendering traditional data augmentation techniques insufficient. In this study, we propose a new data augmentation technique called random image cropping and patching (RICAP) which randomly crops four images and patches them to create a new training image. Moreover, RICAP mixes the class labels of the four images, resulting in an advantage similar to label smoothing. We evaluated RICAP with current state-of-the-art CNNs (e.g., the shake-shake regularization model) by comparison with competitive data augmentation techniques such as cutout and mixup. RICAP achieves a new state-of-the-art test error of \$2.19\textbackslash\%\$ on CIFAR-10. We also confirmed that deep CNNs with RICAP achieve better results on classification tasks using CIFAR-100 and ImageNet and an image-caption retrieval task using Microsoft COCO.}
      \field{eprintclass}{cs}
      \field{eprinttype}{arxiv}
      \field{issn}{1051-8215, 1558-2205}
      \field{journaltitle}{IEEE Transactions on Circuits and Systems for Video Technology}
      \field{month}{9}
      \field{number}{9}
      \field{shortjournal}{IEEE Trans. Circuits Syst. Video Technol.}
      \field{title}{Data {{Augmentation}} Using {{Random Image Cropping}} and {{Patching}} for {{Deep CNNs}}}
      \field{urlday}{30}
      \field{urlmonth}{3}
      \field{urlyear}{2023}
      \field{volume}{30}
      \field{year}{2020}
      \field{dateera}{ce}
      \field{urldateera}{ce}
      \field{pages}{2917\bibrangedash 2931}
      \range{pages}{15}
      \verb{doi}
      \verb 10.1109/TCSVT.2019.2935128
      \endverb
      \verb{eprint}
      \verb 1811.09030
      \endverb
      \verb{file}
      \verb /Users/eragon/Zotero/storage/7KUF8FPR/Takahashi et al. - 2020 - Data Augmentation using Random Image Cropping and .pdf
      \endverb
      \verb{urlraw}
      \verb http://arxiv.org/abs/1811.09030
      \endverb
      \verb{url}
      \verb http://arxiv.org/abs/1811.09030
      \endverb
      \keyw{Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning}
    \endentry
    \entry{leeSmoothMixSimpleEffective2020}{inproceedings}{}
      \name{author}{4}{}{%
        {{hash=74942925cc41da237a6f1e3f96e7fe73}{%
           family={Lee},
           familyi={L\bibinitperiod},
           given={Jin-Ha},
           giveni={J\bibinithyphendelim H\bibinitperiod}}}%
        {{hash=e65ffa98cfbc6a6d0bd1f23087127c07}{%
           family={Zaheer},
           familyi={Z\bibinitperiod},
           given={Muhammad\bibnamedelima Zaigham},
           giveni={M\bibinitperiod\bibinitdelim Z\bibinitperiod}}}%
        {{hash=4299e3908c725302f1396772e340ec52}{%
           family={Astrid},
           familyi={A\bibinitperiod},
           given={Marcella},
           giveni={M\bibinitperiod}}}%
        {{hash=237c15c3e7acfc462bac679db005df14}{%
           family={Lee},
           familyi={L\bibinitperiod},
           given={Seung-Ik},
           giveni={S\bibinithyphendelim I\bibinitperiod}}}%
      }
      \strng{namehash}{ac5e19c431c58d7e2dbde925331b84c0}
      \strng{fullhash}{ce6f8a8c1b1594913f70613e828002b5}
      \strng{bibnamehash}{ac5e19c431c58d7e2dbde925331b84c0}
      \strng{authorbibnamehash}{ac5e19c431c58d7e2dbde925331b84c0}
      \strng{authornamehash}{ac5e19c431c58d7e2dbde925331b84c0}
      \strng{authorfullhash}{ce6f8a8c1b1594913f70613e828002b5}
      \field{sortinit}{1}
      \field{sortinithash}{4f6aaa89bab872aa0999fec09ff8e98a}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{shorttitle}
      \field{eventtitle}{Proceedings of the {{IEEE}}/{{CVF Conference}} on {{Computer Vision}} and {{Pattern Recognition Workshops}}}
      \field{shorttitle}{{{SmoothMix}}}
      \field{title}{{{SmoothMix}}: {{A Simple Yet Effective Data Augmentation}} to {{Train Robust Classifiers}}}
      \field{urlday}{29}
      \field{urlmonth}{3}
      \field{urlyear}{2023}
      \field{year}{2020}
      \field{dateera}{ce}
      \field{urldateera}{ce}
      \field{pages}{756\bibrangedash 757}
      \range{pages}{2}
      \verb{file}
      \verb /Users/eragon/Zotero/storage/UAHLZ9ZT/Lee et al. - 2020 - SmoothMix A Simple Yet Effective Data Augmentatio.pdf
      \endverb
      \verb{urlraw}
      \verb https://openaccess.thecvf.com/content_CVPRW_2020/html/w45/Lee_SmoothMix_A_Simple_Yet_Effective_Data_Augmentation_to_Train_Robust_CVPRW_2020_paper.html
      \endverb
      \verb{url}
      \verb https://openaccess.thecvf.com/content_CVPRW_2020/html/w45/Lee_SmoothMix_A_Simple_Yet_Effective_Data_Augmentation_to_Train_Robust_CVPRW_2020_paper.html
      \endverb
    \endentry
  \enddatalist
\endrefsection
\endinput

