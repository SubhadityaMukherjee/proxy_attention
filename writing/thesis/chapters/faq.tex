\chapter{Frequently Asked Questions} \label{ch:faq}

\section{Data Augmentation}
\begin{itemize}
    \item \textbf{Why not provide annotations and object position? }Datasets that contain annotations and positions are not easy to compile. For custom tasks, it is quite difficult to obtain such datasets. That being the case, Proxy Attention is a good alternative as it does not require any extra information.

    \item \textbf{Why not apply it every epoch like augmentation? } Applying Proxy Attention every epoch comes with certain caveats. Since gradient maps are being computed for multiple images, this process is slightly more computationally expensive than standard training. Doing so might also lead to overfitting as the network is given too much feedback. Since Proxy Attention relies on the model's predictions, giving the network time to learn is a good idea.

    \item \textbf{Isn't it the same as giving more images to the model? } This is somewhat true. Proxy Attention provides similar benefits to augmentation but with more specific information. In the models tested, an equal number of images were given to each model. Models trained with Proxy Attention and those trained without it received the same number of images. For example, if the modified image was present, the original image was not passed to the network to maintain fairness.
\end{itemize}

\section{Other Domains}
\begin{itemize}
\item Why is it not SSL?
\item Why not use distillation?
\end{itemize}

\section{Model Architecture and Attention Modules}
\begin{itemize}
    \item \textbf{Why not just use a Transformer? }The use of Transformers was indeed tested, but they are more computationally expensive and not as easy to train as Convolutional Neural Networks (CNNs). The objective of the study was to explore whether the effects of the attention module could be approximated using gradient-based techniques. As a side note though, Proxy Attention, which also works with Transformers and also seems to improve the results of the model.
    \item \textbf{Why not modify the network architecture to include attention modules? }Proxy Attention was developed as a general technique that can be applied to any network architecture, not limited to CNNs. Many of the surveyed papers required specialized architectures, which can be counterintuitive and not always feasible to implement. Thus, Proxy Attention offers a more versatile approach for improving performance by only modifying the training process.
\end{itemize}

\section{Gradient Based Techniques}
\begin{itemize}
    \item \textbf{Why use a different gradient-based technique for the results?} To ensure fairness in the evaluation process, it is important to use a different gradient-based technique for the results. Neural networks excel at approximating transformations, so if the same technique is used for both training and evaluation, the network may end up learning to approximate the technique itself instead of learning where to look, which would defeat the whole point of Proxy Attention. Testing with a different technique ensures a fair comparison and avoids bias in the evaluation.

    \item \textbf{Combining gradient-based techniques with training is a bad idea, right?} This study was conducted specifically to investigate the feasibility of combining gradient-based techniques with training. While further rigorous testing is necessary to gain a deeper understanding of why and to what extent this approach works, our findings indicate that it is a promising starting point. Combining gradient-based techniques with training can lead to improved performance, but more research is needed to fully comprehend the underlying mechanisms and limitations of this approach.
\end{itemize}

\section{Hyperparameters}
\begin{itemize}
    \item \textbf{Why so many hyperparameters?} Since Proxy Attention is a novel technique, it necessitated testing multiple hyperparameters to determine which ones yield the best results. The extensive exploration of hyperparameters enabled the author to narrow down the search space for future experiments and focus only on the most effective ones. Varying the hyperparameters also allowed the author to examine the impact of different components of the pipeline, leading to a better understanding of the overall effects of using Proxy Attention.

    \item \textbf{The hyperparameters do not seem to be very sensitive, why?} In certain datasets, the hyperparameters may not exhibit significant effects. This could be attributed to the network already performing well enough on those datasets, rendering the hyperparameter variations less impactful. While there are theoretical expectations of certain effects, such as faster convergence, the practical results may not always demonstrate a substantial improvement in our studies. But although the effects may not be pronounced, they still contribute to enhancing the overall results to a certain degree. If nothing else, they do not seem to have a negative impact on the results, so they are still worth exploring.
\end{itemize}

\section{Stability and Training Effects}
\begin{itemize}
    \item \textbf{Will this destabilize training?} Some predictions that were previously classified correctly may become incorrect when using Proxy Attention. It is also to be noted that this does not seem to occur too frequently, so it is not a major concern. While this phenomenon does not appear to destabilize the training process, it does make the network more sensitive to applying Proxy Attention too frequently. The results indicate that applying Proxy Attention improves performance regardless, but it is not recommended to apply it every epoch. 

    \item \textbf{In later iterations, what happens if a correctly predicted image is wrongly classified?} Since the images generated through Proxy Attention are not persistent, the network should be capable of recovering from such misclassifications. In the worst-case scenario, the network will be trained on a slightly modified image, which is not necessarily detrimental. Moreover, the network has previously encountered the original image, so it should be able to learn a better representation of the image through subsequent iterations.

\end{itemize}
