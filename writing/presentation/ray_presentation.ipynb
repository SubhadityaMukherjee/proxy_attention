{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to use Ray?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ray import tune\n",
    "import ray\n",
    "from ray.tune import CLIReporter\n",
    "from ray.tune.schedulers import ASHAScheduler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"experiment_name\": \"test_asl_starter\",\n",
    "    \"ds_path\": Path(\"/mnt/e/Datasets/asl/asl_alphabet_train/asl_alphabet_train\"),\n",
    "    \"ds_name\": \"asl\",\n",
    "    \"name_fn\": proxyattention.data_utils.asl_name_fn,\n",
    "    \"image_size\": 224,\n",
    "    \"batch_size\": 64,\n",
    "    \"epoch_steps\": [1, 2],\n",
    "    \"enable_proxy_attention\": True,\n",
    "    \"change_subset_attention\": tune.loguniform(0.1, 0.8),\n",
    "    \"validation_split\": 0.3,\n",
    "    \"shuffle_dataset\": tune.choice([True, False]),\n",
    "    \"num_gpu\": 1,\n",
    "    \"transfer_imagenet\": False,\n",
    "    \"subset_images\": 8000,\n",
    "    \"proxy_threshold\": tune.loguniform(0.008, 0.01),\n",
    "    \"pixel_replacement_method\": tune.choice([\"mean\", \"max\", \"min\", \"black\", \"white\"]),\n",
    "    \"model\": \"resnet18\",\n",
    "    # \"proxy_steps\": tune.choice([[1, \"p\", 1], [3, \"p\", 1], [1, 1], [3,1]]),\n",
    "    # \"proxy_steps\": tune.choice([[\"p\", 1],[1, 1], [\"p\",1], [1, \"p\",1], [1,1,1]]),\n",
    "    \"proxy_steps\": tune.choice([[\"p\",3]]),\n",
    "    \"load_proxy_data\": False,\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(\n",
    "    model,\n",
    "    criterion,\n",
    "    optimizer,\n",
    "    scheduler,\n",
    "    dataloaders,\n",
    "    dataset_sizes,\n",
    "    num_epochs=25,\n",
    "    proxy_step=False,\n",
    "    config=None,\n",
    "):\n",
    "    writer = SummaryWriter(log_dir=config[\"fname_start\"], comment=config[\"fname_start\"])\n",
    "    since = time.time()\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "    pbar = tqdm(range(num_epochs), total=num_epochs)\n",
    "    for epoch in pbar:\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in [\"train\", \"val\"]:\n",
    "            if phase == \"train\":\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()  # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            # Iterate over data.\n",
    "\n",
    "            optimizer.zero_grad(set_to_none=True)\n",
    "            scaler = torch.cuda.amp.GradScaler()\n",
    "            for inps in tqdm(\n",
    "                dataloaders[phase], total=len(dataloaders[phase]), leave=False\n",
    "            ):\n",
    "                inputs = inps[\"x\"].to(config[\"device\"], non_blocking=True)\n",
    "                labels = inps[\"y\"].to(config[\"device\"], non_blocking=True)\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == \"train\"):\n",
    "                    with torch.cuda.amp.autocast():\n",
    "                        if phase == \"train\":\n",
    "                            outputs = model(inputs)\n",
    "                        else:\n",
    "                            with torch.no_grad():\n",
    "                                outputs = model(inputs)\n",
    "                        _, preds = torch.max(outputs, 1)\n",
    "                        loss = criterion(outputs, labels)\n",
    "        \n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == \"train\":\n",
    "                        scaler.scale(loss).backward()\n",
    "                        # optimizer.step()\n",
    "\n",
    "                        scaler.step(optimizer)\n",
    "                        scaler.update()\n",
    "                        optimizer.zero_grad(set_to_none=True)\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "                pbar.set_postfix(\n",
    "                    {\n",
    "                        \"Phase\": \"running\",\n",
    "                        \"Loss\": running_loss / dataset_sizes[phase],\n",
    "                        # 'Acc' : running_corrects.double() / dataset_sizes[phase],\n",
    "                    }\n",
    "                )\n",
    "\n",
    "            if phase == \"train\":\n",
    "                scheduler.step()\n",
    "\n",
    "            # --------------------------------------------------------------\n",
    "            # --------------------------------------------------------------\n",
    "            # --------------------------------------------------------------\n",
    "            # --------------------------------------------------------------\n",
    "            # --------------------------------------------------------------\n",
    "            # --------------------------------------------------------------\n",
    "\n",
    "            for ind in tqdm(range(len(label_wrong)), total=len(label_wrong)):\n",
    "                    # original_images[ind][grad_thresholds[ind]] = pixel_replacement[ind]\n",
    "                    # TODO Split these into individual comprehensions for speed\n",
    "                    # TODO Check if % of image is gone or not\n",
    "                    original_images[ind][\n",
    "                        grads[ind].mean(axis=2) > config[\"proxy_threshold\"]\n",
    "                    ] = decide_pixel_replacement(\n",
    "                        original_image=original_images[ind],\n",
    "                        method=config[\"pixel_replacement_method\"],\n",
    "                    )\n",
    "\n",
    "\n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
    "\n",
    "            pbar.set_postfix({\"Phase\": phase, \"Loss\": epoch_loss, \"Acc\": epoch_acc})\n",
    "\n",
    "            # TODO Add more loss functions\n",
    "            # TODO Classwise accuracy\n",
    "            if proxy_step == True:\n",
    "                writer.add_scalar(\"proxy_step\", True)\n",
    "            else:\n",
    "                writer.add_scalar(\"proxy_step\", False)\n",
    "\n",
    "            if phase == \"train\":\n",
    "                writer.add_scalar(\"Loss/Train\", epoch_loss, epoch)\n",
    "                writer.add_scalar(\"Acc/Train\", epoch_acc, epoch)\n",
    "            if phase == \"val\":\n",
    "                writer.add_scalar(\"Loss/Val\", epoch_loss, epoch)\n",
    "                writer.add_scalar(\"Acc/Val\", epoch_acc, epoch)\n",
    "                with tune.checkpoint_dir(epoch) as checkpoint_dir:\n",
    "                    save_path = Path(config[\"fname_start\"]) / \"checkpoint\"\n",
    "                    torch.save((model.state_dict(), optimizer.state_dict()), save_path)\n",
    "\n",
    "                tune.report(loss=epoch_loss, accuracy=epoch_acc)\n",
    "\n",
    "            # deep copy the model\n",
    "            if phase == \"val\" and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "        # print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print(f\"Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s\")\n",
    "    print(f\"Best val Acc: {best_acc:4f}\")\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_train_round(config, proxy_step=False, num_epochs=1):\n",
    "    # Data part\n",
    "    #TODO Configure data for proxy attention\n",
    "    train, val = create_folds(config)\n",
    "    image_datasets, dataloaders, dataset_sizes = create_dls(\n",
    "        train, val, config\n",
    "    )\n",
    "    class_names = image_datasets[\"train\"].classes\n",
    "    config[\"num_classes\"] = len(config[\"label_map\"].keys())\n",
    "\n",
    "    model_ft = choose_network(config)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    # Observe that all parameters are being optimized\n",
    "    optimizer_ft = optim.Adam(model_ft.parameters(), lr=3e-4)\n",
    "\n",
    "    # Decay LR by a factor of 0.1 every 7 epochs\n",
    "    exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)\n",
    "    trained_model = train_model(\n",
    "        model_ft,\n",
    "        criterion,\n",
    "        optimizer_ft,\n",
    "        exp_lr_scheduler,\n",
    "        dataloaders,\n",
    "        dataset_sizes,\n",
    "        num_epochs=num_epochs,\n",
    "        config=config,\n",
    "        proxy_step=proxy_step,\n",
    "    )\n",
    "\n",
    "\n",
    "def train_proxy_steps(config):\n",
    "    assert torch.cuda.is_available()\n",
    "    for step in config[\"proxy_steps\"]:\n",
    "        if step == \"p\":\n",
    "            setup_train_round(config=config, proxy_step=True, num_epochs=1)\n",
    "            config[\"load_proxy_data\"] = True\n",
    "        else:\n",
    "            setup_train_round(config=config, proxy_step=False, num_epochs=step)\n",
    "            config[\"load_proxy_data\"] = False\n",
    "\n",
    "def tune_func(config):\n",
    "    # tune.utils.wait_for_gpu(target_util = .1)\n",
    "    train_proxy_steps(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hyperparam_tune(config):\n",
    "    ray.init(num_gpus=1, num_cpus=12)\n",
    "    scheduler = ASHAScheduler(\n",
    "        metric=\"loss\", mode=\"min\", max_t=30, grace_period=1, reduction_factor=2,\n",
    "    )\n",
    "\n",
    "    reporter = CLIReporter(metric_columns=[\"loss\", \"accuracy\", \"training_iteration\"])\n",
    "\n",
    "    result = tune.run(\n",
    "        tune_func,\n",
    "        config=config,\n",
    "        scheduler=scheduler,\n",
    "        progress_reporter=reporter,\n",
    "        checkpoint_at_end=True,\n",
    "        max_failures=100,\n",
    "        num_samples=50,\n",
    "        resources_per_trial={\n",
    "            \"gpu\": 1,\n",
    "            \"cpu\": 8,\n",
    "        },\n",
    "        local_dir=config[\"fname_start\"],\n",
    "    )\n",
    "\n",
    "    df_res = result.get_dataframe()\n",
    "    df_res.to_csv(Path(config[\"fname_start\"]) / \"result_log.csv\")\n",
    "    best_trial = result.get_best_trial(\"loss\", \"min\", \"last\")\n",
    "    print(\"Best trial config: {}\".format(best_trial.config))\n",
    "    print(\"Best trial final validation loss: {}\".format(best_trial.last_result[\"loss\"]))\n",
    "    print(\n",
    "        \"Best trial final validation accuracy: {}\".format(\n",
    "            best_trial.last_result[\"accuracy\"]\n",
    "        )\n",
    "    )\n",
    "\n",
    "    print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.8 | packaged by conda-forge | (main, Nov 22 2022, 08:26:04) [GCC 10.4.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8d42e2b5231cfb8d38e0ae547be343c5f08198e6fdc5845a955873ed22cf5709"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
