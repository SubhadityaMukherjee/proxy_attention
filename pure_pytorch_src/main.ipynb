{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sources\n",
    "- https://pytorch.org/tutorials/beginner/transfer_learning_tutorial.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import torch.backends.cudnn as cudnn\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "from tqdm import tqdm\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import glob\n",
    "import mimetypes\n",
    "import itertools\n",
    "from typing import Iterable,Generator,Sequence,Iterator,List,Set,Dict,Union,Optional,Tuple\n",
    "import meta_utils\n",
    "import pandas as pd\n",
    "from sklearn import metrics, model_selection, preprocessing\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import Dataset, TensorDataset, DataLoader\n",
    "import albumentations as A\n",
    "from albumentations.core.composition import Compose\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import cv2\n",
    "\n",
    "sns.set()\n",
    "\n",
    "os.environ[\"TORCH_HOME\"] = \"/media/hdd/Datasets/\"\n",
    "cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def fish_name_fn(x): return str(x).split(\"/\")[-2]\n",
    "def asl_name_fn(x): return str(x).split(\"/\")[-2]\n",
    "\n",
    "ds_path = Path(\"/media/hdd/Datasets/asl/\")\n",
    "ds_name = \"asl\"\n",
    "name_fn = asl_name_fn\n",
    "image_size = 224\n",
    "batch_size = 128\n",
    "pretrained = True\n",
    "epoch_steps = [1,2]\n",
    "enable_proxy_attention = True\n",
    "change_subset_attention = 0.01\n",
    "validation_split = 0.3\n",
    "shuffle_dataset = True\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transforms = {\n",
    "    'train':  A.Compose(\n",
    "        [\n",
    "            A.RandomResizedCrop(image_size, image_size, p=1.0),\n",
    "            A.Normalize(\n",
    "                mean=[0.485, 0.456, 0.406],\n",
    "                std=[0.229, 0.224, 0.225],\n",
    "                max_pixel_value=255.0,\n",
    "                p=1.0,\n",
    "            ),\n",
    "            ToTensorV2(p=1.0),\n",
    "        ],\n",
    "        p=1.0,\n",
    "    ),\n",
    "    'val': A.Compose([\n",
    "        A.CenterCrop(image_size, image_size, p=1.0),\n",
    "        A.Resize(image_size, image_size),\n",
    "        A.Normalize(\n",
    "            mean=[0.485, 0.456, 0.406],\n",
    "            std=[0.229, 0.224, 0.225],\n",
    "            max_pixel_value=255.0,\n",
    "            p=1.0,\n",
    "        ),\n",
    "        ToTensorV2(p=1.0),\n",
    "    ],\n",
    "        p=1.0,\n",
    "    )\n",
    "\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all image files\n",
    "all_files = meta_utils.get_files(ds_path/\"train\")\n",
    "\n",
    "# Put them in a data frame for encoding\n",
    "df = pd.DataFrame.from_dict(\n",
    "    {x: name_fn(x) for x in all_files}, orient=\"index\"\n",
    ").reset_index()\n",
    "df.columns = [\"image_id\", \"label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df[\"label\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert labels to integers\n",
    "temp = preprocessing.LabelEncoder()\n",
    "df[\"label\"] = temp.fit_transform(df.label.values)\n",
    "\n",
    "# Save label map\n",
    "label_map = {i: l for i, l in enumerate(temp.classes_)}\n",
    "\n",
    "# Kfold splits\n",
    "df[\"kfold\"] = -1\n",
    "df = df.sample(frac=1).reset_index(drop=True)\n",
    "stratify = StratifiedKFold(n_splits=2)\n",
    "for i, (t_idx, v_idx) in enumerate(\n",
    "    stratify.split(X=df.image_id.values, y=df.label.values)\n",
    "):\n",
    "    df.loc[v_idx, \"kfold\"] = i\n",
    "df.to_csv(\"train_folds.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageClassDs(Dataset):\n",
    "    def __init__(\n",
    "        self, df: pd.DataFrame, imfolder: str, train: bool = True, transforms=None\n",
    "    ):\n",
    "        self.df = df\n",
    "        self.imfolder = imfolder\n",
    "        self.train = train\n",
    "        self.transforms = transforms\n",
    "        self.classes = self.df[\"label\"]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        im_path = self.df.iloc[index][\"image_id\"]\n",
    "        x = cv2.imread(str(im_path), cv2.IMREAD_COLOR)\n",
    "        x = cv2.cvtColor(x, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        if self.transforms:\n",
    "            x = self.transforms(image=x)[\"image\"]\n",
    "\n",
    "        y = self.df.iloc[index][\"label\"]\n",
    "        return {\n",
    "            \"x\": x,\n",
    "            \"y\": y,\n",
    "        }\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = df.loc[df[\"kfold\"] != 1]\n",
    "val = df.loc[df[\"kfold\"] == 1]\n",
    "image_datasets = {\n",
    "    \"train\": ImageClassDs(train, ds_path, train=True, transforms=data_transforms[\"train\"]),\n",
    "\n",
    "    \"val\": ImageClassDs(val, ds_path, train=False, transforms=data_transforms[\"val\"]),\n",
    "}\n",
    "\n",
    "dataloaders = {\n",
    "    \"train\": torch.utils.data.DataLoader(\n",
    "        image_datasets[\"train\"],\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True, num_workers=12),\n",
    "        \n",
    "    \"val\": torch.utils.data.DataLoader(\n",
    "        image_datasets[\"val\"],\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False, num_workers=12),\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}\n",
    "class_names = image_datasets['train'].classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, scheduler, num_epochs=25):\n",
    "    since = time.time()\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "    pbar = tqdm(range(num_epochs), total=num_epochs)\n",
    "    for epoch in pbar:\n",
    "        # print(f'Epoch {epoch}/{num_epochs - 1}')\n",
    "        # print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            # Iterate over data.\n",
    "            for inps in dataloaders[phase]:\n",
    "                inputs = inps['x'].to(device)\n",
    "                labels = inps['y'].to(device)\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "            if phase == 'train':\n",
    "                scheduler.step()\n",
    "\n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
    "\n",
    "            # print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
    "            pbar.set_postfix({\n",
    "                'Phase' : phase,\n",
    "                'Loss' : epoch_loss,\n",
    "                'Acc' : epoch_acc\n",
    "            })\n",
    "\n",
    "            # deep copy the model\n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print(f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')\n",
    "    print(f'Best val Acc: {best_acc:4f}')\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = len(label_map.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ft = models.resnet18(weights=models.ResNet18_Weights.IMAGENET1K_V1)\n",
    "num_ftrs = model_ft.fc.in_features\n",
    "# Here the size of each output sample is set to 2.\n",
    "# Alternatively, it can be generalized to nn.Linear(num_ftrs, len(class_names)).\n",
    "model_ft.fc = nn.Linear(num_ftrs, num_classes)\n",
    "\n",
    "model_ft = model_ft.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer_ft = optim.SGD(model_ft.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/25 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "model_ft = train_model(model_ft, criterion, optimizer_ft,\n",
    "                       exp_lr_scheduler, num_epochs=25)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "db63ec5837ed7153ffcff7a5d42bf80536894c2cc03a9bb032bbe91b2078875e"
  },
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit ('pytorcher')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
