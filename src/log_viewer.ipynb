{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from tensorboard.backend.event_processing.event_accumulator import EventAccumulator\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import clipboard\n",
    "import base64\n",
    "from io import BytesIO\n",
    "from PIL import Image\n",
    "from proxyattention.meta_utils import read_pickle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0%|                                                    | 0/29 [00:00<?, ?it/s]runs/baseline_run_26032023_124800/events.out.tfevents.1679827680.eragon\n",
      "\u001b[33m\u001b[2mSource path:... \u001b[22m/run/media/eragon/HDD/CODE/Github/improving_robotics_datasets/src/result_aggregator.py\u001b[0m\n",
      "\u001b[32m\u001b[2mStarting var:.. \u001b[22mevent_acc = <tensorboard.backend.event_processing.event_accumulator.EventAccumulator object at 0x7f5b568ed5d0>\u001b[0m\n",
      "\u001b[32m\u001b[2mStarting var:.. \u001b[22msave_ims = False\u001b[0m\n",
      "\u001b[2m01:08:42.927999 call        42\u001b[0m def process_event_acc(event_acc, save_ims = False):\n",
      "\u001b[2m01:08:42.928257 line        44\u001b[0m     all_tags = event_acc.Tags()\n",
      "\u001b[32m\u001b[2mNew var:....... \u001b[22mall_tags = {'images': [], 'audio': [], 'histograms': [], 's...: False, 'meta_graph': False, 'run_metadata': []}\u001b[0m\n",
      "\u001b[2m01:08:42.928304 line        45\u001b[0m     temp_dict = {}\n",
      "\u001b[32m\u001b[2mNew var:....... \u001b[22mtemp_dict = {}\u001b[0m\n",
      "\u001b[2m01:08:42.928355 line        46\u001b[0m     for tag in all_tags.keys():\n",
      "\u001b[32m\u001b[2mNew var:....... \u001b[22mtag = 'images'\u001b[0m\n",
      "\u001b[2m01:08:42.928395 line        47\u001b[0m         if tag == \"scalars\":\n",
      "\u001b[2m01:08:42.928432 line        59\u001b[0m         if tag == \"tensors\":\n",
      "\u001b[2m01:08:42.928464 line        85\u001b[0m         if tag == \"images\" and save_ims == True:\n",
      "\u001b[2m01:08:42.928494 line        46\u001b[0m     for tag in all_tags.keys():\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtag = 'audio'\u001b[0m\n",
      "\u001b[2m01:08:42.928524 line        47\u001b[0m         if tag == \"scalars\":\n",
      "\u001b[2m01:08:42.928556 line        59\u001b[0m         if tag == \"tensors\":\n",
      "\u001b[2m01:08:42.928584 line        85\u001b[0m         if tag == \"images\" and save_ims == True:\n",
      "\u001b[2m01:08:42.928612 line        46\u001b[0m     for tag in all_tags.keys():\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtag = 'histograms'\u001b[0m\n",
      "\u001b[2m01:08:42.928640 line        47\u001b[0m         if tag == \"scalars\":\n",
      "\u001b[2m01:08:42.928674 line        59\u001b[0m         if tag == \"tensors\":\n",
      "\u001b[2m01:08:42.928702 line        85\u001b[0m         if tag == \"images\" and save_ims == True:\n",
      "\u001b[2m01:08:42.928730 line        46\u001b[0m     for tag in all_tags.keys():\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtag = 'scalars'\u001b[0m\n",
      "\u001b[2m01:08:42.928757 line        47\u001b[0m         if tag == \"scalars\":\n",
      "\u001b[2m01:08:42.928789 line        48\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mNew var:....... \u001b[22msubtag = 'proxy_step'\u001b[0m\n",
      "\u001b[2m01:08:42.928817 line        50\u001b[0m                 try:\n",
      "\u001b[2m01:08:42.928852 line        51\u001b[0m                     temp_dict[subtag] = [tag[-1] for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:42.928919 exception   51\u001b[0m                     temp_dict[subtag] = [tag[-1] for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[31mException:..... \u001b[1mTypeError: 'ScalarEvent' object is not subscriptable\u001b[0m\n",
      "\u001b[2m01:08:42.928994 line        54\u001b[0m                 except:\n",
      "\u001b[2m01:08:42.929030 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:42.929071 line        56\u001b[0m                     -1\n",
      "\u001b[2m01:08:42.929105 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:42.929136 line        57\u001b[0m                 ].value\n",
      "\u001b[2m01:08:42.929165 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0}\u001b[0m\n",
      "\u001b[2m01:08:42.929196 line        48\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'Loss/Train'\u001b[0m\n",
      "\u001b[2m01:08:42.929232 line        50\u001b[0m                 try:\n",
      "\u001b[2m01:08:42.929267 line        51\u001b[0m                     temp_dict[subtag] = [tag[-1] for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:42.929313 exception   51\u001b[0m                     temp_dict[subtag] = [tag[-1] for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[31mException:..... \u001b[1mTypeError: 'ScalarEvent' object is not subscriptable\u001b[0m\n",
      "\u001b[2m01:08:42.929388 line        54\u001b[0m                 except:\n",
      "\u001b[2m01:08:42.929425 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:42.929464 line        56\u001b[0m                     -1\n",
      "\u001b[2m01:08:42.929495 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:42.929525 line        57\u001b[0m                 ].value\n",
      "\u001b[2m01:08:42.929556 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 0.0010303171584382653}\u001b[0m\n",
      "\u001b[2m01:08:42.929586 line        48\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'Acc/Train'\u001b[0m\n",
      "\u001b[2m01:08:42.929625 line        50\u001b[0m                 try:\n",
      "\u001b[2m01:08:42.929668 line        51\u001b[0m                     temp_dict[subtag] = [tag[-1] for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:42.929708 exception   51\u001b[0m                     temp_dict[subtag] = [tag[-1] for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[31mException:..... \u001b[1mTypeError: 'ScalarEvent' object is not subscriptable\u001b[0m\n",
      "\u001b[2m01:08:42.929769 line        54\u001b[0m                 except:\n",
      "\u001b[2m01:08:42.929806 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:42.929848 line        56\u001b[0m                     -1\n",
      "\u001b[2m01:08:42.929882 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:42.929915 line        57\u001b[0m                 ].value\n",
      "\u001b[2m01:08:42.929946 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 0.0010303171584382653, 'Acc/Train': 99.43000030517578}\u001b[0m\n",
      "\u001b[2m01:08:42.929978 line        48\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'global_run_count'\u001b[0m\n",
      "\u001b[2m01:08:42.930017 line        50\u001b[0m                 try:\n",
      "\u001b[2m01:08:42.930055 line        51\u001b[0m                     temp_dict[subtag] = [tag[-1] for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:42.930095 exception   51\u001b[0m                     temp_dict[subtag] = [tag[-1] for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[31mException:..... \u001b[1mTypeError: 'ScalarEvent' object is not subscriptable\u001b[0m\n",
      "\u001b[2m01:08:42.930147 line        54\u001b[0m                 except:\n",
      "\u001b[2m01:08:42.930182 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:42.930224 line        56\u001b[0m                     -1\n",
      "\u001b[2m01:08:42.930257 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:42.930289 line        57\u001b[0m                 ].value\n",
      "\u001b[2m01:08:42.930321 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 0.001030317158...in': 99.43000030517578, 'global_run_count': 20.0}\u001b[0m\n",
      "\u001b[2m01:08:42.930361 line        48\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'Loss/Val'\u001b[0m\n",
      "\u001b[2m01:08:42.930452 line        50\u001b[0m                 try:\n",
      "\u001b[2m01:08:42.930494 line        51\u001b[0m                     temp_dict[subtag] = [tag[-1] for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:42.930535 exception   51\u001b[0m                     temp_dict[subtag] = [tag[-1] for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[31mException:..... \u001b[1mTypeError: 'ScalarEvent' object is not subscriptable\u001b[0m\n",
      "\u001b[2m01:08:42.930589 line        54\u001b[0m                 except:\n",
      "\u001b[2m01:08:42.930625 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:42.930666 line        56\u001b[0m                     -1\n",
      "\u001b[2m01:08:42.930700 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:42.930734 line        57\u001b[0m                 ].value\n",
      "\u001b[2m01:08:42.930766 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 0.001030317158...un_count': 20.0, 'Loss/Val': 0.04614705964922905}\u001b[0m\n",
      "\u001b[2m01:08:42.930799 line        48\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'Acc/Val'\u001b[0m\n",
      "\u001b[2m01:08:42.930838 line        50\u001b[0m                 try:\n",
      "\u001b[2m01:08:42.930876 line        51\u001b[0m                     temp_dict[subtag] = [tag[-1] for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:42.930917 exception   51\u001b[0m                     temp_dict[subtag] = [tag[-1] for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[31mException:..... \u001b[1mTypeError: 'ScalarEvent' object is not subscriptable\u001b[0m\n",
      "\u001b[2m01:08:42.930970 line        54\u001b[0m                 except:\n",
      "\u001b[2m01:08:42.931005 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:42.931046 line        56\u001b[0m                     -1\n",
      "\u001b[2m01:08:42.931080 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:42.931113 line        57\u001b[0m                 ].value\n",
      "\u001b[2m01:08:42.931146 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 0.001030317158....04614705964922905, 'Acc/Val': 65.94999694824219}\u001b[0m\n",
      "\u001b[2m01:08:42.931179 line        48\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[2m01:08:42.931219 line        59\u001b[0m         if tag == \"tensors\":\n",
      "\u001b[2m01:08:42.931253 line        85\u001b[0m         if tag == \"images\" and save_ims == True:\n",
      "\u001b[2m01:08:42.931287 line        46\u001b[0m     for tag in all_tags.keys():\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtag = 'distributions'\u001b[0m\n",
      "\u001b[2m01:08:42.931319 line        47\u001b[0m         if tag == \"scalars\":\n",
      "\u001b[2m01:08:42.931357 line        59\u001b[0m         if tag == \"tensors\":\n",
      "\u001b[2m01:08:42.931394 line        85\u001b[0m         if tag == \"images\" and save_ims == True:\n",
      "\u001b[2m01:08:42.931427 line        46\u001b[0m     for tag in all_tags.keys():\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtag = 'tensors'\u001b[0m\n",
      "\u001b[2m01:08:42.931460 line        47\u001b[0m         if tag == \"scalars\":\n",
      "\u001b[2m01:08:42.931498 line        59\u001b[0m         if tag == \"tensors\":\n",
      "\u001b[2m01:08:42.931530 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'experiment_name/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:42.931562 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:42.931619 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:42.931659 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:42.931696 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:42.931730 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 0.001030317158...4999694824219, 'experiment_name': 'baseline_run'}\u001b[0m\n",
      "\u001b[2m01:08:42.931768 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'image_size/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:42.931830 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:42.931905 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:42.931966 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:42.932018 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:42.932069 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 0.001030317158...iment_name': 'baseline_run', 'image_size': '224'}\u001b[0m\n",
      "\u001b[2m01:08:42.932125 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'batch_size/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:42.932169 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:42.932217 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:42.932254 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:42.932289 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:42.932323 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 0.001030317158...ne_run', 'image_size': '224', 'batch_size': '32'}\u001b[0m\n",
      "\u001b[2m01:08:42.932358 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'enable_proxy_attention/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:42.932397 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:42.932442 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:42.932478 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:42.932513 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:42.932548 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 0.001030317158...ch_size': '32', 'enable_proxy_attention': 'True'}\u001b[0m\n",
      "\u001b[2m01:08:42.932582 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'transfer_imagenet/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:42.932621 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:42.932677 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:42.932722 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:42.932778 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:42.932822 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 0.001030317158..._attention': 'True', 'transfer_imagenet': 'True'}\u001b[0m\n",
      "\u001b[2m01:08:42.932858 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'subset_images/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:42.932899 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:42.932953 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:42.932996 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:42.933039 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:42.933075 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 0.001030317158...sfer_imagenet': 'True', 'subset_images': '20000'}\u001b[0m\n",
      "\u001b[2m01:08:42.933110 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'pixel_replacement_method/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:42.933151 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:42.933276 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:42.933332 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:42.933383 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:42.933435 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 0.001030317158...: '20000', 'pixel_replacement_method': 'blended'}\u001b[0m\n",
      "\u001b[2m01:08:42.933499 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'proxy_steps/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:42.933558 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:42.933642 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:42.933704 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:42.933819 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:42.933876 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 0.001030317158...cement_method': 'blended', 'proxy_steps': '[20]'}\u001b[0m\n",
      "\u001b[2m01:08:42.933912 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'load_proxy_data/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:42.934010 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:42.934102 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:42.934188 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:42.934240 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:42.934299 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 0.001030317158...proxy_steps': '[20]', 'load_proxy_data': 'False'}\u001b[0m\n",
      "\u001b[2m01:08:42.934389 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'proxy_step/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:42.934442 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:42.934510 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:42.934549 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:42.934586 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:42.934621 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.00103031...proxy_steps': '[20]', 'load_proxy_data': 'False'}\u001b[0m\n",
      "\u001b[2m01:08:42.934656 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'log_every/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:42.934696 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:42.934749 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:42.934824 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:42.934886 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:42.934934 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.00103031...]', 'load_proxy_data': 'False', 'log_every': '2'}\u001b[0m\n",
      "\u001b[2m01:08:42.934981 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'device/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:42.935023 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:42.935071 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:42.935109 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:42.935145 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:42.935180 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.00103031...': 'False', 'log_every': '2', 'device': 'cuda:0'}\u001b[0m\n",
      "\u001b[2m01:08:42.935216 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'dataset_info/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:42.935256 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:42.935302 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:42.935346 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:42.935383 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:42.935419 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.00103031...t_name at 0x7faec51aba30>, 'num_classes': 101}}\"}\u001b[0m\n",
      "\u001b[2m01:08:42.935455 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'main_run_dir/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:42.935502 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:42.935554 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:42.935596 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:42.935637 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:42.935678 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.00103031...DE/Github/improving_robotics_datasets/src/runs/'}\u001b[0m\n",
      "\u001b[2m01:08:42.935719 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'change_subset_attention/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:42.935765 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:42.935818 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:42.935861 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:42.935906 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:42.935974 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.00103031...ets/src/runs/', 'change_subset_attention': '0.8'}\u001b[0m\n",
      "\u001b[2m01:08:42.936046 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'model/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:42.936127 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:42.936189 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:42.936241 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:42.936295 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:42.936342 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.00103031...ge_subset_attention': '0.8', 'model': 'resnet18'}\u001b[0m\n",
      "\u001b[2m01:08:42.936388 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'proxy_image_weight/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:42.936437 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:42.936490 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:42.936535 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:42.936578 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:42.936621 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.00103031...'model': 'resnet18', 'proxy_image_weight': '0.1'}\u001b[0m\n",
      "\u001b[2m01:08:42.936663 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'proxy_threshold/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:42.936710 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:42.936764 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:42.936818 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:42.936863 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:42.936919 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.00103031..._image_weight': '0.1', 'proxy_threshold': '0.85'}\u001b[0m\n",
      "\u001b[2m01:08:42.936982 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'gradient_method/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:42.937033 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:42.937110 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:42.937156 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:42.937199 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:42.937241 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.00103031...d': '0.85', 'gradient_method': 'gradcamplusplus'}\u001b[0m\n",
      "\u001b[2m01:08:42.937283 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'ds_name/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:42.937330 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:42.937384 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:42.937427 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:42.937470 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:42.937512 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.00103031...ethod': 'gradcamplusplus', 'ds_name': 'cifar100'}\u001b[0m\n",
      "\u001b[2m01:08:42.937575 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'clear_every_step/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:42.937648 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:42.937708 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:42.937759 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:42.937815 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:42.937860 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.00103031...ds_name': 'cifar100', 'clear_every_step': 'True'}\u001b[0m\n",
      "\u001b[2m01:08:42.937903 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'fname_start/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:42.937952 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:42.938006 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:42.938051 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:42.938097 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:42.938141 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.00103031..._datasets/src/runs/baseline_run_26032023_124800'}\u001b[0m\n",
      "\u001b[2m01:08:42.938183 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'ds_path/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:42.938231 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:42.938285 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:42.938329 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:42.938373 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:42.938416 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.00103031...'/run/media/eragon/HDD/Datasets/CIFAR-100/train'}\u001b[0m\n",
      "\u001b[2m01:08:42.938460 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'name_fn/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:42.938513 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:42.938568 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:42.938614 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:42.938665 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:42.938710 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.00103031...: '<function get_parent_name at 0x7faec51aba30>'}\u001b[0m\n",
      "\u001b[2m01:08:42.938754 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'global_run_count/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:42.938817 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:42.938876 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:42.938922 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:42.938967 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:42.939010 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[2m01:08:42.939053 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'writer/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:42.939103 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:42.939159 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:42.939204 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:42.939248 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:42.939291 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.00103031....writer.SummaryWriter object at 0x7fafb2916aa0>'}\u001b[0m\n",
      "\u001b[2m01:08:42.939334 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'label_map/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:42.939382 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:42.939437 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:42.939486 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:42.939532 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:42.939575 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.00103031...low_tree', 97: 'wolf', 98: 'woman', 99: 'worm'}\"}\u001b[0m\n",
      "\u001b[2m01:08:42.939620 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'rev_label_map/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:42.939681 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:42.939745 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:42.939797 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:42.939852 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:42.939910 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.00103031...tree': 96, 'wolf': 97, 'woman': 98, 'worm': 99}\"}\u001b[0m\n",
      "\u001b[2m01:08:42.939962 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'num_classes/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:42.940026 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:42.940102 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:42.940163 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:42.940221 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:42.940279 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.00103031... 'woman': 98, 'worm': 99}\", 'num_classes': '100'}\u001b[0m\n",
      "\u001b[2m01:08:42.940336 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'dataset_sizes/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:42.940414 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:42.940486 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:42.940546 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:42.940604 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:42.940662 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.00103031...dataset_sizes': \"{'train': 10000, 'val': 10000}\"}\u001b[0m\n",
      "\u001b[2m01:08:42.940721 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'criterion/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:42.940790 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:42.940867 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:42.940958 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:42.941022 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:42.941081 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.00103031...val': 10000}\", 'criterion': 'CrossEntropyLoss()'}\u001b[0m\n",
      "\u001b[2m01:08:42.941141 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'cam/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:42.941205 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:42.941277 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:42.941345 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:42.941421 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:42.941507 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.00103031...splus.GradCAMPlusPlus object at 0x7faeb6f5dde0>'}\u001b[0m\n",
      "\u001b[2m01:08:42.941583 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'save_path/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:42.941653 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:42.941726 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:42.941788 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:42.941849 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:42.941908 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.00103031...rc/runs/baseline_run_26032023_124800/checkpoint'}\u001b[0m\n",
      "\u001b[2m01:08:42.941967 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'final_acc/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:42.942032 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:42.942103 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:42.942164 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:42.942223 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:42.942282 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.00103031...6032023_124800/checkpoint', 'final_acc': '65.95'}\u001b[0m\n",
      "\u001b[2m01:08:42.942340 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[2m01:08:42.942407 line        85\u001b[0m         if tag == \"images\" and save_ims == True:\n",
      "\u001b[2m01:08:42.942477 line        46\u001b[0m     for tag in all_tags.keys():\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtag = 'graph'\u001b[0m\n",
      "\u001b[2m01:08:42.942554 line        47\u001b[0m         if tag == \"scalars\":\n",
      "\u001b[2m01:08:42.942624 line        59\u001b[0m         if tag == \"tensors\":\n",
      "\u001b[2m01:08:42.942701 line        85\u001b[0m         if tag == \"images\" and save_ims == True:\n",
      "\u001b[2m01:08:42.942762 line        46\u001b[0m     for tag in all_tags.keys():\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtag = 'meta_graph'\u001b[0m\n",
      "\u001b[2m01:08:42.942820 line        47\u001b[0m         if tag == \"scalars\":\n",
      "\u001b[2m01:08:42.942885 line        59\u001b[0m         if tag == \"tensors\":\n",
      "\u001b[2m01:08:42.942943 line        85\u001b[0m         if tag == \"images\" and save_ims == True:\n",
      "\u001b[2m01:08:42.943002 line        46\u001b[0m     for tag in all_tags.keys():\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtag = 'run_metadata'\u001b[0m\n",
      "\u001b[2m01:08:42.943070 line        47\u001b[0m         if tag == \"scalars\":\n",
      "\u001b[2m01:08:42.943159 line        59\u001b[0m         if tag == \"tensors\":\n",
      "\u001b[2m01:08:42.943254 line        85\u001b[0m         if tag == \"images\" and save_ims == True:\n",
      "\u001b[2m01:08:42.943321 line        46\u001b[0m     for tag in all_tags.keys():\n",
      "\u001b[2m01:08:42.943382 line        96\u001b[0m     return temp_dict\n",
      "\u001b[2m01:08:42.943441 return      96\u001b[0m     return temp_dict\n",
      "\u001b[36m\u001b[2mReturn value:.. \u001b[22m{'proxy_step': 'False', 'Loss/Train': 0.00103031...6032023_124800/checkpoint', 'final_acc': '65.95'}\u001b[0m\n",
      "\u001b[33m\u001b[2mElapsed time: \u001b[22m00:00:00.015570\u001b[0m\n",
      "runs/baseline_run_26032023_132227/events.out.tfevents.1679829747.eragon\n",
      "\u001b[32m\u001b[2mStarting var:.. \u001b[22mevent_acc = <tensorboard.backend.event_processing.event_accumulator.EventAccumulator object at 0x7f5b568effd0>\u001b[0m\n",
      "\u001b[32m\u001b[2mStarting var:.. \u001b[22msave_ims = False\u001b[0m\n",
      "\u001b[2m01:08:42.952862 call        42\u001b[0m def process_event_acc(event_acc, save_ims = False):\n",
      "\u001b[2m01:08:42.952936 line        44\u001b[0m     all_tags = event_acc.Tags()\n",
      "\u001b[32m\u001b[2mNew var:....... \u001b[22mall_tags = {'images': [], 'audio': [], 'histograms': [], 's...: False, 'meta_graph': False, 'run_metadata': []}\u001b[0m\n",
      "\u001b[2m01:08:42.952977 line        45\u001b[0m     temp_dict = {}\n",
      "\u001b[32m\u001b[2mNew var:....... \u001b[22mtemp_dict = {}\u001b[0m\n",
      "\u001b[2m01:08:42.953063 line        46\u001b[0m     for tag in all_tags.keys():\n",
      "\u001b[32m\u001b[2mNew var:....... \u001b[22mtag = 'images'\u001b[0m\n",
      "\u001b[2m01:08:42.953104 line        47\u001b[0m         if tag == \"scalars\":\n",
      "\u001b[2m01:08:42.953141 line        59\u001b[0m         if tag == \"tensors\":\n",
      "\u001b[2m01:08:42.953170 line        85\u001b[0m         if tag == \"images\" and save_ims == True:\n",
      "\u001b[2m01:08:42.953200 line        46\u001b[0m     for tag in all_tags.keys():\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtag = 'audio'\u001b[0m\n",
      "\u001b[2m01:08:42.953249 line        47\u001b[0m         if tag == \"scalars\":\n",
      "\u001b[2m01:08:42.953298 line        59\u001b[0m         if tag == \"tensors\":\n",
      "\u001b[2m01:08:42.953330 line        85\u001b[0m         if tag == \"images\" and save_ims == True:\n",
      "\u001b[2m01:08:42.953359 line        46\u001b[0m     for tag in all_tags.keys():\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtag = 'histograms'\u001b[0m\n",
      "\u001b[2m01:08:42.953388 line        47\u001b[0m         if tag == \"scalars\":\n",
      "\u001b[2m01:08:42.953421 line        59\u001b[0m         if tag == \"tensors\":\n",
      "\u001b[2m01:08:42.953451 line        85\u001b[0m         if tag == \"images\" and save_ims == True:\n",
      "\u001b[2m01:08:42.953482 line        46\u001b[0m     for tag in all_tags.keys():\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtag = 'scalars'\u001b[0m\n",
      "\u001b[2m01:08:42.953511 line        47\u001b[0m         if tag == \"scalars\":\n",
      "\u001b[2m01:08:42.953544 line        48\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mNew var:....... \u001b[22msubtag = 'proxy_step'\u001b[0m\n",
      "\u001b[2m01:08:42.953573 line        50\u001b[0m                 try:\n",
      "\u001b[2m01:08:42.953609 line        51\u001b[0m                     temp_dict[subtag] = [tag[-1] for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:42.953649 exception   51\u001b[0m                     temp_dict[subtag] = [tag[-1] for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[31mException:..... \u001b[1mTypeError: 'ScalarEvent' object is not subscriptable\u001b[0m\n",
      "\u001b[2m01:08:42.953713 line        54\u001b[0m                 except:\n",
      "\u001b[2m01:08:42.953760 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:42.953802 line        56\u001b[0m                     -1\n",
      "\u001b[2m01:08:42.953833 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:42.953877 line        57\u001b[0m                 ].value\n",
      "\u001b[2m01:08:42.953914 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0}\u001b[0m\n",
      "\u001b[2m01:08:42.953966 line        48\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'Loss/Train'\u001b[0m\n",
      "\u001b[2m01:08:42.954012 line        50\u001b[0m                 try:\n",
      "\u001b[2m01:08:42.954049 line        51\u001b[0m                     temp_dict[subtag] = [tag[-1] for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:42.954089 exception   51\u001b[0m                     temp_dict[subtag] = [tag[-1] for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[31mException:..... \u001b[1mTypeError: 'ScalarEvent' object is not subscriptable\u001b[0m\n",
      "\u001b[2m01:08:42.954150 line        54\u001b[0m                 except:\n",
      "\u001b[2m01:08:42.954190 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:42.954230 line        56\u001b[0m                     -1\n",
      "\u001b[2m01:08:42.954261 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:42.954291 line        57\u001b[0m                 ].value\n",
      "\u001b[2m01:08:42.954321 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 0.0005016947397962213}\u001b[0m\n",
      "\u001b[2m01:08:42.954351 line        48\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'Acc/Train'\u001b[0m\n",
      "\u001b[2m01:08:42.954390 line        50\u001b[0m                 try:\n",
      "\u001b[2m01:08:42.954427 line        51\u001b[0m                     temp_dict[subtag] = [tag[-1] for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:42.954466 exception   51\u001b[0m                     temp_dict[subtag] = [tag[-1] for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[31mException:..... \u001b[1mTypeError: 'ScalarEvent' object is not subscriptable\u001b[0m\n",
      "\u001b[2m01:08:42.954518 line        54\u001b[0m                 except:\n",
      "\u001b[2m01:08:42.954552 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:42.954604 line        56\u001b[0m                     -1\n",
      "\u001b[2m01:08:42.954640 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:42.954673 line        57\u001b[0m                 ].value\n",
      "\u001b[2m01:08:42.954705 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 0.0005016947397962213, 'Acc/Train': 99.45999908447266}\u001b[0m\n",
      "\u001b[2m01:08:42.954737 line        48\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'global_run_count'\u001b[0m\n",
      "\u001b[2m01:08:42.954776 line        50\u001b[0m                 try:\n",
      "\u001b[2m01:08:42.954815 line        51\u001b[0m                     temp_dict[subtag] = [tag[-1] for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:42.954854 exception   51\u001b[0m                     temp_dict[subtag] = [tag[-1] for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[31mException:..... \u001b[1mTypeError: 'ScalarEvent' object is not subscriptable\u001b[0m\n",
      "\u001b[2m01:08:42.954908 line        54\u001b[0m                 except:\n",
      "\u001b[2m01:08:42.954943 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:42.954984 line        56\u001b[0m                     -1\n",
      "\u001b[2m01:08:42.955017 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:42.955050 line        57\u001b[0m                 ].value\n",
      "\u001b[2m01:08:42.955081 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 0.000501694739...in': 99.45999908447266, 'global_run_count': 20.0}\u001b[0m\n",
      "\u001b[2m01:08:42.955114 line        48\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'Loss/Val'\u001b[0m\n",
      "\u001b[2m01:08:42.955159 line        50\u001b[0m                 try:\n",
      "\u001b[2m01:08:42.955200 line        51\u001b[0m                     temp_dict[subtag] = [tag[-1] for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:42.955240 exception   51\u001b[0m                     temp_dict[subtag] = [tag[-1] for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[31mException:..... \u001b[1mTypeError: 'ScalarEvent' object is not subscriptable\u001b[0m\n",
      "\u001b[2m01:08:42.955298 line        54\u001b[0m                 except:\n",
      "\u001b[2m01:08:42.955335 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:42.955377 line        56\u001b[0m                     -1\n",
      "\u001b[2m01:08:42.955411 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:42.955445 line        57\u001b[0m                 ].value\n",
      "\u001b[2m01:08:42.955478 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 0.000501694739...un_count': 20.0, 'Loss/Val': 0.02409709058701992}\u001b[0m\n",
      "\u001b[2m01:08:42.955511 line        48\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'Acc/Val'\u001b[0m\n",
      "\u001b[2m01:08:42.955551 line        50\u001b[0m                 try:\n",
      "\u001b[2m01:08:42.955590 line        51\u001b[0m                     temp_dict[subtag] = [tag[-1] for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:42.955630 exception   51\u001b[0m                     temp_dict[subtag] = [tag[-1] for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[31mException:..... \u001b[1mTypeError: 'ScalarEvent' object is not subscriptable\u001b[0m\n",
      "\u001b[2m01:08:42.955683 line        54\u001b[0m                 except:\n",
      "\u001b[2m01:08:42.955720 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:42.955780 line        56\u001b[0m                     -1\n",
      "\u001b[2m01:08:42.955818 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:42.955852 line        57\u001b[0m                 ].value\n",
      "\u001b[2m01:08:42.955886 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 0.000501694739....02409709058701992, 'Acc/Val': 63.65999984741211}\u001b[0m\n",
      "\u001b[2m01:08:42.955920 line        48\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[2m01:08:42.955961 line        59\u001b[0m         if tag == \"tensors\":\n",
      "\u001b[2m01:08:42.955996 line        85\u001b[0m         if tag == \"images\" and save_ims == True:\n",
      "\u001b[2m01:08:42.956030 line        46\u001b[0m     for tag in all_tags.keys():\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtag = 'distributions'\u001b[0m\n",
      "\u001b[2m01:08:42.956063 line        47\u001b[0m         if tag == \"scalars\":\n",
      "\u001b[2m01:08:42.956102 line        59\u001b[0m         if tag == \"tensors\":\n",
      "\u001b[2m01:08:42.956136 line        85\u001b[0m         if tag == \"images\" and save_ims == True:\n",
      "\u001b[2m01:08:42.956169 line        46\u001b[0m     for tag in all_tags.keys():\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtag = 'tensors'\u001b[0m\n",
      "\u001b[2m01:08:42.956202 line        47\u001b[0m         if tag == \"scalars\":\n",
      "\u001b[2m01:08:42.956240 line        59\u001b[0m         if tag == \"tensors\":\n",
      "\u001b[2m01:08:42.956273 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'experiment_name/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:42.956306 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:42.956352 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:42.956399 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:42.956440 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:42.956484 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 0.000501694739...5999984741211, 'experiment_name': 'baseline_run'}\u001b[0m\n",
      "\u001b[2m01:08:42.956522 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'image_size/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:42.956562 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:42.956609 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:42.956647 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:42.956683 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:42.956717 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 0.000501694739...iment_name': 'baseline_run', 'image_size': '224'}\u001b[0m\n",
      "\u001b[2m01:08:42.956752 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'batch_size/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:42.956808 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:42.956883 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:42.956944 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:42.956996 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:42.957037 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 0.000501694739...ne_run', 'image_size': '224', 'batch_size': '64'}\u001b[0m\n",
      "\u001b[2m01:08:42.957123 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'enable_proxy_attention/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:42.957190 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:42.957243 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:42.957283 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:42.957321 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:42.957356 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 0.000501694739...ch_size': '64', 'enable_proxy_attention': 'True'}\u001b[0m\n",
      "\u001b[2m01:08:42.957392 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'transfer_imagenet/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:42.957434 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:42.957529 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:42.957570 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:42.957606 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:42.957644 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 0.000501694739..._attention': 'True', 'transfer_imagenet': 'True'}\u001b[0m\n",
      "\u001b[2m01:08:42.957680 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'subset_images/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:42.957721 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:42.957779 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:42.957855 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:42.957912 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:42.957950 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 0.000501694739...sfer_imagenet': 'True', 'subset_images': '20000'}\u001b[0m\n",
      "\u001b[2m01:08:42.957986 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'pixel_replacement_method/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:42.958042 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:42.958092 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:42.958130 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:42.958166 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:42.958202 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 0.000501694739...: '20000', 'pixel_replacement_method': 'blended'}\u001b[0m\n",
      "\u001b[2m01:08:42.958237 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'proxy_steps/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:42.958277 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:42.958324 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:42.958361 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:42.958396 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:42.958431 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 0.000501694739...cement_method': 'blended', 'proxy_steps': '[20]'}\u001b[0m\n",
      "\u001b[2m01:08:42.958466 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'load_proxy_data/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:42.958506 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:42.958552 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:42.958589 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:42.958658 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:42.958700 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 0.000501694739...proxy_steps': '[20]', 'load_proxy_data': 'False'}\u001b[0m\n",
      "\u001b[2m01:08:42.958736 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'proxy_step/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:42.958777 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:42.958824 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:42.958862 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:42.958898 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:42.958932 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.00050169...proxy_steps': '[20]', 'load_proxy_data': 'False'}\u001b[0m\n",
      "\u001b[2m01:08:42.958981 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'log_every/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:42.959024 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:42.959074 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:42.959121 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:42.959159 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:42.959195 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.00050169...]', 'load_proxy_data': 'False', 'log_every': '2'}\u001b[0m\n",
      "\u001b[2m01:08:42.959230 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'device/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:42.959306 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:42.959356 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:42.959394 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:42.959430 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:42.959472 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.00050169...': 'False', 'log_every': '2', 'device': 'cuda:0'}\u001b[0m\n",
      "\u001b[2m01:08:42.959516 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'dataset_info/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:42.959564 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:42.959620 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:42.959662 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:42.959747 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:42.959815 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.00050169...t_name at 0x7f005b9cfa30>, 'num_classes': 101}}\"}\u001b[0m\n",
      "\u001b[2m01:08:42.959858 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'main_run_dir/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:42.959909 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:42.959966 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:42.960011 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:42.960071 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:42.960115 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.00050169...DE/Github/improving_robotics_datasets/src/runs/'}\u001b[0m\n",
      "\u001b[2m01:08:42.960157 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'change_subset_attention/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:42.960204 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:42.960259 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:42.960303 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:42.960361 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:42.960441 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.00050169...ets/src/runs/', 'change_subset_attention': '0.8'}\u001b[0m\n",
      "\u001b[2m01:08:42.960493 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'model/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:42.960545 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:42.960603 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:42.960648 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:42.960692 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:42.960735 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.00050169...ge_subset_attention': '0.8', 'model': 'resnet18'}\u001b[0m\n",
      "\u001b[2m01:08:42.960778 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'proxy_image_weight/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:42.960826 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:42.960879 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:42.960924 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:42.960993 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:42.961062 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.00050169...'model': 'resnet18', 'proxy_image_weight': '0.1'}\u001b[0m\n",
      "\u001b[2m01:08:42.961134 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'proxy_threshold/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:42.961189 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:42.961244 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:42.961290 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:42.961334 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:42.961376 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.00050169..._image_weight': '0.1', 'proxy_threshold': '0.85'}\u001b[0m\n",
      "\u001b[2m01:08:42.961418 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'gradient_method/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:42.961465 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:42.961519 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:42.961562 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:42.961605 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:42.961647 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.00050169...d': '0.85', 'gradient_method': 'gradcamplusplus'}\u001b[0m\n",
      "\u001b[2m01:08:42.961689 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'ds_name/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:42.961736 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:42.961790 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:42.961837 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:42.961880 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:42.961922 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.00050169...nt_method': 'gradcamplusplus', 'ds_name': 'dogs'}\u001b[0m\n",
      "\u001b[2m01:08:42.961970 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'clear_every_step/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:42.962033 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:42.962104 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:42.962159 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:42.962204 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:42.962247 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.00050169...', 'ds_name': 'dogs', 'clear_every_step': 'True'}\u001b[0m\n",
      "\u001b[2m01:08:42.962289 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'fname_start/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:42.962337 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:42.962393 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:42.962443 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:42.962492 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:42.962540 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.00050169..._datasets/src/runs/baseline_run_26032023_132227'}\u001b[0m\n",
      "\u001b[2m01:08:42.962584 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'ds_path/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:42.962648 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:42.962708 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:42.962766 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:42.962831 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:42.962880 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.00050169...un/media/eragon/HDD/Datasets/dogs/images/Images'}\u001b[0m\n",
      "\u001b[2m01:08:42.962926 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'name_fn/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:42.962980 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:42.963037 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:42.963082 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:42.963128 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:42.963172 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.00050169...: '<function get_parent_name at 0x7f005b9cfa30>'}\u001b[0m\n",
      "\u001b[2m01:08:42.963217 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'global_run_count/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:42.963266 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:42.963321 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:42.963367 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:42.963412 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:42.963455 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[2m01:08:42.963507 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'writer/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:42.963565 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:42.963625 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:42.963671 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:42.963716 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:42.963775 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.00050169....writer.SummaryWriter object at 0x7f014901aaa0>'}\u001b[0m\n",
      "\u001b[2m01:08:42.963819 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'label_map/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:42.963874 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:42.963932 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:42.963978 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:42.964023 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:42.964067 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.00050169...3-dhole', 119: 'n02116738-African_hunting_dog'}\"}\u001b[0m\n",
      "\u001b[2m01:08:42.964111 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'rev_label_map/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:42.964183 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:42.964256 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:42.964320 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:42.964383 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:42.964446 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.00050169...le': 118, 'n02116738-African_hunting_dog': 119}\"}\u001b[0m\n",
      "\u001b[2m01:08:42.964510 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'num_classes/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:42.964614 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:42.964708 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:42.964799 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:42.964889 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:42.964972 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.00050169...frican_hunting_dog': 119}\", 'num_classes': '120'}\u001b[0m\n",
      "\u001b[2m01:08:42.965051 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'dataset_sizes/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:42.965152 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:42.965250 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:42.965344 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:42.965427 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:42.965512 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.00050169...dataset_sizes': \"{'train': 10000, 'val': 10000}\"}\u001b[0m\n",
      "\u001b[2m01:08:42.965594 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'criterion/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:42.965688 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:42.965783 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:42.965867 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:42.965950 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:42.966030 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.00050169...val': 10000}\", 'criterion': 'CrossEntropyLoss()'}\u001b[0m\n",
      "\u001b[2m01:08:42.966111 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'cam/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:42.966197 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:42.966290 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:42.966373 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:42.966462 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:42.966545 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.00050169...splus.GradCAMPlusPlus object at 0x7f0061179330>'}\u001b[0m\n",
      "\u001b[2m01:08:42.966626 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'save_path/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:42.966713 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:42.966807 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:42.966890 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:42.966971 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:42.967071 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.00050169...rc/runs/baseline_run_26032023_132227/checkpoint'}\u001b[0m\n",
      "\u001b[2m01:08:42.967170 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'final_acc/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:42.967259 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:42.967353 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:42.967436 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:42.967519 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:42.967610 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.00050169...6032023_132227/checkpoint', 'final_acc': '63.66'}\u001b[0m\n",
      "\u001b[2m01:08:42.967692 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[2m01:08:42.967791 line        85\u001b[0m         if tag == \"images\" and save_ims == True:\n",
      "\u001b[2m01:08:42.967873 line        46\u001b[0m     for tag in all_tags.keys():\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtag = 'graph'\u001b[0m\n",
      "\u001b[2m01:08:42.967953 line        47\u001b[0m         if tag == \"scalars\":\n",
      "\u001b[2m01:08:42.968038 line        59\u001b[0m         if tag == \"tensors\":\n",
      "\u001b[2m01:08:42.968122 line        85\u001b[0m         if tag == \"images\" and save_ims == True:\n",
      "\u001b[2m01:08:42.968203 line        46\u001b[0m     for tag in all_tags.keys():\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtag = 'meta_graph'\u001b[0m\n",
      "\u001b[2m01:08:42.968284 line        47\u001b[0m         if tag == \"scalars\":\n",
      "\u001b[2m01:08:42.968369 line        59\u001b[0m         if tag == \"tensors\":\n",
      "\u001b[2m01:08:42.968448 line        85\u001b[0m         if tag == \"images\" and save_ims == True:\n",
      "\u001b[2m01:08:42.968528 line        46\u001b[0m     for tag in all_tags.keys():\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtag = 'run_metadata'\u001b[0m\n",
      "\u001b[2m01:08:42.968606 line        47\u001b[0m         if tag == \"scalars\":\n",
      "\u001b[2m01:08:42.968692 line        59\u001b[0m         if tag == \"tensors\":\n",
      "\u001b[2m01:08:42.968771 line        85\u001b[0m         if tag == \"images\" and save_ims == True:\n",
      "\u001b[2m01:08:42.968860 line        46\u001b[0m     for tag in all_tags.keys():\n",
      "\u001b[2m01:08:42.968957 line        96\u001b[0m     return temp_dict\n",
      "\u001b[2m01:08:42.969038 return      96\u001b[0m     return temp_dict\n",
      "\u001b[36m\u001b[2mReturn value:.. \u001b[22m{'proxy_step': 'False', 'Loss/Train': 0.00050169...6032023_132227/checkpoint', 'final_acc': '63.66'}\u001b[0m\n",
      "\u001b[33m\u001b[2mElapsed time: \u001b[22m00:00:00.016342\u001b[0m\n",
      "runs/baseline_run_26032023_133425/events.out.tfevents.1679830468.eragon\n",
      "\u001b[32m\u001b[2mStarting var:.. \u001b[22mevent_acc = <tensorboard.backend.event_processing.event_accumulator.EventAccumulator object at 0x7f5b568ed5a0>\u001b[0m\n",
      "\u001b[32m\u001b[2mStarting var:.. \u001b[22msave_ims = False\u001b[0m\n",
      "\u001b[2m01:08:42.978046 call        42\u001b[0m def process_event_acc(event_acc, save_ims = False):\n",
      "\u001b[2m01:08:42.978119 line        44\u001b[0m     all_tags = event_acc.Tags()\n",
      "\u001b[32m\u001b[2mNew var:....... \u001b[22mall_tags = {'images': [], 'audio': [], 'histograms': [], 's...: False, 'meta_graph': False, 'run_metadata': []}\u001b[0m\n",
      "\u001b[2m01:08:42.978162 line        45\u001b[0m     temp_dict = {}\n",
      "\u001b[32m\u001b[2mNew var:....... \u001b[22mtemp_dict = {}\u001b[0m\n",
      "\u001b[2m01:08:42.978245 line        46\u001b[0m     for tag in all_tags.keys():\n",
      "\u001b[32m\u001b[2mNew var:....... \u001b[22mtag = 'images'\u001b[0m\n",
      "\u001b[2m01:08:42.978286 line        47\u001b[0m         if tag == \"scalars\":\n",
      "\u001b[2m01:08:42.978324 line        59\u001b[0m         if tag == \"tensors\":\n",
      "\u001b[2m01:08:42.978355 line        85\u001b[0m         if tag == \"images\" and save_ims == True:\n",
      "\u001b[2m01:08:42.978385 line        46\u001b[0m     for tag in all_tags.keys():\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtag = 'audio'\u001b[0m\n",
      "\u001b[2m01:08:42.978414 line        47\u001b[0m         if tag == \"scalars\":\n",
      "\u001b[2m01:08:42.978450 line        59\u001b[0m         if tag == \"tensors\":\n",
      "\u001b[2m01:08:42.978479 line        85\u001b[0m         if tag == \"images\" and save_ims == True:\n",
      "\u001b[2m01:08:42.978507 line        46\u001b[0m     for tag in all_tags.keys():\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtag = 'histograms'\u001b[0m\n",
      "\u001b[2m01:08:42.978540 line        47\u001b[0m         if tag == \"scalars\":\n",
      "\u001b[2m01:08:42.978574 line        59\u001b[0m         if tag == \"tensors\":\n",
      "\u001b[2m01:08:42.978601 line        85\u001b[0m         if tag == \"images\" and save_ims == True:\n",
      "\u001b[2m01:08:42.978629 line        46\u001b[0m     for tag in all_tags.keys():\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtag = 'scalars'\u001b[0m\n",
      "\u001b[2m01:08:42.978660 line        47\u001b[0m         if tag == \"scalars\":\n",
      "\u001b[2m01:08:42.978696 line        48\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mNew var:....... \u001b[22msubtag = 'proxy_step'\u001b[0m\n",
      "\u001b[2m01:08:42.978725 line        50\u001b[0m                 try:\n",
      "\u001b[2m01:08:42.978760 line        51\u001b[0m                     temp_dict[subtag] = [tag[-1] for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:42.978800 exception   51\u001b[0m                     temp_dict[subtag] = [tag[-1] for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[31mException:..... \u001b[1mTypeError: 'ScalarEvent' object is not subscriptable\u001b[0m\n",
      "\u001b[2m01:08:42.978861 line        54\u001b[0m                 except:\n",
      "\u001b[2m01:08:42.978896 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:42.978937 line        56\u001b[0m                     -1\n",
      "\u001b[2m01:08:42.978968 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:42.978997 line        57\u001b[0m                 ].value\n",
      "\u001b[2m01:08:42.979026 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0}\u001b[0m\n",
      "\u001b[2m01:08:42.979056 line        48\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'Loss/Train'\u001b[0m\n",
      "\u001b[2m01:08:42.979093 line        50\u001b[0m                 try:\n",
      "\u001b[2m01:08:42.979146 line        51\u001b[0m                     temp_dict[subtag] = [tag[-1] for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:42.979195 exception   51\u001b[0m                     temp_dict[subtag] = [tag[-1] for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[31mException:..... \u001b[1mTypeError: 'ScalarEvent' object is not subscriptable\u001b[0m\n",
      "\u001b[2m01:08:42.979250 line        54\u001b[0m                 except:\n",
      "\u001b[2m01:08:42.979283 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:42.979322 line        56\u001b[0m                     -1\n",
      "\u001b[2m01:08:42.979353 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:42.979383 line        57\u001b[0m                 ].value\n",
      "\u001b[2m01:08:42.979413 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 7.946377445477992e-05}\u001b[0m\n",
      "\u001b[2m01:08:42.979444 line        48\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'Acc/Train'\u001b[0m\n",
      "\u001b[2m01:08:42.979483 line        50\u001b[0m                 try:\n",
      "\u001b[2m01:08:42.979519 line        51\u001b[0m                     temp_dict[subtag] = [tag[-1] for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:42.979557 exception   51\u001b[0m                     temp_dict[subtag] = [tag[-1] for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[31mException:..... \u001b[1mTypeError: 'ScalarEvent' object is not subscriptable\u001b[0m\n",
      "\u001b[2m01:08:42.979608 line        54\u001b[0m                 except:\n",
      "\u001b[2m01:08:42.979642 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:42.979686 line        56\u001b[0m                     -1\n",
      "\u001b[2m01:08:42.979718 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:42.979750 line        57\u001b[0m                 ].value\n",
      "\u001b[2m01:08:42.979781 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 7.946377445477992e-05, 'Acc/Train': 99.91252899169922}\u001b[0m\n",
      "\u001b[2m01:08:42.979813 line        48\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'global_run_count'\u001b[0m\n",
      "\u001b[2m01:08:42.979850 line        50\u001b[0m                 try:\n",
      "\u001b[2m01:08:42.979887 line        51\u001b[0m                     temp_dict[subtag] = [tag[-1] for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:42.979925 exception   51\u001b[0m                     temp_dict[subtag] = [tag[-1] for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[31mException:..... \u001b[1mTypeError: 'ScalarEvent' object is not subscriptable\u001b[0m\n",
      "\u001b[2m01:08:42.979977 line        54\u001b[0m                 except:\n",
      "\u001b[2m01:08:42.980011 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:42.980052 line        56\u001b[0m                     -1\n",
      "\u001b[2m01:08:42.980085 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:42.980117 line        57\u001b[0m                 ].value\n",
      "\u001b[2m01:08:42.980149 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 7.946377445477...in': 99.91252899169922, 'global_run_count': 20.0}\u001b[0m\n",
      "\u001b[2m01:08:42.980197 line        48\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'Loss/Val'\u001b[0m\n",
      "\u001b[2m01:08:42.980238 line        50\u001b[0m                 try:\n",
      "\u001b[2m01:08:42.980276 line        51\u001b[0m                     temp_dict[subtag] = [tag[-1] for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:42.980316 exception   51\u001b[0m                     temp_dict[subtag] = [tag[-1] for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[31mException:..... \u001b[1mTypeError: 'ScalarEvent' object is not subscriptable\u001b[0m\n",
      "\u001b[2m01:08:42.980435 line        54\u001b[0m                 except:\n",
      "\u001b[2m01:08:42.980482 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:42.980528 line        56\u001b[0m                     -1\n",
      "\u001b[2m01:08:42.980564 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:42.980598 line        57\u001b[0m                 ].value\n",
      "\u001b[2m01:08:42.980632 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 7.946377445477...un_count': 20.0, 'Loss/Val': 0.00705804955214262}\u001b[0m\n",
      "\u001b[2m01:08:42.980666 line        48\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'Acc/Val'\u001b[0m\n",
      "\u001b[2m01:08:42.980707 line        50\u001b[0m                 try:\n",
      "\u001b[2m01:08:42.980746 line        51\u001b[0m                     temp_dict[subtag] = [tag[-1] for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:42.980787 exception   51\u001b[0m                     temp_dict[subtag] = [tag[-1] for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[31mException:..... \u001b[1mTypeError: 'ScalarEvent' object is not subscriptable\u001b[0m\n",
      "\u001b[2m01:08:42.980842 line        54\u001b[0m                 except:\n",
      "\u001b[2m01:08:42.980880 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:42.980921 line        56\u001b[0m                     -1\n",
      "\u001b[2m01:08:42.980956 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:42.980990 line        57\u001b[0m                 ].value\n",
      "\u001b[2m01:08:42.981024 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 7.946377445477....00705804955214262, 'Acc/Val': 88.95450592041016}\u001b[0m\n",
      "\u001b[2m01:08:42.981057 line        48\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[2m01:08:42.981098 line        59\u001b[0m         if tag == \"tensors\":\n",
      "\u001b[2m01:08:42.981133 line        85\u001b[0m         if tag == \"images\" and save_ims == True:\n",
      "\u001b[2m01:08:42.981167 line        46\u001b[0m     for tag in all_tags.keys():\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtag = 'distributions'\u001b[0m\n",
      "\u001b[2m01:08:42.981201 line        47\u001b[0m         if tag == \"scalars\":\n",
      "\u001b[2m01:08:42.981239 line        59\u001b[0m         if tag == \"tensors\":\n",
      "\u001b[2m01:08:42.981272 line        85\u001b[0m         if tag == \"images\" and save_ims == True:\n",
      "\u001b[2m01:08:42.981306 line        46\u001b[0m     for tag in all_tags.keys():\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtag = 'tensors'\u001b[0m\n",
      "\u001b[2m01:08:42.981339 line        47\u001b[0m         if tag == \"scalars\":\n",
      "\u001b[2m01:08:42.981376 line        59\u001b[0m         if tag == \"tensors\":\n",
      "\u001b[2m01:08:42.981410 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'experiment_name/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:42.981453 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:42.981500 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:42.981538 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:42.981575 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:42.981609 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 7.946377445477...5450592041016, 'experiment_name': 'baseline_run'}\u001b[0m\n",
      "\u001b[2m01:08:42.981643 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'image_size/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:42.981686 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:42.981731 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:42.981772 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:42.981820 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:42.981856 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 7.946377445477...iment_name': 'baseline_run', 'image_size': '224'}\u001b[0m\n",
      "\u001b[2m01:08:42.981891 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'batch_size/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:42.981930 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:42.981976 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:42.982023 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:42.982080 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:42.982121 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 7.946377445477...ne_run', 'image_size': '224', 'batch_size': '64'}\u001b[0m\n",
      "\u001b[2m01:08:42.982168 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'enable_proxy_attention/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:42.982228 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:42.982277 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:42.982316 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:42.982352 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:42.982387 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 7.946377445477...ch_size': '64', 'enable_proxy_attention': 'True'}\u001b[0m\n",
      "\u001b[2m01:08:42.982422 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'transfer_imagenet/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:42.982462 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:42.982509 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:42.982546 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:42.982583 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:42.982618 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 7.946377445477..._attention': 'True', 'transfer_imagenet': 'True'}\u001b[0m\n",
      "\u001b[2m01:08:42.982655 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'subset_images/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:42.982696 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:42.982745 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:42.982782 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:42.982829 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:42.982876 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 7.946377445477...sfer_imagenet': 'True', 'subset_images': '20000'}\u001b[0m\n",
      "\u001b[2m01:08:42.982917 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'pixel_replacement_method/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:42.982975 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:42.983041 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:42.983090 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:42.983136 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:42.983176 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 7.946377445477...: '20000', 'pixel_replacement_method': 'blended'}\u001b[0m\n",
      "\u001b[2m01:08:42.983216 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'proxy_steps/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:42.983262 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:42.983316 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:42.983356 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:42.983397 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:42.983436 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 7.946377445477...cement_method': 'blended', 'proxy_steps': '[20]'}\u001b[0m\n",
      "\u001b[2m01:08:42.983475 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'load_proxy_data/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:42.983521 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:42.983574 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:42.983614 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:42.983653 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:42.983692 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 7.946377445477...proxy_steps': '[20]', 'load_proxy_data': 'False'}\u001b[0m\n",
      "\u001b[2m01:08:42.983743 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'proxy_step/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:42.983790 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:42.983842 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:42.983881 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:42.983920 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:42.983960 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 7.94637744...proxy_steps': '[20]', 'load_proxy_data': 'False'}\u001b[0m\n",
      "\u001b[2m01:08:42.983999 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'log_every/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:42.984044 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:42.984097 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:42.984137 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:42.984181 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:42.984227 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 7.94637744...]', 'load_proxy_data': 'False', 'log_every': '2'}\u001b[0m\n",
      "\u001b[2m01:08:42.984265 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'device/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:42.984312 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:42.984374 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:42.984425 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:42.984466 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:42.984502 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 7.94637744...': 'False', 'log_every': '2', 'device': 'cuda:0'}\u001b[0m\n",
      "\u001b[2m01:08:42.984539 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'dataset_info/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:42.984584 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:42.984636 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:42.984677 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:42.984717 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:42.984756 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 7.94637744...t_name at 0x7f7acff7ba30>, 'num_classes': 101}}\"}\u001b[0m\n",
      "\u001b[2m01:08:42.984796 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'main_run_dir/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:42.984848 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:42.984907 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:42.984962 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:42.985033 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:42.985094 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 7.94637744...DE/Github/improving_robotics_datasets/src/runs/'}\u001b[0m\n",
      "\u001b[2m01:08:42.985153 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'change_subset_attention/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:42.985216 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:42.985273 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:42.985318 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:42.985363 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:42.985405 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 7.94637744...ets/src/runs/', 'change_subset_attention': '0.8'}\u001b[0m\n",
      "\u001b[2m01:08:42.985448 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'model/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:42.985497 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:42.985552 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:42.985597 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:42.985640 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:42.985682 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 7.94637744...ge_subset_attention': '0.8', 'model': 'resnet18'}\u001b[0m\n",
      "\u001b[2m01:08:42.985724 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'proxy_image_weight/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:42.985778 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:42.985833 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:42.985877 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:42.985921 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:42.985985 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 7.94637744...'model': 'resnet18', 'proxy_image_weight': '0.1'}\u001b[0m\n",
      "\u001b[2m01:08:42.986059 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'proxy_threshold/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:42.986139 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:42.986227 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:42.986287 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:42.986349 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:42.986399 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 7.94637744..._image_weight': '0.1', 'proxy_threshold': '0.85'}\u001b[0m\n",
      "\u001b[2m01:08:42.986447 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'gradient_method/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:42.986503 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:42.986560 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:42.986605 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:42.986650 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:42.986692 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 7.94637744...d': '0.85', 'gradient_method': 'gradcamplusplus'}\u001b[0m\n",
      "\u001b[2m01:08:42.986735 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'ds_name/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:42.986782 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:42.986836 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:42.986880 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:42.986924 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:42.986967 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 7.94637744...hod': 'gradcamplusplus', 'ds_name': 'caltech101'}\u001b[0m\n",
      "\u001b[2m01:08:42.987010 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'clear_every_step/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:42.987080 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:42.987138 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:42.987186 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:42.987231 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:42.987274 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 7.94637744..._name': 'caltech101', 'clear_every_step': 'True'}\u001b[0m\n",
      "\u001b[2m01:08:42.987318 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'fname_start/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:42.987369 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:42.987425 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:42.987472 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:42.987517 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:42.987561 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 7.94637744..._datasets/src/runs/baseline_run_26032023_133425'}\u001b[0m\n",
      "\u001b[2m01:08:42.987606 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'ds_path/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:42.987656 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:42.987712 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:42.987759 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:42.987814 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:42.987866 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 7.94637744...h': '/run/media/eragon/HDD/Datasets/caltech-101'}\u001b[0m\n",
      "\u001b[2m01:08:42.987913 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'name_fn/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:42.987965 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:42.988022 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:42.988070 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:42.988117 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:42.988163 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 7.94637744...: '<function get_parent_name at 0x7f7acff7ba30>'}\u001b[0m\n",
      "\u001b[2m01:08:42.988208 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'global_run_count/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:42.988260 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:42.988320 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:42.988369 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:42.988428 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:42.988476 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[2m01:08:42.988521 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'writer/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:42.988567 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:42.988625 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:42.988672 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:42.988719 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:42.988764 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 7.94637744....writer.SummaryWriter object at 0x7f7bbd116aa0>'}\u001b[0m\n",
      "\u001b[2m01:08:42.988818 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'label_map/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:42.988871 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:42.988931 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:42.988979 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:42.989026 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:42.989073 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 7.94637744...windsor_chair', 100: 'wrench', 101: 'yin_yang'}\"}\u001b[0m\n",
      "\u001b[2m01:08:42.989120 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'rev_label_map/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:42.989182 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:42.989251 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:42.989308 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:42.989364 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:42.989418 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 7.94637744...sor_chair': 99, 'wrench': 100, 'yin_yang': 101}\"}\u001b[0m\n",
      "\u001b[2m01:08:42.989495 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'num_classes/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:42.989592 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:42.989685 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:42.989755 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:42.989820 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:42.989883 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 7.94637744...h': 100, 'yin_yang': 101}\", 'num_classes': '102'}\u001b[0m\n",
      "\u001b[2m01:08:42.989945 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'dataset_sizes/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:42.990013 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:42.990087 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:42.990182 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:42.990287 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:42.990379 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 7.94637744... 'dataset_sizes': \"{'train': 4573, 'val': 4572}\"}\u001b[0m\n",
      "\u001b[2m01:08:42.990466 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'criterion/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:42.990536 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:42.990615 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:42.990681 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:42.990745 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:42.990820 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 7.94637744...'val': 4572}\", 'criterion': 'CrossEntropyLoss()'}\u001b[0m\n",
      "\u001b[2m01:08:42.990885 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'cam/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:42.990953 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:42.991028 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:42.991092 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:42.991153 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:42.991214 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 7.94637744...splus.GradCAMPlusPlus object at 0x7f7ac249a470>'}\u001b[0m\n",
      "\u001b[2m01:08:42.991274 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'save_path/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:42.991340 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:42.991413 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:42.991476 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:42.991536 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:42.991600 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 7.94637744...rc/runs/baseline_run_26032023_133425/checkpoint'}\u001b[0m\n",
      "\u001b[2m01:08:42.991661 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'final_acc/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:42.991728 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:42.991809 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:42.991873 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:42.991935 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:42.991996 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 7.94637744...25/checkpoint', 'final_acc': '88.95450568678915'}\u001b[0m\n",
      "\u001b[2m01:08:42.992057 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[2m01:08:42.992124 line        85\u001b[0m         if tag == \"images\" and save_ims == True:\n",
      "\u001b[2m01:08:42.992185 line        46\u001b[0m     for tag in all_tags.keys():\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtag = 'graph'\u001b[0m\n",
      "\u001b[2m01:08:42.992246 line        47\u001b[0m         if tag == \"scalars\":\n",
      "\u001b[2m01:08:42.992311 line        59\u001b[0m         if tag == \"tensors\":\n",
      "\u001b[2m01:08:42.992370 line        85\u001b[0m         if tag == \"images\" and save_ims == True:\n",
      "\u001b[2m01:08:42.992429 line        46\u001b[0m     for tag in all_tags.keys():\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtag = 'meta_graph'\u001b[0m\n",
      "\u001b[2m01:08:42.992491 line        47\u001b[0m         if tag == \"scalars\":\n",
      "\u001b[2m01:08:42.992557 line        59\u001b[0m         if tag == \"tensors\":\n",
      "\u001b[2m01:08:42.992619 line        85\u001b[0m         if tag == \"images\" and save_ims == True:\n",
      "\u001b[2m01:08:42.992681 line        46\u001b[0m     for tag in all_tags.keys():\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtag = 'run_metadata'\u001b[0m\n",
      "\u001b[2m01:08:42.992742 line        47\u001b[0m         if tag == \"scalars\":\n",
      "\u001b[2m01:08:42.992809 line        59\u001b[0m         if tag == \"tensors\":\n",
      "\u001b[2m01:08:42.992870 line        85\u001b[0m         if tag == \"images\" and save_ims == True:\n",
      "\u001b[2m01:08:42.992932 line        46\u001b[0m     for tag in all_tags.keys():\n",
      "\u001b[2m01:08:42.992996 line        96\u001b[0m     return temp_dict\n",
      "\u001b[2m01:08:42.993065 return      96\u001b[0m     return temp_dict\n",
      "\u001b[36m\u001b[2mReturn value:.. \u001b[22m{'proxy_step': 'False', 'Loss/Train': 7.94637744...25/checkpoint', 'final_acc': '88.95450568678915'}\u001b[0m\n",
      "\u001b[33m\u001b[2mElapsed time: \u001b[22m00:00:00.015157\u001b[0m\n",
      "runs/baseline_run_26032023_134035/events.out.tfevents.1679830836.eragon\n",
      "\u001b[32m\u001b[2mStarting var:.. \u001b[22mevent_acc = <tensorboard.backend.event_processing.event_accumulator.EventAccumulator object at 0x7f5b568efa30>\u001b[0m\n",
      "\u001b[32m\u001b[2mStarting var:.. \u001b[22msave_ims = False\u001b[0m\n",
      "\u001b[2m01:08:43.001776 call        42\u001b[0m def process_event_acc(event_acc, save_ims = False):\n",
      "\u001b[2m01:08:43.001863 line        44\u001b[0m     all_tags = event_acc.Tags()\n",
      "\u001b[32m\u001b[2mNew var:....... \u001b[22mall_tags = {'images': [], 'audio': [], 'histograms': [], 's...: False, 'meta_graph': False, 'run_metadata': []}\u001b[0m\n",
      "\u001b[2m01:08:43.001907 line        45\u001b[0m     temp_dict = {}\n",
      "\u001b[32m\u001b[2mNew var:....... \u001b[22mtemp_dict = {}\u001b[0m\n",
      "\u001b[2m01:08:43.002004 line        46\u001b[0m     for tag in all_tags.keys():\n",
      "\u001b[32m\u001b[2mNew var:....... \u001b[22mtag = 'images'\u001b[0m\n",
      "\u001b[2m01:08:43.002045 line        47\u001b[0m         if tag == \"scalars\":\n",
      "\u001b[2m01:08:43.002082 line        59\u001b[0m         if tag == \"tensors\":\n",
      "\u001b[2m01:08:43.002112 line        85\u001b[0m         if tag == \"images\" and save_ims == True:\n",
      "\u001b[2m01:08:43.002140 line        46\u001b[0m     for tag in all_tags.keys():\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtag = 'audio'\u001b[0m\n",
      "\u001b[2m01:08:43.002168 line        47\u001b[0m         if tag == \"scalars\":\n",
      "\u001b[2m01:08:43.002200 line        59\u001b[0m         if tag == \"tensors\":\n",
      "\u001b[2m01:08:43.002227 line        85\u001b[0m         if tag == \"images\" and save_ims == True:\n",
      "\u001b[2m01:08:43.002254 line        46\u001b[0m     for tag in all_tags.keys():\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtag = 'histograms'\u001b[0m\n",
      "\u001b[2m01:08:43.002281 line        47\u001b[0m         if tag == \"scalars\":\n",
      "\u001b[2m01:08:43.002313 line        59\u001b[0m         if tag == \"tensors\":\n",
      "\u001b[2m01:08:43.002341 line        85\u001b[0m         if tag == \"images\" and save_ims == True:\n",
      "\u001b[2m01:08:43.002367 line        46\u001b[0m     for tag in all_tags.keys():\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtag = 'scalars'\u001b[0m\n",
      "\u001b[2m01:08:43.002394 line        47\u001b[0m         if tag == \"scalars\":\n",
      "\u001b[2m01:08:43.002427 line        48\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mNew var:....... \u001b[22msubtag = 'proxy_step'\u001b[0m\n",
      "\u001b[2m01:08:43.002453 line        50\u001b[0m                 try:\n",
      "\u001b[2m01:08:43.002488 line        51\u001b[0m                     temp_dict[subtag] = [tag[-1] for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.002528 exception   51\u001b[0m                     temp_dict[subtag] = [tag[-1] for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[31mException:..... \u001b[1mTypeError: 'ScalarEvent' object is not subscriptable\u001b[0m\n",
      "\u001b[2m01:08:43.002589 line        54\u001b[0m                 except:\n",
      "\u001b[2m01:08:43.002635 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.002676 line        56\u001b[0m                     -1\n",
      "\u001b[2m01:08:43.002707 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.002737 line        57\u001b[0m                 ].value\n",
      "\u001b[2m01:08:43.002767 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0}\u001b[0m\n",
      "\u001b[2m01:08:43.002798 line        48\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'Loss/Train'\u001b[0m\n",
      "\u001b[2m01:08:43.002835 line        50\u001b[0m                 try:\n",
      "\u001b[2m01:08:43.002870 line        51\u001b[0m                     temp_dict[subtag] = [tag[-1] for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.002907 exception   51\u001b[0m                     temp_dict[subtag] = [tag[-1] for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[31mException:..... \u001b[1mTypeError: 'ScalarEvent' object is not subscriptable\u001b[0m\n",
      "\u001b[2m01:08:43.002973 line        54\u001b[0m                 except:\n",
      "\u001b[2m01:08:43.003011 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.003062 line        56\u001b[0m                     -1\n",
      "\u001b[2m01:08:43.003096 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.003126 line        57\u001b[0m                 ].value\n",
      "\u001b[2m01:08:43.003156 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 7.436733540089335e-06}\u001b[0m\n",
      "\u001b[2m01:08:43.003186 line        48\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'Acc/Train'\u001b[0m\n",
      "\u001b[2m01:08:43.003225 line        50\u001b[0m                 try:\n",
      "\u001b[2m01:08:43.003263 line        51\u001b[0m                     temp_dict[subtag] = [tag[-1] for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.003301 exception   51\u001b[0m                     temp_dict[subtag] = [tag[-1] for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[31mException:..... \u001b[1mTypeError: 'ScalarEvent' object is not subscriptable\u001b[0m\n",
      "\u001b[2m01:08:43.003353 line        54\u001b[0m                 except:\n",
      "\u001b[2m01:08:43.003387 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.003427 line        56\u001b[0m                     -1\n",
      "\u001b[2m01:08:43.003459 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.003490 line        57\u001b[0m                 ].value\n",
      "\u001b[2m01:08:43.003521 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 7.436733540089335e-06, 'Acc/Train': 100.0}\u001b[0m\n",
      "\u001b[2m01:08:43.003553 line        48\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'global_run_count'\u001b[0m\n",
      "\u001b[2m01:08:43.003590 line        50\u001b[0m                 try:\n",
      "\u001b[2m01:08:43.003626 line        51\u001b[0m                     temp_dict[subtag] = [tag[-1] for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.003664 exception   51\u001b[0m                     temp_dict[subtag] = [tag[-1] for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[31mException:..... \u001b[1mTypeError: 'ScalarEvent' object is not subscriptable\u001b[0m\n",
      "\u001b[2m01:08:43.003714 line        54\u001b[0m                 except:\n",
      "\u001b[2m01:08:43.003764 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.003806 line        56\u001b[0m                     -1\n",
      "\u001b[2m01:08:43.003839 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.003871 line        57\u001b[0m                 ].value\n",
      "\u001b[2m01:08:43.003902 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 7.436733540089...06, 'Acc/Train': 100.0, 'global_run_count': 20.0}\u001b[0m\n",
      "\u001b[2m01:08:43.003934 line        48\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'Loss/Val'\u001b[0m\n",
      "\u001b[2m01:08:43.003974 line        50\u001b[0m                 try:\n",
      "\u001b[2m01:08:43.004011 line        51\u001b[0m                     temp_dict[subtag] = [tag[-1] for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.004050 exception   51\u001b[0m                     temp_dict[subtag] = [tag[-1] for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[31mException:..... \u001b[1mTypeError: 'ScalarEvent' object is not subscriptable\u001b[0m\n",
      "\u001b[2m01:08:43.004102 line        54\u001b[0m                 except:\n",
      "\u001b[2m01:08:43.004137 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.004176 line        56\u001b[0m                     -1\n",
      "\u001b[2m01:08:43.004209 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.004241 line        57\u001b[0m                 ].value\n",
      "\u001b[2m01:08:43.004273 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 7.436733540089...count': 20.0, 'Loss/Val': 1.3483436305250507e-06}\u001b[0m\n",
      "\u001b[2m01:08:43.004305 line        48\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'Acc/Val'\u001b[0m\n",
      "\u001b[2m01:08:43.004344 line        50\u001b[0m                 try:\n",
      "\u001b[2m01:08:43.004381 line        51\u001b[0m                     temp_dict[subtag] = [tag[-1] for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.004420 exception   51\u001b[0m                     temp_dict[subtag] = [tag[-1] for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[31mException:..... \u001b[1mTypeError: 'ScalarEvent' object is not subscriptable\u001b[0m\n",
      "\u001b[2m01:08:43.004471 line        54\u001b[0m                 except:\n",
      "\u001b[2m01:08:43.004507 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.004548 line        56\u001b[0m                     -1\n",
      "\u001b[2m01:08:43.004589 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.004626 line        57\u001b[0m                 ].value\n",
      "\u001b[2m01:08:43.004666 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 7.436733540089...s/Val': 1.3483436305250507e-06, 'Acc/Val': 100.0}\u001b[0m\n",
      "\u001b[2m01:08:43.004701 line        48\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[2m01:08:43.004740 line        59\u001b[0m         if tag == \"tensors\":\n",
      "\u001b[2m01:08:43.004772 line        85\u001b[0m         if tag == \"images\" and save_ims == True:\n",
      "\u001b[2m01:08:43.004805 line        46\u001b[0m     for tag in all_tags.keys():\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtag = 'distributions'\u001b[0m\n",
      "\u001b[2m01:08:43.004837 line        47\u001b[0m         if tag == \"scalars\":\n",
      "\u001b[2m01:08:43.004874 line        59\u001b[0m         if tag == \"tensors\":\n",
      "\u001b[2m01:08:43.004907 line        85\u001b[0m         if tag == \"images\" and save_ims == True:\n",
      "\u001b[2m01:08:43.004939 line        46\u001b[0m     for tag in all_tags.keys():\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtag = 'tensors'\u001b[0m\n",
      "\u001b[2m01:08:43.004970 line        47\u001b[0m         if tag == \"scalars\":\n",
      "\u001b[2m01:08:43.005007 line        59\u001b[0m         if tag == \"tensors\":\n",
      "\u001b[2m01:08:43.005039 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'experiment_name/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.005071 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.005118 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.005157 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.005193 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.005228 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 7.436733540089...c/Val': 100.0, 'experiment_name': 'baseline_run'}\u001b[0m\n",
      "\u001b[2m01:08:43.005261 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'image_size/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.005300 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.005345 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.005379 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.005414 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.005447 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 7.436733540089...iment_name': 'baseline_run', 'image_size': '224'}\u001b[0m\n",
      "\u001b[2m01:08:43.005480 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'batch_size/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.005522 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.005568 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.005603 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.005643 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.005681 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 7.436733540089...ne_run', 'image_size': '224', 'batch_size': '64'}\u001b[0m\n",
      "\u001b[2m01:08:43.005715 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'enable_proxy_attention/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.005754 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.005800 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.005837 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.005873 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.005906 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 7.436733540089...ch_size': '64', 'enable_proxy_attention': 'True'}\u001b[0m\n",
      "\u001b[2m01:08:43.005940 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'transfer_imagenet/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.005979 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.006024 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.006059 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.006093 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.006126 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 7.436733540089..._attention': 'True', 'transfer_imagenet': 'True'}\u001b[0m\n",
      "\u001b[2m01:08:43.006159 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'subset_images/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.006198 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.006243 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.006280 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.006315 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.006350 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 7.436733540089...sfer_imagenet': 'True', 'subset_images': '20000'}\u001b[0m\n",
      "\u001b[2m01:08:43.006384 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'pixel_replacement_method/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.006423 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.006469 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.006505 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.006540 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.006574 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 7.436733540089...: '20000', 'pixel_replacement_method': 'blended'}\u001b[0m\n",
      "\u001b[2m01:08:43.006608 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'proxy_steps/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.006648 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.006694 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.006732 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.006776 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.006818 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 7.436733540089...cement_method': 'blended', 'proxy_steps': '[20]'}\u001b[0m\n",
      "\u001b[2m01:08:43.006856 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'load_proxy_data/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.006897 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.006960 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.007002 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.007043 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.007109 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 7.436733540089...proxy_steps': '[20]', 'load_proxy_data': 'False'}\u001b[0m\n",
      "\u001b[2m01:08:43.007147 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'proxy_step/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.007188 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.007237 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.007275 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.007312 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.007348 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 7.43673354...proxy_steps': '[20]', 'load_proxy_data': 'False'}\u001b[0m\n",
      "\u001b[2m01:08:43.007401 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'log_every/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.007444 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.007492 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.007529 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.007565 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.007600 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 7.43673354...]', 'load_proxy_data': 'False', 'log_every': '2'}\u001b[0m\n",
      "\u001b[2m01:08:43.007636 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'device/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.007676 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.007724 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.007761 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.007798 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.007834 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 7.43673354...': 'False', 'log_every': '2', 'device': 'cuda:0'}\u001b[0m\n",
      "\u001b[2m01:08:43.007870 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'dataset_info/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.007913 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.007968 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.008006 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.008050 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.008093 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 7.43673354...t_name at 0x7f92835bfa30>, 'num_classes': 101}}\"}\u001b[0m\n",
      "\u001b[2m01:08:43.008131 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'main_run_dir/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.008179 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.008233 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.008276 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.008319 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.008360 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 7.43673354...DE/Github/improving_robotics_datasets/src/runs/'}\u001b[0m\n",
      "\u001b[2m01:08:43.008400 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'change_subset_attention/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.008445 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.008498 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.008541 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.008583 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.008623 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 7.43673354...ets/src/runs/', 'change_subset_attention': '0.8'}\u001b[0m\n",
      "\u001b[2m01:08:43.008664 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'model/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.008711 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.008763 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.008806 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.008853 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.008894 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 7.43673354...ge_subset_attention': '0.8', 'model': 'resnet18'}\u001b[0m\n",
      "\u001b[2m01:08:43.008935 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'proxy_image_weight/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.008981 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.009033 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.009078 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.009123 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.009169 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 7.43673354...'model': 'resnet18', 'proxy_image_weight': '0.1'}\u001b[0m\n",
      "\u001b[2m01:08:43.009229 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'proxy_threshold/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.009285 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.009347 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.009405 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.009452 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.009500 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 7.43673354..._image_weight': '0.1', 'proxy_threshold': '0.85'}\u001b[0m\n",
      "\u001b[2m01:08:43.009564 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'gradient_method/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.009620 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.009680 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.009758 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.009832 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.009897 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 7.43673354...d': '0.85', 'gradient_method': 'gradcamplusplus'}\u001b[0m\n",
      "\u001b[2m01:08:43.009962 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'ds_name/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.010022 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.010085 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.010149 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.010209 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.010257 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 7.43673354...ent_method': 'gradcamplusplus', 'ds_name': 'asl'}\u001b[0m\n",
      "\u001b[2m01:08:43.010319 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'clear_every_step/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.010374 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.010465 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.010521 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.010565 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.010608 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 7.43673354...s', 'ds_name': 'asl', 'clear_every_step': 'True'}\u001b[0m\n",
      "\u001b[2m01:08:43.010665 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'fname_start/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.010717 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.010772 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.010830 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.010878 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.010923 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 7.43673354..._datasets/src/runs/baseline_run_26032023_134035'}\u001b[0m\n",
      "\u001b[2m01:08:43.010980 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'ds_path/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.011044 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.011103 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.011152 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.011212 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.011261 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 7.43673354...asets/asl/asl_alphabet_train/asl_alphabet_train'}\u001b[0m\n",
      "\u001b[2m01:08:43.011308 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'name_fn/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.011375 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.011438 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.011486 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.011548 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.011597 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 7.43673354...: '<function get_parent_name at 0x7f92835bfa30>'}\u001b[0m\n",
      "\u001b[2m01:08:43.011644 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'global_run_count/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.011708 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.011767 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.011814 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.011870 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.011924 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[2m01:08:43.011969 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'writer/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.012011 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.012086 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.012135 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.012183 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.012243 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 7.43673354....writer.SummaryWriter object at 0x7f937061aa40>'}\u001b[0m\n",
      "\u001b[2m01:08:43.012292 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'label_map/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.012346 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.012422 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.012473 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.012521 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.012567 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 7.43673354...P', 16: 'Q', 17: 'U', 18: 'del', 19: 'nothing'}\"}\u001b[0m\n",
      "\u001b[2m01:08:43.012639 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'rev_label_map/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.012715 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.012793 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.012856 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.012906 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.012951 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 7.43673354...15, 'Q': 16, 'U': 17, 'del': 18, 'nothing': 19}\"}\u001b[0m\n",
      "\u001b[2m01:08:43.013003 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'num_classes/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.013062 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.013127 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.013188 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.013243 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.013290 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 7.43673354... 'del': 18, 'nothing': 19}\", 'num_classes': '20'}\u001b[0m\n",
      "\u001b[2m01:08:43.013336 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'dataset_sizes/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.013402 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.013465 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.013514 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.013576 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.013624 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 7.43673354...dataset_sizes': \"{'train': 10000, 'val': 10000}\"}\u001b[0m\n",
      "\u001b[2m01:08:43.013671 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'criterion/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.013757 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.013820 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.013871 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.013933 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.013982 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 7.43673354...val': 10000}\", 'criterion': 'CrossEntropyLoss()'}\u001b[0m\n",
      "\u001b[2m01:08:43.014029 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'cam/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.014097 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.014159 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.014206 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.014269 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.014318 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 7.43673354...splus.GradCAMPlusPlus object at 0x7f9274c95660>'}\u001b[0m\n",
      "\u001b[2m01:08:43.014364 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'save_path/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.014434 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.014498 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.014547 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.014612 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.014664 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 7.43673354...rc/runs/baseline_run_26032023_134035/checkpoint'}\u001b[0m\n",
      "\u001b[2m01:08:43.014712 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'final_acc/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.014770 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.014843 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.014893 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.014943 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.015005 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 7.43673354...6032023_134035/checkpoint', 'final_acc': '100.0'}\u001b[0m\n",
      "\u001b[2m01:08:43.015054 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[2m01:08:43.015116 line        85\u001b[0m         if tag == \"images\" and save_ims == True:\n",
      "\u001b[2m01:08:43.015171 line        46\u001b[0m     for tag in all_tags.keys():\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtag = 'graph'\u001b[0m\n",
      "\u001b[2m01:08:43.015240 line        47\u001b[0m         if tag == \"scalars\":\n",
      "\u001b[2m01:08:43.015308 line        59\u001b[0m         if tag == \"tensors\":\n",
      "\u001b[2m01:08:43.015357 line        85\u001b[0m         if tag == \"images\" and save_ims == True:\n",
      "\u001b[2m01:08:43.015404 line        46\u001b[0m     for tag in all_tags.keys():\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtag = 'meta_graph'\u001b[0m\n",
      "\u001b[2m01:08:43.015450 line        47\u001b[0m         if tag == \"scalars\":\n",
      "\u001b[2m01:08:43.015511 line        59\u001b[0m         if tag == \"tensors\":\n",
      "\u001b[2m01:08:43.015558 line        85\u001b[0m         if tag == \"images\" and save_ims == True:\n",
      "\u001b[2m01:08:43.015604 line        46\u001b[0m     for tag in all_tags.keys():\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtag = 'run_metadata'\u001b[0m\n",
      "\u001b[2m01:08:43.015650 line        47\u001b[0m         if tag == \"scalars\":\n",
      "\u001b[2m01:08:43.015705 line        59\u001b[0m         if tag == \"tensors\":\n",
      "\u001b[2m01:08:43.015761 line        85\u001b[0m         if tag == \"images\" and save_ims == True:\n",
      "\u001b[2m01:08:43.015819 line        46\u001b[0m     for tag in all_tags.keys():\n",
      "\u001b[2m01:08:43.015883 line        96\u001b[0m     return temp_dict\n",
      "\u001b[2m01:08:43.015959 return      96\u001b[0m     return temp_dict\n",
      "\u001b[36m\u001b[2mReturn value:.. \u001b[22m{'proxy_step': 'False', 'Loss/Train': 7.43673354...6032023_134035/checkpoint', 'final_acc': '100.0'}\u001b[0m\n",
      "\u001b[33m\u001b[2mElapsed time: \u001b[22m00:00:00.014314\u001b[0m\n",
      "runs/baseline_run_26032023_135310/events.out.tfevents.1679831590.eragon\n",
      "\u001b[32m\u001b[2mStarting var:.. \u001b[22mevent_acc = <tensorboard.backend.event_processing.event_accumulator.EventAccumulator object at 0x7f5b568ee230>\u001b[0m\n",
      "\u001b[32m\u001b[2mStarting var:.. \u001b[22msave_ims = False\u001b[0m\n",
      "\u001b[2m01:08:43.023748 call        42\u001b[0m def process_event_acc(event_acc, save_ims = False):\n",
      "\u001b[2m01:08:43.023827 line        44\u001b[0m     all_tags = event_acc.Tags()\n",
      "\u001b[32m\u001b[2mNew var:....... \u001b[22mall_tags = {'images': [], 'audio': [], 'histograms': [], 's...: False, 'meta_graph': False, 'run_metadata': []}\u001b[0m\n",
      "\u001b[2m01:08:43.023869 line        45\u001b[0m     temp_dict = {}\n",
      "\u001b[32m\u001b[2mNew var:....... \u001b[22mtemp_dict = {}\u001b[0m\n",
      "\u001b[2m01:08:43.023960 line        46\u001b[0m     for tag in all_tags.keys():\n",
      "\u001b[32m\u001b[2mNew var:....... \u001b[22mtag = 'images'\u001b[0m\n",
      "\u001b[2m01:08:43.024000 line        47\u001b[0m         if tag == \"scalars\":\n",
      "\u001b[2m01:08:43.024038 line        59\u001b[0m         if tag == \"tensors\":\n",
      "\u001b[2m01:08:43.024069 line        85\u001b[0m         if tag == \"images\" and save_ims == True:\n",
      "\u001b[2m01:08:43.024098 line        46\u001b[0m     for tag in all_tags.keys():\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtag = 'audio'\u001b[0m\n",
      "\u001b[2m01:08:43.024126 line        47\u001b[0m         if tag == \"scalars\":\n",
      "\u001b[2m01:08:43.024160 line        59\u001b[0m         if tag == \"tensors\":\n",
      "\u001b[2m01:08:43.024187 line        85\u001b[0m         if tag == \"images\" and save_ims == True:\n",
      "\u001b[2m01:08:43.024214 line        46\u001b[0m     for tag in all_tags.keys():\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtag = 'histograms'\u001b[0m\n",
      "\u001b[2m01:08:43.024241 line        47\u001b[0m         if tag == \"scalars\":\n",
      "\u001b[2m01:08:43.024272 line        59\u001b[0m         if tag == \"tensors\":\n",
      "\u001b[2m01:08:43.024299 line        85\u001b[0m         if tag == \"images\" and save_ims == True:\n",
      "\u001b[2m01:08:43.024326 line        46\u001b[0m     for tag in all_tags.keys():\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtag = 'scalars'\u001b[0m\n",
      "\u001b[2m01:08:43.024354 line        47\u001b[0m         if tag == \"scalars\":\n",
      "\u001b[2m01:08:43.024387 line        48\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mNew var:....... \u001b[22msubtag = 'proxy_step'\u001b[0m\n",
      "\u001b[2m01:08:43.024416 line        50\u001b[0m                 try:\n",
      "\u001b[2m01:08:43.024451 line        51\u001b[0m                     temp_dict[subtag] = [tag[-1] for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.024492 exception   51\u001b[0m                     temp_dict[subtag] = [tag[-1] for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[31mException:..... \u001b[1mTypeError: 'ScalarEvent' object is not subscriptable\u001b[0m\n",
      "\u001b[2m01:08:43.024557 line        54\u001b[0m                 except:\n",
      "\u001b[2m01:08:43.024607 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.024650 line        56\u001b[0m                     -1\n",
      "\u001b[2m01:08:43.024681 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.024710 line        57\u001b[0m                 ].value\n",
      "\u001b[2m01:08:43.024740 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0}\u001b[0m\n",
      "\u001b[2m01:08:43.024770 line        48\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'Loss/Train'\u001b[0m\n",
      "\u001b[2m01:08:43.024807 line        50\u001b[0m                 try:\n",
      "\u001b[2m01:08:43.024841 line        51\u001b[0m                     temp_dict[subtag] = [tag[-1] for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.024881 exception   51\u001b[0m                     temp_dict[subtag] = [tag[-1] for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[31mException:..... \u001b[1mTypeError: 'ScalarEvent' object is not subscriptable\u001b[0m\n",
      "\u001b[2m01:08:43.024933 line        54\u001b[0m                 except:\n",
      "\u001b[2m01:08:43.024966 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.025004 line        56\u001b[0m                     -1\n",
      "\u001b[2m01:08:43.025035 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.025065 line        57\u001b[0m                 ].value\n",
      "\u001b[2m01:08:43.025094 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 0.0001120001616072841}\u001b[0m\n",
      "\u001b[2m01:08:43.025124 line        48\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'Acc/Train'\u001b[0m\n",
      "\u001b[2m01:08:43.025162 line        50\u001b[0m                 try:\n",
      "\u001b[2m01:08:43.025197 line        51\u001b[0m                     temp_dict[subtag] = [tag[-1] for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.025234 exception   51\u001b[0m                     temp_dict[subtag] = [tag[-1] for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[31mException:..... \u001b[1mTypeError: 'ScalarEvent' object is not subscriptable\u001b[0m\n",
      "\u001b[2m01:08:43.025284 line        54\u001b[0m                 except:\n",
      "\u001b[2m01:08:43.025318 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.025357 line        56\u001b[0m                     -1\n",
      "\u001b[2m01:08:43.025388 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.025418 line        57\u001b[0m                 ].value\n",
      "\u001b[2m01:08:43.025449 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 0.0001120001616072841, 'Acc/Train': 99.87328338623047}\u001b[0m\n",
      "\u001b[2m01:08:43.025480 line        48\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'global_run_count'\u001b[0m\n",
      "\u001b[2m01:08:43.025518 line        50\u001b[0m                 try:\n",
      "\u001b[2m01:08:43.025555 line        51\u001b[0m                     temp_dict[subtag] = [tag[-1] for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.025594 exception   51\u001b[0m                     temp_dict[subtag] = [tag[-1] for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[31mException:..... \u001b[1mTypeError: 'ScalarEvent' object is not subscriptable\u001b[0m\n",
      "\u001b[2m01:08:43.025644 line        54\u001b[0m                 except:\n",
      "\u001b[2m01:08:43.025678 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.025719 line        56\u001b[0m                     -1\n",
      "\u001b[2m01:08:43.025752 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.025783 line        57\u001b[0m                 ].value\n",
      "\u001b[2m01:08:43.025814 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 0.000112000161...in': 99.87328338623047, 'global_run_count': 20.0}\u001b[0m\n",
      "\u001b[2m01:08:43.025846 line        48\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'Loss/Val'\u001b[0m\n",
      "\u001b[2m01:08:43.025905 line        50\u001b[0m                 try:\n",
      "\u001b[2m01:08:43.025944 line        51\u001b[0m                     temp_dict[subtag] = [tag[-1] for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.025983 exception   51\u001b[0m                     temp_dict[subtag] = [tag[-1] for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[31mException:..... \u001b[1mTypeError: 'ScalarEvent' object is not subscriptable\u001b[0m\n",
      "\u001b[2m01:08:43.026034 line        54\u001b[0m                 except:\n",
      "\u001b[2m01:08:43.026069 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.026109 line        56\u001b[0m                     -1\n",
      "\u001b[2m01:08:43.026142 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.026174 line        57\u001b[0m                 ].value\n",
      "\u001b[2m01:08:43.026205 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 0.000112000161...n_count': 20.0, 'Loss/Val': 0.003803000785410404}\u001b[0m\n",
      "\u001b[2m01:08:43.026237 line        48\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'Acc/Val'\u001b[0m\n",
      "\u001b[2m01:08:43.026275 line        50\u001b[0m                 try:\n",
      "\u001b[2m01:08:43.026313 line        51\u001b[0m                     temp_dict[subtag] = [tag[-1] for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.026352 exception   51\u001b[0m                     temp_dict[subtag] = [tag[-1] for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[31mException:..... \u001b[1mTypeError: 'ScalarEvent' object is not subscriptable\u001b[0m\n",
      "\u001b[2m01:08:43.026403 line        54\u001b[0m                 except:\n",
      "\u001b[2m01:08:43.026438 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.026478 line        56\u001b[0m                     -1\n",
      "\u001b[2m01:08:43.026511 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.026543 line        57\u001b[0m                 ].value\n",
      "\u001b[2m01:08:43.026575 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 0.000112000161...003803000785410404, 'Acc/Val': 93.40937805175781}\u001b[0m\n",
      "\u001b[2m01:08:43.026608 line        48\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[2m01:08:43.026648 line        59\u001b[0m         if tag == \"tensors\":\n",
      "\u001b[2m01:08:43.026682 line        85\u001b[0m         if tag == \"images\" and save_ims == True:\n",
      "\u001b[2m01:08:43.026718 line        46\u001b[0m     for tag in all_tags.keys():\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtag = 'distributions'\u001b[0m\n",
      "\u001b[2m01:08:43.026751 line        47\u001b[0m         if tag == \"scalars\":\n",
      "\u001b[2m01:08:43.026789 line        59\u001b[0m         if tag == \"tensors\":\n",
      "\u001b[2m01:08:43.026821 line        85\u001b[0m         if tag == \"images\" and save_ims == True:\n",
      "\u001b[2m01:08:43.026854 line        46\u001b[0m     for tag in all_tags.keys():\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtag = 'tensors'\u001b[0m\n",
      "\u001b[2m01:08:43.026887 line        47\u001b[0m         if tag == \"scalars\":\n",
      "\u001b[2m01:08:43.026924 line        59\u001b[0m         if tag == \"tensors\":\n",
      "\u001b[2m01:08:43.026956 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'experiment_name/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.026989 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.027034 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.027088 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.027127 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.027161 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 0.000112000161...0937805175781, 'experiment_name': 'baseline_run'}\u001b[0m\n",
      "\u001b[2m01:08:43.027196 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'image_size/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.027235 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.027280 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.027316 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.027351 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.027384 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 0.000112000161...iment_name': 'baseline_run', 'image_size': '224'}\u001b[0m\n",
      "\u001b[2m01:08:43.027418 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'batch_size/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.027458 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.027502 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.027538 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.027572 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.027616 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 0.000112000161...ne_run', 'image_size': '224', 'batch_size': '64'}\u001b[0m\n",
      "\u001b[2m01:08:43.027650 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'enable_proxy_attention/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.027689 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.027734 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.027770 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.027805 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.027839 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 0.000112000161...ch_size': '64', 'enable_proxy_attention': 'True'}\u001b[0m\n",
      "\u001b[2m01:08:43.027872 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'transfer_imagenet/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.027911 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.027956 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.027992 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.028027 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.028061 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 0.000112000161..._attention': 'True', 'transfer_imagenet': 'True'}\u001b[0m\n",
      "\u001b[2m01:08:43.028095 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'subset_images/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.028135 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.028181 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.028216 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.028251 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.028285 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 0.000112000161...sfer_imagenet': 'True', 'subset_images': '20000'}\u001b[0m\n",
      "\u001b[2m01:08:43.028319 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'pixel_replacement_method/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.028358 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.028402 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.028438 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.028473 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.028508 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 0.000112000161...: '20000', 'pixel_replacement_method': 'blended'}\u001b[0m\n",
      "\u001b[2m01:08:43.028542 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'proxy_steps/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.028580 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.028625 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.028660 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.028695 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.028729 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 0.000112000161...cement_method': 'blended', 'proxy_steps': '[20]'}\u001b[0m\n",
      "\u001b[2m01:08:43.028767 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'load_proxy_data/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.028807 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.028852 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.028888 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.028923 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.028957 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 0.000112000161...proxy_steps': '[20]', 'load_proxy_data': 'False'}\u001b[0m\n",
      "\u001b[2m01:08:43.028991 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'proxy_step/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.029031 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.029077 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.029113 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.029148 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.029182 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.00011200...proxy_steps': '[20]', 'load_proxy_data': 'False'}\u001b[0m\n",
      "\u001b[2m01:08:43.029216 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'log_every/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.029255 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.029300 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.029336 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.029393 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.029441 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.00011200...]', 'load_proxy_data': 'False', 'log_every': '2'}\u001b[0m\n",
      "\u001b[2m01:08:43.029477 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'device/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.029518 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.029564 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.029601 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.029638 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.029673 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.00011200...': 'False', 'log_every': '2', 'device': 'cuda:0'}\u001b[0m\n",
      "\u001b[2m01:08:43.029707 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'dataset_info/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.029748 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.029794 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.029830 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.029867 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.029909 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.00011200...t_name at 0x7fd873f9fa30>, 'num_classes': 101}}\"}\u001b[0m\n",
      "\u001b[2m01:08:43.029944 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'main_run_dir/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.029992 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.030044 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.030087 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.030130 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.030171 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.00011200...DE/Github/improving_robotics_datasets/src/runs/'}\u001b[0m\n",
      "\u001b[2m01:08:43.030211 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'change_subset_attention/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.030257 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.030310 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.030352 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.030417 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.030464 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.00011200...ets/src/runs/', 'change_subset_attention': '0.8'}\u001b[0m\n",
      "\u001b[2m01:08:43.030506 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'model/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.030554 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.030608 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.030650 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.030693 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.030734 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.00011200...ge_subset_attention': '0.8', 'model': 'resnet18'}\u001b[0m\n",
      "\u001b[2m01:08:43.030775 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'proxy_image_weight/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.030821 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.030873 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.030916 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.030959 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.031000 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.00011200...'model': 'resnet18', 'proxy_image_weight': '0.1'}\u001b[0m\n",
      "\u001b[2m01:08:43.031041 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'proxy_threshold/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.031088 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.031140 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.031183 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.031225 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.031266 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.00011200..._image_weight': '0.1', 'proxy_threshold': '0.85'}\u001b[0m\n",
      "\u001b[2m01:08:43.031307 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'gradient_method/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.031353 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.031406 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.031477 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.031521 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.031562 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.00011200...d': '0.85', 'gradient_method': 'gradcamplusplus'}\u001b[0m\n",
      "\u001b[2m01:08:43.031605 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'ds_name/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.031652 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.031818 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.031868 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.031917 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.031959 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.00011200...hod': 'gradcamplusplus', 'ds_name': 'imagenette'}\u001b[0m\n",
      "\u001b[2m01:08:43.032003 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'clear_every_step/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.032049 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.032103 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.032147 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.032190 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.032232 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.00011200..._name': 'imagenette', 'clear_every_step': 'True'}\u001b[0m\n",
      "\u001b[2m01:08:43.032274 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'fname_start/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.032321 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.032375 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.032418 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.032461 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.032503 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.00011200..._datasets/src/runs/baseline_run_26032023_135310'}\u001b[0m\n",
      "\u001b[2m01:08:43.032544 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'ds_path/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.032591 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.032645 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.032689 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.032731 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.032774 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.00011200...media/eragon/HDD/Datasets/imagenette2-320/train'}\u001b[0m\n",
      "\u001b[2m01:08:43.032816 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'name_fn/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.032879 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.032936 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.032980 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.033024 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.033067 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.00011200...: '<function get_parent_name at 0x7fd873f9fa30>'}\u001b[0m\n",
      "\u001b[2m01:08:43.033109 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'global_run_count/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.033157 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.033218 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.033264 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.033308 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.033351 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[2m01:08:43.033392 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'writer/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.033434 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.033489 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.033533 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.033577 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.033619 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.00011200....writer.SummaryWriter object at 0x7fd961116aa0>'}\u001b[0m\n",
      "\u001b[2m01:08:43.033662 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'label_map/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.033710 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.033785 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.033831 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.033875 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.033919 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.00011200...7: 'n03425413', 8: 'n03445777', 9: 'n03888257'}\"}\u001b[0m\n",
      "\u001b[2m01:08:43.033963 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'rev_label_map/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.034012 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.034067 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.034112 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.034158 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.034202 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.00011200...'n03425413': 7, 'n03445777': 8, 'n03888257': 9}\"}\u001b[0m\n",
      "\u001b[2m01:08:43.034271 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'num_classes/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.034321 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.034377 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.034423 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.034467 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.034512 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.00011200...45777': 8, 'n03888257': 9}\", 'num_classes': '10'}\u001b[0m\n",
      "\u001b[2m01:08:43.034556 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'dataset_sizes/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.034605 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.034660 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.034706 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.034751 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.034795 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.00011200... 'dataset_sizes': \"{'train': 4735, 'val': 4734}\"}\u001b[0m\n",
      "\u001b[2m01:08:43.034839 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'criterion/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.034889 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.034946 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.034992 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.035038 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.035083 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.00011200...'val': 4734}\", 'criterion': 'CrossEntropyLoss()'}\u001b[0m\n",
      "\u001b[2m01:08:43.035127 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'cam/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.035177 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.035237 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.035283 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.035328 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.035373 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.00011200...splus.GradCAMPlusPlus object at 0x7fd8663bcf10>'}\u001b[0m\n",
      "\u001b[2m01:08:43.035418 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'save_path/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.035468 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.035524 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.035571 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.035617 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.035662 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.00011200...rc/runs/baseline_run_26032023_135310/checkpoint'}\u001b[0m\n",
      "\u001b[2m01:08:43.035707 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'final_acc/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.035757 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.035815 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.035862 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.035909 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.035988 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.00011200...10/checkpoint', 'final_acc': '93.40937896070976'}\u001b[0m\n",
      "\u001b[2m01:08:43.036034 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[2m01:08:43.036085 line        85\u001b[0m         if tag == \"images\" and save_ims == True:\n",
      "\u001b[2m01:08:43.036131 line        46\u001b[0m     for tag in all_tags.keys():\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtag = 'graph'\u001b[0m\n",
      "\u001b[2m01:08:43.036178 line        47\u001b[0m         if tag == \"scalars\":\n",
      "\u001b[2m01:08:43.036230 line        59\u001b[0m         if tag == \"tensors\":\n",
      "\u001b[2m01:08:43.036275 line        85\u001b[0m         if tag == \"images\" and save_ims == True:\n",
      "\u001b[2m01:08:43.036321 line        46\u001b[0m     for tag in all_tags.keys():\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtag = 'meta_graph'\u001b[0m\n",
      "\u001b[2m01:08:43.036365 line        47\u001b[0m         if tag == \"scalars\":\n",
      "\u001b[2m01:08:43.036415 line        59\u001b[0m         if tag == \"tensors\":\n",
      "\u001b[2m01:08:43.036460 line        85\u001b[0m         if tag == \"images\" and save_ims == True:\n",
      "\u001b[2m01:08:43.036505 line        46\u001b[0m     for tag in all_tags.keys():\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtag = 'run_metadata'\u001b[0m\n",
      "\u001b[2m01:08:43.036549 line        47\u001b[0m         if tag == \"scalars\":\n",
      "\u001b[2m01:08:43.036599 line        59\u001b[0m         if tag == \"tensors\":\n",
      "\u001b[2m01:08:43.036643 line        85\u001b[0m         if tag == \"images\" and save_ims == True:\n",
      "\u001b[2m01:08:43.036688 line        46\u001b[0m     for tag in all_tags.keys():\n",
      "\u001b[2m01:08:43.036732 line        96\u001b[0m     return temp_dict\n",
      "\u001b[2m01:08:43.036779 return      96\u001b[0m     return temp_dict\n",
      "\u001b[36m\u001b[2mReturn value:.. \u001b[22m{'proxy_step': 'False', 'Loss/Train': 0.00011200...10/checkpoint', 'final_acc': '93.40937896070976'}\u001b[0m\n",
      "\u001b[33m\u001b[2mElapsed time: \u001b[22m00:00:00.013150\u001b[0m\n",
      " 17%|███████▌                                    | 5/29 [00:00<00:00, 42.07it/s]runs/baseline_run_26032023_190957/events.out.tfevents.1679850602.eragon\n",
      "\u001b[32m\u001b[2mStarting var:.. \u001b[22mevent_acc = <tensorboard.backend.event_processing.event_accumulator.EventAccumulator object at 0x7f5b568ee4a0>\u001b[0m\n",
      "\u001b[32m\u001b[2mStarting var:.. \u001b[22msave_ims = False\u001b[0m\n",
      "\u001b[2m01:08:43.045140 call        42\u001b[0m def process_event_acc(event_acc, save_ims = False):\n",
      "\u001b[2m01:08:43.045219 line        44\u001b[0m     all_tags = event_acc.Tags()\n",
      "\u001b[32m\u001b[2mNew var:....... \u001b[22mall_tags = {'images': [], 'audio': [], 'histograms': [], 's...: False, 'meta_graph': False, 'run_metadata': []}\u001b[0m\n",
      "\u001b[2m01:08:43.045263 line        45\u001b[0m     temp_dict = {}\n",
      "\u001b[32m\u001b[2mNew var:....... \u001b[22mtemp_dict = {}\u001b[0m\n",
      "\u001b[2m01:08:43.045907 line        46\u001b[0m     for tag in all_tags.keys():\n",
      "\u001b[32m\u001b[2mNew var:....... \u001b[22mtag = 'images'\u001b[0m\n",
      "\u001b[2m01:08:43.045955 line        47\u001b[0m         if tag == \"scalars\":\n",
      "\u001b[2m01:08:43.045995 line        59\u001b[0m         if tag == \"tensors\":\n",
      "\u001b[2m01:08:43.046026 line        85\u001b[0m         if tag == \"images\" and save_ims == True:\n",
      "\u001b[2m01:08:43.046055 line        46\u001b[0m     for tag in all_tags.keys():\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtag = 'audio'\u001b[0m\n",
      "\u001b[2m01:08:43.046083 line        47\u001b[0m         if tag == \"scalars\":\n",
      "\u001b[2m01:08:43.046116 line        59\u001b[0m         if tag == \"tensors\":\n",
      "\u001b[2m01:08:43.046144 line        85\u001b[0m         if tag == \"images\" and save_ims == True:\n",
      "\u001b[2m01:08:43.046171 line        46\u001b[0m     for tag in all_tags.keys():\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtag = 'histograms'\u001b[0m\n",
      "\u001b[2m01:08:43.046198 line        47\u001b[0m         if tag == \"scalars\":\n",
      "\u001b[2m01:08:43.046231 line        59\u001b[0m         if tag == \"tensors\":\n",
      "\u001b[2m01:08:43.046258 line        85\u001b[0m         if tag == \"images\" and save_ims == True:\n",
      "\u001b[2m01:08:43.046286 line        46\u001b[0m     for tag in all_tags.keys():\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtag = 'scalars'\u001b[0m\n",
      "\u001b[2m01:08:43.046318 line        47\u001b[0m         if tag == \"scalars\":\n",
      "\u001b[2m01:08:43.046353 line        48\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mNew var:....... \u001b[22msubtag = 'proxy_step'\u001b[0m\n",
      "\u001b[2m01:08:43.046381 line        50\u001b[0m                 try:\n",
      "\u001b[2m01:08:43.046417 line        51\u001b[0m                     temp_dict[subtag] = [tag[-1] for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.046457 exception   51\u001b[0m                     temp_dict[subtag] = [tag[-1] for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[31mException:..... \u001b[1mTypeError: 'ScalarEvent' object is not subscriptable\u001b[0m\n",
      "\u001b[2m01:08:43.046519 line        54\u001b[0m                 except:\n",
      "\u001b[2m01:08:43.046552 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.046593 line        56\u001b[0m                     -1\n",
      "\u001b[2m01:08:43.046624 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.046653 line        57\u001b[0m                 ].value\n",
      "\u001b[2m01:08:43.046683 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0}\u001b[0m\n",
      "\u001b[2m01:08:43.046712 line        48\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'Loss/Train'\u001b[0m\n",
      "\u001b[2m01:08:43.046748 line        50\u001b[0m                 try:\n",
      "\u001b[2m01:08:43.046783 line        51\u001b[0m                     temp_dict[subtag] = [tag[-1] for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.046819 exception   51\u001b[0m                     temp_dict[subtag] = [tag[-1] for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[31mException:..... \u001b[1mTypeError: 'ScalarEvent' object is not subscriptable\u001b[0m\n",
      "\u001b[2m01:08:43.046889 line        54\u001b[0m                 except:\n",
      "\u001b[2m01:08:43.046924 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.046963 line        56\u001b[0m                     -1\n",
      "\u001b[2m01:08:43.046993 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.047024 line        57\u001b[0m                 ].value\n",
      "\u001b[2m01:08:43.047070 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 6.579648470506072e-05}\u001b[0m\n",
      "\u001b[2m01:08:43.047108 line        48\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'Acc/Train'\u001b[0m\n",
      "\u001b[2m01:08:43.047148 line        50\u001b[0m                 try:\n",
      "\u001b[2m01:08:43.047185 line        51\u001b[0m                     temp_dict[subtag] = [tag[-1] for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.047225 exception   51\u001b[0m                     temp_dict[subtag] = [tag[-1] for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[31mException:..... \u001b[1mTypeError: 'ScalarEvent' object is not subscriptable\u001b[0m\n",
      "\u001b[2m01:08:43.047277 line        54\u001b[0m                 except:\n",
      "\u001b[2m01:08:43.047310 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.047349 line        56\u001b[0m                     -1\n",
      "\u001b[2m01:08:43.047380 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.047412 line        57\u001b[0m                 ].value\n",
      "\u001b[2m01:08:43.047442 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 6.579648470506072e-05, 'Acc/Train': 99.94999694824219}\u001b[0m\n",
      "\u001b[2m01:08:43.047473 line        48\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'global_run_count'\u001b[0m\n",
      "\u001b[2m01:08:43.047511 line        50\u001b[0m                 try:\n",
      "\u001b[2m01:08:43.047547 line        51\u001b[0m                     temp_dict[subtag] = [tag[-1] for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.047586 exception   51\u001b[0m                     temp_dict[subtag] = [tag[-1] for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[31mException:..... \u001b[1mTypeError: 'ScalarEvent' object is not subscriptable\u001b[0m\n",
      "\u001b[2m01:08:43.047638 line        54\u001b[0m                 except:\n",
      "\u001b[2m01:08:43.047671 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.047711 line        56\u001b[0m                     -1\n",
      "\u001b[2m01:08:43.047743 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.047775 line        57\u001b[0m                 ].value\n",
      "\u001b[2m01:08:43.047807 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 6.579648470506...in': 99.94999694824219, 'global_run_count': 20.0}\u001b[0m\n",
      "\u001b[2m01:08:43.047838 line        48\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'Loss/Val'\u001b[0m\n",
      "\u001b[2m01:08:43.047876 line        50\u001b[0m                 try:\n",
      "\u001b[2m01:08:43.047939 line        51\u001b[0m                     temp_dict[subtag] = [tag[-1] for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.047979 exception   51\u001b[0m                     temp_dict[subtag] = [tag[-1] for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[31mException:..... \u001b[1mTypeError: 'ScalarEvent' object is not subscriptable\u001b[0m\n",
      "\u001b[2m01:08:43.048032 line        54\u001b[0m                 except:\n",
      "\u001b[2m01:08:43.048066 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.048106 line        56\u001b[0m                     -1\n",
      "\u001b[2m01:08:43.048139 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.048171 line        57\u001b[0m                 ].value\n",
      "\u001b[2m01:08:43.048204 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 6.579648470506...n_count': 20.0, 'Loss/Val': 0.019909845665097237}\u001b[0m\n",
      "\u001b[2m01:08:43.048236 line        48\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'Acc/Val'\u001b[0m\n",
      "\u001b[2m01:08:43.048275 line        50\u001b[0m                 try:\n",
      "\u001b[2m01:08:43.048312 line        51\u001b[0m                     temp_dict[subtag] = [tag[-1] for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.048354 exception   51\u001b[0m                     temp_dict[subtag] = [tag[-1] for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[31mException:..... \u001b[1mTypeError: 'ScalarEvent' object is not subscriptable\u001b[0m\n",
      "\u001b[2m01:08:43.048406 line        54\u001b[0m                 except:\n",
      "\u001b[2m01:08:43.048455 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.048496 line        56\u001b[0m                     -1\n",
      "\u001b[2m01:08:43.048531 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.048564 line        57\u001b[0m                 ].value\n",
      "\u001b[2m01:08:43.048596 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 6.579648470506...019909845665097237, 'Acc/Val': 73.31999969482422}\u001b[0m\n",
      "\u001b[2m01:08:43.048629 line        48\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[2m01:08:43.048668 line        59\u001b[0m         if tag == \"tensors\":\n",
      "\u001b[2m01:08:43.048702 line        85\u001b[0m         if tag == \"images\" and save_ims == True:\n",
      "\u001b[2m01:08:43.048742 line        46\u001b[0m     for tag in all_tags.keys():\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtag = 'distributions'\u001b[0m\n",
      "\u001b[2m01:08:43.048775 line        47\u001b[0m         if tag == \"scalars\":\n",
      "\u001b[2m01:08:43.048814 line        59\u001b[0m         if tag == \"tensors\":\n",
      "\u001b[2m01:08:43.048846 line        85\u001b[0m         if tag == \"images\" and save_ims == True:\n",
      "\u001b[2m01:08:43.048878 line        46\u001b[0m     for tag in all_tags.keys():\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtag = 'tensors'\u001b[0m\n",
      "\u001b[2m01:08:43.048910 line        47\u001b[0m         if tag == \"scalars\":\n",
      "\u001b[2m01:08:43.048948 line        59\u001b[0m         if tag == \"tensors\":\n",
      "\u001b[2m01:08:43.048981 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'experiment_name/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.049013 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.049060 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.049099 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.049138 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.049175 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 6.579648470506...1999969482422, 'experiment_name': 'baseline_run'}\u001b[0m\n",
      "\u001b[2m01:08:43.049209 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'image_size/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.049249 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.049297 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.049336 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.049374 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.049408 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 6.579648470506...iment_name': 'baseline_run', 'image_size': '224'}\u001b[0m\n",
      "\u001b[2m01:08:43.049442 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'batch_size/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.049484 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.049534 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.049571 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.049607 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.049641 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 6.579648470506...ne_run', 'image_size': '224', 'batch_size': '64'}\u001b[0m\n",
      "\u001b[2m01:08:43.049675 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'enable_proxy_attention/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.049735 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.049782 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.049818 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.049855 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.049889 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 6.579648470506...ch_size': '64', 'enable_proxy_attention': 'True'}\u001b[0m\n",
      "\u001b[2m01:08:43.049923 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'transfer_imagenet/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.049962 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.050006 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.050042 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.050078 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.050112 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 6.579648470506..._attention': 'True', 'transfer_imagenet': 'True'}\u001b[0m\n",
      "\u001b[2m01:08:43.050146 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'subset_images/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.050188 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.050235 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.050271 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.050307 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.050341 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 6.579648470506...sfer_imagenet': 'True', 'subset_images': '20000'}\u001b[0m\n",
      "\u001b[2m01:08:43.050375 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'pixel_replacement_method/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.050431 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.050478 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.050515 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.050550 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.050585 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 6.579648470506...: '20000', 'pixel_replacement_method': 'blended'}\u001b[0m\n",
      "\u001b[2m01:08:43.050620 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'proxy_steps/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.050659 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.050705 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.050798 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.050835 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.050873 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 6.579648470506...cement_method': 'blended', 'proxy_steps': '[20]'}\u001b[0m\n",
      "\u001b[2m01:08:43.050932 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'load_proxy_data/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.051000 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.051086 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.051150 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.051196 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.051233 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 6.579648470506...proxy_steps': '[20]', 'load_proxy_data': 'False'}\u001b[0m\n",
      "\u001b[2m01:08:43.051296 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'proxy_step/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.051339 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.051387 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.051425 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.051461 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.051496 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 6.57964847...proxy_steps': '[20]', 'load_proxy_data': 'False'}\u001b[0m\n",
      "\u001b[2m01:08:43.051530 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'log_every/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.051570 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.051617 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.051653 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.051689 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.051723 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 6.57964847...]', 'load_proxy_data': 'False', 'log_every': '2'}\u001b[0m\n",
      "\u001b[2m01:08:43.051759 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'device/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.051799 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.051845 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.051882 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.051917 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.051956 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 6.57964847...': 'False', 'log_every': '2', 'device': 'cuda:0'}\u001b[0m\n",
      "\u001b[2m01:08:43.051992 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'dataset_info/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.052032 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.052078 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.052115 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.052151 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.052187 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 6.57964847...t_name at 0x7f1b73dd3a30>, 'num_classes': 101}}\"}\u001b[0m\n",
      "\u001b[2m01:08:43.052223 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'main_run_dir/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.052269 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.052322 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.052365 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.052406 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.052446 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 6.57964847...DE/Github/improving_robotics_datasets/src/runs/'}\u001b[0m\n",
      "\u001b[2m01:08:43.052486 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'change_subset_attention/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.052533 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.052585 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.052642 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.052684 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.052725 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 6.57964847...ets/src/runs/', 'change_subset_attention': '0.8'}\u001b[0m\n",
      "\u001b[2m01:08:43.052766 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'model/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.052813 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.052866 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.052909 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.052952 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.052993 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 6.57964847...et_attention': '0.8', 'model': 'efficientnet_b0'}\u001b[0m\n",
      "\u001b[2m01:08:43.053033 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'proxy_image_weight/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.053080 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.053132 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.053175 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.053217 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.053258 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 6.57964847...: 'efficientnet_b0', 'proxy_image_weight': '0.1'}\u001b[0m\n",
      "\u001b[2m01:08:43.053300 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'proxy_threshold/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.053347 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.053400 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.053444 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.053488 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.053529 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 6.57964847..._image_weight': '0.1', 'proxy_threshold': '0.85'}\u001b[0m\n",
      "\u001b[2m01:08:43.053571 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'gradient_method/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.053617 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.053671 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.053739 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.053793 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.053835 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 6.57964847...d': '0.85', 'gradient_method': 'gradcamplusplus'}\u001b[0m\n",
      "\u001b[2m01:08:43.053877 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'ds_name/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.053923 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.053977 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.054026 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.054069 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.054111 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 6.57964847...ethod': 'gradcamplusplus', 'ds_name': 'cifar100'}\u001b[0m\n",
      "\u001b[2m01:08:43.054153 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'clear_every_step/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.054200 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.054253 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.054297 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.054341 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.054383 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 6.57964847...ds_name': 'cifar100', 'clear_every_step': 'True'}\u001b[0m\n",
      "\u001b[2m01:08:43.054425 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'fname_start/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.054473 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.054528 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.054573 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.054616 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.054684 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 6.57964847..._datasets/src/runs/baseline_run_26032023_190957'}\u001b[0m\n",
      "\u001b[2m01:08:43.054742 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'ds_path/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.054792 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.054846 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.054891 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.054935 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.054978 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 6.57964847...'/run/media/eragon/HDD/Datasets/CIFAR-100/train'}\u001b[0m\n",
      "\u001b[2m01:08:43.055020 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'name_fn/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.055068 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.055122 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.055166 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.055216 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.055259 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 6.57964847...: '<function get_parent_name at 0x7f1b73dd3a30>'}\u001b[0m\n",
      "\u001b[2m01:08:43.055303 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'global_run_count/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.055356 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.055410 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.055455 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.055500 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.055542 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[2m01:08:43.055585 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'writer/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.055628 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.055682 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.055725 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.055788 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.055833 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 6.57964847....writer.SummaryWriter object at 0x7f1c6141aaa0>'}\u001b[0m\n",
      "\u001b[2m01:08:43.055876 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'label_map/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.055924 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.055979 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.056023 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.056068 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.056112 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 6.57964847...low_tree', 97: 'wolf', 98: 'woman', 99: 'worm'}\"}\u001b[0m\n",
      "\u001b[2m01:08:43.056156 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'rev_label_map/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.056213 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.056276 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.056329 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.056381 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.056433 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 6.57964847...tree': 96, 'wolf': 97, 'woman': 98, 'worm': 99}\"}\u001b[0m\n",
      "\u001b[2m01:08:43.056484 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'num_classes/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.056546 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.056615 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.056674 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.056732 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.056803 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 6.57964847... 'woman': 98, 'worm': 99}\", 'num_classes': '100'}\u001b[0m\n",
      "\u001b[2m01:08:43.056888 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'dataset_sizes/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.056955 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.057029 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.057106 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.057167 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.057224 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 6.57964847...dataset_sizes': \"{'train': 10000, 'val': 10000}\"}\u001b[0m\n",
      "\u001b[2m01:08:43.057283 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'criterion/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.057346 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.057417 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.057479 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.057576 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.057637 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 6.57964847...val': 10000}\", 'criterion': 'CrossEntropyLoss()'}\u001b[0m\n",
      "\u001b[2m01:08:43.057696 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'cam/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.057760 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.057831 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.057971 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.058034 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.058094 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 6.57964847...splus.GradCAMPlusPlus object at 0x7f1b651ebe50>'}\u001b[0m\n",
      "\u001b[2m01:08:43.058153 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'save_path/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.058239 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.058317 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.058379 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.058440 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.058500 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 6.57964847...rc/runs/baseline_run_26032023_190957/checkpoint'}\u001b[0m\n",
      "\u001b[2m01:08:43.058559 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'final_acc/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.058622 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.058694 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.058756 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.058817 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.058886 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 6.57964847...6032023_190957/checkpoint', 'final_acc': '73.32'}\u001b[0m\n",
      "\u001b[2m01:08:43.058946 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[2m01:08:43.059011 line        85\u001b[0m         if tag == \"images\" and save_ims == True:\n",
      "\u001b[2m01:08:43.059070 line        46\u001b[0m     for tag in all_tags.keys():\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtag = 'graph'\u001b[0m\n",
      "\u001b[2m01:08:43.059141 line        47\u001b[0m         if tag == \"scalars\":\n",
      "\u001b[2m01:08:43.059208 line        59\u001b[0m         if tag == \"tensors\":\n",
      "\u001b[2m01:08:43.059267 line        85\u001b[0m         if tag == \"images\" and save_ims == True:\n",
      "\u001b[2m01:08:43.059325 line        46\u001b[0m     for tag in all_tags.keys():\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtag = 'meta_graph'\u001b[0m\n",
      "\u001b[2m01:08:43.059384 line        47\u001b[0m         if tag == \"scalars\":\n",
      "\u001b[2m01:08:43.059447 line        59\u001b[0m         if tag == \"tensors\":\n",
      "\u001b[2m01:08:43.059505 line        85\u001b[0m         if tag == \"images\" and save_ims == True:\n",
      "\u001b[2m01:08:43.059563 line        46\u001b[0m     for tag in all_tags.keys():\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtag = 'run_metadata'\u001b[0m\n",
      "\u001b[2m01:08:43.059621 line        47\u001b[0m         if tag == \"scalars\":\n",
      "\u001b[2m01:08:43.059684 line        59\u001b[0m         if tag == \"tensors\":\n",
      "\u001b[2m01:08:43.059742 line        85\u001b[0m         if tag == \"images\" and save_ims == True:\n",
      "\u001b[2m01:08:43.059801 line        46\u001b[0m     for tag in all_tags.keys():\n",
      "\u001b[2m01:08:43.059858 line        96\u001b[0m     return temp_dict\n",
      "\u001b[2m01:08:43.059918 return      96\u001b[0m     return temp_dict\n",
      "\u001b[36m\u001b[2mReturn value:.. \u001b[22m{'proxy_step': 'False', 'Loss/Train': 6.57964847...6032023_190957/checkpoint', 'final_acc': '73.32'}\u001b[0m\n",
      "\u001b[33m\u001b[2mElapsed time: \u001b[22m00:00:00.014904\u001b[0m\n",
      "runs/baseline_run_26032023_193957/events.out.tfevents.1679852397.eragon\n",
      "\u001b[32m\u001b[2mStarting var:.. \u001b[22mevent_acc = <tensorboard.backend.event_processing.event_accumulator.EventAccumulator object at 0x7f5b568efb80>\u001b[0m\n",
      "\u001b[32m\u001b[2mStarting var:.. \u001b[22msave_ims = False\u001b[0m\n",
      "\u001b[2m01:08:43.068719 call        42\u001b[0m def process_event_acc(event_acc, save_ims = False):\n",
      "\u001b[2m01:08:43.068790 line        44\u001b[0m     all_tags = event_acc.Tags()\n",
      "\u001b[32m\u001b[2mNew var:....... \u001b[22mall_tags = {'images': [], 'audio': [], 'histograms': [], 's...: False, 'meta_graph': False, 'run_metadata': []}\u001b[0m\n",
      "\u001b[2m01:08:43.068831 line        45\u001b[0m     temp_dict = {}\n",
      "\u001b[32m\u001b[2mNew var:....... \u001b[22mtemp_dict = {}\u001b[0m\n",
      "\u001b[2m01:08:43.068917 line        46\u001b[0m     for tag in all_tags.keys():\n",
      "\u001b[32m\u001b[2mNew var:....... \u001b[22mtag = 'images'\u001b[0m\n",
      "\u001b[2m01:08:43.068972 line        47\u001b[0m         if tag == \"scalars\":\n",
      "\u001b[2m01:08:43.069013 line        59\u001b[0m         if tag == \"tensors\":\n",
      "\u001b[2m01:08:43.069043 line        85\u001b[0m         if tag == \"images\" and save_ims == True:\n",
      "\u001b[2m01:08:43.069072 line        46\u001b[0m     for tag in all_tags.keys():\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtag = 'audio'\u001b[0m\n",
      "\u001b[2m01:08:43.069100 line        47\u001b[0m         if tag == \"scalars\":\n",
      "\u001b[2m01:08:43.069133 line        59\u001b[0m         if tag == \"tensors\":\n",
      "\u001b[2m01:08:43.069162 line        85\u001b[0m         if tag == \"images\" and save_ims == True:\n",
      "\u001b[2m01:08:43.069189 line        46\u001b[0m     for tag in all_tags.keys():\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtag = 'histograms'\u001b[0m\n",
      "\u001b[2m01:08:43.069216 line        47\u001b[0m         if tag == \"scalars\":\n",
      "\u001b[2m01:08:43.069253 line        59\u001b[0m         if tag == \"tensors\":\n",
      "\u001b[2m01:08:43.069291 line        85\u001b[0m         if tag == \"images\" and save_ims == True:\n",
      "\u001b[2m01:08:43.069321 line        46\u001b[0m     for tag in all_tags.keys():\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtag = 'scalars'\u001b[0m\n",
      "\u001b[2m01:08:43.069348 line        47\u001b[0m         if tag == \"scalars\":\n",
      "\u001b[2m01:08:43.069381 line        48\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mNew var:....... \u001b[22msubtag = 'proxy_step'\u001b[0m\n",
      "\u001b[2m01:08:43.069408 line        50\u001b[0m                 try:\n",
      "\u001b[2m01:08:43.069443 line        51\u001b[0m                     temp_dict[subtag] = [tag[-1] for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.069484 exception   51\u001b[0m                     temp_dict[subtag] = [tag[-1] for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[31mException:..... \u001b[1mTypeError: 'ScalarEvent' object is not subscriptable\u001b[0m\n",
      "\u001b[2m01:08:43.069545 line        54\u001b[0m                 except:\n",
      "\u001b[2m01:08:43.069583 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.069624 line        56\u001b[0m                     -1\n",
      "\u001b[2m01:08:43.069654 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.069683 line        57\u001b[0m                 ].value\n",
      "\u001b[2m01:08:43.069712 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0}\u001b[0m\n",
      "\u001b[2m01:08:43.069742 line        48\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'Loss/Train'\u001b[0m\n",
      "\u001b[2m01:08:43.069779 line        50\u001b[0m                 try:\n",
      "\u001b[2m01:08:43.069815 line        51\u001b[0m                     temp_dict[subtag] = [tag[-1] for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.069852 exception   51\u001b[0m                     temp_dict[subtag] = [tag[-1] for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[31mException:..... \u001b[1mTypeError: 'ScalarEvent' object is not subscriptable\u001b[0m\n",
      "\u001b[2m01:08:43.069907 line        54\u001b[0m                 except:\n",
      "\u001b[2m01:08:43.069938 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.069976 line        56\u001b[0m                     -1\n",
      "\u001b[2m01:08:43.070006 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.070036 line        57\u001b[0m                 ].value\n",
      "\u001b[2m01:08:43.070065 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 0.00010345811460865662}\u001b[0m\n",
      "\u001b[2m01:08:43.070109 line        48\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'Acc/Train'\u001b[0m\n",
      "\u001b[2m01:08:43.070152 line        50\u001b[0m                 try:\n",
      "\u001b[2m01:08:43.070188 line        51\u001b[0m                     temp_dict[subtag] = [tag[-1] for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.070227 exception   51\u001b[0m                     temp_dict[subtag] = [tag[-1] for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[31mException:..... \u001b[1mTypeError: 'ScalarEvent' object is not subscriptable\u001b[0m\n",
      "\u001b[2m01:08:43.070280 line        54\u001b[0m                 except:\n",
      "\u001b[2m01:08:43.070314 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.070353 line        56\u001b[0m                     -1\n",
      "\u001b[2m01:08:43.070405 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.070443 line        57\u001b[0m                 ].value\n",
      "\u001b[2m01:08:43.070475 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 0.00010345811460865662, 'Acc/Train': 99.8499984741211}\u001b[0m\n",
      "\u001b[2m01:08:43.070507 line        48\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'global_run_count'\u001b[0m\n",
      "\u001b[2m01:08:43.070545 line        50\u001b[0m                 try:\n",
      "\u001b[2m01:08:43.070592 line        51\u001b[0m                     temp_dict[subtag] = [tag[-1] for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.070633 exception   51\u001b[0m                     temp_dict[subtag] = [tag[-1] for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[31mException:..... \u001b[1mTypeError: 'ScalarEvent' object is not subscriptable\u001b[0m\n",
      "\u001b[2m01:08:43.070686 line        54\u001b[0m                 except:\n",
      "\u001b[2m01:08:43.070723 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.070765 line        56\u001b[0m                     -1\n",
      "\u001b[2m01:08:43.070797 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.070829 line        57\u001b[0m                 ].value\n",
      "\u001b[2m01:08:43.070860 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 0.000103458114...ain': 99.8499984741211, 'global_run_count': 20.0}\u001b[0m\n",
      "\u001b[2m01:08:43.070892 line        48\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'Loss/Val'\u001b[0m\n",
      "\u001b[2m01:08:43.070931 line        50\u001b[0m                 try:\n",
      "\u001b[2m01:08:43.070968 line        51\u001b[0m                     temp_dict[subtag] = [tag[-1] for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.071007 exception   51\u001b[0m                     temp_dict[subtag] = [tag[-1] for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[31mException:..... \u001b[1mTypeError: 'ScalarEvent' object is not subscriptable\u001b[0m\n",
      "\u001b[2m01:08:43.071061 line        54\u001b[0m                 except:\n",
      "\u001b[2m01:08:43.071097 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.071137 line        56\u001b[0m                     -1\n",
      "\u001b[2m01:08:43.071170 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.071203 line        57\u001b[0m                 ].value\n",
      "\u001b[2m01:08:43.071235 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 0.000103458114...n_count': 20.0, 'Loss/Val': 0.020691784098744392}\u001b[0m\n",
      "\u001b[2m01:08:43.071268 line        48\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'Acc/Val'\u001b[0m\n",
      "\u001b[2m01:08:43.071308 line        50\u001b[0m                 try:\n",
      "\u001b[2m01:08:43.071348 line        51\u001b[0m                     temp_dict[subtag] = [tag[-1] for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.071399 exception   51\u001b[0m                     temp_dict[subtag] = [tag[-1] for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[31mException:..... \u001b[1mTypeError: 'ScalarEvent' object is not subscriptable\u001b[0m\n",
      "\u001b[2m01:08:43.071454 line        54\u001b[0m                 except:\n",
      "\u001b[2m01:08:43.071490 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.071532 line        56\u001b[0m                     -1\n",
      "\u001b[2m01:08:43.071565 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.071600 line        57\u001b[0m                 ].value\n",
      "\u001b[2m01:08:43.071633 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 0.000103458114....020691784098744392, 'Acc/Val': 71.5199966430664}\u001b[0m\n",
      "\u001b[2m01:08:43.071667 line        48\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[2m01:08:43.071707 line        59\u001b[0m         if tag == \"tensors\":\n",
      "\u001b[2m01:08:43.071740 line        85\u001b[0m         if tag == \"images\" and save_ims == True:\n",
      "\u001b[2m01:08:43.071774 line        46\u001b[0m     for tag in all_tags.keys():\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtag = 'distributions'\u001b[0m\n",
      "\u001b[2m01:08:43.071807 line        47\u001b[0m         if tag == \"scalars\":\n",
      "\u001b[2m01:08:43.071852 line        59\u001b[0m         if tag == \"tensors\":\n",
      "\u001b[2m01:08:43.071890 line        85\u001b[0m         if tag == \"images\" and save_ims == True:\n",
      "\u001b[2m01:08:43.071924 line        46\u001b[0m     for tag in all_tags.keys():\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtag = 'tensors'\u001b[0m\n",
      "\u001b[2m01:08:43.071956 line        47\u001b[0m         if tag == \"scalars\":\n",
      "\u001b[2m01:08:43.072010 line        59\u001b[0m         if tag == \"tensors\":\n",
      "\u001b[2m01:08:43.072047 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'experiment_name/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.072081 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.072128 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.072166 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.072203 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.072238 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 0.000103458114...5199966430664, 'experiment_name': 'baseline_run'}\u001b[0m\n",
      "\u001b[2m01:08:43.072277 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'image_size/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.072320 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.072366 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.072401 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.072436 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.072470 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 0.000103458114...iment_name': 'baseline_run', 'image_size': '224'}\u001b[0m\n",
      "\u001b[2m01:08:43.072503 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'batch_size/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.072542 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.072587 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.072621 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.072657 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.072690 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 0.000103458114...ne_run', 'image_size': '224', 'batch_size': '64'}\u001b[0m\n",
      "\u001b[2m01:08:43.072724 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'enable_proxy_attention/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.072763 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.072808 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.072843 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.072878 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.072913 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 0.000103458114...ch_size': '64', 'enable_proxy_attention': 'True'}\u001b[0m\n",
      "\u001b[2m01:08:43.072947 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'transfer_imagenet/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.072987 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.073031 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.073067 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.073102 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.073136 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 0.000103458114..._attention': 'True', 'transfer_imagenet': 'True'}\u001b[0m\n",
      "\u001b[2m01:08:43.073170 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'subset_images/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.073209 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.073254 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.073302 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.073346 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.073381 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 0.000103458114...sfer_imagenet': 'True', 'subset_images': '20000'}\u001b[0m\n",
      "\u001b[2m01:08:43.073416 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'pixel_replacement_method/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.073462 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.073508 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.073544 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.073580 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.073614 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 0.000103458114...: '20000', 'pixel_replacement_method': 'blended'}\u001b[0m\n",
      "\u001b[2m01:08:43.073649 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'proxy_steps/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.073689 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.073753 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.073791 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.073832 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.073868 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 0.000103458114...cement_method': 'blended', 'proxy_steps': '[20]'}\u001b[0m\n",
      "\u001b[2m01:08:43.073903 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'load_proxy_data/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.073943 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.073990 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.074026 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.074062 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.074097 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 0.000103458114...proxy_steps': '[20]', 'load_proxy_data': 'False'}\u001b[0m\n",
      "\u001b[2m01:08:43.074132 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'proxy_step/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.074172 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.074217 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.074253 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.074288 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.074323 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.00010345...proxy_steps': '[20]', 'load_proxy_data': 'False'}\u001b[0m\n",
      "\u001b[2m01:08:43.074357 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'log_every/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.074397 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.074442 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.074479 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.074515 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.074550 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.00010345...]', 'load_proxy_data': 'False', 'log_every': '2'}\u001b[0m\n",
      "\u001b[2m01:08:43.074585 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'device/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.074625 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.074671 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.074708 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.074744 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.074781 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.00010345...': 'False', 'log_every': '2', 'device': 'cuda:0'}\u001b[0m\n",
      "\u001b[2m01:08:43.074817 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'dataset_info/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.074858 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.074911 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.074948 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.074985 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.075022 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.00010345...t_name at 0x7f510b1aba30>, 'num_classes': 101}}\"}\u001b[0m\n",
      "\u001b[2m01:08:43.075057 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'main_run_dir/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.075104 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.075156 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.075198 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.075240 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.075280 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.00010345...DE/Github/improving_robotics_datasets/src/runs/'}\u001b[0m\n",
      "\u001b[2m01:08:43.075321 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'change_subset_attention/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.075370 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.075422 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.075465 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.075507 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.075548 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.00010345...ets/src/runs/', 'change_subset_attention': '0.8'}\u001b[0m\n",
      "\u001b[2m01:08:43.075589 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'model/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.075637 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.075690 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.075733 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.075774 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.075815 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.00010345...et_attention': '0.8', 'model': 'efficientnet_b0'}\u001b[0m\n",
      "\u001b[2m01:08:43.075856 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'proxy_image_weight/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.075902 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.075955 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.075999 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.076044 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.076086 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.00010345...: 'efficientnet_b0', 'proxy_image_weight': '0.1'}\u001b[0m\n",
      "\u001b[2m01:08:43.076127 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'proxy_threshold/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.076173 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.076226 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.076270 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.076312 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.076354 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.00010345..._image_weight': '0.1', 'proxy_threshold': '0.85'}\u001b[0m\n",
      "\u001b[2m01:08:43.076413 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'gradient_method/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.076463 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.076517 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.076560 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.076603 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.076645 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.00010345...d': '0.85', 'gradient_method': 'gradcamplusplus'}\u001b[0m\n",
      "\u001b[2m01:08:43.076696 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'ds_name/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.076744 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.076797 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.076841 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.076883 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.076924 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.00010345...nt_method': 'gradcamplusplus', 'ds_name': 'dogs'}\u001b[0m\n",
      "\u001b[2m01:08:43.076964 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'clear_every_step/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.077010 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.077075 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.077120 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.077163 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.077205 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.00010345...', 'ds_name': 'dogs', 'clear_every_step': 'True'}\u001b[0m\n",
      "\u001b[2m01:08:43.077246 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'fname_start/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.077293 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.077359 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.077409 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.077452 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.077494 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.00010345..._datasets/src/runs/baseline_run_26032023_193957'}\u001b[0m\n",
      "\u001b[2m01:08:43.077537 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'ds_path/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.077584 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.077648 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.077697 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.077741 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.077784 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.00010345...un/media/eragon/HDD/Datasets/dogs/images/Images'}\u001b[0m\n",
      "\u001b[2m01:08:43.077828 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'name_fn/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.077876 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.077930 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.077975 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.078018 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.078061 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.00010345...: '<function get_parent_name at 0x7f510b1aba30>'}\u001b[0m\n",
      "\u001b[2m01:08:43.078104 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'global_run_count/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.078153 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.078207 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.078252 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.078297 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.078353 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[2m01:08:43.078399 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'writer/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.078442 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.078497 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.078541 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.078585 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.078635 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.00010345....writer.SummaryWriter object at 0x7f51f8916aa0>'}\u001b[0m\n",
      "\u001b[2m01:08:43.078679 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'label_map/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.078727 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.078781 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.078825 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.078869 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.078913 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.00010345...3-dhole', 119: 'n02116738-African_hunting_dog'}\"}\u001b[0m\n",
      "\u001b[2m01:08:43.078957 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'rev_label_map/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.079028 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.079101 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.079164 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.079227 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.079288 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.00010345...le': 118, 'n02116738-African_hunting_dog': 119}\"}\u001b[0m\n",
      "\u001b[2m01:08:43.079352 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'num_classes/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.079439 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.079528 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.079608 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.079687 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.079765 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.00010345...frican_hunting_dog': 119}\", 'num_classes': '120'}\u001b[0m\n",
      "\u001b[2m01:08:43.079844 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'dataset_sizes/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.079927 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.080016 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.080097 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.080176 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.080254 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.00010345...dataset_sizes': \"{'train': 10000, 'val': 10000}\"}\u001b[0m\n",
      "\u001b[2m01:08:43.080332 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'criterion/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.080427 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.080519 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.080601 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.080682 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.080760 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.00010345...val': 10000}\", 'criterion': 'CrossEntropyLoss()'}\u001b[0m\n",
      "\u001b[2m01:08:43.080839 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'cam/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.080923 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.081013 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.081094 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.081173 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.081252 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.00010345...splus.GradCAMPlusPlus object at 0x7f51021dfeb0>'}\u001b[0m\n",
      "\u001b[2m01:08:43.081330 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'save_path/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.081415 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.081551 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.081654 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.081736 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.081822 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.00010345...rc/runs/baseline_run_26032023_193957/checkpoint'}\u001b[0m\n",
      "\u001b[2m01:08:43.081902 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'final_acc/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.081991 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.082083 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.082165 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.082246 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.082337 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.00010345...6032023_193957/checkpoint', 'final_acc': '71.52'}\u001b[0m\n",
      "\u001b[2m01:08:43.082425 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[2m01:08:43.082514 line        85\u001b[0m         if tag == \"images\" and save_ims == True:\n",
      "\u001b[2m01:08:43.082595 line        46\u001b[0m     for tag in all_tags.keys():\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtag = 'graph'\u001b[0m\n",
      "\u001b[2m01:08:43.082675 line        47\u001b[0m         if tag == \"scalars\":\n",
      "\u001b[2m01:08:43.082779 line        59\u001b[0m         if tag == \"tensors\":\n",
      "\u001b[2m01:08:43.082862 line        85\u001b[0m         if tag == \"images\" and save_ims == True:\n",
      "\u001b[2m01:08:43.082947 line        46\u001b[0m     for tag in all_tags.keys():\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtag = 'meta_graph'\u001b[0m\n",
      "\u001b[2m01:08:43.083027 line        47\u001b[0m         if tag == \"scalars\":\n",
      "\u001b[2m01:08:43.083114 line        59\u001b[0m         if tag == \"tensors\":\n",
      "\u001b[2m01:08:43.083194 line        85\u001b[0m         if tag == \"images\" and save_ims == True:\n",
      "\u001b[2m01:08:43.083273 line        46\u001b[0m     for tag in all_tags.keys():\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtag = 'run_metadata'\u001b[0m\n",
      "\u001b[2m01:08:43.083353 line        47\u001b[0m         if tag == \"scalars\":\n",
      "\u001b[2m01:08:43.083440 line        59\u001b[0m         if tag == \"tensors\":\n",
      "\u001b[2m01:08:43.083528 line        85\u001b[0m         if tag == \"images\" and save_ims == True:\n",
      "\u001b[2m01:08:43.083609 line        46\u001b[0m     for tag in all_tags.keys():\n",
      "\u001b[2m01:08:43.083689 line        96\u001b[0m     return temp_dict\n",
      "\u001b[2m01:08:43.083823 return      96\u001b[0m     return temp_dict\n",
      "\u001b[36m\u001b[2mReturn value:.. \u001b[22m{'proxy_step': 'False', 'Loss/Train': 0.00010345...6032023_193957/checkpoint', 'final_acc': '71.52'}\u001b[0m\n",
      "\u001b[33m\u001b[2mElapsed time: \u001b[22m00:00:00.015282\u001b[0m\n",
      "runs/baseline_run_26032023_203613/events.out.tfevents.1679855773.eragon\n",
      "\u001b[32m\u001b[2mStarting var:.. \u001b[22mevent_acc = <tensorboard.backend.event_processing.event_accumulator.EventAccumulator object at 0x7f5b568ee800>\u001b[0m\n",
      "\u001b[32m\u001b[2mStarting var:.. \u001b[22msave_ims = False\u001b[0m\n",
      "\u001b[2m01:08:43.091818 call        42\u001b[0m def process_event_acc(event_acc, save_ims = False):\n",
      "\u001b[2m01:08:43.091901 line        44\u001b[0m     all_tags = event_acc.Tags()\n",
      "\u001b[32m\u001b[2mNew var:....... \u001b[22mall_tags = {'images': [], 'audio': [], 'histograms': [], 's...: False, 'meta_graph': False, 'run_metadata': []}\u001b[0m\n",
      "\u001b[2m01:08:43.091949 line        45\u001b[0m     temp_dict = {}\n",
      "\u001b[32m\u001b[2mNew var:....... \u001b[22mtemp_dict = {}\u001b[0m\n",
      "\u001b[2m01:08:43.092062 line        46\u001b[0m     for tag in all_tags.keys():\n",
      "\u001b[32m\u001b[2mNew var:....... \u001b[22mtag = 'images'\u001b[0m\n",
      "\u001b[2m01:08:43.092102 line        47\u001b[0m         if tag == \"scalars\":\n",
      "\u001b[2m01:08:43.092140 line        59\u001b[0m         if tag == \"tensors\":\n",
      "\u001b[2m01:08:43.092170 line        85\u001b[0m         if tag == \"images\" and save_ims == True:\n",
      "\u001b[2m01:08:43.092199 line        46\u001b[0m     for tag in all_tags.keys():\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtag = 'audio'\u001b[0m\n",
      "\u001b[2m01:08:43.092227 line        47\u001b[0m         if tag == \"scalars\":\n",
      "\u001b[2m01:08:43.092260 line        59\u001b[0m         if tag == \"tensors\":\n",
      "\u001b[2m01:08:43.092287 line        85\u001b[0m         if tag == \"images\" and save_ims == True:\n",
      "\u001b[2m01:08:43.092315 line        46\u001b[0m     for tag in all_tags.keys():\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtag = 'histograms'\u001b[0m\n",
      "\u001b[2m01:08:43.092342 line        47\u001b[0m         if tag == \"scalars\":\n",
      "\u001b[2m01:08:43.092374 line        59\u001b[0m         if tag == \"tensors\":\n",
      "\u001b[2m01:08:43.092400 line        85\u001b[0m         if tag == \"images\" and save_ims == True:\n",
      "\u001b[2m01:08:43.092427 line        46\u001b[0m     for tag in all_tags.keys():\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtag = 'scalars'\u001b[0m\n",
      "\u001b[2m01:08:43.092457 line        47\u001b[0m         if tag == \"scalars\":\n",
      "\u001b[2m01:08:43.092489 line        48\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mNew var:....... \u001b[22msubtag = 'proxy_step'\u001b[0m\n",
      "\u001b[2m01:08:43.092517 line        50\u001b[0m                 try:\n",
      "\u001b[2m01:08:43.092551 line        51\u001b[0m                     temp_dict[subtag] = [tag[-1] for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.092591 exception   51\u001b[0m                     temp_dict[subtag] = [tag[-1] for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[31mException:..... \u001b[1mTypeError: 'ScalarEvent' object is not subscriptable\u001b[0m\n",
      "\u001b[2m01:08:43.092653 line        54\u001b[0m                 except:\n",
      "\u001b[2m01:08:43.092687 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.092726 line        56\u001b[0m                     -1\n",
      "\u001b[2m01:08:43.092755 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.092784 line        57\u001b[0m                 ].value\n",
      "\u001b[2m01:08:43.092813 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0}\u001b[0m\n",
      "\u001b[2m01:08:43.092842 line        48\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'Loss/Train'\u001b[0m\n",
      "\u001b[2m01:08:43.092878 line        50\u001b[0m                 try:\n",
      "\u001b[2m01:08:43.092912 line        51\u001b[0m                     temp_dict[subtag] = [tag[-1] for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.092948 exception   51\u001b[0m                     temp_dict[subtag] = [tag[-1] for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[31mException:..... \u001b[1mTypeError: 'ScalarEvent' object is not subscriptable\u001b[0m\n",
      "\u001b[2m01:08:43.093002 line        54\u001b[0m                 except:\n",
      "\u001b[2m01:08:43.093035 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.093072 line        56\u001b[0m                     -1\n",
      "\u001b[2m01:08:43.093103 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.093134 line        57\u001b[0m                 ].value\n",
      "\u001b[2m01:08:43.093164 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 0.0014325878582894802}\u001b[0m\n",
      "\u001b[2m01:08:43.093195 line        48\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'Acc/Train'\u001b[0m\n",
      "\u001b[2m01:08:43.093236 line        50\u001b[0m                 try:\n",
      "\u001b[2m01:08:43.093273 line        51\u001b[0m                     temp_dict[subtag] = [tag[-1] for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.093313 exception   51\u001b[0m                     temp_dict[subtag] = [tag[-1] for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[31mException:..... \u001b[1mTypeError: 'ScalarEvent' object is not subscriptable\u001b[0m\n",
      "\u001b[2m01:08:43.093365 line        54\u001b[0m                 except:\n",
      "\u001b[2m01:08:43.093398 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.093437 line        56\u001b[0m                     -1\n",
      "\u001b[2m01:08:43.093469 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.093500 line        57\u001b[0m                 ].value\n",
      "\u001b[2m01:08:43.093531 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 0.0014325878582894802, 'Acc/Train': 97.79000091552734}\u001b[0m\n",
      "\u001b[2m01:08:43.093562 line        48\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'global_run_count'\u001b[0m\n",
      "\u001b[2m01:08:43.093600 line        50\u001b[0m                 try:\n",
      "\u001b[2m01:08:43.093637 line        51\u001b[0m                     temp_dict[subtag] = [tag[-1] for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.093676 exception   51\u001b[0m                     temp_dict[subtag] = [tag[-1] for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[31mException:..... \u001b[1mTypeError: 'ScalarEvent' object is not subscriptable\u001b[0m\n",
      "\u001b[2m01:08:43.093748 line        54\u001b[0m                 except:\n",
      "\u001b[2m01:08:43.093787 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.093828 line        56\u001b[0m                     -1\n",
      "\u001b[2m01:08:43.093861 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.093893 line        57\u001b[0m                 ].value\n",
      "\u001b[2m01:08:43.093924 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 0.001432587858...in': 97.79000091552734, 'global_run_count': 20.0}\u001b[0m\n",
      "\u001b[2m01:08:43.093955 line        48\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'Loss/Val'\u001b[0m\n",
      "\u001b[2m01:08:43.093994 line        50\u001b[0m                 try:\n",
      "\u001b[2m01:08:43.094030 line        51\u001b[0m                     temp_dict[subtag] = [tag[-1] for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.094069 exception   51\u001b[0m                     temp_dict[subtag] = [tag[-1] for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[31mException:..... \u001b[1mTypeError: 'ScalarEvent' object is not subscriptable\u001b[0m\n",
      "\u001b[2m01:08:43.094121 line        54\u001b[0m                 except:\n",
      "\u001b[2m01:08:43.094155 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.094196 line        56\u001b[0m                     -1\n",
      "\u001b[2m01:08:43.094229 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.094285 line        57\u001b[0m                 ].value\n",
      "\u001b[2m01:08:43.094318 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 0.001432587858...count': 20.0, 'Loss/Val': 0.00028798263520002365}\u001b[0m\n",
      "\u001b[2m01:08:43.094351 line        48\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'Acc/Val'\u001b[0m\n",
      "\u001b[2m01:08:43.094390 line        50\u001b[0m                 try:\n",
      "\u001b[2m01:08:43.094427 line        51\u001b[0m                     temp_dict[subtag] = [tag[-1] for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.094466 exception   51\u001b[0m                     temp_dict[subtag] = [tag[-1] for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[31mException:..... \u001b[1mTypeError: 'ScalarEvent' object is not subscriptable\u001b[0m\n",
      "\u001b[2m01:08:43.094518 line        54\u001b[0m                 except:\n",
      "\u001b[2m01:08:43.094553 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.094594 line        56\u001b[0m                     -1\n",
      "\u001b[2m01:08:43.094628 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.094661 line        57\u001b[0m                 ].value\n",
      "\u001b[2m01:08:43.094694 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 0.001432587858...028798263520002365, 'Acc/Val': 99.51000213623047}\u001b[0m\n",
      "\u001b[2m01:08:43.094727 line        48\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[2m01:08:43.094798 line        59\u001b[0m         if tag == \"tensors\":\n",
      "\u001b[2m01:08:43.094834 line        85\u001b[0m         if tag == \"images\" and save_ims == True:\n",
      "\u001b[2m01:08:43.094866 line        46\u001b[0m     for tag in all_tags.keys():\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtag = 'distributions'\u001b[0m\n",
      "\u001b[2m01:08:43.094900 line        47\u001b[0m         if tag == \"scalars\":\n",
      "\u001b[2m01:08:43.094938 line        59\u001b[0m         if tag == \"tensors\":\n",
      "\u001b[2m01:08:43.094970 line        85\u001b[0m         if tag == \"images\" and save_ims == True:\n",
      "\u001b[2m01:08:43.095003 line        46\u001b[0m     for tag in all_tags.keys():\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtag = 'tensors'\u001b[0m\n",
      "\u001b[2m01:08:43.095035 line        47\u001b[0m         if tag == \"scalars\":\n",
      "\u001b[2m01:08:43.095073 line        59\u001b[0m         if tag == \"tensors\":\n",
      "\u001b[2m01:08:43.095105 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'experiment_name/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.095137 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.095183 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.095222 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.095259 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.095294 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 0.001432587858...1000213623047, 'experiment_name': 'baseline_run'}\u001b[0m\n",
      "\u001b[2m01:08:43.095328 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'image_size/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.095367 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.095413 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.095449 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.095484 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.095518 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 0.001432587858...iment_name': 'baseline_run', 'image_size': '224'}\u001b[0m\n",
      "\u001b[2m01:08:43.095552 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'batch_size/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.095591 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.095636 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.095672 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.095707 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.095778 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 0.001432587858...ne_run', 'image_size': '224', 'batch_size': '64'}\u001b[0m\n",
      "\u001b[2m01:08:43.095818 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'enable_proxy_attention/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.095858 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.095905 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.095941 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.095977 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.096012 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 0.001432587858...ch_size': '64', 'enable_proxy_attention': 'True'}\u001b[0m\n",
      "\u001b[2m01:08:43.096046 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'transfer_imagenet/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.096087 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.096133 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.096169 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.096204 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.096238 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 0.001432587858..._attention': 'True', 'transfer_imagenet': 'True'}\u001b[0m\n",
      "\u001b[2m01:08:43.096273 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'subset_images/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.096312 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.096358 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.096394 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.096449 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.096485 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 0.001432587858...sfer_imagenet': 'True', 'subset_images': '20000'}\u001b[0m\n",
      "\u001b[2m01:08:43.096519 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'pixel_replacement_method/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.096559 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.096605 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.096641 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.096676 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.096710 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 0.001432587858...: '20000', 'pixel_replacement_method': 'blended'}\u001b[0m\n",
      "\u001b[2m01:08:43.096744 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'proxy_steps/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.096783 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.096828 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.096865 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.096900 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.096934 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 0.001432587858...cement_method': 'blended', 'proxy_steps': '[20]'}\u001b[0m\n",
      "\u001b[2m01:08:43.096968 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'load_proxy_data/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.097007 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.097058 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.097095 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.097130 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.097165 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 0.001432587858...proxy_steps': '[20]', 'load_proxy_data': 'False'}\u001b[0m\n",
      "\u001b[2m01:08:43.097200 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'proxy_step/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.097239 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.097309 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.097361 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.097400 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.097472 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.00143258...proxy_steps': '[20]', 'load_proxy_data': 'False'}\u001b[0m\n",
      "\u001b[2m01:08:43.097510 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'log_every/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.097552 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.097600 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.097637 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.097674 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.097709 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.00143258...]', 'load_proxy_data': 'False', 'log_every': '2'}\u001b[0m\n",
      "\u001b[2m01:08:43.097758 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'device/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.097803 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.097852 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.097888 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.097932 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.097968 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.00143258...': 'False', 'log_every': '2', 'device': 'cuda:0'}\u001b[0m\n",
      "\u001b[2m01:08:43.098003 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'dataset_info/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.098043 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.098089 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.098126 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.098163 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.098198 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.00143258...t_name at 0x7f0e1c3d3a30>, 'num_classes': 101}}\"}\u001b[0m\n",
      "\u001b[2m01:08:43.098233 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'main_run_dir/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.098280 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.098331 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.098373 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.098414 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.098464 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.00143258...DE/Github/improving_robotics_datasets/src/runs/'}\u001b[0m\n",
      "\u001b[2m01:08:43.098505 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'change_subset_attention/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.098551 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.098602 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.098645 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.098687 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.098728 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.00143258...ets/src/runs/', 'change_subset_attention': '0.8'}\u001b[0m\n",
      "\u001b[2m01:08:43.098769 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'model/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.098815 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.098866 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.098910 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.098952 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.098993 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.00143258...et_attention': '0.8', 'model': 'efficientnet_b0'}\u001b[0m\n",
      "\u001b[2m01:08:43.099094 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'proxy_image_weight/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.099161 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.099217 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.099261 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.099305 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.099347 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.00143258...: 'efficientnet_b0', 'proxy_image_weight': '0.1'}\u001b[0m\n",
      "\u001b[2m01:08:43.099391 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'proxy_threshold/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.099439 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.099492 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.099536 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.099579 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.099627 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.00143258..._image_weight': '0.1', 'proxy_threshold': '0.85'}\u001b[0m\n",
      "\u001b[2m01:08:43.099668 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'gradient_method/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.099747 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.099804 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.099848 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.099892 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.099934 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.00143258...d': '0.85', 'gradient_method': 'gradcamplusplus'}\u001b[0m\n",
      "\u001b[2m01:08:43.099975 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'ds_name/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.100022 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.100076 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.100120 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.100187 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.100231 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.00143258...ent_method': 'gradcamplusplus', 'ds_name': 'asl'}\u001b[0m\n",
      "\u001b[2m01:08:43.100273 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'clear_every_step/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.100342 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.100410 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.100456 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.100499 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.100540 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.00143258...s', 'ds_name': 'asl', 'clear_every_step': 'True'}\u001b[0m\n",
      "\u001b[2m01:08:43.100581 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'fname_start/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.100635 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.100689 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.100733 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.100780 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.100822 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.00143258..._datasets/src/runs/baseline_run_26032023_203613'}\u001b[0m\n",
      "\u001b[2m01:08:43.100865 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'ds_path/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.100913 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.100966 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.101010 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.101053 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.101095 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.00143258...asets/asl/asl_alphabet_train/asl_alphabet_train'}\u001b[0m\n",
      "\u001b[2m01:08:43.101138 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'name_fn/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.101187 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.101241 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.101285 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.101329 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.101372 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.00143258...: '<function get_parent_name at 0x7f0e1c3d3a30>'}\u001b[0m\n",
      "\u001b[2m01:08:43.101414 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'global_run_count/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.101462 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.101516 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.101560 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.101612 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.101656 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[2m01:08:43.101699 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'writer/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.101741 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.101795 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.101839 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.101882 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.101926 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.00143258....writer.SummaryWriter object at 0x7f0e11a81480>'}\u001b[0m\n",
      "\u001b[2m01:08:43.101968 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'label_map/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.102016 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.102069 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.102113 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.102156 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.102199 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.00143258...P', 16: 'Q', 17: 'U', 18: 'del', 19: 'nothing'}\"}\u001b[0m\n",
      "\u001b[2m01:08:43.102241 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'rev_label_map/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.102291 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.102347 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.102397 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.102444 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.102488 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.00143258...15, 'Q': 16, 'U': 17, 'del': 18, 'nothing': 19}\"}\u001b[0m\n",
      "\u001b[2m01:08:43.102532 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'num_classes/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.102581 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.102659 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.102706 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.102757 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.102828 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.00143258... 'del': 18, 'nothing': 19}\", 'num_classes': '20'}\u001b[0m\n",
      "\u001b[2m01:08:43.102883 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'dataset_sizes/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.102986 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.103140 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.103236 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.103314 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.103385 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.00143258...dataset_sizes': \"{'train': 10000, 'val': 10000}\"}\u001b[0m\n",
      "\u001b[2m01:08:43.103538 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'criterion/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.103629 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.103783 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.103871 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.103979 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.104073 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.00143258...val': 10000}\", 'criterion': 'CrossEntropyLoss()'}\u001b[0m\n",
      "\u001b[2m01:08:43.104128 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'cam/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.104185 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.104250 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.104314 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.104367 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.104414 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.00143258...splus.GradCAMPlusPlus object at 0x7f0dffe04c10>'}\u001b[0m\n",
      "\u001b[2m01:08:43.104462 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'save_path/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.104517 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.104575 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.104624 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.104671 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.104718 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.00143258...rc/runs/baseline_run_26032023_203613/checkpoint'}\u001b[0m\n",
      "\u001b[2m01:08:43.104769 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'final_acc/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.104823 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.104882 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.104930 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.104978 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.105026 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.00143258...6032023_203613/checkpoint', 'final_acc': '99.51'}\u001b[0m\n",
      "\u001b[2m01:08:43.105073 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[2m01:08:43.105126 line        85\u001b[0m         if tag == \"images\" and save_ims == True:\n",
      "\u001b[2m01:08:43.105174 line        46\u001b[0m     for tag in all_tags.keys():\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtag = 'graph'\u001b[0m\n",
      "\u001b[2m01:08:43.105220 line        47\u001b[0m         if tag == \"scalars\":\n",
      "\u001b[2m01:08:43.105272 line        59\u001b[0m         if tag == \"tensors\":\n",
      "\u001b[2m01:08:43.105318 line        85\u001b[0m         if tag == \"images\" and save_ims == True:\n",
      "\u001b[2m01:08:43.105364 line        46\u001b[0m     for tag in all_tags.keys():\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtag = 'meta_graph'\u001b[0m\n",
      "\u001b[2m01:08:43.105410 line        47\u001b[0m         if tag == \"scalars\":\n",
      "\u001b[2m01:08:43.105461 line        59\u001b[0m         if tag == \"tensors\":\n",
      "\u001b[2m01:08:43.105508 line        85\u001b[0m         if tag == \"images\" and save_ims == True:\n",
      "\u001b[2m01:08:43.105554 line        46\u001b[0m     for tag in all_tags.keys():\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtag = 'run_metadata'\u001b[0m\n",
      "\u001b[2m01:08:43.105600 line        47\u001b[0m         if tag == \"scalars\":\n",
      "\u001b[2m01:08:43.105652 line        59\u001b[0m         if tag == \"tensors\":\n",
      "\u001b[2m01:08:43.105697 line        85\u001b[0m         if tag == \"images\" and save_ims == True:\n",
      "\u001b[2m01:08:43.105743 line        46\u001b[0m     for tag in all_tags.keys():\n",
      "\u001b[2m01:08:43.105789 line        96\u001b[0m     return temp_dict\n",
      "\u001b[2m01:08:43.105839 return      96\u001b[0m     return temp_dict\n",
      "\u001b[36m\u001b[2mReturn value:.. \u001b[22m{'proxy_step': 'False', 'Loss/Train': 0.00143258...6032023_203613/checkpoint', 'final_acc': '99.51'}\u001b[0m\n",
      "\u001b[33m\u001b[2mElapsed time: \u001b[22m00:00:00.014132\u001b[0m\n",
      "runs/baseline_run_26032023_205454/events.out.tfevents.1679856894.eragon\n",
      "\u001b[32m\u001b[2mStarting var:.. \u001b[22mevent_acc = <tensorboard.backend.event_processing.event_accumulator.EventAccumulator object at 0x7f5b568ee1d0>\u001b[0m\n",
      "\u001b[32m\u001b[2mStarting var:.. \u001b[22msave_ims = False\u001b[0m\n",
      "\u001b[2m01:08:43.114044 call        42\u001b[0m def process_event_acc(event_acc, save_ims = False):\n",
      "\u001b[2m01:08:43.114116 line        44\u001b[0m     all_tags = event_acc.Tags()\n",
      "\u001b[32m\u001b[2mNew var:....... \u001b[22mall_tags = {'images': [], 'audio': [], 'histograms': [], 's...: False, 'meta_graph': False, 'run_metadata': []}\u001b[0m\n",
      "\u001b[2m01:08:43.114157 line        45\u001b[0m     temp_dict = {}\n",
      "\u001b[32m\u001b[2mNew var:....... \u001b[22mtemp_dict = {}\u001b[0m\n",
      "\u001b[2m01:08:43.114242 line        46\u001b[0m     for tag in all_tags.keys():\n",
      "\u001b[32m\u001b[2mNew var:....... \u001b[22mtag = 'images'\u001b[0m\n",
      "\u001b[2m01:08:43.114282 line        47\u001b[0m         if tag == \"scalars\":\n",
      "\u001b[2m01:08:43.114319 line        59\u001b[0m         if tag == \"tensors\":\n",
      "\u001b[2m01:08:43.114349 line        85\u001b[0m         if tag == \"images\" and save_ims == True:\n",
      "\u001b[2m01:08:43.114377 line        46\u001b[0m     for tag in all_tags.keys():\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtag = 'audio'\u001b[0m\n",
      "\u001b[2m01:08:43.114405 line        47\u001b[0m         if tag == \"scalars\":\n",
      "\u001b[2m01:08:43.114437 line        59\u001b[0m         if tag == \"tensors\":\n",
      "\u001b[2m01:08:43.114464 line        85\u001b[0m         if tag == \"images\" and save_ims == True:\n",
      "\u001b[2m01:08:43.114492 line        46\u001b[0m     for tag in all_tags.keys():\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtag = 'histograms'\u001b[0m\n",
      "\u001b[2m01:08:43.114519 line        47\u001b[0m         if tag == \"scalars\":\n",
      "\u001b[2m01:08:43.114551 line        59\u001b[0m         if tag == \"tensors\":\n",
      "\u001b[2m01:08:43.114579 line        85\u001b[0m         if tag == \"images\" and save_ims == True:\n",
      "\u001b[2m01:08:43.114606 line        46\u001b[0m     for tag in all_tags.keys():\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtag = 'scalars'\u001b[0m\n",
      "\u001b[2m01:08:43.114633 line        47\u001b[0m         if tag == \"scalars\":\n",
      "\u001b[2m01:08:43.114665 line        48\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mNew var:....... \u001b[22msubtag = 'proxy_step'\u001b[0m\n",
      "\u001b[2m01:08:43.114692 line        50\u001b[0m                 try:\n",
      "\u001b[2m01:08:43.114726 line        51\u001b[0m                     temp_dict[subtag] = [tag[-1] for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.114764 exception   51\u001b[0m                     temp_dict[subtag] = [tag[-1] for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[31mException:..... \u001b[1mTypeError: 'ScalarEvent' object is not subscriptable\u001b[0m\n",
      "\u001b[2m01:08:43.114822 line        54\u001b[0m                 except:\n",
      "\u001b[2m01:08:43.114854 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.114893 line        56\u001b[0m                     -1\n",
      "\u001b[2m01:08:43.114923 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.114952 line        57\u001b[0m                 ].value\n",
      "\u001b[2m01:08:43.114982 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0}\u001b[0m\n",
      "\u001b[2m01:08:43.115011 line        48\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'Loss/Train'\u001b[0m\n",
      "\u001b[2m01:08:43.115046 line        50\u001b[0m                 try:\n",
      "\u001b[2m01:08:43.115080 line        51\u001b[0m                     temp_dict[subtag] = [tag[-1] for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.115121 exception   51\u001b[0m                     temp_dict[subtag] = [tag[-1] for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[31mException:..... \u001b[1mTypeError: 'ScalarEvent' object is not subscriptable\u001b[0m\n",
      "\u001b[2m01:08:43.115171 line        54\u001b[0m                 except:\n",
      "\u001b[2m01:08:43.115203 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.115241 line        56\u001b[0m                     -1\n",
      "\u001b[2m01:08:43.115271 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.115301 line        57\u001b[0m                 ].value\n",
      "\u001b[2m01:08:43.115330 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 0.0075822207145392895}\u001b[0m\n",
      "\u001b[2m01:08:43.115365 line        48\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'Acc/Train'\u001b[0m\n",
      "\u001b[2m01:08:43.115403 line        50\u001b[0m                 try:\n",
      "\u001b[2m01:08:43.115439 line        51\u001b[0m                     temp_dict[subtag] = [tag[-1] for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.115477 exception   51\u001b[0m                     temp_dict[subtag] = [tag[-1] for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[31mException:..... \u001b[1mTypeError: 'ScalarEvent' object is not subscriptable\u001b[0m\n",
      "\u001b[2m01:08:43.115527 line        54\u001b[0m                 except:\n",
      "\u001b[2m01:08:43.115561 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.115600 line        56\u001b[0m                     -1\n",
      "\u001b[2m01:08:43.115632 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.115662 line        57\u001b[0m                 ].value\n",
      "\u001b[2m01:08:43.115700 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 0.0075822207145392895, 'Acc/Train': 88.55332946777344}\u001b[0m\n",
      "\u001b[2m01:08:43.115732 line        48\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'global_run_count'\u001b[0m\n",
      "\u001b[2m01:08:43.115769 line        50\u001b[0m                 try:\n",
      "\u001b[2m01:08:43.115804 line        51\u001b[0m                     temp_dict[subtag] = [tag[-1] for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.115842 exception   51\u001b[0m                     temp_dict[subtag] = [tag[-1] for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[31mException:..... \u001b[1mTypeError: 'ScalarEvent' object is not subscriptable\u001b[0m\n",
      "\u001b[2m01:08:43.115892 line        54\u001b[0m                 except:\n",
      "\u001b[2m01:08:43.115926 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.115966 line        56\u001b[0m                     -1\n",
      "\u001b[2m01:08:43.115998 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.116029 line        57\u001b[0m                 ].value\n",
      "\u001b[2m01:08:43.116060 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 0.007582220714...in': 88.55332946777344, 'global_run_count': 20.0}\u001b[0m\n",
      "\u001b[2m01:08:43.116091 line        48\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'Loss/Val'\u001b[0m\n",
      "\u001b[2m01:08:43.116129 line        50\u001b[0m                 try:\n",
      "\u001b[2m01:08:43.116166 line        51\u001b[0m                     temp_dict[subtag] = [tag[-1] for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.116204 exception   51\u001b[0m                     temp_dict[subtag] = [tag[-1] for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[31mException:..... \u001b[1mTypeError: 'ScalarEvent' object is not subscriptable\u001b[0m\n",
      "\u001b[2m01:08:43.116254 line        54\u001b[0m                 except:\n",
      "\u001b[2m01:08:43.116290 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.116330 line        56\u001b[0m                     -1\n",
      "\u001b[2m01:08:43.116363 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.116396 line        57\u001b[0m                 ].value\n",
      "\u001b[2m01:08:43.116427 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 0.007582220714...n_count': 20.0, 'Loss/Val': 0.006840897724032402}\u001b[0m\n",
      "\u001b[2m01:08:43.116459 line        48\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'Acc/Val'\u001b[0m\n",
      "\u001b[2m01:08:43.116497 line        50\u001b[0m                 try:\n",
      "\u001b[2m01:08:43.116534 line        51\u001b[0m                     temp_dict[subtag] = [tag[-1] for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.116573 exception   51\u001b[0m                     temp_dict[subtag] = [tag[-1] for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[31mException:..... \u001b[1mTypeError: 'ScalarEvent' object is not subscriptable\u001b[0m\n",
      "\u001b[2m01:08:43.116625 line        54\u001b[0m                 except:\n",
      "\u001b[2m01:08:43.116660 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.116700 line        56\u001b[0m                     -1\n",
      "\u001b[2m01:08:43.116734 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.116767 line        57\u001b[0m                 ].value\n",
      "\u001b[2m01:08:43.116799 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 0.007582220714....006840897724032402, 'Acc/Val': 88.0016860961914}\u001b[0m\n",
      "\u001b[2m01:08:43.116832 line        48\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[2m01:08:43.116869 line        59\u001b[0m         if tag == \"tensors\":\n",
      "\u001b[2m01:08:43.116902 line        85\u001b[0m         if tag == \"images\" and save_ims == True:\n",
      "\u001b[2m01:08:43.116935 line        46\u001b[0m     for tag in all_tags.keys():\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtag = 'distributions'\u001b[0m\n",
      "\u001b[2m01:08:43.116966 line        47\u001b[0m         if tag == \"scalars\":\n",
      "\u001b[2m01:08:43.117003 line        59\u001b[0m         if tag == \"tensors\":\n",
      "\u001b[2m01:08:43.117035 line        85\u001b[0m         if tag == \"images\" and save_ims == True:\n",
      "\u001b[2m01:08:43.117082 line        46\u001b[0m     for tag in all_tags.keys():\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtag = 'tensors'\u001b[0m\n",
      "\u001b[2m01:08:43.117117 line        47\u001b[0m         if tag == \"scalars\":\n",
      "\u001b[2m01:08:43.117155 line        59\u001b[0m         if tag == \"tensors\":\n",
      "\u001b[2m01:08:43.117187 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'experiment_name/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.117220 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.117266 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.117304 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.117343 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.117379 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 0.007582220714...0016860961914, 'experiment_name': 'baseline_run'}\u001b[0m\n",
      "\u001b[2m01:08:43.117414 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'image_size/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.117453 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.117499 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.117542 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.117580 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.117613 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 0.007582220714...iment_name': 'baseline_run', 'image_size': '224'}\u001b[0m\n",
      "\u001b[2m01:08:43.117646 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'batch_size/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.117684 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.117728 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.117762 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.117796 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.117830 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 0.007582220714...ne_run', 'image_size': '224', 'batch_size': '64'}\u001b[0m\n",
      "\u001b[2m01:08:43.117863 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'enable_proxy_attention/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.117901 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.117945 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.117980 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.118013 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.118046 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 0.007582220714...ch_size': '64', 'enable_proxy_attention': 'True'}\u001b[0m\n",
      "\u001b[2m01:08:43.118079 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'transfer_imagenet/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.118117 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.118160 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.118202 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.118255 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.118292 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 0.007582220714..._attention': 'True', 'transfer_imagenet': 'True'}\u001b[0m\n",
      "\u001b[2m01:08:43.118326 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'subset_images/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.118365 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.118410 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.118446 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.118480 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.118519 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 0.007582220714...sfer_imagenet': 'True', 'subset_images': '20000'}\u001b[0m\n",
      "\u001b[2m01:08:43.118557 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'pixel_replacement_method/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.118595 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.118639 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.118674 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.118709 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.118743 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 0.007582220714...: '20000', 'pixel_replacement_method': 'blended'}\u001b[0m\n",
      "\u001b[2m01:08:43.118776 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'proxy_steps/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.118814 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.118859 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.118899 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.118933 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.118968 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 0.007582220714...cement_method': 'blended', 'proxy_steps': '[20]'}\u001b[0m\n",
      "\u001b[2m01:08:43.119002 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'load_proxy_data/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.119041 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.119087 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.119125 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.119160 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.119195 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 0.007582220714...proxy_steps': '[20]', 'load_proxy_data': 'False'}\u001b[0m\n",
      "\u001b[2m01:08:43.119235 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'proxy_step/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.119287 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.119334 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.119371 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.119406 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.119441 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.00758222...proxy_steps': '[20]', 'load_proxy_data': 'False'}\u001b[0m\n",
      "\u001b[2m01:08:43.119476 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'log_every/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.119517 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.119566 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.119602 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.119637 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.119672 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.00758222...]', 'load_proxy_data': 'False', 'log_every': '2'}\u001b[0m\n",
      "\u001b[2m01:08:43.119706 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'device/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.119745 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.119790 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.119825 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.119860 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.119894 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.00758222...': 'False', 'log_every': '2', 'device': 'cuda:0'}\u001b[0m\n",
      "\u001b[2m01:08:43.119931 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'dataset_info/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.119970 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.120017 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.120054 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.120091 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.120154 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.00758222...t_name at 0x7f87661cfa30>, 'num_classes': 101}}\"}\u001b[0m\n",
      "\u001b[2m01:08:43.120236 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'main_run_dir/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.120286 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.120379 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.120477 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.120543 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.120626 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.00758222...DE/Github/improving_robotics_datasets/src/runs/'}\u001b[0m\n",
      "\u001b[2m01:08:43.120708 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'change_subset_attention/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.120795 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.120889 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.120949 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.120989 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.121044 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.00758222...ets/src/runs/', 'change_subset_attention': '0.8'}\u001b[0m\n",
      "\u001b[2m01:08:43.121087 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'model/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.121135 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.121189 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.121237 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.121288 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.121337 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.00758222...et_attention': '0.8', 'model': 'efficientnet_b0'}\u001b[0m\n",
      "\u001b[2m01:08:43.121387 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'proxy_image_weight/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.121439 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.121492 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.121535 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.121578 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.121622 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.00758222...: 'efficientnet_b0', 'proxy_image_weight': '0.1'}\u001b[0m\n",
      "\u001b[2m01:08:43.121664 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'proxy_threshold/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.121712 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.121766 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.121809 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.121852 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.121894 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.00758222..._image_weight': '0.1', 'proxy_threshold': '0.85'}\u001b[0m\n",
      "\u001b[2m01:08:43.121935 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'gradient_method/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.121982 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.122035 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.122078 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.122130 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.122172 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.00758222...d': '0.85', 'gradient_method': 'gradcamplusplus'}\u001b[0m\n",
      "\u001b[2m01:08:43.122214 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'ds_name/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.122261 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.122313 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.122356 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.122399 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.122440 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.00758222...hod': 'gradcamplusplus', 'ds_name': 'imagenette'}\u001b[0m\n",
      "\u001b[2m01:08:43.122481 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'clear_every_step/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.122527 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.122579 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.122644 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.122687 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.122745 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.00758222..._name': 'imagenette', 'clear_every_step': 'True'}\u001b[0m\n",
      "\u001b[2m01:08:43.122785 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'fname_start/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.122831 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.122883 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.122925 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.122968 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.123008 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.00758222..._datasets/src/runs/baseline_run_26032023_205454'}\u001b[0m\n",
      "\u001b[2m01:08:43.123049 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'ds_path/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.123095 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.123147 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.123190 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.123235 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.123276 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.00758222...media/eragon/HDD/Datasets/imagenette2-320/train'}\u001b[0m\n",
      "\u001b[2m01:08:43.123317 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'name_fn/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.123363 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.123416 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.123466 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.123510 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.123552 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.00758222...: '<function get_parent_name at 0x7f87661cfa30>'}\u001b[0m\n",
      "\u001b[2m01:08:43.123593 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'global_run_count/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.123640 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.123712 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.123794 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.123839 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.123882 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[2m01:08:43.123926 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'writer/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.123975 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.124046 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.124104 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.124156 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.124199 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.00758222....writer.SummaryWriter object at 0x7f875739d450>'}\u001b[0m\n",
      "\u001b[2m01:08:43.124241 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'label_map/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.124288 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.124341 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.124386 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.124430 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.124473 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.00758222...7: 'n03425413', 8: 'n03445777', 9: 'n03888257'}\"}\u001b[0m\n",
      "\u001b[2m01:08:43.124515 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'rev_label_map/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.124564 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.124618 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.124664 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.124708 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.124751 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.00758222...'n03425413': 7, 'n03445777': 8, 'n03888257': 9}\"}\u001b[0m\n",
      "\u001b[2m01:08:43.124794 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'num_classes/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.124843 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.124897 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.124943 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.124988 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.125032 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.00758222...45777': 8, 'n03888257': 9}\", 'num_classes': '10'}\u001b[0m\n",
      "\u001b[2m01:08:43.125075 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'dataset_sizes/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.125126 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.125183 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.125230 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.125277 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.125321 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.00758222... 'dataset_sizes': \"{'train': 4735, 'val': 4734}\"}\u001b[0m\n",
      "\u001b[2m01:08:43.125365 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'criterion/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.125415 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.125474 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.125520 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.125571 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.125620 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.00758222...'val': 4734}\", 'criterion': 'CrossEntropyLoss()'}\u001b[0m\n",
      "\u001b[2m01:08:43.125679 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'cam/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.125730 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.125788 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.125834 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.125879 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.125922 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.00758222...splus.GradCAMPlusPlus object at 0x7f876b71b8e0>'}\u001b[0m\n",
      "\u001b[2m01:08:43.125966 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'save_path/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.126016 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.126072 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.126119 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.126165 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.126209 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.00758222...rc/runs/baseline_run_26032023_205454/checkpoint'}\u001b[0m\n",
      "\u001b[2m01:08:43.126254 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'final_acc/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.126304 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.126360 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.126406 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.126453 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.126497 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.00758222...54/checkpoint', 'final_acc': '88.00168990283059'}\u001b[0m\n",
      "\u001b[2m01:08:43.126542 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[2m01:08:43.126608 line        85\u001b[0m         if tag == \"images\" and save_ims == True:\n",
      "\u001b[2m01:08:43.126658 line        46\u001b[0m     for tag in all_tags.keys():\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtag = 'graph'\u001b[0m\n",
      "\u001b[2m01:08:43.126703 line        47\u001b[0m         if tag == \"scalars\":\n",
      "\u001b[2m01:08:43.126754 line        59\u001b[0m         if tag == \"tensors\":\n",
      "\u001b[2m01:08:43.126799 line        85\u001b[0m         if tag == \"images\" and save_ims == True:\n",
      "\u001b[2m01:08:43.126844 line        46\u001b[0m     for tag in all_tags.keys():\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtag = 'meta_graph'\u001b[0m\n",
      "\u001b[2m01:08:43.126890 line        47\u001b[0m         if tag == \"scalars\":\n",
      "\u001b[2m01:08:43.126943 line        59\u001b[0m         if tag == \"tensors\":\n",
      "\u001b[2m01:08:43.126993 line        85\u001b[0m         if tag == \"images\" and save_ims == True:\n",
      "\u001b[2m01:08:43.127039 line        46\u001b[0m     for tag in all_tags.keys():\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtag = 'run_metadata'\u001b[0m\n",
      "\u001b[2m01:08:43.127098 line        47\u001b[0m         if tag == \"scalars\":\n",
      "\u001b[2m01:08:43.127149 line        59\u001b[0m         if tag == \"tensors\":\n",
      "\u001b[2m01:08:43.127194 line        85\u001b[0m         if tag == \"images\" and save_ims == True:\n",
      "\u001b[2m01:08:43.127242 line        46\u001b[0m     for tag in all_tags.keys():\n",
      "\u001b[2m01:08:43.127287 line        96\u001b[0m     return temp_dict\n",
      "\u001b[2m01:08:43.127334 return      96\u001b[0m     return temp_dict\n",
      "\u001b[36m\u001b[2mReturn value:.. \u001b[22m{'proxy_step': 'False', 'Loss/Train': 0.00758222...54/checkpoint', 'final_acc': '88.00168990283059'}\u001b[0m\n",
      "\u001b[33m\u001b[2mElapsed time: \u001b[22m00:00:00.013397\u001b[0m\n",
      "runs/baseline_run_26032023_210253/events.out.tfevents.1679857377.eragon\n",
      "\u001b[32m\u001b[2mStarting var:.. \u001b[22mevent_acc = <tensorboard.backend.event_processing.event_accumulator.EventAccumulator object at 0x7f5b568effa0>\u001b[0m\n",
      "\u001b[32m\u001b[2mStarting var:.. \u001b[22msave_ims = False\u001b[0m\n",
      "\u001b[2m01:08:43.135788 call        42\u001b[0m def process_event_acc(event_acc, save_ims = False):\n",
      "\u001b[2m01:08:43.135905 line        44\u001b[0m     all_tags = event_acc.Tags()\n",
      "\u001b[32m\u001b[2mNew var:....... \u001b[22mall_tags = {'images': [], 'audio': [], 'histograms': [], 's...: False, 'meta_graph': False, 'run_metadata': []}\u001b[0m\n",
      "\u001b[2m01:08:43.135986 line        45\u001b[0m     temp_dict = {}\n",
      "\u001b[32m\u001b[2mNew var:....... \u001b[22mtemp_dict = {}\u001b[0m\n",
      "\u001b[2m01:08:43.136121 line        46\u001b[0m     for tag in all_tags.keys():\n",
      "\u001b[32m\u001b[2mNew var:....... \u001b[22mtag = 'images'\u001b[0m\n",
      "\u001b[2m01:08:43.136162 line        47\u001b[0m         if tag == \"scalars\":\n",
      "\u001b[2m01:08:43.136202 line        59\u001b[0m         if tag == \"tensors\":\n",
      "\u001b[2m01:08:43.136234 line        85\u001b[0m         if tag == \"images\" and save_ims == True:\n",
      "\u001b[2m01:08:43.136265 line        46\u001b[0m     for tag in all_tags.keys():\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtag = 'audio'\u001b[0m\n",
      "\u001b[2m01:08:43.136294 line        47\u001b[0m         if tag == \"scalars\":\n",
      "\u001b[2m01:08:43.136327 line        59\u001b[0m         if tag == \"tensors\":\n",
      "\u001b[2m01:08:43.136356 line        85\u001b[0m         if tag == \"images\" and save_ims == True:\n",
      "\u001b[2m01:08:43.136384 line        46\u001b[0m     for tag in all_tags.keys():\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtag = 'histograms'\u001b[0m\n",
      "\u001b[2m01:08:43.136411 line        47\u001b[0m         if tag == \"scalars\":\n",
      "\u001b[2m01:08:43.136444 line        59\u001b[0m         if tag == \"tensors\":\n",
      "\u001b[2m01:08:43.136471 line        85\u001b[0m         if tag == \"images\" and save_ims == True:\n",
      "\u001b[2m01:08:43.136498 line        46\u001b[0m     for tag in all_tags.keys():\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtag = 'scalars'\u001b[0m\n",
      "\u001b[2m01:08:43.136526 line        47\u001b[0m         if tag == \"scalars\":\n",
      "\u001b[2m01:08:43.136558 line        48\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mNew var:....... \u001b[22msubtag = 'proxy_step'\u001b[0m\n",
      "\u001b[2m01:08:43.136586 line        50\u001b[0m                 try:\n",
      "\u001b[2m01:08:43.136620 line        51\u001b[0m                     temp_dict[subtag] = [tag[-1] for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.136661 exception   51\u001b[0m                     temp_dict[subtag] = [tag[-1] for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[31mException:..... \u001b[1mTypeError: 'ScalarEvent' object is not subscriptable\u001b[0m\n",
      "\u001b[2m01:08:43.136723 line        54\u001b[0m                 except:\n",
      "\u001b[2m01:08:43.136757 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.136796 line        56\u001b[0m                     -1\n",
      "\u001b[2m01:08:43.136827 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.136862 line        57\u001b[0m                 ].value\n",
      "\u001b[2m01:08:43.136894 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0}\u001b[0m\n",
      "\u001b[2m01:08:43.136924 line        48\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'Loss/Train'\u001b[0m\n",
      "\u001b[2m01:08:43.136963 line        50\u001b[0m                 try:\n",
      "\u001b[2m01:08:43.136998 line        51\u001b[0m                     temp_dict[subtag] = [tag[-1] for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.137037 exception   51\u001b[0m                     temp_dict[subtag] = [tag[-1] for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[31mException:..... \u001b[1mTypeError: 'ScalarEvent' object is not subscriptable\u001b[0m\n",
      "\u001b[2m01:08:43.137121 line        54\u001b[0m                 except:\n",
      "\u001b[2m01:08:43.137156 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.137197 line        56\u001b[0m                     -1\n",
      "\u001b[2m01:08:43.137229 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.137261 line        57\u001b[0m                 ].value\n",
      "\u001b[2m01:08:43.137292 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 0.027845097705721855}\u001b[0m\n",
      "\u001b[2m01:08:43.137324 line        48\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'Acc/Train'\u001b[0m\n",
      "\u001b[2m01:08:43.137362 line        50\u001b[0m                 try:\n",
      "\u001b[2m01:08:43.137398 line        51\u001b[0m                     temp_dict[subtag] = [tag[-1] for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.137435 exception   51\u001b[0m                     temp_dict[subtag] = [tag[-1] for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[31mException:..... \u001b[1mTypeError: 'ScalarEvent' object is not subscriptable\u001b[0m\n",
      "\u001b[2m01:08:43.137485 line        54\u001b[0m                 except:\n",
      "\u001b[2m01:08:43.137519 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.137558 line        56\u001b[0m                     -1\n",
      "\u001b[2m01:08:43.137590 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.137620 line        57\u001b[0m                 ].value\n",
      "\u001b[2m01:08:43.137661 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 0.027845097705721855, 'Acc/Train': 73.91000366210938}\u001b[0m\n",
      "\u001b[2m01:08:43.137699 line        48\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'global_run_count'\u001b[0m\n",
      "\u001b[2m01:08:43.137751 line        50\u001b[0m                 try:\n",
      "\u001b[2m01:08:43.137788 line        51\u001b[0m                     temp_dict[subtag] = [tag[-1] for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.137830 exception   51\u001b[0m                     temp_dict[subtag] = [tag[-1] for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[31mException:..... \u001b[1mTypeError: 'ScalarEvent' object is not subscriptable\u001b[0m\n",
      "\u001b[2m01:08:43.137888 line        54\u001b[0m                 except:\n",
      "\u001b[2m01:08:43.137924 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.137969 line        56\u001b[0m                     -1\n",
      "\u001b[2m01:08:43.138009 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.138045 line        57\u001b[0m                 ].value\n",
      "\u001b[2m01:08:43.138081 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 0.027845097705...in': 73.91000366210938, 'global_run_count': 20.0}\u001b[0m\n",
      "\u001b[2m01:08:43.138114 line        48\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'Loss/Val'\u001b[0m\n",
      "\u001b[2m01:08:43.138162 line        50\u001b[0m                 try:\n",
      "\u001b[2m01:08:43.138202 line        51\u001b[0m                     temp_dict[subtag] = [tag[-1] for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.138242 exception   51\u001b[0m                     temp_dict[subtag] = [tag[-1] for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[31mException:..... \u001b[1mTypeError: 'ScalarEvent' object is not subscriptable\u001b[0m\n",
      "\u001b[2m01:08:43.138300 line        54\u001b[0m                 except:\n",
      "\u001b[2m01:08:43.138336 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.138377 line        56\u001b[0m                     -1\n",
      "\u001b[2m01:08:43.138410 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.138443 line        57\u001b[0m                 ].value\n",
      "\u001b[2m01:08:43.138476 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 0.027845097705...un_count': 20.0, 'Loss/Val': 0.04357531666755676}\u001b[0m\n",
      "\u001b[2m01:08:43.138510 line        48\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'Acc/Val'\u001b[0m\n",
      "\u001b[2m01:08:43.138549 line        50\u001b[0m                 try:\n",
      "\u001b[2m01:08:43.138587 line        51\u001b[0m                     temp_dict[subtag] = [tag[-1] for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.138627 exception   51\u001b[0m                     temp_dict[subtag] = [tag[-1] for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[31mException:..... \u001b[1mTypeError: 'ScalarEvent' object is not subscriptable\u001b[0m\n",
      "\u001b[2m01:08:43.138690 line        54\u001b[0m                 except:\n",
      "\u001b[2m01:08:43.138727 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.138769 line        56\u001b[0m                     -1\n",
      "\u001b[2m01:08:43.138803 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.138836 line        57\u001b[0m                 ].value\n",
      "\u001b[2m01:08:43.138868 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 0.027845097705....04357531666755676, 'Acc/Val': 63.65999984741211}\u001b[0m\n",
      "\u001b[2m01:08:43.138901 line        48\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[2m01:08:43.138940 line        59\u001b[0m         if tag == \"tensors\":\n",
      "\u001b[2m01:08:43.138973 line        85\u001b[0m         if tag == \"images\" and save_ims == True:\n",
      "\u001b[2m01:08:43.139006 line        46\u001b[0m     for tag in all_tags.keys():\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtag = 'distributions'\u001b[0m\n",
      "\u001b[2m01:08:43.139039 line        47\u001b[0m         if tag == \"scalars\":\n",
      "\u001b[2m01:08:43.139076 line        59\u001b[0m         if tag == \"tensors\":\n",
      "\u001b[2m01:08:43.139109 line        85\u001b[0m         if tag == \"images\" and save_ims == True:\n",
      "\u001b[2m01:08:43.139141 line        46\u001b[0m     for tag in all_tags.keys():\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtag = 'tensors'\u001b[0m\n",
      "\u001b[2m01:08:43.139173 line        47\u001b[0m         if tag == \"scalars\":\n",
      "\u001b[2m01:08:43.139211 line        59\u001b[0m         if tag == \"tensors\":\n",
      "\u001b[2m01:08:43.139242 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'experiment_name/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.139275 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.139320 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.139358 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.139395 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.139428 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 0.027845097705...5999984741211, 'experiment_name': 'baseline_run'}\u001b[0m\n",
      "\u001b[2m01:08:43.139462 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'image_size/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.139508 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.139576 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.139615 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.139651 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.139685 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 0.027845097705...iment_name': 'baseline_run', 'image_size': '224'}\u001b[0m\n",
      "\u001b[2m01:08:43.139719 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'batch_size/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.139757 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.139802 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.139838 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.139872 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.139905 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 0.027845097705...ne_run', 'image_size': '224', 'batch_size': '32'}\u001b[0m\n",
      "\u001b[2m01:08:43.139940 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'enable_proxy_attention/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.139979 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.140025 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.140060 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.140099 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.140138 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 0.027845097705...ch_size': '32', 'enable_proxy_attention': 'True'}\u001b[0m\n",
      "\u001b[2m01:08:43.140172 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'transfer_imagenet/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.140211 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.140256 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.140290 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.140324 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.140357 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 0.027845097705..._attention': 'True', 'transfer_imagenet': 'True'}\u001b[0m\n",
      "\u001b[2m01:08:43.140402 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'subset_images/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.140467 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.140520 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.140557 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.140593 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.140630 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 0.027845097705...sfer_imagenet': 'True', 'subset_images': '20000'}\u001b[0m\n",
      "\u001b[2m01:08:43.140677 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'pixel_replacement_method/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.140726 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.140785 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.140830 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.140866 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.140900 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 0.027845097705...: '20000', 'pixel_replacement_method': 'blended'}\u001b[0m\n",
      "\u001b[2m01:08:43.140934 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'proxy_steps/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.140974 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.141019 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.141066 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.141102 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.141137 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 0.027845097705...cement_method': 'blended', 'proxy_steps': '[20]'}\u001b[0m\n",
      "\u001b[2m01:08:43.141171 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'load_proxy_data/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.141212 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.141258 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.141294 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.141329 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.141364 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 0.027845097705...proxy_steps': '[20]', 'load_proxy_data': 'False'}\u001b[0m\n",
      "\u001b[2m01:08:43.141398 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'proxy_step/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.141437 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.141482 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.141518 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.141553 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.141587 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.02784509...proxy_steps': '[20]', 'load_proxy_data': 'False'}\u001b[0m\n",
      "\u001b[2m01:08:43.141622 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'log_every/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.141662 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.141708 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.141744 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.141780 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.141814 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.02784509...]', 'load_proxy_data': 'False', 'log_every': '2'}\u001b[0m\n",
      "\u001b[2m01:08:43.141849 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'device/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.141888 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.141933 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.141968 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.142003 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.142037 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.02784509...': 'False', 'log_every': '2', 'device': 'cuda:0'}\u001b[0m\n",
      "\u001b[2m01:08:43.142072 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'dataset_info/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.142111 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.142157 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.142192 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.142229 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.142265 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.02784509...t_name at 0x7f03991cba30>, 'num_classes': 101}}\"}\u001b[0m\n",
      "\u001b[2m01:08:43.142301 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'main_run_dir/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.142348 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.142399 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.142441 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.142486 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.142529 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.02784509...DE/Github/improving_robotics_datasets/src/runs/'}\u001b[0m\n",
      "\u001b[2m01:08:43.142572 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'change_subset_attention/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.142633 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.142691 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.142737 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.142781 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.142822 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.02784509...ets/src/runs/', 'change_subset_attention': '0.8'}\u001b[0m\n",
      "\u001b[2m01:08:43.142865 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'model/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.142915 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.142973 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.143018 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.143061 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.143114 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.02784509...ge_subset_attention': '0.8', 'model': 'resnet50'}\u001b[0m\n",
      "\u001b[2m01:08:43.143157 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'proxy_image_weight/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.143202 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.143255 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.143297 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.143339 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.143379 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.02784509...'model': 'resnet50', 'proxy_image_weight': '0.1'}\u001b[0m\n",
      "\u001b[2m01:08:43.143420 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'proxy_threshold/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.143466 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.143518 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.143560 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.143601 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.143642 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.02784509..._image_weight': '0.1', 'proxy_threshold': '0.85'}\u001b[0m\n",
      "\u001b[2m01:08:43.143682 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'gradient_method/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.143736 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.143789 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.143831 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.143872 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.143912 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.02784509...d': '0.85', 'gradient_method': 'gradcamplusplus'}\u001b[0m\n",
      "\u001b[2m01:08:43.143952 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'ds_name/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.143997 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.144048 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.144089 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.144131 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.144171 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.02784509...ethod': 'gradcamplusplus', 'ds_name': 'cifar100'}\u001b[0m\n",
      "\u001b[2m01:08:43.144211 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'clear_every_step/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.144257 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.144313 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.144359 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.144404 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.144447 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.02784509...ds_name': 'cifar100', 'clear_every_step': 'True'}\u001b[0m\n",
      "\u001b[2m01:08:43.144488 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'fname_start/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.144539 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.144598 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.144650 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.144694 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.144741 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.02784509..._datasets/src/runs/baseline_run_26032023_210253'}\u001b[0m\n",
      "\u001b[2m01:08:43.144789 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'ds_path/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.144840 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.144898 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.144947 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.144994 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.145039 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.02784509...'/run/media/eragon/HDD/Datasets/CIFAR-100/train'}\u001b[0m\n",
      "\u001b[2m01:08:43.145085 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'name_fn/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.145138 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.145196 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.145245 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.145297 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.145343 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.02784509...: '<function get_parent_name at 0x7f03991cba30>'}\u001b[0m\n",
      "\u001b[2m01:08:43.145384 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'global_run_count/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.145431 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.145483 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.145526 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.145568 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.145609 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[2m01:08:43.145651 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'writer/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.145692 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.145744 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.145786 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.145829 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.145870 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.02784509....writer.SummaryWriter object at 0x7f037e7db670>'}\u001b[0m\n",
      "\u001b[2m01:08:43.145912 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'label_map/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.145958 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.146011 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.146056 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.146101 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.146142 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.02784509...low_tree', 97: 'wolf', 98: 'woman', 99: 'worm'}\"}\u001b[0m\n",
      "\u001b[2m01:08:43.146185 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'rev_label_map/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.146240 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.146301 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.146352 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.146402 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.146452 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.02784509...tree': 96, 'wolf': 97, 'woman': 98, 'worm': 99}\"}\u001b[0m\n",
      "\u001b[2m01:08:43.146501 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'num_classes/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.146580 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.146653 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.146715 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.146774 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.146836 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.02784509... 'woman': 98, 'worm': 99}\", 'num_classes': '100'}\u001b[0m\n",
      "\u001b[2m01:08:43.146897 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'dataset_sizes/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.146964 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.147039 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.147123 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.147183 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.147240 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.02784509...dataset_sizes': \"{'train': 10000, 'val': 10000}\"}\u001b[0m\n",
      "\u001b[2m01:08:43.147296 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'criterion/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.147359 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.147427 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.147486 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.147543 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.147599 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.02784509...val': 10000}\", 'criterion': 'CrossEntropyLoss()'}\u001b[0m\n",
      "\u001b[2m01:08:43.147655 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'cam/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.147719 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.147788 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.147847 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.147905 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.147962 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.02784509...splus.GradCAMPlusPlus object at 0x7f037d0db310>'}\u001b[0m\n",
      "\u001b[2m01:08:43.148019 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'save_path/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.148082 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.148149 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.148209 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.148267 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.148324 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.02784509...rc/runs/baseline_run_26032023_210253/checkpoint'}\u001b[0m\n",
      "\u001b[2m01:08:43.148390 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'final_acc/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.148461 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.148531 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.148593 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.148655 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.148718 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.02784509...6032023_210253/checkpoint', 'final_acc': '63.66'}\u001b[0m\n",
      "\u001b[2m01:08:43.148786 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[2m01:08:43.148853 line        85\u001b[0m         if tag == \"images\" and save_ims == True:\n",
      "\u001b[2m01:08:43.148913 line        46\u001b[0m     for tag in all_tags.keys():\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtag = 'graph'\u001b[0m\n",
      "\u001b[2m01:08:43.148979 line        47\u001b[0m         if tag == \"scalars\":\n",
      "\u001b[2m01:08:43.149043 line        59\u001b[0m         if tag == \"tensors\":\n",
      "\u001b[2m01:08:43.149100 line        85\u001b[0m         if tag == \"images\" and save_ims == True:\n",
      "\u001b[2m01:08:43.149157 line        46\u001b[0m     for tag in all_tags.keys():\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtag = 'meta_graph'\u001b[0m\n",
      "\u001b[2m01:08:43.149213 line        47\u001b[0m         if tag == \"scalars\":\n",
      "\u001b[2m01:08:43.149275 line        59\u001b[0m         if tag == \"tensors\":\n",
      "\u001b[2m01:08:43.149331 line        85\u001b[0m         if tag == \"images\" and save_ims == True:\n",
      "\u001b[2m01:08:43.149387 line        46\u001b[0m     for tag in all_tags.keys():\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtag = 'run_metadata'\u001b[0m\n",
      "\u001b[2m01:08:43.149442 line        47\u001b[0m         if tag == \"scalars\":\n",
      "\u001b[2m01:08:43.149503 line        59\u001b[0m         if tag == \"tensors\":\n",
      "\u001b[2m01:08:43.149558 line        85\u001b[0m         if tag == \"images\" and save_ims == True:\n",
      "\u001b[2m01:08:43.149623 line        46\u001b[0m     for tag in all_tags.keys():\n",
      "\u001b[2m01:08:43.149693 line        96\u001b[0m     return temp_dict\n",
      "\u001b[2m01:08:43.149752 return      96\u001b[0m     return temp_dict\n",
      "\u001b[36m\u001b[2mReturn value:.. \u001b[22m{'proxy_step': 'False', 'Loss/Train': 0.02784509...6032023_210253/checkpoint', 'final_acc': '63.66'}\u001b[0m\n",
      "\u001b[33m\u001b[2mElapsed time: \u001b[22m00:00:00.014089\u001b[0m\n",
      " 34%|██████████████▊                            | 10/29 [00:00<00:00, 43.33it/s]runs/baseline_run_26032023_211712/events.out.tfevents.1679858255.eragon\n",
      "\u001b[32m\u001b[2mStarting var:.. \u001b[22mevent_acc = <tensorboard.backend.event_processing.event_accumulator.EventAccumulator object at 0x7f5b568ed900>\u001b[0m\n",
      "\u001b[32m\u001b[2mStarting var:.. \u001b[22msave_ims = False\u001b[0m\n",
      "\u001b[2m01:08:43.158902 call        42\u001b[0m def process_event_acc(event_acc, save_ims = False):\n",
      "\u001b[2m01:08:43.158974 line        44\u001b[0m     all_tags = event_acc.Tags()\n",
      "\u001b[32m\u001b[2mNew var:....... \u001b[22mall_tags = {'images': [], 'audio': [], 'histograms': [], 's...: False, 'meta_graph': False, 'run_metadata': []}\u001b[0m\n",
      "\u001b[2m01:08:43.159016 line        45\u001b[0m     temp_dict = {}\n",
      "\u001b[32m\u001b[2mNew var:....... \u001b[22mtemp_dict = {}\u001b[0m\n",
      "\u001b[2m01:08:43.159108 line        46\u001b[0m     for tag in all_tags.keys():\n",
      "\u001b[32m\u001b[2mNew var:....... \u001b[22mtag = 'images'\u001b[0m\n",
      "\u001b[2m01:08:43.159154 line        47\u001b[0m         if tag == \"scalars\":\n",
      "\u001b[2m01:08:43.159194 line        59\u001b[0m         if tag == \"tensors\":\n",
      "\u001b[2m01:08:43.159226 line        85\u001b[0m         if tag == \"images\" and save_ims == True:\n",
      "\u001b[2m01:08:43.159255 line        46\u001b[0m     for tag in all_tags.keys():\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtag = 'audio'\u001b[0m\n",
      "\u001b[2m01:08:43.159283 line        47\u001b[0m         if tag == \"scalars\":\n",
      "\u001b[2m01:08:43.159316 line        59\u001b[0m         if tag == \"tensors\":\n",
      "\u001b[2m01:08:43.159344 line        85\u001b[0m         if tag == \"images\" and save_ims == True:\n",
      "\u001b[2m01:08:43.159372 line        46\u001b[0m     for tag in all_tags.keys():\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtag = 'histograms'\u001b[0m\n",
      "\u001b[2m01:08:43.159399 line        47\u001b[0m         if tag == \"scalars\":\n",
      "\u001b[2m01:08:43.159436 line        59\u001b[0m         if tag == \"tensors\":\n",
      "\u001b[2m01:08:43.159464 line        85\u001b[0m         if tag == \"images\" and save_ims == True:\n",
      "\u001b[2m01:08:43.159497 line        46\u001b[0m     for tag in all_tags.keys():\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtag = 'scalars'\u001b[0m\n",
      "\u001b[2m01:08:43.159525 line        47\u001b[0m         if tag == \"scalars\":\n",
      "\u001b[2m01:08:43.159558 line        48\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mNew var:....... \u001b[22msubtag = 'proxy_step'\u001b[0m\n",
      "\u001b[2m01:08:43.159586 line        50\u001b[0m                 try:\n",
      "\u001b[2m01:08:43.159620 line        51\u001b[0m                     temp_dict[subtag] = [tag[-1] for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.159659 exception   51\u001b[0m                     temp_dict[subtag] = [tag[-1] for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[31mException:..... \u001b[1mTypeError: 'ScalarEvent' object is not subscriptable\u001b[0m\n",
      "\u001b[2m01:08:43.159720 line        54\u001b[0m                 except:\n",
      "\u001b[2m01:08:43.159753 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.159793 line        56\u001b[0m                     -1\n",
      "\u001b[2m01:08:43.159823 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.159853 line        57\u001b[0m                 ].value\n",
      "\u001b[2m01:08:43.159888 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0}\u001b[0m\n",
      "\u001b[2m01:08:43.159930 line        48\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'Loss/Train'\u001b[0m\n",
      "\u001b[2m01:08:43.159970 line        50\u001b[0m                 try:\n",
      "\u001b[2m01:08:43.160006 line        51\u001b[0m                     temp_dict[subtag] = [tag[-1] for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.160043 exception   51\u001b[0m                     temp_dict[subtag] = [tag[-1] for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[31mException:..... \u001b[1mTypeError: 'ScalarEvent' object is not subscriptable\u001b[0m\n",
      "\u001b[2m01:08:43.160095 line        54\u001b[0m                 except:\n",
      "\u001b[2m01:08:43.160128 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.160166 line        56\u001b[0m                     -1\n",
      "\u001b[2m01:08:43.160196 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.160234 line        57\u001b[0m                 ].value\n",
      "\u001b[2m01:08:43.160264 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 0.025359544903039932}\u001b[0m\n",
      "\u001b[2m01:08:43.160294 line        48\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'Acc/Train'\u001b[0m\n",
      "\u001b[2m01:08:43.160331 line        50\u001b[0m                 try:\n",
      "\u001b[2m01:08:43.160367 line        51\u001b[0m                     temp_dict[subtag] = [tag[-1] for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.160427 exception   51\u001b[0m                     temp_dict[subtag] = [tag[-1] for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[31mException:..... \u001b[1mTypeError: 'ScalarEvent' object is not subscriptable\u001b[0m\n",
      "\u001b[2m01:08:43.160480 line        54\u001b[0m                 except:\n",
      "\u001b[2m01:08:43.160514 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.160562 line        56\u001b[0m                     -1\n",
      "\u001b[2m01:08:43.160594 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.160625 line        57\u001b[0m                 ].value\n",
      "\u001b[2m01:08:43.160656 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 0.025359544903039932, 'Acc/Train': 76.11000061035156}\u001b[0m\n",
      "\u001b[2m01:08:43.160686 line        48\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'global_run_count'\u001b[0m\n",
      "\u001b[2m01:08:43.160723 line        50\u001b[0m                 try:\n",
      "\u001b[2m01:08:43.160760 line        51\u001b[0m                     temp_dict[subtag] = [tag[-1] for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.160798 exception   51\u001b[0m                     temp_dict[subtag] = [tag[-1] for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[31mException:..... \u001b[1mTypeError: 'ScalarEvent' object is not subscriptable\u001b[0m\n",
      "\u001b[2m01:08:43.160849 line        54\u001b[0m                 except:\n",
      "\u001b[2m01:08:43.160884 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.160925 line        56\u001b[0m                     -1\n",
      "\u001b[2m01:08:43.160963 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.160995 line        57\u001b[0m                 ].value\n",
      "\u001b[2m01:08:43.161026 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 0.025359544903...in': 76.11000061035156, 'global_run_count': 20.0}\u001b[0m\n",
      "\u001b[2m01:08:43.161058 line        48\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'Loss/Val'\u001b[0m\n",
      "\u001b[2m01:08:43.161098 line        50\u001b[0m                 try:\n",
      "\u001b[2m01:08:43.161135 line        51\u001b[0m                     temp_dict[subtag] = [tag[-1] for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.161175 exception   51\u001b[0m                     temp_dict[subtag] = [tag[-1] for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[31mException:..... \u001b[1mTypeError: 'ScalarEvent' object is not subscriptable\u001b[0m\n",
      "\u001b[2m01:08:43.161242 line        54\u001b[0m                 except:\n",
      "\u001b[2m01:08:43.161283 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.161324 line        56\u001b[0m                     -1\n",
      "\u001b[2m01:08:43.161358 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.161391 line        57\u001b[0m                 ].value\n",
      "\u001b[2m01:08:43.161423 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 0.025359544903...n_count': 20.0, 'Loss/Val': 0.036955881863832474}\u001b[0m\n",
      "\u001b[2m01:08:43.161457 line        48\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'Acc/Val'\u001b[0m\n",
      "\u001b[2m01:08:43.161495 line        50\u001b[0m                 try:\n",
      "\u001b[2m01:08:43.161533 line        51\u001b[0m                     temp_dict[subtag] = [tag[-1] for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.161582 exception   51\u001b[0m                     temp_dict[subtag] = [tag[-1] for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[31mException:..... \u001b[1mTypeError: 'ScalarEvent' object is not subscriptable\u001b[0m\n",
      "\u001b[2m01:08:43.161636 line        54\u001b[0m                 except:\n",
      "\u001b[2m01:08:43.161671 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.161725 line        56\u001b[0m                     -1\n",
      "\u001b[2m01:08:43.161760 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.161793 line        57\u001b[0m                 ].value\n",
      "\u001b[2m01:08:43.161826 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 0.025359544903...036955881863832474, 'Acc/Val': 66.62999725341797}\u001b[0m\n",
      "\u001b[2m01:08:43.161861 line        48\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[2m01:08:43.161900 line        59\u001b[0m         if tag == \"tensors\":\n",
      "\u001b[2m01:08:43.161934 line        85\u001b[0m         if tag == \"images\" and save_ims == True:\n",
      "\u001b[2m01:08:43.161969 line        46\u001b[0m     for tag in all_tags.keys():\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtag = 'distributions'\u001b[0m\n",
      "\u001b[2m01:08:43.162003 line        47\u001b[0m         if tag == \"scalars\":\n",
      "\u001b[2m01:08:43.162041 line        59\u001b[0m         if tag == \"tensors\":\n",
      "\u001b[2m01:08:43.162074 line        85\u001b[0m         if tag == \"images\" and save_ims == True:\n",
      "\u001b[2m01:08:43.162107 line        46\u001b[0m     for tag in all_tags.keys():\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtag = 'tensors'\u001b[0m\n",
      "\u001b[2m01:08:43.162139 line        47\u001b[0m         if tag == \"scalars\":\n",
      "\u001b[2m01:08:43.162176 line        59\u001b[0m         if tag == \"tensors\":\n",
      "\u001b[2m01:08:43.162209 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'experiment_name/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.162241 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.162306 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.162348 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.162386 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.162421 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 0.025359544903...2999725341797, 'experiment_name': 'baseline_run'}\u001b[0m\n",
      "\u001b[2m01:08:43.162455 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'image_size/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.162494 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.162539 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.162577 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.162621 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.162656 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 0.025359544903...iment_name': 'baseline_run', 'image_size': '224'}\u001b[0m\n",
      "\u001b[2m01:08:43.162696 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'batch_size/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.162747 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.162794 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.162831 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.162866 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.162900 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 0.025359544903...ne_run', 'image_size': '224', 'batch_size': '32'}\u001b[0m\n",
      "\u001b[2m01:08:43.162934 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'enable_proxy_attention/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.162973 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.163019 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.163054 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.163089 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.163123 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 0.025359544903...ch_size': '32', 'enable_proxy_attention': 'True'}\u001b[0m\n",
      "\u001b[2m01:08:43.163158 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'transfer_imagenet/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.163197 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.163243 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.163279 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.163314 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.163348 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 0.025359544903..._attention': 'True', 'transfer_imagenet': 'True'}\u001b[0m\n",
      "\u001b[2m01:08:43.163382 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'subset_images/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.163421 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.163467 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.163503 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.163538 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.163572 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 0.025359544903...sfer_imagenet': 'True', 'subset_images': '20000'}\u001b[0m\n",
      "\u001b[2m01:08:43.163606 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'pixel_replacement_method/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.163645 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.163690 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.163741 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.163779 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.163813 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 0.025359544903...: '20000', 'pixel_replacement_method': 'blended'}\u001b[0m\n",
      "\u001b[2m01:08:43.163852 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'proxy_steps/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.163896 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.163942 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.163978 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.164014 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.164048 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 0.025359544903...cement_method': 'blended', 'proxy_steps': '[20]'}\u001b[0m\n",
      "\u001b[2m01:08:43.164083 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'load_proxy_data/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.164122 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.164168 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.164203 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.164239 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.164273 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 0.025359544903...proxy_steps': '[20]', 'load_proxy_data': 'False'}\u001b[0m\n",
      "\u001b[2m01:08:43.164308 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'proxy_step/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.164347 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.164393 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.164429 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.164464 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.164499 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.02535954...proxy_steps': '[20]', 'load_proxy_data': 'False'}\u001b[0m\n",
      "\u001b[2m01:08:43.164533 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'log_every/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.164573 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.164622 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.164660 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.164697 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.164733 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.02535954...]', 'load_proxy_data': 'False', 'log_every': '2'}\u001b[0m\n",
      "\u001b[2m01:08:43.164767 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'device/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.164808 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.164854 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.164890 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.164926 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.164960 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.02535954...': 'False', 'log_every': '2', 'device': 'cuda:0'}\u001b[0m\n",
      "\u001b[2m01:08:43.164995 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'dataset_info/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.165036 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.165082 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.165133 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.165170 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.165205 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.02535954...t_name at 0x7f27efbc7a30>, 'num_classes': 101}}\"}\u001b[0m\n",
      "\u001b[2m01:08:43.165240 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'main_run_dir/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.165286 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.165339 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.165382 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.165423 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.165463 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.02535954...DE/Github/improving_robotics_datasets/src/runs/'}\u001b[0m\n",
      "\u001b[2m01:08:43.165503 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'change_subset_attention/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.165548 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.165599 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.165646 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.165696 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.165737 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.02535954...ets/src/runs/', 'change_subset_attention': '0.8'}\u001b[0m\n",
      "\u001b[2m01:08:43.165777 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'model/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.165823 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.165876 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.165919 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.165961 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.166001 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.02535954...ge_subset_attention': '0.8', 'model': 'resnet50'}\u001b[0m\n",
      "\u001b[2m01:08:43.166047 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'proxy_image_weight/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.166093 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.166144 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.166186 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.166228 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.166268 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.02535954...'model': 'resnet50', 'proxy_image_weight': '0.1'}\u001b[0m\n",
      "\u001b[2m01:08:43.166309 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'proxy_threshold/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.166355 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.166406 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.166454 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.166506 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.166548 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.02535954..._image_weight': '0.1', 'proxy_threshold': '0.85'}\u001b[0m\n",
      "\u001b[2m01:08:43.166588 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'gradient_method/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.166634 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.166685 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.166728 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.166774 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.166818 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.02535954...d': '0.85', 'gradient_method': 'gradcamplusplus'}\u001b[0m\n",
      "\u001b[2m01:08:43.166859 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'ds_name/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.166904 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.166956 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.166999 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.167040 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.167092 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.02535954...nt_method': 'gradcamplusplus', 'ds_name': 'dogs'}\u001b[0m\n",
      "\u001b[2m01:08:43.167133 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'clear_every_step/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.167179 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.167230 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.167273 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.167315 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.167356 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.02535954...', 'ds_name': 'dogs', 'clear_every_step': 'True'}\u001b[0m\n",
      "\u001b[2m01:08:43.167397 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'fname_start/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.167444 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.167496 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.167538 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.167580 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.167621 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.02535954..._datasets/src/runs/baseline_run_26032023_211712'}\u001b[0m\n",
      "\u001b[2m01:08:43.167673 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'ds_path/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.167726 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.167779 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.167825 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.167868 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.167909 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.02535954...un/media/eragon/HDD/Datasets/dogs/images/Images'}\u001b[0m\n",
      "\u001b[2m01:08:43.167950 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'name_fn/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.168004 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.168058 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.168101 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.168143 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.168184 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.02535954...: '<function get_parent_name at 0x7f27efbc7a30>'}\u001b[0m\n",
      "\u001b[2m01:08:43.168226 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'global_run_count/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.168273 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.168326 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.168369 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.168411 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.168453 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[2m01:08:43.168495 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'writer/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.168536 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.168591 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.168645 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.168689 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.168730 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.02535954....writer.SummaryWriter object at 0x7f27e4cfd0f0>'}\u001b[0m\n",
      "\u001b[2m01:08:43.168781 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'label_map/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.168836 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.168891 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.168935 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.168985 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.169029 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.02535954...3-dhole', 119: 'n02116738-African_hunting_dog'}\"}\u001b[0m\n",
      "\u001b[2m01:08:43.169074 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'rev_label_map/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.169144 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.169217 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.169289 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.169353 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.169417 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.02535954...le': 118, 'n02116738-African_hunting_dog': 119}\"}\u001b[0m\n",
      "\u001b[2m01:08:43.169478 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'num_classes/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.169576 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.169672 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.169753 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.169837 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.169915 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.02535954...frican_hunting_dog': 119}\", 'num_classes': '120'}\u001b[0m\n",
      "\u001b[2m01:08:43.169993 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'dataset_sizes/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.170076 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.170165 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.170245 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.170324 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.170411 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.02535954...dataset_sizes': \"{'train': 10000, 'val': 10000}\"}\u001b[0m\n",
      "\u001b[2m01:08:43.170491 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'criterion/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.170574 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.170665 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.170746 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.170847 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.170928 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.02535954...val': 10000}\", 'criterion': 'CrossEntropyLoss()'}\u001b[0m\n",
      "\u001b[2m01:08:43.171009 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'cam/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.171093 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.171190 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.171272 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.171353 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.171433 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.02535954...splus.GradCAMPlusPlus object at 0x7f27e339e140>'}\u001b[0m\n",
      "\u001b[2m01:08:43.171514 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'save_path/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.171601 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.171694 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.171791 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.171875 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.171964 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.02535954...rc/runs/baseline_run_26032023_211712/checkpoint'}\u001b[0m\n",
      "\u001b[2m01:08:43.172046 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'final_acc/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.172144 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.172240 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.172323 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.172404 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.172485 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.02535954...6032023_211712/checkpoint', 'final_acc': '66.63'}\u001b[0m\n",
      "\u001b[2m01:08:43.172566 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[2m01:08:43.172652 line        85\u001b[0m         if tag == \"images\" and save_ims == True:\n",
      "\u001b[2m01:08:43.172733 line        46\u001b[0m     for tag in all_tags.keys():\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtag = 'graph'\u001b[0m\n",
      "\u001b[2m01:08:43.172812 line        47\u001b[0m         if tag == \"scalars\":\n",
      "\u001b[2m01:08:43.172896 line        59\u001b[0m         if tag == \"tensors\":\n",
      "\u001b[2m01:08:43.172976 line        85\u001b[0m         if tag == \"images\" and save_ims == True:\n",
      "\u001b[2m01:08:43.173064 line        46\u001b[0m     for tag in all_tags.keys():\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtag = 'meta_graph'\u001b[0m\n",
      "\u001b[2m01:08:43.173147 line        47\u001b[0m         if tag == \"scalars\":\n",
      "\u001b[2m01:08:43.173234 line        59\u001b[0m         if tag == \"tensors\":\n",
      "\u001b[2m01:08:43.173314 line        85\u001b[0m         if tag == \"images\" and save_ims == True:\n",
      "\u001b[2m01:08:43.173393 line        46\u001b[0m     for tag in all_tags.keys():\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtag = 'run_metadata'\u001b[0m\n",
      "\u001b[2m01:08:43.173477 line        47\u001b[0m         if tag == \"scalars\":\n",
      "\u001b[2m01:08:43.173561 line        59\u001b[0m         if tag == \"tensors\":\n",
      "\u001b[2m01:08:43.173641 line        85\u001b[0m         if tag == \"images\" and save_ims == True:\n",
      "\u001b[2m01:08:43.173750 line        46\u001b[0m     for tag in all_tags.keys():\n",
      "\u001b[2m01:08:43.173849 line        96\u001b[0m     return temp_dict\n",
      "\u001b[2m01:08:43.173938 return      96\u001b[0m     return temp_dict\n",
      "\u001b[36m\u001b[2mReturn value:.. \u001b[22m{'proxy_step': 'False', 'Loss/Train': 0.02535954...6032023_211712/checkpoint', 'final_acc': '66.63'}\u001b[0m\n",
      "\u001b[33m\u001b[2mElapsed time: \u001b[22m00:00:00.015247\u001b[0m\n",
      "runs/baseline_run_26032023_213720/events.out.tfevents.1679859442.eragon\n",
      "\u001b[32m\u001b[2mStarting var:.. \u001b[22mevent_acc = <tensorboard.backend.event_processing.event_accumulator.EventAccumulator object at 0x7f5b568ed660>\u001b[0m\n",
      "\u001b[32m\u001b[2mStarting var:.. \u001b[22msave_ims = False\u001b[0m\n",
      "\u001b[2m01:08:43.182983 call        42\u001b[0m def process_event_acc(event_acc, save_ims = False):\n",
      "\u001b[2m01:08:43.183059 line        44\u001b[0m     all_tags = event_acc.Tags()\n",
      "\u001b[32m\u001b[2mNew var:....... \u001b[22mall_tags = {'images': [], 'audio': [], 'histograms': [], 's...: False, 'meta_graph': False, 'run_metadata': []}\u001b[0m\n",
      "\u001b[2m01:08:43.183101 line        45\u001b[0m     temp_dict = {}\n",
      "\u001b[32m\u001b[2mNew var:....... \u001b[22mtemp_dict = {}\u001b[0m\n",
      "\u001b[2m01:08:43.183192 line        46\u001b[0m     for tag in all_tags.keys():\n",
      "\u001b[32m\u001b[2mNew var:....... \u001b[22mtag = 'images'\u001b[0m\n",
      "\u001b[2m01:08:43.183231 line        47\u001b[0m         if tag == \"scalars\":\n",
      "\u001b[2m01:08:43.183268 line        59\u001b[0m         if tag == \"tensors\":\n",
      "\u001b[2m01:08:43.183297 line        85\u001b[0m         if tag == \"images\" and save_ims == True:\n",
      "\u001b[2m01:08:43.183327 line        46\u001b[0m     for tag in all_tags.keys():\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtag = 'audio'\u001b[0m\n",
      "\u001b[2m01:08:43.183356 line        47\u001b[0m         if tag == \"scalars\":\n",
      "\u001b[2m01:08:43.183389 line        59\u001b[0m         if tag == \"tensors\":\n",
      "\u001b[2m01:08:43.183417 line        85\u001b[0m         if tag == \"images\" and save_ims == True:\n",
      "\u001b[2m01:08:43.183444 line        46\u001b[0m     for tag in all_tags.keys():\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtag = 'histograms'\u001b[0m\n",
      "\u001b[2m01:08:43.183471 line        47\u001b[0m         if tag == \"scalars\":\n",
      "\u001b[2m01:08:43.183502 line        59\u001b[0m         if tag == \"tensors\":\n",
      "\u001b[2m01:08:43.183529 line        85\u001b[0m         if tag == \"images\" and save_ims == True:\n",
      "\u001b[2m01:08:43.183556 line        46\u001b[0m     for tag in all_tags.keys():\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtag = 'scalars'\u001b[0m\n",
      "\u001b[2m01:08:43.183583 line        47\u001b[0m         if tag == \"scalars\":\n",
      "\u001b[2m01:08:43.183616 line        48\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mNew var:....... \u001b[22msubtag = 'proxy_step'\u001b[0m\n",
      "\u001b[2m01:08:43.183643 line        50\u001b[0m                 try:\n",
      "\u001b[2m01:08:43.183677 line        51\u001b[0m                     temp_dict[subtag] = [tag[-1] for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.183716 exception   51\u001b[0m                     temp_dict[subtag] = [tag[-1] for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[31mException:..... \u001b[1mTypeError: 'ScalarEvent' object is not subscriptable\u001b[0m\n",
      "\u001b[2m01:08:43.183788 line        54\u001b[0m                 except:\n",
      "\u001b[2m01:08:43.183821 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.183860 line        56\u001b[0m                     -1\n",
      "\u001b[2m01:08:43.183891 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.183920 line        57\u001b[0m                 ].value\n",
      "\u001b[2m01:08:43.183948 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0}\u001b[0m\n",
      "\u001b[2m01:08:43.183978 line        48\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'Loss/Train'\u001b[0m\n",
      "\u001b[2m01:08:43.184014 line        50\u001b[0m                 try:\n",
      "\u001b[2m01:08:43.184049 line        51\u001b[0m                     temp_dict[subtag] = [tag[-1] for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.184085 exception   51\u001b[0m                     temp_dict[subtag] = [tag[-1] for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[31mException:..... \u001b[1mTypeError: 'ScalarEvent' object is not subscriptable\u001b[0m\n",
      "\u001b[2m01:08:43.184137 line        54\u001b[0m                 except:\n",
      "\u001b[2m01:08:43.184169 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.184206 line        56\u001b[0m                     -1\n",
      "\u001b[2m01:08:43.184237 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.184267 line        57\u001b[0m                 ].value\n",
      "\u001b[2m01:08:43.184296 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 0.011942555196583271}\u001b[0m\n",
      "\u001b[2m01:08:43.184326 line        48\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'Acc/Train'\u001b[0m\n",
      "\u001b[2m01:08:43.184363 line        50\u001b[0m                 try:\n",
      "\u001b[2m01:08:43.184398 line        51\u001b[0m                     temp_dict[subtag] = [tag[-1] for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.184435 exception   51\u001b[0m                     temp_dict[subtag] = [tag[-1] for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[31mException:..... \u001b[1mTypeError: 'ScalarEvent' object is not subscriptable\u001b[0m\n",
      "\u001b[2m01:08:43.184486 line        54\u001b[0m                 except:\n",
      "\u001b[2m01:08:43.184520 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.184559 line        56\u001b[0m                     -1\n",
      "\u001b[2m01:08:43.184590 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.184621 line        57\u001b[0m                 ].value\n",
      "\u001b[2m01:08:43.184651 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 0.011942555196583271, 'Acc/Train': 89.74414825439453}\u001b[0m\n",
      "\u001b[2m01:08:43.184682 line        48\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'global_run_count'\u001b[0m\n",
      "\u001b[2m01:08:43.184719 line        50\u001b[0m                 try:\n",
      "\u001b[2m01:08:43.184755 line        51\u001b[0m                     temp_dict[subtag] = [tag[-1] for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.184793 exception   51\u001b[0m                     temp_dict[subtag] = [tag[-1] for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[31mException:..... \u001b[1mTypeError: 'ScalarEvent' object is not subscriptable\u001b[0m\n",
      "\u001b[2m01:08:43.184844 line        54\u001b[0m                 except:\n",
      "\u001b[2m01:08:43.184877 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.184918 line        56\u001b[0m                     -1\n",
      "\u001b[2m01:08:43.184952 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.184982 line        57\u001b[0m                 ].value\n",
      "\u001b[2m01:08:43.185013 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 0.011942555196...in': 89.74414825439453, 'global_run_count': 20.0}\u001b[0m\n",
      "\u001b[2m01:08:43.185044 line        48\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'Loss/Val'\u001b[0m\n",
      "\u001b[2m01:08:43.185081 line        50\u001b[0m                 try:\n",
      "\u001b[2m01:08:43.185117 line        51\u001b[0m                     temp_dict[subtag] = [tag[-1] for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.185156 exception   51\u001b[0m                     temp_dict[subtag] = [tag[-1] for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[31mException:..... \u001b[1mTypeError: 'ScalarEvent' object is not subscriptable\u001b[0m\n",
      "\u001b[2m01:08:43.185206 line        54\u001b[0m                 except:\n",
      "\u001b[2m01:08:43.185241 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.185281 line        56\u001b[0m                     -1\n",
      "\u001b[2m01:08:43.185314 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.185346 line        57\u001b[0m                 ].value\n",
      "\u001b[2m01:08:43.185380 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 0.011942555196...n_count': 20.0, 'Loss/Val': 0.017720835283398628}\u001b[0m\n",
      "\u001b[2m01:08:43.185429 line        48\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'Acc/Val'\u001b[0m\n",
      "\u001b[2m01:08:43.185477 line        50\u001b[0m                 try:\n",
      "\u001b[2m01:08:43.185516 line        51\u001b[0m                     temp_dict[subtag] = [tag[-1] for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.185556 exception   51\u001b[0m                     temp_dict[subtag] = [tag[-1] for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[31mException:..... \u001b[1mTypeError: 'ScalarEvent' object is not subscriptable\u001b[0m\n",
      "\u001b[2m01:08:43.185610 line        54\u001b[0m                 except:\n",
      "\u001b[2m01:08:43.185646 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.185688 line        56\u001b[0m                     -1\n",
      "\u001b[2m01:08:43.185722 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.185755 line        57\u001b[0m                 ].value\n",
      "\u001b[2m01:08:43.185788 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 0.011942555196...017720835283398628, 'Acc/Val': 85.45494079589844}\u001b[0m\n",
      "\u001b[2m01:08:43.185821 line        48\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[2m01:08:43.185861 line        59\u001b[0m         if tag == \"tensors\":\n",
      "\u001b[2m01:08:43.185895 line        85\u001b[0m         if tag == \"images\" and save_ims == True:\n",
      "\u001b[2m01:08:43.185931 line        46\u001b[0m     for tag in all_tags.keys():\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtag = 'distributions'\u001b[0m\n",
      "\u001b[2m01:08:43.185977 line        47\u001b[0m         if tag == \"scalars\":\n",
      "\u001b[2m01:08:43.186016 line        59\u001b[0m         if tag == \"tensors\":\n",
      "\u001b[2m01:08:43.186108 line        85\u001b[0m         if tag == \"images\" and save_ims == True:\n",
      "\u001b[2m01:08:43.186142 line        46\u001b[0m     for tag in all_tags.keys():\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtag = 'tensors'\u001b[0m\n",
      "\u001b[2m01:08:43.186214 line        47\u001b[0m         if tag == \"scalars\":\n",
      "\u001b[2m01:08:43.186253 line        59\u001b[0m         if tag == \"tensors\":\n",
      "\u001b[2m01:08:43.186287 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'experiment_name/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.186321 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.186371 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.186414 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.186458 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.186495 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 0.011942555196...5494079589844, 'experiment_name': 'baseline_run'}\u001b[0m\n",
      "\u001b[2m01:08:43.186531 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'image_size/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.186573 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.186638 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.186716 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.186760 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.186807 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 0.011942555196...iment_name': 'baseline_run', 'image_size': '224'}\u001b[0m\n",
      "\u001b[2m01:08:43.186847 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'batch_size/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.186896 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.186953 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.187019 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.187089 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.187171 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 0.011942555196...ne_run', 'image_size': '224', 'batch_size': '32'}\u001b[0m\n",
      "\u001b[2m01:08:43.187208 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'enable_proxy_attention/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.187252 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.187302 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.187357 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.187393 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.187427 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 0.011942555196...ch_size': '32', 'enable_proxy_attention': 'True'}\u001b[0m\n",
      "\u001b[2m01:08:43.187460 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'transfer_imagenet/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.187499 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.187556 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.187615 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.187697 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.187737 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 0.011942555196..._attention': 'True', 'transfer_imagenet': 'True'}\u001b[0m\n",
      "\u001b[2m01:08:43.187813 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'subset_images/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.187895 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.187983 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.188039 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.188098 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.188149 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 0.011942555196...sfer_imagenet': 'True', 'subset_images': '20000'}\u001b[0m\n",
      "\u001b[2m01:08:43.188182 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'pixel_replacement_method/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.188221 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.188267 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.188303 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.188338 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.188372 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 0.011942555196...: '20000', 'pixel_replacement_method': 'blended'}\u001b[0m\n",
      "\u001b[2m01:08:43.188407 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'proxy_steps/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.188445 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.188491 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.188526 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.188560 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.188594 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 0.011942555196...cement_method': 'blended', 'proxy_steps': '[20]'}\u001b[0m\n",
      "\u001b[2m01:08:43.188628 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'load_proxy_data/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.188667 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.188713 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.188768 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.188804 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.188840 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 0.011942555196...proxy_steps': '[20]', 'load_proxy_data': 'False'}\u001b[0m\n",
      "\u001b[2m01:08:43.188875 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'proxy_step/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.188919 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.188972 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.189013 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.189052 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.189090 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.01194255...proxy_steps': '[20]', 'load_proxy_data': 'False'}\u001b[0m\n",
      "\u001b[2m01:08:43.189127 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'log_every/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.189174 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.189224 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.189267 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.189307 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.189346 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.01194255...]', 'load_proxy_data': 'False', 'log_every': '2'}\u001b[0m\n",
      "\u001b[2m01:08:43.189383 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'device/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.189426 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.189477 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.189516 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.189553 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.189604 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.01194255...': 'False', 'log_every': '2', 'device': 'cuda:0'}\u001b[0m\n",
      "\u001b[2m01:08:43.189672 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'dataset_info/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.189719 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.189768 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.189805 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.189842 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.189882 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.01194255...t_name at 0x7fe7d737ba30>, 'num_classes': 101}}\"}\u001b[0m\n",
      "\u001b[2m01:08:43.189927 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'main_run_dir/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.189981 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.190043 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.190087 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.190148 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.190194 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.01194255...DE/Github/improving_robotics_datasets/src/runs/'}\u001b[0m\n",
      "\u001b[2m01:08:43.190277 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'change_subset_attention/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.190325 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.190382 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.190468 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.190511 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.190552 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.01194255...ets/src/runs/', 'change_subset_attention': '0.8'}\u001b[0m\n",
      "\u001b[2m01:08:43.190593 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'model/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.190641 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.190697 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.190740 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.190785 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.190834 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.01194255...ge_subset_attention': '0.8', 'model': 'resnet50'}\u001b[0m\n",
      "\u001b[2m01:08:43.190875 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'proxy_image_weight/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.190921 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.190973 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.191016 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.191058 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.191099 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.01194255...'model': 'resnet50', 'proxy_image_weight': '0.1'}\u001b[0m\n",
      "\u001b[2m01:08:43.191140 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'proxy_threshold/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.191186 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.191238 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.191281 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.191323 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.191363 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.01194255..._image_weight': '0.1', 'proxy_threshold': '0.85'}\u001b[0m\n",
      "\u001b[2m01:08:43.191403 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'gradient_method/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.191448 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.191500 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.191542 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.191583 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.191623 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.01194255...d': '0.85', 'gradient_method': 'gradcamplusplus'}\u001b[0m\n",
      "\u001b[2m01:08:43.191663 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'ds_name/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.191708 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.191759 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.191813 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.191860 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.191902 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.01194255...hod': 'gradcamplusplus', 'ds_name': 'caltech101'}\u001b[0m\n",
      "\u001b[2m01:08:43.191943 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'clear_every_step/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.191989 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.192041 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.192084 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.192126 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.192167 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.01194255..._name': 'caltech101', 'clear_every_step': 'True'}\u001b[0m\n",
      "\u001b[2m01:08:43.192208 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'fname_start/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.192254 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.192307 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.192349 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.192392 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.192433 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.01194255..._datasets/src/runs/baseline_run_26032023_213720'}\u001b[0m\n",
      "\u001b[2m01:08:43.192474 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'ds_path/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.192521 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.192573 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.192616 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.192659 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.192700 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.01194255...h': '/run/media/eragon/HDD/Datasets/caltech-101'}\u001b[0m\n",
      "\u001b[2m01:08:43.192742 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'name_fn/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.192789 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.192842 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.192886 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.192928 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.192970 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.01194255...: '<function get_parent_name at 0x7fe7d737ba30>'}\u001b[0m\n",
      "\u001b[2m01:08:43.193012 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'global_run_count/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.193059 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.193112 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.193156 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.193199 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.193241 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[2m01:08:43.193288 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'writer/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.193330 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.193384 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.193427 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.193471 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.193513 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.01194255....writer.SummaryWriter object at 0x7fe7cc5ad270>'}\u001b[0m\n",
      "\u001b[2m01:08:43.193554 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'label_map/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.193601 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.193655 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.193698 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.193796 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.193892 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.01194255...windsor_chair', 100: 'wrench', 101: 'yin_yang'}\"}\u001b[0m\n",
      "\u001b[2m01:08:43.193972 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'rev_label_map/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.194032 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.194098 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.194153 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.194207 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.194264 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.01194255...sor_chair': 99, 'wrench': 100, 'yin_yang': 101}\"}\u001b[0m\n",
      "\u001b[2m01:08:43.194326 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'num_classes/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.194391 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.194466 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.194551 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.194614 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.194693 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.01194255...h': 100, 'yin_yang': 101}\", 'num_classes': '102'}\u001b[0m\n",
      "\u001b[2m01:08:43.194753 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'dataset_sizes/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.194817 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.194936 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.194998 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.195057 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.195117 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.01194255... 'dataset_sizes': \"{'train': 4573, 'val': 4572}\"}\u001b[0m\n",
      "\u001b[2m01:08:43.195175 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'criterion/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.195240 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.195311 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.195374 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.195435 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.195494 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.01194255...'val': 4572}\", 'criterion': 'CrossEntropyLoss()'}\u001b[0m\n",
      "\u001b[2m01:08:43.195553 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'cam/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.195618 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.195688 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.195749 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.195809 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.195867 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.01194255...splus.GradCAMPlusPlus object at 0x7fe7cc1f79d0>'}\u001b[0m\n",
      "\u001b[2m01:08:43.195929 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'save_path/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.195995 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.196066 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.196127 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.196189 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.196249 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.01194255...rc/runs/baseline_run_26032023_213720/checkpoint'}\u001b[0m\n",
      "\u001b[2m01:08:43.196309 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'final_acc/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.196376 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.196448 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.196510 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.196582 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.196647 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.01194255...20/checkpoint', 'final_acc': '85.45494313210848'}\u001b[0m\n",
      "\u001b[2m01:08:43.196709 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[2m01:08:43.196776 line        85\u001b[0m         if tag == \"images\" and save_ims == True:\n",
      "\u001b[2m01:08:43.196837 line        46\u001b[0m     for tag in all_tags.keys():\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtag = 'graph'\u001b[0m\n",
      "\u001b[2m01:08:43.196897 line        47\u001b[0m         if tag == \"scalars\":\n",
      "\u001b[2m01:08:43.196964 line        59\u001b[0m         if tag == \"tensors\":\n",
      "\u001b[2m01:08:43.197025 line        85\u001b[0m         if tag == \"images\" and save_ims == True:\n",
      "\u001b[2m01:08:43.197153 line        46\u001b[0m     for tag in all_tags.keys():\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtag = 'meta_graph'\u001b[0m\n",
      "\u001b[2m01:08:43.197217 line        47\u001b[0m         if tag == \"scalars\":\n",
      "\u001b[2m01:08:43.197283 line        59\u001b[0m         if tag == \"tensors\":\n",
      "\u001b[2m01:08:43.197346 line        85\u001b[0m         if tag == \"images\" and save_ims == True:\n",
      "\u001b[2m01:08:43.197422 line        46\u001b[0m     for tag in all_tags.keys():\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtag = 'run_metadata'\u001b[0m\n",
      "\u001b[2m01:08:43.197494 line        47\u001b[0m         if tag == \"scalars\":\n",
      "\u001b[2m01:08:43.197567 line        59\u001b[0m         if tag == \"tensors\":\n",
      "\u001b[2m01:08:43.197628 line        85\u001b[0m         if tag == \"images\" and save_ims == True:\n",
      "\u001b[2m01:08:43.197701 line        46\u001b[0m     for tag in all_tags.keys():\n",
      "\u001b[2m01:08:43.197761 line        96\u001b[0m     return temp_dict\n",
      "\u001b[2m01:08:43.197821 return      96\u001b[0m     return temp_dict\n",
      "\u001b[36m\u001b[2mReturn value:.. \u001b[22m{'proxy_step': 'False', 'Loss/Train': 0.01194255...20/checkpoint', 'final_acc': '85.45494313210848'}\u001b[0m\n",
      "\u001b[33m\u001b[2mElapsed time: \u001b[22m00:00:00.014969\u001b[0m\n",
      "runs/baseline_run_26032023_214436/events.out.tfevents.1679859876.eragon\n",
      "\u001b[32m\u001b[2mStarting var:.. \u001b[22mevent_acc = <tensorboard.backend.event_processing.event_accumulator.EventAccumulator object at 0x7f5b568efd00>\u001b[0m\n",
      "\u001b[32m\u001b[2mStarting var:.. \u001b[22msave_ims = False\u001b[0m\n",
      "\u001b[2m01:08:43.208633 call        42\u001b[0m def process_event_acc(event_acc, save_ims = False):\n",
      "\u001b[2m01:08:43.208709 line        44\u001b[0m     all_tags = event_acc.Tags()\n",
      "\u001b[32m\u001b[2mNew var:....... \u001b[22mall_tags = {'images': [], 'audio': [], 'histograms': [], 's...: False, 'meta_graph': False, 'run_metadata': []}\u001b[0m\n",
      "\u001b[2m01:08:43.208814 line        45\u001b[0m     temp_dict = {}\n",
      "\u001b[32m\u001b[2mNew var:....... \u001b[22mtemp_dict = {}\u001b[0m\n",
      "\u001b[2m01:08:43.208922 line        46\u001b[0m     for tag in all_tags.keys():\n",
      "\u001b[32m\u001b[2mNew var:....... \u001b[22mtag = 'images'\u001b[0m\n",
      "\u001b[2m01:08:43.208963 line        47\u001b[0m         if tag == \"scalars\":\n",
      "\u001b[2m01:08:43.209001 line        59\u001b[0m         if tag == \"tensors\":\n",
      "\u001b[2m01:08:43.209032 line        85\u001b[0m         if tag == \"images\" and save_ims == True:\n",
      "\u001b[2m01:08:43.209062 line        46\u001b[0m     for tag in all_tags.keys():\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtag = 'audio'\u001b[0m\n",
      "\u001b[2m01:08:43.209089 line        47\u001b[0m         if tag == \"scalars\":\n",
      "\u001b[2m01:08:43.209145 line        59\u001b[0m         if tag == \"tensors\":\n",
      "\u001b[2m01:08:43.209189 line        85\u001b[0m         if tag == \"images\" and save_ims == True:\n",
      "\u001b[2m01:08:43.209231 line        46\u001b[0m     for tag in all_tags.keys():\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtag = 'histograms'\u001b[0m\n",
      "\u001b[2m01:08:43.209261 line        47\u001b[0m         if tag == \"scalars\":\n",
      "\u001b[2m01:08:43.209304 line        59\u001b[0m         if tag == \"tensors\":\n",
      "\u001b[2m01:08:43.209348 line        85\u001b[0m         if tag == \"images\" and save_ims == True:\n",
      "\u001b[2m01:08:43.209391 line        46\u001b[0m     for tag in all_tags.keys():\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtag = 'scalars'\u001b[0m\n",
      "\u001b[2m01:08:43.209435 line        47\u001b[0m         if tag == \"scalars\":\n",
      "\u001b[2m01:08:43.209488 line        48\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mNew var:....... \u001b[22msubtag = 'proxy_step'\u001b[0m\n",
      "\u001b[2m01:08:43.209536 line        50\u001b[0m                 try:\n",
      "\u001b[2m01:08:43.209591 line        51\u001b[0m                     temp_dict[subtag] = [tag[-1] for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.209658 exception   51\u001b[0m                     temp_dict[subtag] = [tag[-1] for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[31mException:..... \u001b[1mTypeError: 'ScalarEvent' object is not subscriptable\u001b[0m\n",
      "\u001b[2m01:08:43.209830 line        54\u001b[0m                 except:\n",
      "\u001b[2m01:08:43.209919 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.209993 line        56\u001b[0m                     -1\n",
      "\u001b[2m01:08:43.210046 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.210118 line        57\u001b[0m                 ].value\n",
      "\u001b[2m01:08:43.210170 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0}\u001b[0m\n",
      "\u001b[2m01:08:43.210221 line        48\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'Loss/Train'\u001b[0m\n",
      "\u001b[2m01:08:43.210282 line        50\u001b[0m                 try:\n",
      "\u001b[2m01:08:43.210346 line        51\u001b[0m                     temp_dict[subtag] = [tag[-1] for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.210424 exception   51\u001b[0m                     temp_dict[subtag] = [tag[-1] for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[31mException:..... \u001b[1mTypeError: 'ScalarEvent' object is not subscriptable\u001b[0m\n",
      "\u001b[2m01:08:43.210515 line        54\u001b[0m                 except:\n",
      "\u001b[2m01:08:43.210574 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.210640 line        56\u001b[0m                     -1\n",
      "\u001b[2m01:08:43.210691 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.210726 line        57\u001b[0m                 ].value\n",
      "\u001b[2m01:08:43.210758 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 0.0012060018489137292}\u001b[0m\n",
      "\u001b[2m01:08:43.210801 line        48\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'Acc/Train'\u001b[0m\n",
      "\u001b[2m01:08:43.210857 line        50\u001b[0m                 try:\n",
      "\u001b[2m01:08:43.210896 line        51\u001b[0m                     temp_dict[subtag] = [tag[-1] for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.210962 exception   51\u001b[0m                     temp_dict[subtag] = [tag[-1] for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[31mException:..... \u001b[1mTypeError: 'ScalarEvent' object is not subscriptable\u001b[0m\n",
      "\u001b[2m01:08:43.211023 line        54\u001b[0m                 except:\n",
      "\u001b[2m01:08:43.211061 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.211102 line        56\u001b[0m                     -1\n",
      "\u001b[2m01:08:43.211138 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.211181 line        57\u001b[0m                 ].value\n",
      "\u001b[2m01:08:43.211227 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 0.0012060018489137292, 'Acc/Train': 98.8499984741211}\u001b[0m\n",
      "\u001b[2m01:08:43.211279 line        48\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'global_run_count'\u001b[0m\n",
      "\u001b[2m01:08:43.211323 line        50\u001b[0m                 try:\n",
      "\u001b[2m01:08:43.211368 line        51\u001b[0m                     temp_dict[subtag] = [tag[-1] for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.211430 exception   51\u001b[0m                     temp_dict[subtag] = [tag[-1] for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[31mException:..... \u001b[1mTypeError: 'ScalarEvent' object is not subscriptable\u001b[0m\n",
      "\u001b[2m01:08:43.211520 line        54\u001b[0m                 except:\n",
      "\u001b[2m01:08:43.211563 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.211610 line        56\u001b[0m                     -1\n",
      "\u001b[2m01:08:43.211651 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.211688 line        57\u001b[0m                 ].value\n",
      "\u001b[2m01:08:43.211721 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 0.001206001848...ain': 98.8499984741211, 'global_run_count': 20.0}\u001b[0m\n",
      "\u001b[2m01:08:43.211754 line        48\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'Loss/Val'\u001b[0m\n",
      "\u001b[2m01:08:43.211795 line        50\u001b[0m                 try:\n",
      "\u001b[2m01:08:43.211835 line        51\u001b[0m                     temp_dict[subtag] = [tag[-1] for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.211876 exception   51\u001b[0m                     temp_dict[subtag] = [tag[-1] for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[31mException:..... \u001b[1mTypeError: 'ScalarEvent' object is not subscriptable\u001b[0m\n",
      "\u001b[2m01:08:43.211929 line        54\u001b[0m                 except:\n",
      "\u001b[2m01:08:43.211964 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.212005 line        56\u001b[0m                     -1\n",
      "\u001b[2m01:08:43.212038 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.212071 line        57\u001b[0m                 ].value\n",
      "\u001b[2m01:08:43.212103 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 0.001206001848..._count': 20.0, 'Loss/Val': 0.0014491359470412135}\u001b[0m\n",
      "\u001b[2m01:08:43.212136 line        48\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'Acc/Val'\u001b[0m\n",
      "\u001b[2m01:08:43.212176 line        50\u001b[0m                 try:\n",
      "\u001b[2m01:08:43.212216 line        51\u001b[0m                     temp_dict[subtag] = [tag[-1] for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.212258 exception   51\u001b[0m                     temp_dict[subtag] = [tag[-1] for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[31mException:..... \u001b[1mTypeError: 'ScalarEvent' object is not subscriptable\u001b[0m\n",
      "\u001b[2m01:08:43.212312 line        54\u001b[0m                 except:\n",
      "\u001b[2m01:08:43.212348 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.212391 line        56\u001b[0m                     -1\n",
      "\u001b[2m01:08:43.212426 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.212459 line        57\u001b[0m                 ].value\n",
      "\u001b[2m01:08:43.212491 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 0.001206001848...014491359470412135, 'Acc/Val': 98.58999633789062}\u001b[0m\n",
      "\u001b[2m01:08:43.212524 line        48\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[2m01:08:43.212622 line        59\u001b[0m         if tag == \"tensors\":\n",
      "\u001b[2m01:08:43.212665 line        85\u001b[0m         if tag == \"images\" and save_ims == True:\n",
      "\u001b[2m01:08:43.212701 line        46\u001b[0m     for tag in all_tags.keys():\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtag = 'distributions'\u001b[0m\n",
      "\u001b[2m01:08:43.212736 line        47\u001b[0m         if tag == \"scalars\":\n",
      "\u001b[2m01:08:43.212779 line        59\u001b[0m         if tag == \"tensors\":\n",
      "\u001b[2m01:08:43.212814 line        85\u001b[0m         if tag == \"images\" and save_ims == True:\n",
      "\u001b[2m01:08:43.212848 line        46\u001b[0m     for tag in all_tags.keys():\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtag = 'tensors'\u001b[0m\n",
      "\u001b[2m01:08:43.212881 line        47\u001b[0m         if tag == \"scalars\":\n",
      "\u001b[2m01:08:43.212920 line        59\u001b[0m         if tag == \"tensors\":\n",
      "\u001b[2m01:08:43.212954 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'experiment_name/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.212995 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.213046 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.213085 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.213123 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.213157 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 0.001206001848...8999633789062, 'experiment_name': 'baseline_run'}\u001b[0m\n",
      "\u001b[2m01:08:43.213192 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'image_size/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.213231 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.213277 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.213312 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.213348 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.213382 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 0.001206001848...iment_name': 'baseline_run', 'image_size': '224'}\u001b[0m\n",
      "\u001b[2m01:08:43.213416 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'batch_size/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.213456 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.213500 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.213536 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.213571 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.213605 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 0.001206001848...ne_run', 'image_size': '224', 'batch_size': '32'}\u001b[0m\n",
      "\u001b[2m01:08:43.213638 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'enable_proxy_attention/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.213677 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.213745 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.213797 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.213836 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.213870 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 0.001206001848...ch_size': '32', 'enable_proxy_attention': 'True'}\u001b[0m\n",
      "\u001b[2m01:08:43.213908 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'transfer_imagenet/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.213949 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.213997 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.214033 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.214068 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.214103 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 0.001206001848..._attention': 'True', 'transfer_imagenet': 'True'}\u001b[0m\n",
      "\u001b[2m01:08:43.214138 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'subset_images/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.214178 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.214223 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.214260 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.214296 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.214331 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 0.001206001848...sfer_imagenet': 'True', 'subset_images': '20000'}\u001b[0m\n",
      "\u001b[2m01:08:43.214366 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'pixel_replacement_method/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.214406 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.214451 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.214488 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.214523 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.214567 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 0.001206001848...: '20000', 'pixel_replacement_method': 'blended'}\u001b[0m\n",
      "\u001b[2m01:08:43.214602 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'proxy_steps/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.214642 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.214687 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.214723 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.214759 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.214795 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 0.001206001848...cement_method': 'blended', 'proxy_steps': '[20]'}\u001b[0m\n",
      "\u001b[2m01:08:43.214830 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'load_proxy_data/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.214870 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.214916 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.214952 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.214989 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.215024 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 0.001206001848...proxy_steps': '[20]', 'load_proxy_data': 'False'}\u001b[0m\n",
      "\u001b[2m01:08:43.215059 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'proxy_step/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.215103 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.215162 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.215200 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.215237 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.215274 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.00120600...proxy_steps': '[20]', 'load_proxy_data': 'False'}\u001b[0m\n",
      "\u001b[2m01:08:43.215311 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'log_every/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.215351 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.215399 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.215435 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.215472 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.215507 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.00120600...]', 'load_proxy_data': 'False', 'log_every': '2'}\u001b[0m\n",
      "\u001b[2m01:08:43.215542 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'device/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.215581 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.215628 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.215664 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.215701 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.215736 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.00120600...': 'False', 'log_every': '2', 'device': 'cuda:0'}\u001b[0m\n",
      "\u001b[2m01:08:43.215772 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'dataset_info/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.215814 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.215868 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.215906 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.215943 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.215979 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.00120600...t_name at 0x7fb0df5c7a30>, 'num_classes': 101}}\"}\u001b[0m\n",
      "\u001b[2m01:08:43.216015 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'main_run_dir/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.216062 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.216114 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.216156 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.216197 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.216238 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.00120600...DE/Github/improving_robotics_datasets/src/runs/'}\u001b[0m\n",
      "\u001b[2m01:08:43.216279 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'change_subset_attention/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.216325 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.216380 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.216422 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.216464 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.216505 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.00120600...ets/src/runs/', 'change_subset_attention': '0.8'}\u001b[0m\n",
      "\u001b[2m01:08:43.216547 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'model/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.216594 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.216646 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.216689 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.216732 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.216773 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.00120600...ge_subset_attention': '0.8', 'model': 'resnet50'}\u001b[0m\n",
      "\u001b[2m01:08:43.216815 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'proxy_image_weight/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.216861 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.216914 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.216956 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.217009 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.217060 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.00120600...'model': 'resnet50', 'proxy_image_weight': '0.1'}\u001b[0m\n",
      "\u001b[2m01:08:43.217104 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'proxy_threshold/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.217152 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.217203 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.217246 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.217287 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.217329 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.00120600..._image_weight': '0.1', 'proxy_threshold': '0.85'}\u001b[0m\n",
      "\u001b[2m01:08:43.217370 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'gradient_method/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.217415 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.217467 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.217510 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.217552 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.217593 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.00120600...d': '0.85', 'gradient_method': 'gradcamplusplus'}\u001b[0m\n",
      "\u001b[2m01:08:43.217634 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'ds_name/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.217680 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.217733 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.217775 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.217817 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.217859 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.00120600...ent_method': 'gradcamplusplus', 'ds_name': 'asl'}\u001b[0m\n",
      "\u001b[2m01:08:43.217900 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'clear_every_step/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.217945 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.217997 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.218041 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.218083 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.218124 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.00120600...s', 'ds_name': 'asl', 'clear_every_step': 'True'}\u001b[0m\n",
      "\u001b[2m01:08:43.218166 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'fname_start/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.218213 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.218265 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.218308 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.218351 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.218397 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.00120600..._datasets/src/runs/baseline_run_26032023_214436'}\u001b[0m\n",
      "\u001b[2m01:08:43.218441 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'ds_path/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.218491 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.218544 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.218588 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.218633 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.218675 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.00120600...asets/asl/asl_alphabet_train/asl_alphabet_train'}\u001b[0m\n",
      "\u001b[2m01:08:43.218716 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'name_fn/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.218765 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.218820 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.218864 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.218908 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.218951 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.00120600...: '<function get_parent_name at 0x7fb0df5c7a30>'}\u001b[0m\n",
      "\u001b[2m01:08:43.218994 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'global_run_count/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.219042 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.219097 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.219141 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.219186 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.219229 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[2m01:08:43.219280 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'writer/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.219325 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.219378 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.219423 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.219467 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.219509 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.00120600....writer.SummaryWriter object at 0x7fb0d4c1a230>'}\u001b[0m\n",
      "\u001b[2m01:08:43.219552 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'label_map/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.219600 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.219654 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.219698 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.219741 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.219783 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.00120600...P', 16: 'Q', 17: 'U', 18: 'del', 19: 'nothing'}\"}\u001b[0m\n",
      "\u001b[2m01:08:43.219826 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'rev_label_map/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.219879 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.219934 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.219980 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.220025 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.220069 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.00120600...15, 'Q': 16, 'U': 17, 'del': 18, 'nothing': 19}\"}\u001b[0m\n",
      "\u001b[2m01:08:43.220113 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'num_classes/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.220163 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.220218 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.220263 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.220317 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.220370 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.00120600... 'del': 18, 'nothing': 19}\", 'num_classes': '20'}\u001b[0m\n",
      "\u001b[2m01:08:43.220427 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'dataset_sizes/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.220478 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.220536 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.220582 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.220627 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.220671 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.00120600...dataset_sizes': \"{'train': 10000, 'val': 10000}\"}\u001b[0m\n",
      "\u001b[2m01:08:43.220717 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'criterion/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.220767 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.220827 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.220875 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.220921 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.220966 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.00120600...val': 10000}\", 'criterion': 'CrossEntropyLoss()'}\u001b[0m\n",
      "\u001b[2m01:08:43.221011 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'cam/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.221061 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.221117 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.221163 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.221209 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.221253 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.00120600...splus.GradCAMPlusPlus object at 0x7fb0d32471f0>'}\u001b[0m\n",
      "\u001b[2m01:08:43.221298 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'save_path/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.221356 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.221427 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.221476 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.221524 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.221570 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.00120600...rc/runs/baseline_run_26032023_214436/checkpoint'}\u001b[0m\n",
      "\u001b[2m01:08:43.221615 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'final_acc/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.221665 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.221723 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.221771 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.221818 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.221864 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.00120600...6032023_214436/checkpoint', 'final_acc': '98.59'}\u001b[0m\n",
      "\u001b[2m01:08:43.221910 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[2m01:08:43.221962 line        85\u001b[0m         if tag == \"images\" and save_ims == True:\n",
      "\u001b[2m01:08:43.222009 line        46\u001b[0m     for tag in all_tags.keys():\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtag = 'graph'\u001b[0m\n",
      "\u001b[2m01:08:43.222056 line        47\u001b[0m         if tag == \"scalars\":\n",
      "\u001b[2m01:08:43.222107 line        59\u001b[0m         if tag == \"tensors\":\n",
      "\u001b[2m01:08:43.222154 line        85\u001b[0m         if tag == \"images\" and save_ims == True:\n",
      "\u001b[2m01:08:43.222200 line        46\u001b[0m     for tag in all_tags.keys():\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtag = 'meta_graph'\u001b[0m\n",
      "\u001b[2m01:08:43.222246 line        47\u001b[0m         if tag == \"scalars\":\n",
      "\u001b[2m01:08:43.222297 line        59\u001b[0m         if tag == \"tensors\":\n",
      "\u001b[2m01:08:43.222343 line        85\u001b[0m         if tag == \"images\" and save_ims == True:\n",
      "\u001b[2m01:08:43.222388 line        46\u001b[0m     for tag in all_tags.keys():\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtag = 'run_metadata'\u001b[0m\n",
      "\u001b[2m01:08:43.222444 line        47\u001b[0m         if tag == \"scalars\":\n",
      "\u001b[2m01:08:43.222496 line        59\u001b[0m         if tag == \"tensors\":\n",
      "\u001b[2m01:08:43.222541 line        85\u001b[0m         if tag == \"images\" and save_ims == True:\n",
      "\u001b[2m01:08:43.222587 line        46\u001b[0m     for tag in all_tags.keys():\n",
      "\u001b[2m01:08:43.222632 line        96\u001b[0m     return temp_dict\n",
      "\u001b[2m01:08:43.222677 return      96\u001b[0m     return temp_dict\n",
      "\u001b[36m\u001b[2mReturn value:.. \u001b[22m{'proxy_step': 'False', 'Loss/Train': 0.00120600...6032023_214436/checkpoint', 'final_acc': '98.59'}\u001b[0m\n",
      "\u001b[33m\u001b[2mElapsed time: \u001b[22m00:00:00.014140\u001b[0m\n",
      "runs/baseline_run_26032023_215855/events.out.tfevents.1679860735.eragon\n",
      "\u001b[32m\u001b[2mStarting var:.. \u001b[22mevent_acc = <tensorboard.backend.event_processing.event_accumulator.EventAccumulator object at 0x7f5b568eee00>\u001b[0m\n",
      "\u001b[32m\u001b[2mStarting var:.. \u001b[22msave_ims = False\u001b[0m\n",
      "\u001b[2m01:08:43.230479 call        42\u001b[0m def process_event_acc(event_acc, save_ims = False):\n",
      "\u001b[2m01:08:43.230554 line        44\u001b[0m     all_tags = event_acc.Tags()\n",
      "\u001b[32m\u001b[2mNew var:....... \u001b[22mall_tags = {'images': [], 'audio': [], 'histograms': [], 's...: False, 'meta_graph': False, 'run_metadata': []}\u001b[0m\n",
      "\u001b[2m01:08:43.230595 line        45\u001b[0m     temp_dict = {}\n",
      "\u001b[32m\u001b[2mNew var:....... \u001b[22mtemp_dict = {}\u001b[0m\n",
      "\u001b[2m01:08:43.230679 line        46\u001b[0m     for tag in all_tags.keys():\n",
      "\u001b[32m\u001b[2mNew var:....... \u001b[22mtag = 'images'\u001b[0m\n",
      "\u001b[2m01:08:43.230719 line        47\u001b[0m         if tag == \"scalars\":\n",
      "\u001b[2m01:08:43.230757 line        59\u001b[0m         if tag == \"tensors\":\n",
      "\u001b[2m01:08:43.230787 line        85\u001b[0m         if tag == \"images\" and save_ims == True:\n",
      "\u001b[2m01:08:43.230815 line        46\u001b[0m     for tag in all_tags.keys():\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtag = 'audio'\u001b[0m\n",
      "\u001b[2m01:08:43.230844 line        47\u001b[0m         if tag == \"scalars\":\n",
      "\u001b[2m01:08:43.230881 line        59\u001b[0m         if tag == \"tensors\":\n",
      "\u001b[2m01:08:43.230908 line        85\u001b[0m         if tag == \"images\" and save_ims == True:\n",
      "\u001b[2m01:08:43.230936 line        46\u001b[0m     for tag in all_tags.keys():\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtag = 'histograms'\u001b[0m\n",
      "\u001b[2m01:08:43.230962 line        47\u001b[0m         if tag == \"scalars\":\n",
      "\u001b[2m01:08:43.230994 line        59\u001b[0m         if tag == \"tensors\":\n",
      "\u001b[2m01:08:43.231022 line        85\u001b[0m         if tag == \"images\" and save_ims == True:\n",
      "\u001b[2m01:08:43.231049 line        46\u001b[0m     for tag in all_tags.keys():\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtag = 'scalars'\u001b[0m\n",
      "\u001b[2m01:08:43.231076 line        47\u001b[0m         if tag == \"scalars\":\n",
      "\u001b[2m01:08:43.231108 line        48\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mNew var:....... \u001b[22msubtag = 'proxy_step'\u001b[0m\n",
      "\u001b[2m01:08:43.231135 line        50\u001b[0m                 try:\n",
      "\u001b[2m01:08:43.231169 line        51\u001b[0m                     temp_dict[subtag] = [tag[-1] for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.231208 exception   51\u001b[0m                     temp_dict[subtag] = [tag[-1] for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[31mException:..... \u001b[1mTypeError: 'ScalarEvent' object is not subscriptable\u001b[0m\n",
      "\u001b[2m01:08:43.231267 line        54\u001b[0m                 except:\n",
      "\u001b[2m01:08:43.231300 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.231341 line        56\u001b[0m                     -1\n",
      "\u001b[2m01:08:43.231372 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.231402 line        57\u001b[0m                 ].value\n",
      "\u001b[2m01:08:43.231439 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0}\u001b[0m\n",
      "\u001b[2m01:08:43.231469 line        48\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'Loss/Train'\u001b[0m\n",
      "\u001b[2m01:08:43.231504 line        50\u001b[0m                 try:\n",
      "\u001b[2m01:08:43.231537 line        51\u001b[0m                     temp_dict[subtag] = [tag[-1] for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.231574 exception   51\u001b[0m                     temp_dict[subtag] = [tag[-1] for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[31mException:..... \u001b[1mTypeError: 'ScalarEvent' object is not subscriptable\u001b[0m\n",
      "\u001b[2m01:08:43.231626 line        54\u001b[0m                 except:\n",
      "\u001b[2m01:08:43.231658 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.231696 line        56\u001b[0m                     -1\n",
      "\u001b[2m01:08:43.231727 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.231757 line        57\u001b[0m                 ].value\n",
      "\u001b[2m01:08:43.231802 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 0.005652691703289747}\u001b[0m\n",
      "\u001b[2m01:08:43.231832 line        48\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'Acc/Train'\u001b[0m\n",
      "\u001b[2m01:08:43.231869 line        50\u001b[0m                 try:\n",
      "\u001b[2m01:08:43.231907 line        51\u001b[0m                     temp_dict[subtag] = [tag[-1] for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.231945 exception   51\u001b[0m                     temp_dict[subtag] = [tag[-1] for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[31mException:..... \u001b[1mTypeError: 'ScalarEvent' object is not subscriptable\u001b[0m\n",
      "\u001b[2m01:08:43.231995 line        54\u001b[0m                 except:\n",
      "\u001b[2m01:08:43.232029 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.232067 line        56\u001b[0m                     -1\n",
      "\u001b[2m01:08:43.232098 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.232129 line        57\u001b[0m                 ].value\n",
      "\u001b[2m01:08:43.232159 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 0.005652691703289747, 'Acc/Train': 94.59345245361328}\u001b[0m\n",
      "\u001b[2m01:08:43.232190 line        48\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'global_run_count'\u001b[0m\n",
      "\u001b[2m01:08:43.232227 line        50\u001b[0m                 try:\n",
      "\u001b[2m01:08:43.232264 line        51\u001b[0m                     temp_dict[subtag] = [tag[-1] for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.232302 exception   51\u001b[0m                     temp_dict[subtag] = [tag[-1] for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[31mException:..... \u001b[1mTypeError: 'ScalarEvent' object is not subscriptable\u001b[0m\n",
      "\u001b[2m01:08:43.232352 line        54\u001b[0m                 except:\n",
      "\u001b[2m01:08:43.232385 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.232426 line        56\u001b[0m                     -1\n",
      "\u001b[2m01:08:43.232458 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.232490 line        57\u001b[0m                 ].value\n",
      "\u001b[2m01:08:43.232521 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 0.005652691703...in': 94.59345245361328, 'global_run_count': 20.0}\u001b[0m\n",
      "\u001b[2m01:08:43.232557 line        48\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'Loss/Val'\u001b[0m\n",
      "\u001b[2m01:08:43.232604 line        50\u001b[0m                 try:\n",
      "\u001b[2m01:08:43.232641 line        51\u001b[0m                     temp_dict[subtag] = [tag[-1] for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.232680 exception   51\u001b[0m                     temp_dict[subtag] = [tag[-1] for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[31mException:..... \u001b[1mTypeError: 'ScalarEvent' object is not subscriptable\u001b[0m\n",
      "\u001b[2m01:08:43.232731 line        54\u001b[0m                 except:\n",
      "\u001b[2m01:08:43.232765 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.232807 line        56\u001b[0m                     -1\n",
      "\u001b[2m01:08:43.232853 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.232888 line        57\u001b[0m                 ].value\n",
      "\u001b[2m01:08:43.232920 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 0.005652691703...n_count': 20.0, 'Loss/Val': 0.006500196643173695}\u001b[0m\n",
      "\u001b[2m01:08:43.232952 line        48\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'Acc/Val'\u001b[0m\n",
      "\u001b[2m01:08:43.232992 line        50\u001b[0m                 try:\n",
      "\u001b[2m01:08:43.233030 line        51\u001b[0m                     temp_dict[subtag] = [tag[-1] for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.233069 exception   51\u001b[0m                     temp_dict[subtag] = [tag[-1] for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[31mException:..... \u001b[1mTypeError: 'ScalarEvent' object is not subscriptable\u001b[0m\n",
      "\u001b[2m01:08:43.233121 line        54\u001b[0m                 except:\n",
      "\u001b[2m01:08:43.233156 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.233197 line        56\u001b[0m                     -1\n",
      "\u001b[2m01:08:43.233231 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.233263 line        57\u001b[0m                 ].value\n",
      "\u001b[2m01:08:43.233296 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 0.005652691703...006500196643173695, 'Acc/Val': 94.19095611572266}\u001b[0m\n",
      "\u001b[2m01:08:43.233329 line        48\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[2m01:08:43.233368 line        59\u001b[0m         if tag == \"tensors\":\n",
      "\u001b[2m01:08:43.233402 line        85\u001b[0m         if tag == \"images\" and save_ims == True:\n",
      "\u001b[2m01:08:43.233435 line        46\u001b[0m     for tag in all_tags.keys():\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtag = 'distributions'\u001b[0m\n",
      "\u001b[2m01:08:43.233467 line        47\u001b[0m         if tag == \"scalars\":\n",
      "\u001b[2m01:08:43.233508 line        59\u001b[0m         if tag == \"tensors\":\n",
      "\u001b[2m01:08:43.233541 line        85\u001b[0m         if tag == \"images\" and save_ims == True:\n",
      "\u001b[2m01:08:43.233573 line        46\u001b[0m     for tag in all_tags.keys():\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtag = 'tensors'\u001b[0m\n",
      "\u001b[2m01:08:43.233613 line        47\u001b[0m         if tag == \"scalars\":\n",
      "\u001b[2m01:08:43.233652 line        59\u001b[0m         if tag == \"tensors\":\n",
      "\u001b[2m01:08:43.233684 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'experiment_name/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.233716 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.233864 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.233912 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.233951 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.233986 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 0.005652691703...9095611572266, 'experiment_name': 'baseline_run'}\u001b[0m\n",
      "\u001b[2m01:08:43.234021 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'image_size/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.234061 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.234107 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.234143 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.234178 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.234234 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 0.005652691703...iment_name': 'baseline_run', 'image_size': '224'}\u001b[0m\n",
      "\u001b[2m01:08:43.234270 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'batch_size/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.234310 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.234356 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.234391 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.234426 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.234461 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 0.005652691703...ne_run', 'image_size': '224', 'batch_size': '32'}\u001b[0m\n",
      "\u001b[2m01:08:43.234494 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'enable_proxy_attention/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.234533 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.234579 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.234614 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.234675 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.234711 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 0.005652691703...ch_size': '32', 'enable_proxy_attention': 'True'}\u001b[0m\n",
      "\u001b[2m01:08:43.234745 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'transfer_imagenet/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.234784 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.234828 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.234865 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.234900 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.234934 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 0.005652691703..._attention': 'True', 'transfer_imagenet': 'True'}\u001b[0m\n",
      "\u001b[2m01:08:43.234968 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'subset_images/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.235007 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.235052 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.235088 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.235122 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.235156 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 0.005652691703...sfer_imagenet': 'True', 'subset_images': '20000'}\u001b[0m\n",
      "\u001b[2m01:08:43.235237 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'pixel_replacement_method/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.235280 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.235326 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.235362 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.235398 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.235432 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 0.005652691703...: '20000', 'pixel_replacement_method': 'blended'}\u001b[0m\n",
      "\u001b[2m01:08:43.235467 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'proxy_steps/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.235506 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.235551 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.235605 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.235644 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.235679 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 0.005652691703...cement_method': 'blended', 'proxy_steps': '[20]'}\u001b[0m\n",
      "\u001b[2m01:08:43.235713 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'load_proxy_data/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.235753 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.235798 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.235835 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.235870 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.235905 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 0.005652691703...proxy_steps': '[20]', 'load_proxy_data': 'False'}\u001b[0m\n",
      "\u001b[2m01:08:43.235953 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'proxy_step/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.235993 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.236039 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.236075 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.236110 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.236145 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.00565269...proxy_steps': '[20]', 'load_proxy_data': 'False'}\u001b[0m\n",
      "\u001b[2m01:08:43.236180 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'log_every/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.236220 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.236266 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.236302 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.236338 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.236373 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.00565269...]', 'load_proxy_data': 'False', 'log_every': '2'}\u001b[0m\n",
      "\u001b[2m01:08:43.236407 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'device/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.236447 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.236492 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.236528 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.236594 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.236632 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.00565269...': 'False', 'log_every': '2', 'device': 'cuda:0'}\u001b[0m\n",
      "\u001b[2m01:08:43.236668 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'dataset_info/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.236713 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.236761 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.236798 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.236834 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.236870 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.00565269...t_name at 0x7f4ed4fc7a30>, 'num_classes': 101}}\"}\u001b[0m\n",
      "\u001b[2m01:08:43.236906 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'main_run_dir/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.236967 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.237021 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.237075 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.237118 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.237159 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.00565269...DE/Github/improving_robotics_datasets/src/runs/'}\u001b[0m\n",
      "\u001b[2m01:08:43.237200 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'change_subset_attention/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.237246 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.237298 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.237341 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.237383 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.237427 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.00565269...ets/src/runs/', 'change_subset_attention': '0.8'}\u001b[0m\n",
      "\u001b[2m01:08:43.237468 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'model/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.237514 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.237567 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.237610 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.237652 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.237693 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.00565269...ge_subset_attention': '0.8', 'model': 'resnet50'}\u001b[0m\n",
      "\u001b[2m01:08:43.237734 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'proxy_image_weight/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.237781 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.237833 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.237876 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.237918 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.237959 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.00565269...'model': 'resnet50', 'proxy_image_weight': '0.1'}\u001b[0m\n",
      "\u001b[2m01:08:43.238000 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'proxy_threshold/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.238046 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.238098 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.238140 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.238204 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.238259 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.00565269..._image_weight': '0.1', 'proxy_threshold': '0.85'}\u001b[0m\n",
      "\u001b[2m01:08:43.238303 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'gradient_method/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.238351 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.238403 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.238447 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.238489 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.238530 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.00565269...d': '0.85', 'gradient_method': 'gradcamplusplus'}\u001b[0m\n",
      "\u001b[2m01:08:43.238571 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'ds_name/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.238617 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.238669 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.238716 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.238759 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.238800 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.00565269...hod': 'gradcamplusplus', 'ds_name': 'imagenette'}\u001b[0m\n",
      "\u001b[2m01:08:43.238841 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'clear_every_step/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.238887 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.238940 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.238982 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.239025 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.239065 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.00565269..._name': 'imagenette', 'clear_every_step': 'True'}\u001b[0m\n",
      "\u001b[2m01:08:43.239106 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'fname_start/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.239153 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.239206 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.239265 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.239310 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.239352 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.00565269..._datasets/src/runs/baseline_run_26032023_215855'}\u001b[0m\n",
      "\u001b[2m01:08:43.239394 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'ds_path/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.239441 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.239493 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.239536 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.239579 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.239621 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.00565269...media/eragon/HDD/Datasets/imagenette2-320/train'}\u001b[0m\n",
      "\u001b[2m01:08:43.239663 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'name_fn/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.239710 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.239763 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.239806 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.239849 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.239892 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.00565269...: '<function get_parent_name at 0x7f4ed4fc7a30>'}\u001b[0m\n",
      "\u001b[2m01:08:43.239934 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'global_run_count/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.239981 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.240036 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.240080 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.240133 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.240175 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[2m01:08:43.240221 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'writer/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.240263 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.240317 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.240364 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.240423 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.240466 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.00565269....writer.SummaryWriter object at 0x7f4ec666f0a0>'}\u001b[0m\n",
      "\u001b[2m01:08:43.240508 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'label_map/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.240556 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.240610 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.240655 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.240698 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.240741 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.00565269...7: 'n03425413', 8: 'n03445777', 9: 'n03888257'}\"}\u001b[0m\n",
      "\u001b[2m01:08:43.240783 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'rev_label_map/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.240832 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.240886 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.240931 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.240977 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.241020 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.00565269...'n03425413': 7, 'n03445777': 8, 'n03888257': 9}\"}\u001b[0m\n",
      "\u001b[2m01:08:43.241063 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'num_classes/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.241113 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.241169 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.241215 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.241260 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.241320 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.00565269...45777': 8, 'n03888257': 9}\", 'num_classes': '10'}\u001b[0m\n",
      "\u001b[2m01:08:43.241365 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'dataset_sizes/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.241414 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.241468 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.241514 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.241558 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.241601 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.00565269... 'dataset_sizes': \"{'train': 4735, 'val': 4734}\"}\u001b[0m\n",
      "\u001b[2m01:08:43.241646 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'criterion/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.241697 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.241753 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.241800 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.241845 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.241888 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.00565269...'val': 4734}\", 'criterion': 'CrossEntropyLoss()'}\u001b[0m\n",
      "\u001b[2m01:08:43.241933 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'cam/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.241982 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.242039 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.242085 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.242131 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.242176 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.00565269...splus.GradCAMPlusPlus object at 0x7f4eda9e13c0>'}\u001b[0m\n",
      "\u001b[2m01:08:43.242223 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'save_path/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.242274 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.242331 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.242378 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.242425 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.242471 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.00565269...rc/runs/baseline_run_26032023_215855/checkpoint'}\u001b[0m\n",
      "\u001b[2m01:08:43.242516 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'final_acc/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.242569 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.242627 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.242674 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.242721 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.242767 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.00565269...55/checkpoint', 'final_acc': '94.19095901985636'}\u001b[0m\n",
      "\u001b[2m01:08:43.242813 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[2m01:08:43.242864 line        85\u001b[0m         if tag == \"images\" and save_ims == True:\n",
      "\u001b[2m01:08:43.242911 line        46\u001b[0m     for tag in all_tags.keys():\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtag = 'graph'\u001b[0m\n",
      "\u001b[2m01:08:43.242957 line        47\u001b[0m         if tag == \"scalars\":\n",
      "\u001b[2m01:08:43.243008 line        59\u001b[0m         if tag == \"tensors\":\n",
      "\u001b[2m01:08:43.243053 line        85\u001b[0m         if tag == \"images\" and save_ims == True:\n",
      "\u001b[2m01:08:43.243099 line        46\u001b[0m     for tag in all_tags.keys():\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtag = 'meta_graph'\u001b[0m\n",
      "\u001b[2m01:08:43.243143 line        47\u001b[0m         if tag == \"scalars\":\n",
      "\u001b[2m01:08:43.243192 line        59\u001b[0m         if tag == \"tensors\":\n",
      "\u001b[2m01:08:43.243236 line        85\u001b[0m         if tag == \"images\" and save_ims == True:\n",
      "\u001b[2m01:08:43.243308 line        46\u001b[0m     for tag in all_tags.keys():\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtag = 'run_metadata'\u001b[0m\n",
      "\u001b[2m01:08:43.243354 line        47\u001b[0m         if tag == \"scalars\":\n",
      "\u001b[2m01:08:43.243407 line        59\u001b[0m         if tag == \"tensors\":\n",
      "\u001b[2m01:08:43.243452 line        85\u001b[0m         if tag == \"images\" and save_ims == True:\n",
      "\u001b[2m01:08:43.243498 line        46\u001b[0m     for tag in all_tags.keys():\n",
      "\u001b[2m01:08:43.243544 line        96\u001b[0m     return temp_dict\n",
      "\u001b[2m01:08:43.243590 return      96\u001b[0m     return temp_dict\n",
      "\u001b[36m\u001b[2mReturn value:.. \u001b[22m{'proxy_step': 'False', 'Loss/Train': 0.00565269...55/checkpoint', 'final_acc': '94.19095901985636'}\u001b[0m\n",
      "\u001b[33m\u001b[2mElapsed time: \u001b[22m00:00:00.013209\u001b[0m\n",
      "runs/baseline_run_26032023_232253/events.out.tfevents.1679865774.eragon\n",
      "\u001b[32m\u001b[2mStarting var:.. \u001b[22mevent_acc = <tensorboard.backend.event_processing.event_accumulator.EventAccumulator object at 0x7f5b568ef9d0>\u001b[0m\n",
      "\u001b[32m\u001b[2mStarting var:.. \u001b[22msave_ims = False\u001b[0m\n",
      "\u001b[2m01:08:43.255563 call        42\u001b[0m def process_event_acc(event_acc, save_ims = False):\n",
      "\u001b[2m01:08:43.255809 line        44\u001b[0m     all_tags = event_acc.Tags()\n",
      "\u001b[32m\u001b[2mNew var:....... \u001b[22mall_tags = {'images': [], 'audio': [], 'histograms': [], 's...: False, 'meta_graph': False, 'run_metadata': []}\u001b[0m\n",
      "\u001b[2m01:08:43.255958 line        45\u001b[0m     temp_dict = {}\n",
      "\u001b[32m\u001b[2mNew var:....... \u001b[22mtemp_dict = {}\u001b[0m\n",
      "\u001b[2m01:08:43.256050 line        46\u001b[0m     for tag in all_tags.keys():\n",
      "\u001b[32m\u001b[2mNew var:....... \u001b[22mtag = 'images'\u001b[0m\n",
      "\u001b[2m01:08:43.256176 line        47\u001b[0m         if tag == \"scalars\":\n",
      "\u001b[2m01:08:43.256260 line        59\u001b[0m         if tag == \"tensors\":\n",
      "\u001b[2m01:08:43.256350 line        85\u001b[0m         if tag == \"images\" and save_ims == True:\n",
      "\u001b[2m01:08:43.256403 line        46\u001b[0m     for tag in all_tags.keys():\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtag = 'audio'\u001b[0m\n",
      "\u001b[2m01:08:43.256481 line        47\u001b[0m         if tag == \"scalars\":\n",
      "\u001b[2m01:08:43.256535 line        59\u001b[0m         if tag == \"tensors\":\n",
      "\u001b[2m01:08:43.256579 line        85\u001b[0m         if tag == \"images\" and save_ims == True:\n",
      "\u001b[2m01:08:43.256660 line        46\u001b[0m     for tag in all_tags.keys():\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtag = 'histograms'\u001b[0m\n",
      "\u001b[2m01:08:43.256715 line        47\u001b[0m         if tag == \"scalars\":\n",
      "\u001b[2m01:08:43.256865 line        59\u001b[0m         if tag == \"tensors\":\n",
      "\u001b[2m01:08:43.256926 line        85\u001b[0m         if tag == \"images\" and save_ims == True:\n",
      "\u001b[2m01:08:43.256980 line        46\u001b[0m     for tag in all_tags.keys():\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtag = 'scalars'\u001b[0m\n",
      "\u001b[2m01:08:43.257100 line        47\u001b[0m         if tag == \"scalars\":\n",
      "\u001b[2m01:08:43.257201 line        48\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mNew var:....... \u001b[22msubtag = 'proxy_step'\u001b[0m\n",
      "\u001b[2m01:08:43.257253 line        50\u001b[0m                 try:\n",
      "\u001b[2m01:08:43.257312 line        51\u001b[0m                     temp_dict[subtag] = [tag[-1] for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.257399 exception   51\u001b[0m                     temp_dict[subtag] = [tag[-1] for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[31mException:..... \u001b[1mTypeError: 'ScalarEvent' object is not subscriptable\u001b[0m\n",
      "\u001b[2m01:08:43.257622 line        54\u001b[0m                 except:\n",
      "\u001b[2m01:08:43.257688 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.257769 line        56\u001b[0m                     -1\n",
      "\u001b[2m01:08:43.257829 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.257889 line        57\u001b[0m                 ].value\n",
      "\u001b[2m01:08:43.257948 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0}\u001b[0m\n",
      "\u001b[2m01:08:43.258006 line        48\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'Loss/Train'\u001b[0m\n",
      "\u001b[2m01:08:43.260209 line        50\u001b[0m                 try:\n",
      "\u001b[2m01:08:43.260482 line        51\u001b[0m                     temp_dict[subtag] = [tag[-1] for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.260589 exception   51\u001b[0m                     temp_dict[subtag] = [tag[-1] for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[31mException:..... \u001b[1mTypeError: 'ScalarEvent' object is not subscriptable\u001b[0m\n",
      "\u001b[2m01:08:43.260696 line        54\u001b[0m                 except:\n",
      "\u001b[2m01:08:43.260741 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.260807 line        56\u001b[0m                     -1\n",
      "\u001b[2m01:08:43.260857 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.260903 line        57\u001b[0m                 ].value\n",
      "\u001b[2m01:08:43.260970 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 0.12474711984395981}\u001b[0m\n",
      "\u001b[2m01:08:43.261019 line        48\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'Acc/Train'\u001b[0m\n",
      "\u001b[2m01:08:43.261098 line        50\u001b[0m                 try:\n",
      "\u001b[2m01:08:43.261378 line        51\u001b[0m                     temp_dict[subtag] = [tag[-1] for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.261480 exception   51\u001b[0m                     temp_dict[subtag] = [tag[-1] for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[31mException:..... \u001b[1mTypeError: 'ScalarEvent' object is not subscriptable\u001b[0m\n",
      "\u001b[2m01:08:43.261643 line        54\u001b[0m                 except:\n",
      "\u001b[2m01:08:43.261755 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.261819 line        56\u001b[0m                     -1\n",
      "\u001b[2m01:08:43.261876 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.261933 line        57\u001b[0m                 ].value\n",
      "\u001b[2m01:08:43.261991 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 0.12474711984395981, 'Acc/Train': 9.710000038146973}\u001b[0m\n",
      "\u001b[2m01:08:43.262046 line        48\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'global_run_count'\u001b[0m\n",
      "\u001b[2m01:08:43.262119 line        50\u001b[0m                 try:\n",
      "\u001b[2m01:08:43.262188 line        51\u001b[0m                     temp_dict[subtag] = [tag[-1] for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.262261 exception   51\u001b[0m                     temp_dict[subtag] = [tag[-1] for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[31mException:..... \u001b[1mTypeError: 'ScalarEvent' object is not subscriptable\u001b[0m\n",
      "\u001b[2m01:08:43.262365 line        54\u001b[0m                 except:\n",
      "\u001b[2m01:08:43.262428 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.262503 line        56\u001b[0m                     -1\n",
      "\u001b[2m01:08:43.262565 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.262624 line        57\u001b[0m                 ].value\n",
      "\u001b[2m01:08:43.262676 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 0.124747119843...in': 9.710000038146973, 'global_run_count': 20.0}\u001b[0m\n",
      "\u001b[2m01:08:43.262729 line        48\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'Loss/Val'\u001b[0m\n",
      "\u001b[2m01:08:43.262799 line        50\u001b[0m                 try:\n",
      "\u001b[2m01:08:43.262864 line        51\u001b[0m                     temp_dict[subtag] = [tag[-1] for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.262936 exception   51\u001b[0m                     temp_dict[subtag] = [tag[-1] for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[31mException:..... \u001b[1mTypeError: 'ScalarEvent' object is not subscriptable\u001b[0m\n",
      "\u001b[2m01:08:43.263039 line        54\u001b[0m                 except:\n",
      "\u001b[2m01:08:43.263098 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.263170 line        56\u001b[0m                     -1\n",
      "\u001b[2m01:08:43.263226 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.263283 line        57\u001b[0m                 ].value\n",
      "\u001b[2m01:08:43.263342 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 0.124747119843...un_count': 20.0, 'Loss/Val': 0.11687597632408142}\u001b[0m\n",
      "\u001b[2m01:08:43.263395 line        48\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'Acc/Val'\u001b[0m\n",
      "\u001b[2m01:08:43.263459 line        50\u001b[0m                 try:\n",
      "\u001b[2m01:08:43.263524 line        51\u001b[0m                     temp_dict[subtag] = [tag[-1] for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.263599 exception   51\u001b[0m                     temp_dict[subtag] = [tag[-1] for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[31mException:..... \u001b[1mTypeError: 'ScalarEvent' object is not subscriptable\u001b[0m\n",
      "\u001b[2m01:08:43.263695 line        54\u001b[0m                 except:\n",
      "\u001b[2m01:08:43.263775 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.263852 line        56\u001b[0m                     -1\n",
      "\u001b[2m01:08:43.263910 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.263957 line        57\u001b[0m                 ].value\n",
      "\u001b[2m01:08:43.263993 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 0.124747119843...11687597632408142, 'Acc/Val': 13.119999885559082}\u001b[0m\n",
      "\u001b[2m01:08:43.264027 line        48\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[2m01:08:43.264068 line        59\u001b[0m         if tag == \"tensors\":\n",
      "\u001b[2m01:08:43.264120 line        85\u001b[0m         if tag == \"images\" and save_ims == True:\n",
      "\u001b[2m01:08:43.264156 line        46\u001b[0m     for tag in all_tags.keys():\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtag = 'distributions'\u001b[0m\n",
      "\u001b[2m01:08:43.264190 line        47\u001b[0m         if tag == \"scalars\":\n",
      "\u001b[2m01:08:43.264229 line        59\u001b[0m         if tag == \"tensors\":\n",
      "\u001b[2m01:08:43.264273 line        85\u001b[0m         if tag == \"images\" and save_ims == True:\n",
      "\u001b[2m01:08:43.264312 line        46\u001b[0m     for tag in all_tags.keys():\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtag = 'tensors'\u001b[0m\n",
      "\u001b[2m01:08:43.264345 line        47\u001b[0m         if tag == \"scalars\":\n",
      "\u001b[2m01:08:43.264383 line        59\u001b[0m         if tag == \"tensors\":\n",
      "\u001b[2m01:08:43.264416 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'experiment_name/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.264464 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.264515 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.264555 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.264594 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.264645 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 0.124747119843...9999885559082, 'experiment_name': 'baseline_run'}\u001b[0m\n",
      "\u001b[2m01:08:43.264681 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'image_size/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.264720 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.264766 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.264855 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.264898 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.264935 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 0.124747119843...iment_name': 'baseline_run', 'image_size': '224'}\u001b[0m\n",
      "\u001b[2m01:08:43.264986 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'batch_size/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.265029 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.265077 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.265137 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.265189 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.265243 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 0.124747119843...ne_run', 'image_size': '224', 'batch_size': '32'}\u001b[0m\n",
      "\u001b[2m01:08:43.265298 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'enable_proxy_attention/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.265366 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.265428 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.265467 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.265503 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.265538 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 0.124747119843...ch_size': '32', 'enable_proxy_attention': 'True'}\u001b[0m\n",
      "\u001b[2m01:08:43.265572 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'transfer_imagenet/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.265612 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.265658 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.265700 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.265752 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.265810 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 0.124747119843..._attention': 'True', 'transfer_imagenet': 'True'}\u001b[0m\n",
      "\u001b[2m01:08:43.265872 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'subset_images/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.265963 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.266059 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.266135 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.266182 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.266248 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 0.124747119843...sfer_imagenet': 'True', 'subset_images': '20000'}\u001b[0m\n",
      "\u001b[2m01:08:43.266316 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'pixel_replacement_method/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.266400 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.266498 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.266571 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.266642 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.266708 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 0.124747119843...: '20000', 'pixel_replacement_method': 'blended'}\u001b[0m\n",
      "\u001b[2m01:08:43.266769 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'proxy_steps/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.266838 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.266926 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.266991 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.267064 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.267133 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 0.124747119843...cement_method': 'blended', 'proxy_steps': '[20]'}\u001b[0m\n",
      "\u001b[2m01:08:43.267195 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'load_proxy_data/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.267265 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.267347 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.267408 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.267466 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.267524 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 0.124747119843...proxy_steps': '[20]', 'load_proxy_data': 'False'}\u001b[0m\n",
      "\u001b[2m01:08:43.267581 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'proxy_step/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.267646 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.267744 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.267807 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.267867 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.267925 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.12474711...proxy_steps': '[20]', 'load_proxy_data': 'False'}\u001b[0m\n",
      "\u001b[2m01:08:43.267983 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'log_every/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.268048 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.268158 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.268223 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.268285 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.268343 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.12474711...]', 'load_proxy_data': 'False', 'log_every': '2'}\u001b[0m\n",
      "\u001b[2m01:08:43.268400 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'device/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.268468 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.268561 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.268632 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.268693 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.268832 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.12474711...': 'False', 'log_every': '2', 'device': 'cuda:0'}\u001b[0m\n",
      "\u001b[2m01:08:43.268901 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'dataset_info/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.269049 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.269150 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.269223 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.269324 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.269390 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.12474711...t_name at 0x7f687377fa30>, 'num_classes': 101}}\"}\u001b[0m\n",
      "\u001b[2m01:08:43.269463 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'main_run_dir/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.269589 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.269701 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.269775 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.269856 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.269933 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.12474711...DE/Github/improving_robotics_datasets/src/runs/'}\u001b[0m\n",
      "\u001b[2m01:08:43.270005 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'change_subset_attention/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.270099 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.270200 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.270282 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.270423 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.270500 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.12474711...ets/src/runs/', 'change_subset_attention': '0.8'}\u001b[0m\n",
      "\u001b[2m01:08:43.270574 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'model/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.270656 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.270750 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.270825 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.270906 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.270984 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.12474711...tention': '0.8', 'model': 'vit_base_patch16_224'}\u001b[0m\n",
      "\u001b[2m01:08:43.271059 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'proxy_image_weight/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.271138 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.271229 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.271303 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.271373 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.271442 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.12474711...t_base_patch16_224', 'proxy_image_weight': '0.1'}\u001b[0m\n",
      "\u001b[2m01:08:43.271513 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'proxy_threshold/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.271608 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.271719 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.271798 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.271869 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.271952 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.12474711..._image_weight': '0.1', 'proxy_threshold': '0.85'}\u001b[0m\n",
      "\u001b[2m01:08:43.272027 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'gradient_method/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.272107 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.272199 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.272339 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.272446 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.272527 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.12474711...d': '0.85', 'gradient_method': 'gradcamplusplus'}\u001b[0m\n",
      "\u001b[2m01:08:43.272606 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'ds_name/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.272698 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.272804 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.272890 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.272964 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.273034 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.12474711...ethod': 'gradcamplusplus', 'ds_name': 'cifar100'}\u001b[0m\n",
      "\u001b[2m01:08:43.273101 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'clear_every_step/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.273176 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.273280 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.273361 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.273494 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.273572 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.12474711...ds_name': 'cifar100', 'clear_every_step': 'True'}\u001b[0m\n",
      "\u001b[2m01:08:43.273651 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'fname_start/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.273757 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.273871 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.273953 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.274035 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.274112 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.12474711..._datasets/src/runs/baseline_run_26032023_232253'}\u001b[0m\n",
      "\u001b[2m01:08:43.274190 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'ds_path/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.274284 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.274395 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.274482 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.274560 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.274693 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.12474711...'/run/media/eragon/HDD/Datasets/CIFAR-100/train'}\u001b[0m\n",
      "\u001b[2m01:08:43.274770 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'name_fn/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.274866 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.274969 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.275058 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.275140 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.275216 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.12474711...: '<function get_parent_name at 0x7f687377fa30>'}\u001b[0m\n",
      "\u001b[2m01:08:43.275301 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'global_run_count/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.275396 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.275496 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.275606 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.275685 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.275769 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[2m01:08:43.275851 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'writer/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.275926 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.276037 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.276117 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.276189 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.276263 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.12474711....writer.SummaryWriter object at 0x7f6868999030>'}\u001b[0m\n",
      "\u001b[2m01:08:43.276345 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'label_map/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.276441 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.276550 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.276636 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.276721 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.276804 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.12474711...low_tree', 97: 'wolf', 98: 'woman', 99: 'worm'}\"}\u001b[0m\n",
      "\u001b[2m01:08:43.276887 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'rev_label_map/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.276997 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.277152 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.277253 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.277352 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.277447 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.12474711...tree': 96, 'wolf': 97, 'woman': 98, 'worm': 99}\"}\u001b[0m\n",
      "\u001b[2m01:08:43.277543 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'num_classes/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.277979 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.278320 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.278512 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.278662 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.278806 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.12474711... 'woman': 98, 'worm': 99}\", 'num_classes': '100'}\u001b[0m\n",
      "\u001b[2m01:08:43.278915 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'dataset_sizes/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.279033 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.279200 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.279309 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.279415 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.279521 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.12474711...dataset_sizes': \"{'train': 10000, 'val': 10000}\"}\u001b[0m\n",
      "\u001b[2m01:08:43.279618 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'criterion/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.279738 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.279862 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.279965 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.280061 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.280156 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.12474711...val': 10000}\", 'criterion': 'CrossEntropyLoss()'}\u001b[0m\n",
      "\u001b[2m01:08:43.280252 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'save_path/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.280355 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.280475 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.280574 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.280673 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.280772 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.12474711...rc/runs/baseline_run_26032023_232253/checkpoint'}\u001b[0m\n",
      "\u001b[2m01:08:43.280870 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'final_acc/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.280977 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.281099 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.281204 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.281301 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.281402 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.12474711...6032023_232253/checkpoint', 'final_acc': '13.12'}\u001b[0m\n",
      "\u001b[2m01:08:43.281502 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[2m01:08:43.281612 line        85\u001b[0m         if tag == \"images\" and save_ims == True:\n",
      "\u001b[2m01:08:43.281713 line        46\u001b[0m     for tag in all_tags.keys():\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtag = 'graph'\u001b[0m\n",
      "\u001b[2m01:08:43.281840 line        47\u001b[0m         if tag == \"scalars\":\n",
      "\u001b[2m01:08:43.281951 line        59\u001b[0m         if tag == \"tensors\":\n",
      "\u001b[2m01:08:43.282049 line        85\u001b[0m         if tag == \"images\" and save_ims == True:\n",
      "\u001b[2m01:08:43.282151 line        46\u001b[0m     for tag in all_tags.keys():\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtag = 'meta_graph'\u001b[0m\n",
      "\u001b[2m01:08:43.282300 line        47\u001b[0m         if tag == \"scalars\":\n",
      "\u001b[2m01:08:43.282411 line        59\u001b[0m         if tag == \"tensors\":\n",
      "\u001b[2m01:08:43.282524 line        85\u001b[0m         if tag == \"images\" and save_ims == True:\n",
      "\u001b[2m01:08:43.282635 line        46\u001b[0m     for tag in all_tags.keys():\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtag = 'run_metadata'\u001b[0m\n",
      "\u001b[2m01:08:43.282744 line        47\u001b[0m         if tag == \"scalars\":\n",
      "\u001b[2m01:08:43.282860 line        59\u001b[0m         if tag == \"tensors\":\n",
      "\u001b[2m01:08:43.282959 line        85\u001b[0m         if tag == \"images\" and save_ims == True:\n",
      "\u001b[2m01:08:43.283057 line        46\u001b[0m     for tag in all_tags.keys():\n",
      "\u001b[2m01:08:43.283155 line        96\u001b[0m     return temp_dict\n",
      "\u001b[2m01:08:43.283260 return      96\u001b[0m     return temp_dict\n",
      "\u001b[36m\u001b[2mReturn value:.. \u001b[22m{'proxy_step': 'False', 'Loss/Train': 0.12474711...6032023_232253/checkpoint', 'final_acc': '13.12'}\u001b[0m\n",
      "\u001b[33m\u001b[2mElapsed time: \u001b[22m00:00:00.027936\u001b[0m\n",
      " 52%|██████████████████████▏                    | 15/29 [00:00<00:00, 40.41it/s]runs/baseline_run_27032023_102541/events.out.tfevents.1679905541.eragon\n",
      "\u001b[32m\u001b[2mStarting var:.. \u001b[22mevent_acc = <tensorboard.backend.event_processing.event_accumulator.EventAccumulator object at 0x7f5b568ef8e0>\u001b[0m\n",
      "\u001b[32m\u001b[2mStarting var:.. \u001b[22msave_ims = False\u001b[0m\n",
      "\u001b[2m01:08:43.294422 call        42\u001b[0m def process_event_acc(event_acc, save_ims = False):\n",
      "\u001b[2m01:08:43.294528 line        44\u001b[0m     all_tags = event_acc.Tags()\n",
      "\u001b[32m\u001b[2mNew var:....... \u001b[22mall_tags = {'images': [], 'audio': [], 'histograms': [], 's...: False, 'meta_graph': False, 'run_metadata': []}\u001b[0m\n",
      "\u001b[2m01:08:43.294582 line        45\u001b[0m     temp_dict = {}\n",
      "\u001b[32m\u001b[2mNew var:....... \u001b[22mtemp_dict = {}\u001b[0m\n",
      "\u001b[2m01:08:43.294629 line        46\u001b[0m     for tag in all_tags.keys():\n",
      "\u001b[32m\u001b[2mNew var:....... \u001b[22mtag = 'images'\u001b[0m\n",
      "\u001b[2m01:08:43.294668 line        47\u001b[0m         if tag == \"scalars\":\n",
      "\u001b[2m01:08:43.294737 line        59\u001b[0m         if tag == \"tensors\":\n",
      "\u001b[2m01:08:43.294772 line        85\u001b[0m         if tag == \"images\" and save_ims == True:\n",
      "\u001b[2m01:08:43.294801 line        46\u001b[0m     for tag in all_tags.keys():\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtag = 'audio'\u001b[0m\n",
      "\u001b[2m01:08:43.294829 line        47\u001b[0m         if tag == \"scalars\":\n",
      "\u001b[2m01:08:43.294863 line        59\u001b[0m         if tag == \"tensors\":\n",
      "\u001b[2m01:08:43.294892 line        85\u001b[0m         if tag == \"images\" and save_ims == True:\n",
      "\u001b[2m01:08:43.294920 line        46\u001b[0m     for tag in all_tags.keys():\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtag = 'histograms'\u001b[0m\n",
      "\u001b[2m01:08:43.294948 line        47\u001b[0m         if tag == \"scalars\":\n",
      "\u001b[2m01:08:43.294981 line        59\u001b[0m         if tag == \"tensors\":\n",
      "\u001b[2m01:08:43.295009 line        85\u001b[0m         if tag == \"images\" and save_ims == True:\n",
      "\u001b[2m01:08:43.295036 line        46\u001b[0m     for tag in all_tags.keys():\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtag = 'scalars'\u001b[0m\n",
      "\u001b[2m01:08:43.295066 line        47\u001b[0m         if tag == \"scalars\":\n",
      "\u001b[2m01:08:43.295101 line        48\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mNew var:....... \u001b[22msubtag = 'proxy_step'\u001b[0m\n",
      "\u001b[2m01:08:43.295129 line        50\u001b[0m                 try:\n",
      "\u001b[2m01:08:43.295165 line        51\u001b[0m                     temp_dict[subtag] = [tag[-1] for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.295208 exception   51\u001b[0m                     temp_dict[subtag] = [tag[-1] for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[31mException:..... \u001b[1mTypeError: 'ScalarEvent' object is not subscriptable\u001b[0m\n",
      "\u001b[2m01:08:43.295332 line        54\u001b[0m                 except:\n",
      "\u001b[2m01:08:43.295367 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.295408 line        56\u001b[0m                     -1\n",
      "\u001b[2m01:08:43.295440 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.295470 line        57\u001b[0m                 ].value\n",
      "\u001b[2m01:08:43.295500 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0}\u001b[0m\n",
      "\u001b[2m01:08:43.295530 line        48\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'Loss/Train'\u001b[0m\n",
      "\u001b[2m01:08:43.295566 line        50\u001b[0m                 try:\n",
      "\u001b[2m01:08:43.295600 line        51\u001b[0m                     temp_dict[subtag] = [tag[-1] for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.295637 exception   51\u001b[0m                     temp_dict[subtag] = [tag[-1] for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[31mException:..... \u001b[1mTypeError: 'ScalarEvent' object is not subscriptable\u001b[0m\n",
      "\u001b[2m01:08:43.295713 line        54\u001b[0m                 except:\n",
      "\u001b[2m01:08:43.295746 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.295788 line        56\u001b[0m                     -1\n",
      "\u001b[2m01:08:43.295819 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.295850 line        57\u001b[0m                 ].value\n",
      "\u001b[2m01:08:43.295879 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 0.12349269539117813}\u001b[0m\n",
      "\u001b[2m01:08:43.295910 line        48\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'Acc/Train'\u001b[0m\n",
      "\u001b[2m01:08:43.295948 line        50\u001b[0m                 try:\n",
      "\u001b[2m01:08:43.295994 line        51\u001b[0m                     temp_dict[subtag] = [tag[-1] for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.296054 exception   51\u001b[0m                     temp_dict[subtag] = [tag[-1] for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[31mException:..... \u001b[1mTypeError: 'ScalarEvent' object is not subscriptable\u001b[0m\n",
      "\u001b[2m01:08:43.296129 line        54\u001b[0m                 except:\n",
      "\u001b[2m01:08:43.296175 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.296234 line        56\u001b[0m                     -1\n",
      "\u001b[2m01:08:43.296272 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.296314 line        57\u001b[0m                 ].value\n",
      "\u001b[2m01:08:43.296356 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 0.12349269539117813, 'Acc/Train': 9.850000381469727}\u001b[0m\n",
      "\u001b[2m01:08:43.296404 line        48\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'global_run_count'\u001b[0m\n",
      "\u001b[2m01:08:43.296460 line        50\u001b[0m                 try:\n",
      "\u001b[2m01:08:43.296512 line        51\u001b[0m                     temp_dict[subtag] = [tag[-1] for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.296554 exception   51\u001b[0m                     temp_dict[subtag] = [tag[-1] for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[31mException:..... \u001b[1mTypeError: 'ScalarEvent' object is not subscriptable\u001b[0m\n",
      "\u001b[2m01:08:43.296634 line        54\u001b[0m                 except:\n",
      "\u001b[2m01:08:43.296690 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.296757 line        56\u001b[0m                     -1\n",
      "\u001b[2m01:08:43.296810 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.296899 line        57\u001b[0m                 ].value\n",
      "\u001b[2m01:08:43.296954 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 0.123492695391...in': 9.850000381469727, 'global_run_count': 20.0}\u001b[0m\n",
      "\u001b[2m01:08:43.297006 line        48\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'Loss/Val'\u001b[0m\n",
      "\u001b[2m01:08:43.297168 line        50\u001b[0m                 try:\n",
      "\u001b[2m01:08:43.297233 line        51\u001b[0m                     temp_dict[subtag] = [tag[-1] for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.297300 exception   51\u001b[0m                     temp_dict[subtag] = [tag[-1] for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[31mException:..... \u001b[1mTypeError: 'ScalarEvent' object is not subscriptable\u001b[0m\n",
      "\u001b[2m01:08:43.297387 line        54\u001b[0m                 except:\n",
      "\u001b[2m01:08:43.297443 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.297511 line        56\u001b[0m                     -1\n",
      "\u001b[2m01:08:43.297564 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.297616 line        57\u001b[0m                 ].value\n",
      "\u001b[2m01:08:43.297667 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 0.123492695391...un_count': 20.0, 'Loss/Val': 0.12086772173643112}\u001b[0m\n",
      "\u001b[2m01:08:43.297723 line        48\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'Acc/Val'\u001b[0m\n",
      "\u001b[2m01:08:43.297786 line        50\u001b[0m                 try:\n",
      "\u001b[2m01:08:43.297848 line        51\u001b[0m                     temp_dict[subtag] = [tag[-1] for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.297912 exception   51\u001b[0m                     temp_dict[subtag] = [tag[-1] for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[31mException:..... \u001b[1mTypeError: 'ScalarEvent' object is not subscriptable\u001b[0m\n",
      "\u001b[2m01:08:43.297990 line        54\u001b[0m                 except:\n",
      "\u001b[2m01:08:43.298046 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.298112 line        56\u001b[0m                     -1\n",
      "\u001b[2m01:08:43.298157 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.298192 line        57\u001b[0m                 ].value\n",
      "\u001b[2m01:08:43.298226 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 0.123492695391...12086772173643112, 'Acc/Val': 10.949999809265137}\u001b[0m\n",
      "\u001b[2m01:08:43.298260 line        48\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[2m01:08:43.298301 line        59\u001b[0m         if tag == \"tensors\":\n",
      "\u001b[2m01:08:43.298335 line        85\u001b[0m         if tag == \"images\" and save_ims == True:\n",
      "\u001b[2m01:08:43.298369 line        46\u001b[0m     for tag in all_tags.keys():\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtag = 'distributions'\u001b[0m\n",
      "\u001b[2m01:08:43.298401 line        47\u001b[0m         if tag == \"scalars\":\n",
      "\u001b[2m01:08:43.298457 line        59\u001b[0m         if tag == \"tensors\":\n",
      "\u001b[2m01:08:43.298490 line        85\u001b[0m         if tag == \"images\" and save_ims == True:\n",
      "\u001b[2m01:08:43.298523 line        46\u001b[0m     for tag in all_tags.keys():\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtag = 'tensors'\u001b[0m\n",
      "\u001b[2m01:08:43.298555 line        47\u001b[0m         if tag == \"scalars\":\n",
      "\u001b[2m01:08:43.298592 line        59\u001b[0m         if tag == \"tensors\":\n",
      "\u001b[2m01:08:43.298625 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'experiment_name/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.298657 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.298705 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.298746 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.298801 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.298858 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 0.123492695391...9999809265137, 'experiment_name': 'baseline_run'}\u001b[0m\n",
      "\u001b[2m01:08:43.298912 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'image_size/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.298979 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.299057 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.299117 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.299169 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.299220 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 0.123492695391...iment_name': 'baseline_run', 'image_size': '224'}\u001b[0m\n",
      "\u001b[2m01:08:43.299272 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'batch_size/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.299331 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.299400 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.299455 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.299510 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.299562 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 0.123492695391...ne_run', 'image_size': '224', 'batch_size': '32'}\u001b[0m\n",
      "\u001b[2m01:08:43.299616 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'enable_proxy_attention/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.299677 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.299750 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.299807 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.299863 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.299918 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 0.123492695391...ch_size': '32', 'enable_proxy_attention': 'True'}\u001b[0m\n",
      "\u001b[2m01:08:43.299974 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'transfer_imagenet/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.300039 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.300113 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.300172 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.300235 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.300287 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 0.123492695391..._attention': 'True', 'transfer_imagenet': 'True'}\u001b[0m\n",
      "\u001b[2m01:08:43.300341 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'subset_images/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.300418 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.300492 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.300550 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.300604 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.300659 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 0.123492695391...sfer_imagenet': 'True', 'subset_images': '20000'}\u001b[0m\n",
      "\u001b[2m01:08:43.300717 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'pixel_replacement_method/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.300778 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.300853 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.300910 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.300967 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.301054 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 0.123492695391...: '20000', 'pixel_replacement_method': 'blended'}\u001b[0m\n",
      "\u001b[2m01:08:43.301126 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'proxy_steps/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.301188 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.301260 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.301317 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.301371 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.301426 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 0.123492695391...cement_method': 'blended', 'proxy_steps': '[20]'}\u001b[0m\n",
      "\u001b[2m01:08:43.301483 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'load_proxy_data/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.301556 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.301631 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.301690 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.301750 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.301809 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 0.123492695391...proxy_steps': '[20]', 'load_proxy_data': 'False'}\u001b[0m\n",
      "\u001b[2m01:08:43.301867 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'proxy_step/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.301933 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.302009 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.302068 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.302154 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.302215 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.12349269...proxy_steps': '[20]', 'load_proxy_data': 'False'}\u001b[0m\n",
      "\u001b[2m01:08:43.302273 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'log_every/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.302338 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.302414 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.302474 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.302532 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.302609 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.12349269...]', 'load_proxy_data': 'False', 'log_every': '2'}\u001b[0m\n",
      "\u001b[2m01:08:43.302669 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'device/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.302732 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.302810 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.302874 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.302936 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.302989 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.12349269...': 'False', 'log_every': '2', 'device': 'cuda:0'}\u001b[0m\n",
      "\u001b[2m01:08:43.303051 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'dataset_info/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.303113 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.303184 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.303240 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.303296 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.303399 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.12349269...t_name at 0x7f2bd69cba30>, 'num_classes': 101}}\"}\u001b[0m\n",
      "\u001b[2m01:08:43.303457 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'main_run_dir/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.303534 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.303624 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.303693 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.303777 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.303843 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.12349269...DE/Github/improving_robotics_datasets/src/runs/'}\u001b[0m\n",
      "\u001b[2m01:08:43.303909 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'change_subset_attention/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.303986 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.304072 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.304141 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.304213 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.304277 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.12349269...ets/src/runs/', 'change_subset_attention': '0.8'}\u001b[0m\n",
      "\u001b[2m01:08:43.304346 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'model/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.304395 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.304449 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.304492 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.304536 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.304577 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.12349269...tention': '0.8', 'model': 'vit_base_patch16_224'}\u001b[0m\n",
      "\u001b[2m01:08:43.304618 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'proxy_image_weight/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.304664 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.304716 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.304757 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.304799 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.304840 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.12349269...t_base_patch16_224', 'proxy_image_weight': '0.1'}\u001b[0m\n",
      "\u001b[2m01:08:43.304880 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'proxy_threshold/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.304927 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.304981 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.305055 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.305122 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.305168 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.12349269..._image_weight': '0.1', 'proxy_threshold': '0.85'}\u001b[0m\n",
      "\u001b[2m01:08:43.305211 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'gradient_method/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.305259 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.305315 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.305358 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.305451 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.305499 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.12349269...d': '0.85', 'gradient_method': 'gradcamplusplus'}\u001b[0m\n",
      "\u001b[2m01:08:43.305542 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'ds_name/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.305589 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.305644 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.305701 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.305758 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.305803 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.12349269...nt_method': 'gradcamplusplus', 'ds_name': 'dogs'}\u001b[0m\n",
      "\u001b[2m01:08:43.305869 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'clear_every_step/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.305949 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.306037 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.306107 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.306214 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.306287 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.12349269...', 'ds_name': 'dogs', 'clear_every_step': 'True'}\u001b[0m\n",
      "\u001b[2m01:08:43.306360 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'fname_start/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.306438 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.306534 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.306605 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.306677 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.306745 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.12349269..._datasets/src/runs/baseline_run_27032023_102541'}\u001b[0m\n",
      "\u001b[2m01:08:43.306845 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'ds_path/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.306922 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.307017 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.307109 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.307185 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.307259 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.12349269...un/media/eragon/HDD/Datasets/dogs/images/Images'}\u001b[0m\n",
      "\u001b[2m01:08:43.307329 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'name_fn/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.307405 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.307493 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.307567 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.307634 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.307708 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.12349269...: '<function get_parent_name at 0x7f2bd69cba30>'}\u001b[0m\n",
      "\u001b[2m01:08:43.307779 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'global_run_count/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.307859 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.307950 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.308021 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.308091 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.308159 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[2m01:08:43.308227 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'writer/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.308294 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.308378 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.308448 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.308521 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.308593 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.12349269....writer.SummaryWriter object at 0x7f2bc7a8e920>'}\u001b[0m\n",
      "\u001b[2m01:08:43.308663 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'label_map/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.308744 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.308834 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.308908 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.308979 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.309052 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.12349269...3-dhole', 119: 'n02116738-African_hunting_dog'}\"}\u001b[0m\n",
      "\u001b[2m01:08:43.309124 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'rev_label_map/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.309228 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.309339 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.309435 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.309531 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.309628 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.12349269...le': 118, 'n02116738-African_hunting_dog': 119}\"}\u001b[0m\n",
      "\u001b[2m01:08:43.309789 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'num_classes/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.309939 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.310093 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.310226 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.310367 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.310507 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.12349269...frican_hunting_dog': 119}\", 'num_classes': '120'}\u001b[0m\n",
      "\u001b[2m01:08:43.310642 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'dataset_sizes/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.310782 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.310972 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.311117 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.311268 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.311416 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.12349269...dataset_sizes': \"{'train': 10000, 'val': 10000}\"}\u001b[0m\n",
      "\u001b[2m01:08:43.311566 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'criterion/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.311731 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.311899 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.312043 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.312177 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.312305 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.12349269...val': 10000}\", 'criterion': 'CrossEntropyLoss()'}\u001b[0m\n",
      "\u001b[2m01:08:43.312444 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'save_path/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.312604 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.312784 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.312947 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.313097 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.313243 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.12349269...rc/runs/baseline_run_27032023_102541/checkpoint'}\u001b[0m\n",
      "\u001b[2m01:08:43.313420 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'final_acc/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.313582 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.313775 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.313928 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.314066 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.314197 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.12349269...7032023_102541/checkpoint', 'final_acc': '10.95'}\u001b[0m\n",
      "\u001b[2m01:08:43.314322 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[2m01:08:43.314474 line        85\u001b[0m         if tag == \"images\" and save_ims == True:\n",
      "\u001b[2m01:08:43.314611 line        46\u001b[0m     for tag in all_tags.keys():\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtag = 'graph'\u001b[0m\n",
      "\u001b[2m01:08:43.314760 line        47\u001b[0m         if tag == \"scalars\":\n",
      "\u001b[2m01:08:43.314916 line        59\u001b[0m         if tag == \"tensors\":\n",
      "\u001b[2m01:08:43.315064 line        85\u001b[0m         if tag == \"images\" and save_ims == True:\n",
      "\u001b[2m01:08:43.315220 line        46\u001b[0m     for tag in all_tags.keys():\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtag = 'meta_graph'\u001b[0m\n",
      "\u001b[2m01:08:43.315342 line        47\u001b[0m         if tag == \"scalars\":\n",
      "\u001b[2m01:08:43.315497 line        59\u001b[0m         if tag == \"tensors\":\n",
      "\u001b[2m01:08:43.315635 line        85\u001b[0m         if tag == \"images\" and save_ims == True:\n",
      "\u001b[2m01:08:43.315767 line        46\u001b[0m     for tag in all_tags.keys():\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtag = 'run_metadata'\u001b[0m\n",
      "\u001b[2m01:08:43.315914 line        47\u001b[0m         if tag == \"scalars\":\n",
      "\u001b[2m01:08:43.316067 line        59\u001b[0m         if tag == \"tensors\":\n",
      "\u001b[2m01:08:43.316210 line        85\u001b[0m         if tag == \"images\" and save_ims == True:\n",
      "\u001b[2m01:08:43.316356 line        46\u001b[0m     for tag in all_tags.keys():\n",
      "\u001b[2m01:08:43.316499 line        96\u001b[0m     return temp_dict\n",
      "\u001b[2m01:08:43.316605 return      96\u001b[0m     return temp_dict\n",
      "\u001b[36m\u001b[2mReturn value:.. \u001b[22m{'proxy_step': 'False', 'Loss/Train': 0.12349269...7032023_102541/checkpoint', 'final_acc': '10.95'}\u001b[0m\n",
      "\u001b[33m\u001b[2mElapsed time: \u001b[22m00:00:00.022408\u001b[0m\n",
      "runs/baseline_run_27032023_105652/events.out.tfevents.1679907414.eragon\n",
      "\u001b[32m\u001b[2mStarting var:.. \u001b[22mevent_acc = <tensorboard.backend.event_processing.event_accumulator.EventAccumulator object at 0x7f5b568ed990>\u001b[0m\n",
      "\u001b[32m\u001b[2mStarting var:.. \u001b[22msave_ims = False\u001b[0m\n",
      "\u001b[2m01:08:43.325250 call        42\u001b[0m def process_event_acc(event_acc, save_ims = False):\n",
      "\u001b[2m01:08:43.325321 line        44\u001b[0m     all_tags = event_acc.Tags()\n",
      "\u001b[32m\u001b[2mNew var:....... \u001b[22mall_tags = {'images': [], 'audio': [], 'histograms': [], 's...: False, 'meta_graph': False, 'run_metadata': []}\u001b[0m\n",
      "\u001b[2m01:08:43.325379 line        45\u001b[0m     temp_dict = {}\n",
      "\u001b[32m\u001b[2mNew var:....... \u001b[22mtemp_dict = {}\u001b[0m\n",
      "\u001b[2m01:08:43.325434 line        46\u001b[0m     for tag in all_tags.keys():\n",
      "\u001b[32m\u001b[2mNew var:....... \u001b[22mtag = 'images'\u001b[0m\n",
      "\u001b[2m01:08:43.325473 line        47\u001b[0m         if tag == \"scalars\":\n",
      "\u001b[2m01:08:43.325510 line        59\u001b[0m         if tag == \"tensors\":\n",
      "\u001b[2m01:08:43.325541 line        85\u001b[0m         if tag == \"images\" and save_ims == True:\n",
      "\u001b[2m01:08:43.325570 line        46\u001b[0m     for tag in all_tags.keys():\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtag = 'audio'\u001b[0m\n",
      "\u001b[2m01:08:43.325598 line        47\u001b[0m         if tag == \"scalars\":\n",
      "\u001b[2m01:08:43.325631 line        59\u001b[0m         if tag == \"tensors\":\n",
      "\u001b[2m01:08:43.325659 line        85\u001b[0m         if tag == \"images\" and save_ims == True:\n",
      "\u001b[2m01:08:43.325686 line        46\u001b[0m     for tag in all_tags.keys():\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtag = 'histograms'\u001b[0m\n",
      "\u001b[2m01:08:43.325713 line        47\u001b[0m         if tag == \"scalars\":\n",
      "\u001b[2m01:08:43.325745 line        59\u001b[0m         if tag == \"tensors\":\n",
      "\u001b[2m01:08:43.325772 line        85\u001b[0m         if tag == \"images\" and save_ims == True:\n",
      "\u001b[2m01:08:43.325799 line        46\u001b[0m     for tag in all_tags.keys():\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtag = 'scalars'\u001b[0m\n",
      "\u001b[2m01:08:43.325826 line        47\u001b[0m         if tag == \"scalars\":\n",
      "\u001b[2m01:08:43.325858 line        48\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mNew var:....... \u001b[22msubtag = 'proxy_step'\u001b[0m\n",
      "\u001b[2m01:08:43.325886 line        50\u001b[0m                 try:\n",
      "\u001b[2m01:08:43.325920 line        51\u001b[0m                     temp_dict[subtag] = [tag[-1] for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.325959 exception   51\u001b[0m                     temp_dict[subtag] = [tag[-1] for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[31mException:..... \u001b[1mTypeError: 'ScalarEvent' object is not subscriptable\u001b[0m\n",
      "\u001b[2m01:08:43.326065 line        54\u001b[0m                 except:\n",
      "\u001b[2m01:08:43.326099 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.326139 line        56\u001b[0m                     -1\n",
      "\u001b[2m01:08:43.326169 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.326200 line        57\u001b[0m                 ].value\n",
      "\u001b[2m01:08:43.326229 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0}\u001b[0m\n",
      "\u001b[2m01:08:43.326259 line        48\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'Loss/Train'\u001b[0m\n",
      "\u001b[2m01:08:43.326295 line        50\u001b[0m                 try:\n",
      "\u001b[2m01:08:43.326329 line        51\u001b[0m                     temp_dict[subtag] = [tag[-1] for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.326364 exception   51\u001b[0m                     temp_dict[subtag] = [tag[-1] for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[31mException:..... \u001b[1mTypeError: 'ScalarEvent' object is not subscriptable\u001b[0m\n",
      "\u001b[2m01:08:43.326417 line        54\u001b[0m                 except:\n",
      "\u001b[2m01:08:43.326449 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.326506 line        56\u001b[0m                     -1\n",
      "\u001b[2m01:08:43.326564 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.326598 line        57\u001b[0m                 ].value\n",
      "\u001b[2m01:08:43.326629 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 0.0928124189376831}\u001b[0m\n",
      "\u001b[2m01:08:43.326658 line        48\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'Acc/Train'\u001b[0m\n",
      "\u001b[2m01:08:43.326695 line        50\u001b[0m                 try:\n",
      "\u001b[2m01:08:43.326730 line        51\u001b[0m                     temp_dict[subtag] = [tag[-1] for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.326767 exception   51\u001b[0m                     temp_dict[subtag] = [tag[-1] for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[31mException:..... \u001b[1mTypeError: 'ScalarEvent' object is not subscriptable\u001b[0m\n",
      "\u001b[2m01:08:43.326820 line        54\u001b[0m                 except:\n",
      "\u001b[2m01:08:43.326852 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.326890 line        56\u001b[0m                     -1\n",
      "\u001b[2m01:08:43.326921 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.326950 line        57\u001b[0m                 ].value\n",
      "\u001b[2m01:08:43.326981 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 0.0928124189376831, 'Acc/Train': 32.29827117919922}\u001b[0m\n",
      "\u001b[2m01:08:43.327019 line        48\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'global_run_count'\u001b[0m\n",
      "\u001b[2m01:08:43.327092 line        50\u001b[0m                 try:\n",
      "\u001b[2m01:08:43.327158 line        51\u001b[0m                     temp_dict[subtag] = [tag[-1] for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.327228 exception   51\u001b[0m                     temp_dict[subtag] = [tag[-1] for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[31mException:..... \u001b[1mTypeError: 'ScalarEvent' object is not subscriptable\u001b[0m\n",
      "\u001b[2m01:08:43.327316 line        54\u001b[0m                 except:\n",
      "\u001b[2m01:08:43.327379 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.327448 line        56\u001b[0m                     -1\n",
      "\u001b[2m01:08:43.327488 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.327527 line        57\u001b[0m                 ].value\n",
      "\u001b[2m01:08:43.327584 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 0.092812418937...in': 32.29827117919922, 'global_run_count': 20.0}\u001b[0m\n",
      "\u001b[2m01:08:43.327638 line        48\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'Loss/Val'\u001b[0m\n",
      "\u001b[2m01:08:43.327683 line        50\u001b[0m                 try:\n",
      "\u001b[2m01:08:43.327728 line        51\u001b[0m                     temp_dict[subtag] = [tag[-1] for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.327773 exception   51\u001b[0m                     temp_dict[subtag] = [tag[-1] for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[31mException:..... \u001b[1mTypeError: 'ScalarEvent' object is not subscriptable\u001b[0m\n",
      "\u001b[2m01:08:43.327833 line        54\u001b[0m                 except:\n",
      "\u001b[2m01:08:43.327872 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.327916 line        56\u001b[0m                     -1\n",
      "\u001b[2m01:08:43.327952 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.327988 line        57\u001b[0m                 ].value\n",
      "\u001b[2m01:08:43.328024 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 0.092812418937...un_count': 20.0, 'Loss/Val': 0.09401462972164154}\u001b[0m\n",
      "\u001b[2m01:08:43.328059 line        48\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'Acc/Val'\u001b[0m\n",
      "\u001b[2m01:08:43.328103 line        50\u001b[0m                 try:\n",
      "\u001b[2m01:08:43.328145 line        51\u001b[0m                     temp_dict[subtag] = [tag[-1] for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.328188 exception   51\u001b[0m                     temp_dict[subtag] = [tag[-1] for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[31mException:..... \u001b[1mTypeError: 'ScalarEvent' object is not subscriptable\u001b[0m\n",
      "\u001b[2m01:08:43.328247 line        54\u001b[0m                 except:\n",
      "\u001b[2m01:08:43.328286 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.328332 line        56\u001b[0m                     -1\n",
      "\u001b[2m01:08:43.328369 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.328405 line        57\u001b[0m                 ].value\n",
      "\u001b[2m01:08:43.328441 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 0.092812418937....09401462972164154, 'Acc/Val': 32.87401580810547}\u001b[0m\n",
      "\u001b[2m01:08:43.328478 line        48\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[2m01:08:43.328522 line        59\u001b[0m         if tag == \"tensors\":\n",
      "\u001b[2m01:08:43.328559 line        85\u001b[0m         if tag == \"images\" and save_ims == True:\n",
      "\u001b[2m01:08:43.328595 line        46\u001b[0m     for tag in all_tags.keys():\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtag = 'distributions'\u001b[0m\n",
      "\u001b[2m01:08:43.328645 line        47\u001b[0m         if tag == \"scalars\":\n",
      "\u001b[2m01:08:43.328700 line        59\u001b[0m         if tag == \"tensors\":\n",
      "\u001b[2m01:08:43.328798 line        85\u001b[0m         if tag == \"images\" and save_ims == True:\n",
      "\u001b[2m01:08:43.328839 line        46\u001b[0m     for tag in all_tags.keys():\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtag = 'tensors'\u001b[0m\n",
      "\u001b[2m01:08:43.328876 line        47\u001b[0m         if tag == \"scalars\":\n",
      "\u001b[2m01:08:43.328914 line        59\u001b[0m         if tag == \"tensors\":\n",
      "\u001b[2m01:08:43.328947 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'experiment_name/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.328980 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.329031 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.329072 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.329109 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.329144 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 0.092812418937...7401580810547, 'experiment_name': 'baseline_run'}\u001b[0m\n",
      "\u001b[2m01:08:43.329178 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'image_size/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.329216 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.329262 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.329298 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.329348 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.329402 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 0.092812418937...iment_name': 'baseline_run', 'image_size': '224'}\u001b[0m\n",
      "\u001b[2m01:08:43.329455 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'batch_size/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.329521 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.329600 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.329662 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.329740 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.329797 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 0.092812418937...ne_run', 'image_size': '224', 'batch_size': '32'}\u001b[0m\n",
      "\u001b[2m01:08:43.329858 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'enable_proxy_attention/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.329926 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.329990 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.330029 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.330065 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.330099 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 0.092812418937...ch_size': '32', 'enable_proxy_attention': 'True'}\u001b[0m\n",
      "\u001b[2m01:08:43.330133 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'transfer_imagenet/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.330173 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.330219 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.330254 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.330289 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.330323 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 0.092812418937..._attention': 'True', 'transfer_imagenet': 'True'}\u001b[0m\n",
      "\u001b[2m01:08:43.330357 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'subset_images/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.330421 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.330470 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.330506 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.330542 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.330575 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 0.092812418937...sfer_imagenet': 'True', 'subset_images': '20000'}\u001b[0m\n",
      "\u001b[2m01:08:43.330613 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'pixel_replacement_method/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.330652 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.330697 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.330732 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.330766 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.330799 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 0.092812418937...: '20000', 'pixel_replacement_method': 'blended'}\u001b[0m\n",
      "\u001b[2m01:08:43.330832 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'proxy_steps/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.330873 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.330917 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.330956 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.330990 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.331024 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 0.092812418937...cement_method': 'blended', 'proxy_steps': '[20]'}\u001b[0m\n",
      "\u001b[2m01:08:43.331058 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'load_proxy_data/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.331097 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.331143 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.331178 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.331212 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.331246 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 0.092812418937...proxy_steps': '[20]', 'load_proxy_data': 'False'}\u001b[0m\n",
      "\u001b[2m01:08:43.331280 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'proxy_step/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.331319 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.331363 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.331398 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.331432 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.331466 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.09281241...proxy_steps': '[20]', 'load_proxy_data': 'False'}\u001b[0m\n",
      "\u001b[2m01:08:43.331500 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'log_every/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.331540 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.331585 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.331620 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.331654 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.331688 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.09281241...]', 'load_proxy_data': 'False', 'log_every': '2'}\u001b[0m\n",
      "\u001b[2m01:08:43.331721 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'device/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.331766 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.331814 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.331850 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.331885 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.331918 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.09281241...': 'False', 'log_every': '2', 'device': 'cuda:0'}\u001b[0m\n",
      "\u001b[2m01:08:43.331952 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'dataset_info/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.331990 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.332058 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.332119 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.332175 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.332214 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.09281241...t_name at 0x7f0c947cba30>, 'num_classes': 101}}\"}\u001b[0m\n",
      "\u001b[2m01:08:43.332250 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'main_run_dir/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.332297 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.332349 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.332392 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.332433 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.332505 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.09281241...DE/Github/improving_robotics_datasets/src/runs/'}\u001b[0m\n",
      "\u001b[2m01:08:43.332549 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'change_subset_attention/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.332595 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.332647 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.332689 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.332729 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.332770 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.09281241...ets/src/runs/', 'change_subset_attention': '0.8'}\u001b[0m\n",
      "\u001b[2m01:08:43.332810 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'model/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.332855 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.332907 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.332950 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.332991 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.333031 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.09281241...tention': '0.8', 'model': 'vit_base_patch16_224'}\u001b[0m\n",
      "\u001b[2m01:08:43.333071 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'proxy_image_weight/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.333118 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.333170 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.333212 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.333255 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.333295 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.09281241...t_base_patch16_224', 'proxy_image_weight': '0.1'}\u001b[0m\n",
      "\u001b[2m01:08:43.333336 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'proxy_threshold/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.333382 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.333435 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.333476 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.333544 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.333655 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.09281241..._image_weight': '0.1', 'proxy_threshold': '0.85'}\u001b[0m\n",
      "\u001b[2m01:08:43.333734 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'gradient_method/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.333823 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.333911 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.333985 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.334058 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.334133 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.09281241...d': '0.85', 'gradient_method': 'gradcamplusplus'}\u001b[0m\n",
      "\u001b[2m01:08:43.334179 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'ds_name/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.334227 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.334282 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.334327 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.334370 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.334412 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.09281241...hod': 'gradcamplusplus', 'ds_name': 'caltech101'}\u001b[0m\n",
      "\u001b[2m01:08:43.334454 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'clear_every_step/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.334501 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.334554 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.334596 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.334657 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.334700 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.09281241..._name': 'caltech101', 'clear_every_step': 'True'}\u001b[0m\n",
      "\u001b[2m01:08:43.334743 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'fname_start/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.334790 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.334843 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.334887 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.334930 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.334971 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.09281241..._datasets/src/runs/baseline_run_27032023_105652'}\u001b[0m\n",
      "\u001b[2m01:08:43.335013 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'ds_path/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.335060 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.335114 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.335157 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.335199 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.335240 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.09281241...h': '/run/media/eragon/HDD/Datasets/caltech-101'}\u001b[0m\n",
      "\u001b[2m01:08:43.335281 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'name_fn/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.335328 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.335381 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.335424 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.335466 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.335508 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.09281241...: '<function get_parent_name at 0x7f0c947cba30>'}\u001b[0m\n",
      "\u001b[2m01:08:43.335550 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'global_run_count/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.335596 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.335669 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.335714 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.335756 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.335798 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[2m01:08:43.335840 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'writer/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.335880 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.335943 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.335987 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.336029 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.336074 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.09281241....writer.SummaryWriter object at 0x7f0c8591abf0>'}\u001b[0m\n",
      "\u001b[2m01:08:43.336121 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'label_map/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.336170 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.336254 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.336324 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.336373 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.336418 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.09281241...windsor_chair', 100: 'wrench', 101: 'yin_yang'}\"}\u001b[0m\n",
      "\u001b[2m01:08:43.336462 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'rev_label_map/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.336518 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.336582 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.336634 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.336687 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.336737 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.09281241...sor_chair': 99, 'wrench': 100, 'yin_yang': 101}\"}\u001b[0m\n",
      "\u001b[2m01:08:43.336788 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'num_classes/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.336851 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.336919 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.337028 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.337144 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.337247 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.09281241...h': 100, 'yin_yang': 101}\", 'num_classes': '102'}\u001b[0m\n",
      "\u001b[2m01:08:43.337344 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'dataset_sizes/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.337453 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.337547 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.337613 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.337674 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.337733 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.09281241... 'dataset_sizes': \"{'train': 4573, 'val': 4572}\"}\u001b[0m\n",
      "\u001b[2m01:08:43.337792 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'criterion/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.337855 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.337926 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.337986 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.338046 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.338104 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.09281241...'val': 4572}\", 'criterion': 'CrossEntropyLoss()'}\u001b[0m\n",
      "\u001b[2m01:08:43.338162 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'save_path/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.338225 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.338294 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.338354 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.338438 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.338497 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.09281241...rc/runs/baseline_run_27032023_105652/checkpoint'}\u001b[0m\n",
      "\u001b[2m01:08:43.338556 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'final_acc/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.338620 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.338690 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.338749 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.338808 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.338866 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.09281241...2/checkpoint', 'final_acc': '32.874015748031496'}\u001b[0m\n",
      "\u001b[2m01:08:43.338924 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[2m01:08:43.338987 line        85\u001b[0m         if tag == \"images\" and save_ims == True:\n",
      "\u001b[2m01:08:43.339045 line        46\u001b[0m     for tag in all_tags.keys():\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtag = 'graph'\u001b[0m\n",
      "\u001b[2m01:08:43.339106 line        47\u001b[0m         if tag == \"scalars\":\n",
      "\u001b[2m01:08:43.339169 line        59\u001b[0m         if tag == \"tensors\":\n",
      "\u001b[2m01:08:43.339227 line        85\u001b[0m         if tag == \"images\" and save_ims == True:\n",
      "\u001b[2m01:08:43.339285 line        46\u001b[0m     for tag in all_tags.keys():\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtag = 'meta_graph'\u001b[0m\n",
      "\u001b[2m01:08:43.339342 line        47\u001b[0m         if tag == \"scalars\":\n",
      "\u001b[2m01:08:43.339404 line        59\u001b[0m         if tag == \"tensors\":\n",
      "\u001b[2m01:08:43.339461 line        85\u001b[0m         if tag == \"images\" and save_ims == True:\n",
      "\u001b[2m01:08:43.339519 line        46\u001b[0m     for tag in all_tags.keys():\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtag = 'run_metadata'\u001b[0m\n",
      "\u001b[2m01:08:43.339576 line        47\u001b[0m         if tag == \"scalars\":\n",
      "\u001b[2m01:08:43.339638 line        59\u001b[0m         if tag == \"tensors\":\n",
      "\u001b[2m01:08:43.339695 line        85\u001b[0m         if tag == \"images\" and save_ims == True:\n",
      "\u001b[2m01:08:43.339751 line        46\u001b[0m     for tag in all_tags.keys():\n",
      "\u001b[2m01:08:43.339809 line        96\u001b[0m     return temp_dict\n",
      "\u001b[2m01:08:43.339867 return      96\u001b[0m     return temp_dict\n",
      "\u001b[36m\u001b[2mReturn value:.. \u001b[22m{'proxy_step': 'False', 'Loss/Train': 0.09281241...2/checkpoint', 'final_acc': '32.874015748031496'}\u001b[0m\n",
      "\u001b[33m\u001b[2mElapsed time: \u001b[22m00:00:00.014739\u001b[0m\n",
      "runs/baseline_run_27032023_111325/events.out.tfevents.1679908406.eragon\n",
      "\u001b[32m\u001b[2mStarting var:.. \u001b[22mevent_acc = <tensorboard.backend.event_processing.event_accumulator.EventAccumulator object at 0x7f5b568ef820>\u001b[0m\n",
      "\u001b[32m\u001b[2mStarting var:.. \u001b[22msave_ims = False\u001b[0m\n",
      "\u001b[2m01:08:43.348562 call        42\u001b[0m def process_event_acc(event_acc, save_ims = False):\n",
      "\u001b[2m01:08:43.348659 line        44\u001b[0m     all_tags = event_acc.Tags()\n",
      "\u001b[32m\u001b[2mNew var:....... \u001b[22mall_tags = {'images': [], 'audio': [], 'histograms': [], 's...: False, 'meta_graph': False, 'run_metadata': []}\u001b[0m\n",
      "\u001b[2m01:08:43.348708 line        45\u001b[0m     temp_dict = {}\n",
      "\u001b[32m\u001b[2mNew var:....... \u001b[22mtemp_dict = {}\u001b[0m\n",
      "\u001b[2m01:08:43.348753 line        46\u001b[0m     for tag in all_tags.keys():\n",
      "\u001b[32m\u001b[2mNew var:....... \u001b[22mtag = 'images'\u001b[0m\n",
      "\u001b[2m01:08:43.348792 line        47\u001b[0m         if tag == \"scalars\":\n",
      "\u001b[2m01:08:43.348830 line        59\u001b[0m         if tag == \"tensors\":\n",
      "\u001b[2m01:08:43.348861 line        85\u001b[0m         if tag == \"images\" and save_ims == True:\n",
      "\u001b[2m01:08:43.348890 line        46\u001b[0m     for tag in all_tags.keys():\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtag = 'audio'\u001b[0m\n",
      "\u001b[2m01:08:43.348918 line        47\u001b[0m         if tag == \"scalars\":\n",
      "\u001b[2m01:08:43.348952 line        59\u001b[0m         if tag == \"tensors\":\n",
      "\u001b[2m01:08:43.348980 line        85\u001b[0m         if tag == \"images\" and save_ims == True:\n",
      "\u001b[2m01:08:43.349008 line        46\u001b[0m     for tag in all_tags.keys():\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtag = 'histograms'\u001b[0m\n",
      "\u001b[2m01:08:43.349035 line        47\u001b[0m         if tag == \"scalars\":\n",
      "\u001b[2m01:08:43.349068 line        59\u001b[0m         if tag == \"tensors\":\n",
      "\u001b[2m01:08:43.349100 line        85\u001b[0m         if tag == \"images\" and save_ims == True:\n",
      "\u001b[2m01:08:43.349129 line        46\u001b[0m     for tag in all_tags.keys():\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtag = 'scalars'\u001b[0m\n",
      "\u001b[2m01:08:43.349156 line        47\u001b[0m         if tag == \"scalars\":\n",
      "\u001b[2m01:08:43.349188 line        48\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mNew var:....... \u001b[22msubtag = 'proxy_step'\u001b[0m\n",
      "\u001b[2m01:08:43.349215 line        50\u001b[0m                 try:\n",
      "\u001b[2m01:08:43.349250 line        51\u001b[0m                     temp_dict[subtag] = [tag[-1] for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.349290 exception   51\u001b[0m                     temp_dict[subtag] = [tag[-1] for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[31mException:..... \u001b[1mTypeError: 'ScalarEvent' object is not subscriptable\u001b[0m\n",
      "\u001b[2m01:08:43.349398 line        54\u001b[0m                 except:\n",
      "\u001b[2m01:08:43.349432 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.349473 line        56\u001b[0m                     -1\n",
      "\u001b[2m01:08:43.349505 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.349536 line        57\u001b[0m                 ].value\n",
      "\u001b[2m01:08:43.349565 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0}\u001b[0m\n",
      "\u001b[2m01:08:43.349595 line        48\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'Loss/Train'\u001b[0m\n",
      "\u001b[2m01:08:43.349631 line        50\u001b[0m                 try:\n",
      "\u001b[2m01:08:43.349666 line        51\u001b[0m                     temp_dict[subtag] = [tag[-1] for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.349703 exception   51\u001b[0m                     temp_dict[subtag] = [tag[-1] for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[31mException:..... \u001b[1mTypeError: 'ScalarEvent' object is not subscriptable\u001b[0m\n",
      "\u001b[2m01:08:43.349753 line        54\u001b[0m                 except:\n",
      "\u001b[2m01:08:43.349785 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.349823 line        56\u001b[0m                     -1\n",
      "\u001b[2m01:08:43.349853 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.349882 line        57\u001b[0m                 ].value\n",
      "\u001b[2m01:08:43.349912 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 0.08245135098695755}\u001b[0m\n",
      "\u001b[2m01:08:43.349941 line        48\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'Acc/Train'\u001b[0m\n",
      "\u001b[2m01:08:43.349978 line        50\u001b[0m                 try:\n",
      "\u001b[2m01:08:43.350013 line        51\u001b[0m                     temp_dict[subtag] = [tag[-1] for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.350050 exception   51\u001b[0m                     temp_dict[subtag] = [tag[-1] for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[31mException:..... \u001b[1mTypeError: 'ScalarEvent' object is not subscriptable\u001b[0m\n",
      "\u001b[2m01:08:43.350099 line        54\u001b[0m                 except:\n",
      "\u001b[2m01:08:43.350132 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.350181 line        56\u001b[0m                     -1\n",
      "\u001b[2m01:08:43.350217 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.350251 line        57\u001b[0m                 ].value\n",
      "\u001b[2m01:08:43.350282 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 0.08245135098695755, 'Acc/Train': 14.65999984741211}\u001b[0m\n",
      "\u001b[2m01:08:43.350312 line        48\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'global_run_count'\u001b[0m\n",
      "\u001b[2m01:08:43.350349 line        50\u001b[0m                 try:\n",
      "\u001b[2m01:08:43.350396 line        51\u001b[0m                     temp_dict[subtag] = [tag[-1] for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.350439 exception   51\u001b[0m                     temp_dict[subtag] = [tag[-1] for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[31mException:..... \u001b[1mTypeError: 'ScalarEvent' object is not subscriptable\u001b[0m\n",
      "\u001b[2m01:08:43.350490 line        54\u001b[0m                 except:\n",
      "\u001b[2m01:08:43.350524 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.350565 line        56\u001b[0m                     -1\n",
      "\u001b[2m01:08:43.350597 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.350628 line        57\u001b[0m                 ].value\n",
      "\u001b[2m01:08:43.350659 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 0.082451350986...in': 14.65999984741211, 'global_run_count': 20.0}\u001b[0m\n",
      "\u001b[2m01:08:43.350692 line        48\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'Loss/Val'\u001b[0m\n",
      "\u001b[2m01:08:43.350731 line        50\u001b[0m                 try:\n",
      "\u001b[2m01:08:43.350768 line        51\u001b[0m                     temp_dict[subtag] = [tag[-1] for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.350806 exception   51\u001b[0m                     temp_dict[subtag] = [tag[-1] for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[31mException:..... \u001b[1mTypeError: 'ScalarEvent' object is not subscriptable\u001b[0m\n",
      "\u001b[2m01:08:43.350859 line        54\u001b[0m                 except:\n",
      "\u001b[2m01:08:43.350894 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.350934 line        56\u001b[0m                     -1\n",
      "\u001b[2m01:08:43.350968 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.351000 line        57\u001b[0m                 ].value\n",
      "\u001b[2m01:08:43.351032 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 0.082451350986...un_count': 20.0, 'Loss/Val': 0.08221613615751266}\u001b[0m\n",
      "\u001b[2m01:08:43.351064 line        48\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'Acc/Val'\u001b[0m\n",
      "\u001b[2m01:08:43.351102 line        50\u001b[0m                 try:\n",
      "\u001b[2m01:08:43.351139 line        51\u001b[0m                     temp_dict[subtag] = [tag[-1] for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.351178 exception   51\u001b[0m                     temp_dict[subtag] = [tag[-1] for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[31mException:..... \u001b[1mTypeError: 'ScalarEvent' object is not subscriptable\u001b[0m\n",
      "\u001b[2m01:08:43.351231 line        54\u001b[0m                 except:\n",
      "\u001b[2m01:08:43.351277 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.351319 line        56\u001b[0m                     -1\n",
      "\u001b[2m01:08:43.351353 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.351386 line        57\u001b[0m                 ].value\n",
      "\u001b[2m01:08:43.351419 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 0.082451350986....08221613615751266, 'Acc/Val': 14.09000015258789}\u001b[0m\n",
      "\u001b[2m01:08:43.351451 line        48\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[2m01:08:43.351490 line        59\u001b[0m         if tag == \"tensors\":\n",
      "\u001b[2m01:08:43.351522 line        85\u001b[0m         if tag == \"images\" and save_ims == True:\n",
      "\u001b[2m01:08:43.351555 line        46\u001b[0m     for tag in all_tags.keys():\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtag = 'distributions'\u001b[0m\n",
      "\u001b[2m01:08:43.351587 line        47\u001b[0m         if tag == \"scalars\":\n",
      "\u001b[2m01:08:43.351625 line        59\u001b[0m         if tag == \"tensors\":\n",
      "\u001b[2m01:08:43.351658 line        85\u001b[0m         if tag == \"images\" and save_ims == True:\n",
      "\u001b[2m01:08:43.351690 line        46\u001b[0m     for tag in all_tags.keys():\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtag = 'tensors'\u001b[0m\n",
      "\u001b[2m01:08:43.351722 line        47\u001b[0m         if tag == \"scalars\":\n",
      "\u001b[2m01:08:43.351757 line        59\u001b[0m         if tag == \"tensors\":\n",
      "\u001b[2m01:08:43.351790 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'experiment_name/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.351822 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.351869 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.351907 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.351947 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.351981 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 0.082451350986...9000015258789, 'experiment_name': 'baseline_run'}\u001b[0m\n",
      "\u001b[2m01:08:43.352016 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'image_size/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.352058 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.352104 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.352139 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.352175 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.352209 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 0.082451350986...iment_name': 'baseline_run', 'image_size': '224'}\u001b[0m\n",
      "\u001b[2m01:08:43.352242 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'batch_size/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.352282 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.352327 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.352372 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.352412 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.352447 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 0.082451350986...ne_run', 'image_size': '224', 'batch_size': '32'}\u001b[0m\n",
      "\u001b[2m01:08:43.352480 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'enable_proxy_attention/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.352519 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.352567 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.352613 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.352650 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.352684 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 0.082451350986...ch_size': '32', 'enable_proxy_attention': 'True'}\u001b[0m\n",
      "\u001b[2m01:08:43.352719 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'transfer_imagenet/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.352758 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.352803 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.352838 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.352876 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.352910 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 0.082451350986..._attention': 'True', 'transfer_imagenet': 'True'}\u001b[0m\n",
      "\u001b[2m01:08:43.352944 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'subset_images/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.352983 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.353027 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.353063 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.353099 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.353134 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 0.082451350986...sfer_imagenet': 'True', 'subset_images': '20000'}\u001b[0m\n",
      "\u001b[2m01:08:43.353168 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'pixel_replacement_method/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.353207 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.353255 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.353292 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.353326 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.353360 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 0.082451350986...: '20000', 'pixel_replacement_method': 'blended'}\u001b[0m\n",
      "\u001b[2m01:08:43.353394 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'proxy_steps/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.353433 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.353478 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.353513 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.353548 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.353583 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 0.082451350986...cement_method': 'blended', 'proxy_steps': '[20]'}\u001b[0m\n",
      "\u001b[2m01:08:43.353618 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'load_proxy_data/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.353659 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.353705 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.353756 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.353793 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.353828 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 0.082451350986...proxy_steps': '[20]', 'load_proxy_data': 'False'}\u001b[0m\n",
      "\u001b[2m01:08:43.353869 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'proxy_step/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.353912 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.353958 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.353994 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.354029 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.354063 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.08245135...proxy_steps': '[20]', 'load_proxy_data': 'False'}\u001b[0m\n",
      "\u001b[2m01:08:43.354096 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'log_every/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.354142 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.354194 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.354233 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.354272 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.354310 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.08245135...]', 'load_proxy_data': 'False', 'log_every': '2'}\u001b[0m\n",
      "\u001b[2m01:08:43.354347 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'device/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.354392 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.354443 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.354482 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.354521 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.354559 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.08245135...': 'False', 'log_every': '2', 'device': 'cuda:0'}\u001b[0m\n",
      "\u001b[2m01:08:43.354597 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'dataset_info/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.354645 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.354697 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.354738 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.354778 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.354817 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.08245135...t_name at 0x7fdf047a3a30>, 'num_classes': 101}}\"}\u001b[0m\n",
      "\u001b[2m01:08:43.354856 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'main_run_dir/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.354909 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.354972 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.355017 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.355063 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.355108 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.08245135...DE/Github/improving_robotics_datasets/src/runs/'}\u001b[0m\n",
      "\u001b[2m01:08:43.355194 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'change_subset_attention/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.355245 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.355303 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.355348 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.355430 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.355474 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.08245135...ets/src/runs/', 'change_subset_attention': '0.8'}\u001b[0m\n",
      "\u001b[2m01:08:43.355518 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'model/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.355569 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.355629 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.355675 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.355720 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.355765 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.08245135...tention': '0.8', 'model': 'vit_base_patch16_224'}\u001b[0m\n",
      "\u001b[2m01:08:43.355810 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'proxy_image_weight/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.355867 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.355922 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.355983 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.356044 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.356122 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.08245135...t_base_patch16_224', 'proxy_image_weight': '0.1'}\u001b[0m\n",
      "\u001b[2m01:08:43.356181 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'proxy_threshold/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.356225 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.356304 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.356365 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.356406 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.356446 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.08245135..._image_weight': '0.1', 'proxy_threshold': '0.85'}\u001b[0m\n",
      "\u001b[2m01:08:43.356487 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'gradient_method/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.356538 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.356594 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.356639 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.356683 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.356727 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.08245135...d': '0.85', 'gradient_method': 'gradcamplusplus'}\u001b[0m\n",
      "\u001b[2m01:08:43.356781 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'ds_name/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.356833 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.356909 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.356955 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.357000 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.357083 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.08245135...ent_method': 'gradcamplusplus', 'ds_name': 'asl'}\u001b[0m\n",
      "\u001b[2m01:08:43.357133 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'clear_every_step/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.357186 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.357245 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.357291 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.357339 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.357384 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.08245135...s', 'ds_name': 'asl', 'clear_every_step': 'True'}\u001b[0m\n",
      "\u001b[2m01:08:43.357447 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'fname_start/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.357497 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.357554 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.357599 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.357643 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.357686 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.08245135..._datasets/src/runs/baseline_run_27032023_111325'}\u001b[0m\n",
      "\u001b[2m01:08:43.357730 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'ds_path/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.357781 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.357875 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.357959 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.358003 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.358066 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.08245135...asets/asl/asl_alphabet_train/asl_alphabet_train'}\u001b[0m\n",
      "\u001b[2m01:08:43.358128 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'name_fn/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.358198 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.358293 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.358339 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.358385 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.358432 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.08245135...: '<function get_parent_name at 0x7fdf047a3a30>'}\u001b[0m\n",
      "\u001b[2m01:08:43.358478 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'global_run_count/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.358530 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.358588 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.358635 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.358682 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.358727 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[2m01:08:43.358772 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'writer/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.358817 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.358875 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.358920 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.358966 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.359012 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.08245135....writer.SummaryWriter object at 0x7fdef5977550>'}\u001b[0m\n",
      "\u001b[2m01:08:43.359065 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'label_map/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.359119 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.359187 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.359235 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.359283 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.359330 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.08245135...P', 16: 'Q', 17: 'U', 18: 'del', 19: 'nothing'}\"}\u001b[0m\n",
      "\u001b[2m01:08:43.359376 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'rev_label_map/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.359466 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.359545 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.359592 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.359664 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.359756 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.08245135...15, 'Q': 16, 'U': 17, 'del': 18, 'nothing': 19}\"}\u001b[0m\n",
      "\u001b[2m01:08:43.359822 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'num_classes/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.359900 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.359963 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.360012 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.360078 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.360125 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.08245135... 'del': 18, 'nothing': 19}\", 'num_classes': '20'}\u001b[0m\n",
      "\u001b[2m01:08:43.360191 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'dataset_sizes/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.360282 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.360347 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.360411 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.360487 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.360532 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.08245135...dataset_sizes': \"{'train': 10000, 'val': 10000}\"}\u001b[0m\n",
      "\u001b[2m01:08:43.360575 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'criterion/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.360625 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.360681 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.360727 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.360772 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.360815 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.08245135...val': 10000}\", 'criterion': 'CrossEntropyLoss()'}\u001b[0m\n",
      "\u001b[2m01:08:43.360859 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'save_path/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.360910 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.361019 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.361067 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.361113 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.361157 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.08245135...rc/runs/baseline_run_27032023_111325/checkpoint'}\u001b[0m\n",
      "\u001b[2m01:08:43.361201 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'final_acc/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.361249 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.361304 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.361351 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.361396 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.361440 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.08245135...7032023_111325/checkpoint', 'final_acc': '14.09'}\u001b[0m\n",
      "\u001b[2m01:08:43.361484 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[2m01:08:43.361534 line        85\u001b[0m         if tag == \"images\" and save_ims == True:\n",
      "\u001b[2m01:08:43.361579 line        46\u001b[0m     for tag in all_tags.keys():\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtag = 'graph'\u001b[0m\n",
      "\u001b[2m01:08:43.361623 line        47\u001b[0m         if tag == \"scalars\":\n",
      "\u001b[2m01:08:43.361673 line        59\u001b[0m         if tag == \"tensors\":\n",
      "\u001b[2m01:08:43.361718 line        85\u001b[0m         if tag == \"images\" and save_ims == True:\n",
      "\u001b[2m01:08:43.361762 line        46\u001b[0m     for tag in all_tags.keys():\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtag = 'meta_graph'\u001b[0m\n",
      "\u001b[2m01:08:43.361804 line        47\u001b[0m         if tag == \"scalars\":\n",
      "\u001b[2m01:08:43.361852 line        59\u001b[0m         if tag == \"tensors\":\n",
      "\u001b[2m01:08:43.361895 line        85\u001b[0m         if tag == \"images\" and save_ims == True:\n",
      "\u001b[2m01:08:43.361939 line        46\u001b[0m     for tag in all_tags.keys():\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtag = 'run_metadata'\u001b[0m\n",
      "\u001b[2m01:08:43.361982 line        47\u001b[0m         if tag == \"scalars\":\n",
      "\u001b[2m01:08:43.362030 line        59\u001b[0m         if tag == \"tensors\":\n",
      "\u001b[2m01:08:43.362092 line        85\u001b[0m         if tag == \"images\" and save_ims == True:\n",
      "\u001b[2m01:08:43.362157 line        46\u001b[0m     for tag in all_tags.keys():\n",
      "\u001b[2m01:08:43.362225 line        96\u001b[0m     return temp_dict\n",
      "\u001b[2m01:08:43.362292 return      96\u001b[0m     return temp_dict\n",
      "\u001b[36m\u001b[2mReturn value:.. \u001b[22m{'proxy_step': 'False', 'Loss/Train': 0.08245135...7032023_111325/checkpoint', 'final_acc': '14.09'}\u001b[0m\n",
      "\u001b[33m\u001b[2mElapsed time: \u001b[22m00:00:00.013833\u001b[0m\n",
      "runs/baseline_run_27032023_114723/events.out.tfevents.1679910444.eragon\n",
      "\u001b[32m\u001b[2mStarting var:.. \u001b[22mevent_acc = <tensorboard.backend.event_processing.event_accumulator.EventAccumulator object at 0x7f5b568edf60>\u001b[0m\n",
      "\u001b[32m\u001b[2mStarting var:.. \u001b[22msave_ims = False\u001b[0m\n",
      "\u001b[2m01:08:43.370173 call        42\u001b[0m def process_event_acc(event_acc, save_ims = False):\n",
      "\u001b[2m01:08:43.370251 line        44\u001b[0m     all_tags = event_acc.Tags()\n",
      "\u001b[32m\u001b[2mNew var:....... \u001b[22mall_tags = {'images': [], 'audio': [], 'histograms': [], 's...: False, 'meta_graph': False, 'run_metadata': []}\u001b[0m\n",
      "\u001b[2m01:08:43.370297 line        45\u001b[0m     temp_dict = {}\n",
      "\u001b[32m\u001b[2mNew var:....... \u001b[22mtemp_dict = {}\u001b[0m\n",
      "\u001b[2m01:08:43.370375 line        46\u001b[0m     for tag in all_tags.keys():\n",
      "\u001b[32m\u001b[2mNew var:....... \u001b[22mtag = 'images'\u001b[0m\n",
      "\u001b[2m01:08:43.370455 line        47\u001b[0m         if tag == \"scalars\":\n",
      "\u001b[2m01:08:43.370498 line        59\u001b[0m         if tag == \"tensors\":\n",
      "\u001b[2m01:08:43.370531 line        85\u001b[0m         if tag == \"images\" and save_ims == True:\n",
      "\u001b[2m01:08:43.370564 line        46\u001b[0m     for tag in all_tags.keys():\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtag = 'audio'\u001b[0m\n",
      "\u001b[2m01:08:43.370594 line        47\u001b[0m         if tag == \"scalars\":\n",
      "\u001b[2m01:08:43.370632 line        59\u001b[0m         if tag == \"tensors\":\n",
      "\u001b[2m01:08:43.370663 line        85\u001b[0m         if tag == \"images\" and save_ims == True:\n",
      "\u001b[2m01:08:43.370702 line        46\u001b[0m     for tag in all_tags.keys():\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtag = 'histograms'\u001b[0m\n",
      "\u001b[2m01:08:43.370732 line        47\u001b[0m         if tag == \"scalars\":\n",
      "\u001b[2m01:08:43.370765 line        59\u001b[0m         if tag == \"tensors\":\n",
      "\u001b[2m01:08:43.370793 line        85\u001b[0m         if tag == \"images\" and save_ims == True:\n",
      "\u001b[2m01:08:43.370849 line        46\u001b[0m     for tag in all_tags.keys():\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtag = 'scalars'\u001b[0m\n",
      "\u001b[2m01:08:43.370895 line        47\u001b[0m         if tag == \"scalars\":\n",
      "\u001b[2m01:08:43.370927 line        48\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mNew var:....... \u001b[22msubtag = 'proxy_step'\u001b[0m\n",
      "\u001b[2m01:08:43.370954 line        50\u001b[0m                 try:\n",
      "\u001b[2m01:08:43.370989 line        51\u001b[0m                     temp_dict[subtag] = [tag[-1] for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.371029 exception   51\u001b[0m                     temp_dict[subtag] = [tag[-1] for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[31mException:..... \u001b[1mTypeError: 'ScalarEvent' object is not subscriptable\u001b[0m\n",
      "\u001b[2m01:08:43.371142 line        54\u001b[0m                 except:\n",
      "\u001b[2m01:08:43.371176 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.371215 line        56\u001b[0m                     -1\n",
      "\u001b[2m01:08:43.371245 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.371274 line        57\u001b[0m                 ].value\n",
      "\u001b[2m01:08:43.371303 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0}\u001b[0m\n",
      "\u001b[2m01:08:43.371332 line        48\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'Loss/Train'\u001b[0m\n",
      "\u001b[2m01:08:43.371367 line        50\u001b[0m                 try:\n",
      "\u001b[2m01:08:43.371401 line        51\u001b[0m                     temp_dict[subtag] = [tag[-1] for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.371436 exception   51\u001b[0m                     temp_dict[subtag] = [tag[-1] for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[31mException:..... \u001b[1mTypeError: 'ScalarEvent' object is not subscriptable\u001b[0m\n",
      "\u001b[2m01:08:43.371486 line        54\u001b[0m                 except:\n",
      "\u001b[2m01:08:43.371521 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.371558 line        56\u001b[0m                     -1\n",
      "\u001b[2m01:08:43.371588 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.371617 line        57\u001b[0m                 ].value\n",
      "\u001b[2m01:08:43.371646 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 0.05942106246948242}\u001b[0m\n",
      "\u001b[2m01:08:43.371675 line        48\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'Acc/Train'\u001b[0m\n",
      "\u001b[2m01:08:43.371711 line        50\u001b[0m                 try:\n",
      "\u001b[2m01:08:43.371746 line        51\u001b[0m                     temp_dict[subtag] = [tag[-1] for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.371791 exception   51\u001b[0m                     temp_dict[subtag] = [tag[-1] for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[31mException:..... \u001b[1mTypeError: 'ScalarEvent' object is not subscriptable\u001b[0m\n",
      "\u001b[2m01:08:43.371841 line        54\u001b[0m                 except:\n",
      "\u001b[2m01:08:43.371874 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.371911 line        56\u001b[0m                     -1\n",
      "\u001b[2m01:08:43.371942 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.371972 line        57\u001b[0m                 ].value\n",
      "\u001b[2m01:08:43.372001 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 0.05942106246948242, 'Acc/Train': 34.76240921020508}\u001b[0m\n",
      "\u001b[2m01:08:43.372031 line        48\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'global_run_count'\u001b[0m\n",
      "\u001b[2m01:08:43.372067 line        50\u001b[0m                 try:\n",
      "\u001b[2m01:08:43.372102 line        51\u001b[0m                     temp_dict[subtag] = [tag[-1] for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.372138 exception   51\u001b[0m                     temp_dict[subtag] = [tag[-1] for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[31mException:..... \u001b[1mTypeError: 'ScalarEvent' object is not subscriptable\u001b[0m\n",
      "\u001b[2m01:08:43.372188 line        54\u001b[0m                 except:\n",
      "\u001b[2m01:08:43.372221 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.372264 line        56\u001b[0m                     -1\n",
      "\u001b[2m01:08:43.372297 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.372331 line        57\u001b[0m                 ].value\n",
      "\u001b[2m01:08:43.372363 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 0.059421062469...in': 34.76240921020508, 'global_run_count': 20.0}\u001b[0m\n",
      "\u001b[2m01:08:43.372394 line        48\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'Loss/Val'\u001b[0m\n",
      "\u001b[2m01:08:43.372431 line        50\u001b[0m                 try:\n",
      "\u001b[2m01:08:43.372466 line        51\u001b[0m                     temp_dict[subtag] = [tag[-1] for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.372504 exception   51\u001b[0m                     temp_dict[subtag] = [tag[-1] for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[31mException:..... \u001b[1mTypeError: 'ScalarEvent' object is not subscriptable\u001b[0m\n",
      "\u001b[2m01:08:43.372555 line        54\u001b[0m                 except:\n",
      "\u001b[2m01:08:43.372588 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.372627 line        56\u001b[0m                     -1\n",
      "\u001b[2m01:08:43.372658 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.372690 line        57\u001b[0m                 ].value\n",
      "\u001b[2m01:08:43.372720 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 0.059421062469...un_count': 20.0, 'Loss/Val': 0.05685579031705856}\u001b[0m\n",
      "\u001b[2m01:08:43.372751 line        48\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'Acc/Val'\u001b[0m\n",
      "\u001b[2m01:08:43.372788 line        50\u001b[0m                 try:\n",
      "\u001b[2m01:08:43.372826 line        51\u001b[0m                     temp_dict[subtag] = [tag[-1] for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.372864 exception   51\u001b[0m                     temp_dict[subtag] = [tag[-1] for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[31mException:..... \u001b[1mTypeError: 'ScalarEvent' object is not subscriptable\u001b[0m\n",
      "\u001b[2m01:08:43.372916 line        54\u001b[0m                 except:\n",
      "\u001b[2m01:08:43.372950 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.372990 line        56\u001b[0m                     -1\n",
      "\u001b[2m01:08:43.373023 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.373055 line        57\u001b[0m                 ].value\n",
      "\u001b[2m01:08:43.373087 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 0.059421062469....05685579031705856, 'Acc/Val': 39.54372787475586}\u001b[0m\n",
      "\u001b[2m01:08:43.373119 line        48\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[2m01:08:43.373157 line        59\u001b[0m         if tag == \"tensors\":\n",
      "\u001b[2m01:08:43.373189 line        85\u001b[0m         if tag == \"images\" and save_ims == True:\n",
      "\u001b[2m01:08:43.373221 line        46\u001b[0m     for tag in all_tags.keys():\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtag = 'distributions'\u001b[0m\n",
      "\u001b[2m01:08:43.373253 line        47\u001b[0m         if tag == \"scalars\":\n",
      "\u001b[2m01:08:43.373290 line        59\u001b[0m         if tag == \"tensors\":\n",
      "\u001b[2m01:08:43.373322 line        85\u001b[0m         if tag == \"images\" and save_ims == True:\n",
      "\u001b[2m01:08:43.373353 line        46\u001b[0m     for tag in all_tags.keys():\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtag = 'tensors'\u001b[0m\n",
      "\u001b[2m01:08:43.373385 line        47\u001b[0m         if tag == \"scalars\":\n",
      "\u001b[2m01:08:43.373422 line        59\u001b[0m         if tag == \"tensors\":\n",
      "\u001b[2m01:08:43.373460 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'experiment_name/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.373491 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.373536 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.373574 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.373610 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.373643 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 0.059421062469...4372787475586, 'experiment_name': 'baseline_run'}\u001b[0m\n",
      "\u001b[2m01:08:43.373699 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'image_size/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.373770 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.373816 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.373851 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.373885 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.373917 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 0.059421062469...iment_name': 'baseline_run', 'image_size': '224'}\u001b[0m\n",
      "\u001b[2m01:08:43.373950 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'batch_size/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.373987 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.374031 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.374065 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.374098 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.374130 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 0.059421062469...ne_run', 'image_size': '224', 'batch_size': '32'}\u001b[0m\n",
      "\u001b[2m01:08:43.374163 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'enable_proxy_attention/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.374200 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.374243 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.374278 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.374311 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.374344 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 0.059421062469...ch_size': '32', 'enable_proxy_attention': 'True'}\u001b[0m\n",
      "\u001b[2m01:08:43.374377 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'transfer_imagenet/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.374414 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.374458 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.374492 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.374525 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.374557 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 0.059421062469..._attention': 'True', 'transfer_imagenet': 'True'}\u001b[0m\n",
      "\u001b[2m01:08:43.374590 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'subset_images/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.374628 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.374671 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.374705 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.374738 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.374771 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 0.059421062469...sfer_imagenet': 'True', 'subset_images': '20000'}\u001b[0m\n",
      "\u001b[2m01:08:43.374803 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'pixel_replacement_method/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.374840 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.374883 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.374917 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.374950 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.374982 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 0.059421062469...: '20000', 'pixel_replacement_method': 'blended'}\u001b[0m\n",
      "\u001b[2m01:08:43.375015 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'proxy_steps/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.375052 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.375094 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.375128 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.375161 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.375194 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 0.059421062469...cement_method': 'blended', 'proxy_steps': '[20]'}\u001b[0m\n",
      "\u001b[2m01:08:43.375227 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'load_proxy_data/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.375264 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.375307 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.375341 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.375374 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.375407 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 0.059421062469...proxy_steps': '[20]', 'load_proxy_data': 'False'}\u001b[0m\n",
      "\u001b[2m01:08:43.375440 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'proxy_step/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.375477 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.375520 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.375554 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.375588 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.375626 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.05942106...proxy_steps': '[20]', 'load_proxy_data': 'False'}\u001b[0m\n",
      "\u001b[2m01:08:43.375665 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'log_every/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.375712 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.375759 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.375794 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.375829 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.375862 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.05942106...]', 'load_proxy_data': 'False', 'log_every': '2'}\u001b[0m\n",
      "\u001b[2m01:08:43.375895 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'device/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.375932 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.375975 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.376010 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.376044 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.376076 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.05942106...': 'False', 'log_every': '2', 'device': 'cuda:0'}\u001b[0m\n",
      "\u001b[2m01:08:43.376109 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'dataset_info/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.376147 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.376190 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.376225 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.376261 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.376295 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.05942106...t_name at 0x7f78e21cba30>, 'num_classes': 101}}\"}\u001b[0m\n",
      "\u001b[2m01:08:43.376328 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'main_run_dir/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.376372 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.376420 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.376460 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.376499 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.376538 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.05942106...DE/Github/improving_robotics_datasets/src/runs/'}\u001b[0m\n",
      "\u001b[2m01:08:43.376576 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'change_subset_attention/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.376619 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.376668 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.376708 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.376748 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.376791 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.05942106...ets/src/runs/', 'change_subset_attention': '0.8'}\u001b[0m\n",
      "\u001b[2m01:08:43.376834 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'model/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.376877 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.376927 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.376968 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.377032 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.377117 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.05942106...tention': '0.8', 'model': 'vit_base_patch16_224'}\u001b[0m\n",
      "\u001b[2m01:08:43.377161 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'proxy_image_weight/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.377206 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.377256 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.377297 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.377337 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.377375 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.05942106...t_base_patch16_224', 'proxy_image_weight': '0.1'}\u001b[0m\n",
      "\u001b[2m01:08:43.377414 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'proxy_threshold/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.377458 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.377508 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.377549 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.377589 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.377639 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.05942106..._image_weight': '0.1', 'proxy_threshold': '0.85'}\u001b[0m\n",
      "\u001b[2m01:08:43.377679 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'gradient_method/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.377726 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.377776 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.377817 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.377857 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.377896 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.05942106...d': '0.85', 'gradient_method': 'gradcamplusplus'}\u001b[0m\n",
      "\u001b[2m01:08:43.377937 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'ds_name/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.377998 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.378056 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.378100 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.378144 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.378187 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.05942106...hod': 'gradcamplusplus', 'ds_name': 'imagenette'}\u001b[0m\n",
      "\u001b[2m01:08:43.378232 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'clear_every_step/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.378330 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.378387 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.378431 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.378474 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.378517 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.05942106..._name': 'imagenette', 'clear_every_step': 'True'}\u001b[0m\n",
      "\u001b[2m01:08:43.378561 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'fname_start/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.378610 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.378666 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.378711 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.378755 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.378798 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.05942106..._datasets/src/runs/baseline_run_27032023_114723'}\u001b[0m\n",
      "\u001b[2m01:08:43.378842 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'ds_path/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.378893 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.378955 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.379002 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.379048 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.379092 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.05942106...media/eragon/HDD/Datasets/imagenette2-320/train'}\u001b[0m\n",
      "\u001b[2m01:08:43.379187 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'name_fn/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.379237 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.379293 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.379338 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.379383 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.379426 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.05942106...: '<function get_parent_name at 0x7f78e21cba30>'}\u001b[0m\n",
      "\u001b[2m01:08:43.379471 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'global_run_count/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.379521 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.379578 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.379623 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.379691 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.379777 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[2m01:08:43.379823 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'writer/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.379867 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.379925 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.379971 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.380033 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.380076 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.05942106....writer.SummaryWriter object at 0x7f78d3392e90>'}\u001b[0m\n",
      "\u001b[2m01:08:43.380120 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'label_map/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.380193 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.380259 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.380305 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.380351 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.380407 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.05942106...7: 'n03425413', 8: 'n03445777', 9: 'n03888257'}\"}\u001b[0m\n",
      "\u001b[2m01:08:43.380467 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'rev_label_map/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.380513 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.380565 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.380608 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.380650 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.380691 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.05942106...'n03425413': 7, 'n03445777': 8, 'n03888257': 9}\"}\u001b[0m\n",
      "\u001b[2m01:08:43.380734 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'num_classes/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.380782 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.380877 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.380921 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.380964 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.381007 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.05942106...45777': 8, 'n03888257': 9}\", 'num_classes': '10'}\u001b[0m\n",
      "\u001b[2m01:08:43.381049 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'dataset_sizes/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.381096 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.381150 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.381193 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.381237 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.381279 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.05942106... 'dataset_sizes': \"{'train': 4735, 'val': 4734}\"}\u001b[0m\n",
      "\u001b[2m01:08:43.381321 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'criterion/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.381369 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.381423 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.381467 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.381509 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.381552 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.05942106...'val': 4734}\", 'criterion': 'CrossEntropyLoss()'}\u001b[0m\n",
      "\u001b[2m01:08:43.381595 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'save_path/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.381642 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.381694 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.381737 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.381790 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.381833 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.05942106...rc/runs/baseline_run_27032023_114723/checkpoint'}\u001b[0m\n",
      "\u001b[2m01:08:43.381875 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'final_acc/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.381923 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.381977 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.382022 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.382066 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.382108 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.05942106...3/checkpoint', 'final_acc': '39.543726235741445'}\u001b[0m\n",
      "\u001b[2m01:08:43.382152 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[2m01:08:43.382199 line        85\u001b[0m         if tag == \"images\" and save_ims == True:\n",
      "\u001b[2m01:08:43.382242 line        46\u001b[0m     for tag in all_tags.keys():\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtag = 'graph'\u001b[0m\n",
      "\u001b[2m01:08:43.382284 line        47\u001b[0m         if tag == \"scalars\":\n",
      "\u001b[2m01:08:43.382332 line        59\u001b[0m         if tag == \"tensors\":\n",
      "\u001b[2m01:08:43.382374 line        85\u001b[0m         if tag == \"images\" and save_ims == True:\n",
      "\u001b[2m01:08:43.382416 line        46\u001b[0m     for tag in all_tags.keys():\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtag = 'meta_graph'\u001b[0m\n",
      "\u001b[2m01:08:43.382458 line        47\u001b[0m         if tag == \"scalars\":\n",
      "\u001b[2m01:08:43.382504 line        59\u001b[0m         if tag == \"tensors\":\n",
      "\u001b[2m01:08:43.382547 line        85\u001b[0m         if tag == \"images\" and save_ims == True:\n",
      "\u001b[2m01:08:43.382627 line        46\u001b[0m     for tag in all_tags.keys():\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtag = 'run_metadata'\u001b[0m\n",
      "\u001b[2m01:08:43.382706 line        47\u001b[0m         if tag == \"scalars\":\n",
      "\u001b[2m01:08:43.382810 line        59\u001b[0m         if tag == \"tensors\":\n",
      "\u001b[2m01:08:43.382874 line        85\u001b[0m         if tag == \"images\" and save_ims == True:\n",
      "\u001b[2m01:08:43.382921 line        46\u001b[0m     for tag in all_tags.keys():\n",
      "\u001b[2m01:08:43.382969 line        96\u001b[0m     return temp_dict\n",
      "\u001b[2m01:08:43.383016 return      96\u001b[0m     return temp_dict\n",
      "\u001b[36m\u001b[2mReturn value:.. \u001b[22m{'proxy_step': 'False', 'Loss/Train': 0.05942106...3/checkpoint', 'final_acc': '39.543726235741445'}\u001b[0m\n",
      "\u001b[33m\u001b[2mElapsed time: \u001b[22m00:00:00.012940\u001b[0m\n",
      "runs/baseline_run_27032023_122730/events.out.tfevents.1679912852.eragon\n",
      "\u001b[32m\u001b[2mStarting var:.. \u001b[22mevent_acc = <tensorboard.backend.event_processing.event_accumulator.EventAccumulator object at 0x7f5b568ef640>\u001b[0m\n",
      "\u001b[32m\u001b[2mStarting var:.. \u001b[22msave_ims = False\u001b[0m\n",
      "\u001b[2m01:08:43.391900 call        42\u001b[0m def process_event_acc(event_acc, save_ims = False):\n",
      "\u001b[2m01:08:43.391987 line        44\u001b[0m     all_tags = event_acc.Tags()\n",
      "\u001b[32m\u001b[2mNew var:....... \u001b[22mall_tags = {'images': [], 'audio': [], 'histograms': [], 's...: False, 'meta_graph': False, 'run_metadata': []}\u001b[0m\n",
      "\u001b[2m01:08:43.392038 line        45\u001b[0m     temp_dict = {}\n",
      "\u001b[32m\u001b[2mNew var:....... \u001b[22mtemp_dict = {}\u001b[0m\n",
      "\u001b[2m01:08:43.392103 line        46\u001b[0m     for tag in all_tags.keys():\n",
      "\u001b[32m\u001b[2mNew var:....... \u001b[22mtag = 'images'\u001b[0m\n",
      "\u001b[2m01:08:43.392237 line        47\u001b[0m         if tag == \"scalars\":\n",
      "\u001b[2m01:08:43.392364 line        59\u001b[0m         if tag == \"tensors\":\n",
      "\u001b[2m01:08:43.392414 line        85\u001b[0m         if tag == \"images\" and save_ims == True:\n",
      "\u001b[2m01:08:43.392471 line        46\u001b[0m     for tag in all_tags.keys():\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtag = 'audio'\u001b[0m\n",
      "\u001b[2m01:08:43.392542 line        47\u001b[0m         if tag == \"scalars\":\n",
      "\u001b[2m01:08:43.392619 line        59\u001b[0m         if tag == \"tensors\":\n",
      "\u001b[2m01:08:43.392666 line        85\u001b[0m         if tag == \"images\" and save_ims == True:\n",
      "\u001b[2m01:08:43.392718 line        46\u001b[0m     for tag in all_tags.keys():\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtag = 'histograms'\u001b[0m\n",
      "\u001b[2m01:08:43.392746 line        47\u001b[0m         if tag == \"scalars\":\n",
      "\u001b[2m01:08:43.392779 line        59\u001b[0m         if tag == \"tensors\":\n",
      "\u001b[2m01:08:43.392807 line        85\u001b[0m         if tag == \"images\" and save_ims == True:\n",
      "\u001b[2m01:08:43.392835 line        46\u001b[0m     for tag in all_tags.keys():\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtag = 'scalars'\u001b[0m\n",
      "\u001b[2m01:08:43.392863 line        47\u001b[0m         if tag == \"scalars\":\n",
      "\u001b[2m01:08:43.392895 line        48\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mNew var:....... \u001b[22msubtag = 'proxy_step'\u001b[0m\n",
      "\u001b[2m01:08:43.392924 line        50\u001b[0m                 try:\n",
      "\u001b[2m01:08:43.392959 line        51\u001b[0m                     temp_dict[subtag] = [tag[-1] for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.393003 exception   51\u001b[0m                     temp_dict[subtag] = [tag[-1] for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[31mException:..... \u001b[1mTypeError: 'ScalarEvent' object is not subscriptable\u001b[0m\n",
      "\u001b[2m01:08:43.393141 line        54\u001b[0m                 except:\n",
      "\u001b[2m01:08:43.393178 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.393219 line        56\u001b[0m                     -1\n",
      "\u001b[2m01:08:43.393250 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.393280 line        57\u001b[0m                 ].value\n",
      "\u001b[2m01:08:43.393310 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0}\u001b[0m\n",
      "\u001b[2m01:08:43.393340 line        48\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'Loss/Train'\u001b[0m\n",
      "\u001b[2m01:08:43.393376 line        50\u001b[0m                 try:\n",
      "\u001b[2m01:08:43.393410 line        51\u001b[0m                     temp_dict[subtag] = [tag[-1] for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.393446 exception   51\u001b[0m                     temp_dict[subtag] = [tag[-1] for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[31mException:..... \u001b[1mTypeError: 'ScalarEvent' object is not subscriptable\u001b[0m\n",
      "\u001b[2m01:08:43.393500 line        54\u001b[0m                 except:\n",
      "\u001b[2m01:08:43.393532 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.393570 line        56\u001b[0m                     -1\n",
      "\u001b[2m01:08:43.393600 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.393630 line        57\u001b[0m                 ].value\n",
      "\u001b[2m01:08:43.393659 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 0.10856704413890839}\u001b[0m\n",
      "\u001b[2m01:08:43.393689 line        48\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'Acc/Train'\u001b[0m\n",
      "\u001b[2m01:08:43.393742 line        50\u001b[0m                 try:\n",
      "\u001b[2m01:08:43.393779 line        51\u001b[0m                     temp_dict[subtag] = [tag[-1] for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.393817 exception   51\u001b[0m                     temp_dict[subtag] = [tag[-1] for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[31mException:..... \u001b[1mTypeError: 'ScalarEvent' object is not subscriptable\u001b[0m\n",
      "\u001b[2m01:08:43.393870 line        54\u001b[0m                 except:\n",
      "\u001b[2m01:08:43.393904 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.393943 line        56\u001b[0m                     -1\n",
      "\u001b[2m01:08:43.393975 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.394005 line        57\u001b[0m                 ].value\n",
      "\u001b[2m01:08:43.394035 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 0.10856704413890839, 'Acc/Train': 16.420000076293945}\u001b[0m\n",
      "\u001b[2m01:08:43.394066 line        48\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'global_run_count'\u001b[0m\n",
      "\u001b[2m01:08:43.394103 line        50\u001b[0m                 try:\n",
      "\u001b[2m01:08:43.394139 line        51\u001b[0m                     temp_dict[subtag] = [tag[-1] for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.394204 exception   51\u001b[0m                     temp_dict[subtag] = [tag[-1] for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[31mException:..... \u001b[1mTypeError: 'ScalarEvent' object is not subscriptable\u001b[0m\n",
      "\u001b[2m01:08:43.394268 line        54\u001b[0m                 except:\n",
      "\u001b[2m01:08:43.394303 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.394343 line        56\u001b[0m                     -1\n",
      "\u001b[2m01:08:43.394375 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.394408 line        57\u001b[0m                 ].value\n",
      "\u001b[2m01:08:43.394442 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 0.108567044138...n': 16.420000076293945, 'global_run_count': 20.0}\u001b[0m\n",
      "\u001b[2m01:08:43.394477 line        48\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'Loss/Val'\u001b[0m\n",
      "\u001b[2m01:08:43.394556 line        50\u001b[0m                 try:\n",
      "\u001b[2m01:08:43.394592 line        51\u001b[0m                     temp_dict[subtag] = [tag[-1] for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.394672 exception   51\u001b[0m                     temp_dict[subtag] = [tag[-1] for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[31mException:..... \u001b[1mTypeError: 'ScalarEvent' object is not subscriptable\u001b[0m\n",
      "\u001b[2m01:08:43.394725 line        54\u001b[0m                 except:\n",
      "\u001b[2m01:08:43.394759 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.394800 line        56\u001b[0m                     -1\n",
      "\u001b[2m01:08:43.394833 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.394865 line        57\u001b[0m                 ].value\n",
      "\u001b[2m01:08:43.394897 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 0.108567044138...un_count': 20.0, 'Loss/Val': 0.11231575906276703}\u001b[0m\n",
      "\u001b[2m01:08:43.394930 line        48\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'Acc/Val'\u001b[0m\n",
      "\u001b[2m01:08:43.394967 line        50\u001b[0m                 try:\n",
      "\u001b[2m01:08:43.395004 line        51\u001b[0m                     temp_dict[subtag] = [tag[-1] for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.395043 exception   51\u001b[0m                     temp_dict[subtag] = [tag[-1] for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[31mException:..... \u001b[1mTypeError: 'ScalarEvent' object is not subscriptable\u001b[0m\n",
      "\u001b[2m01:08:43.395096 line        54\u001b[0m                 except:\n",
      "\u001b[2m01:08:43.395131 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.395181 line        56\u001b[0m                     -1\n",
      "\u001b[2m01:08:43.395270 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.395322 line        57\u001b[0m                 ].value\n",
      "\u001b[2m01:08:43.395386 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 0.108567044138...11231575906276703, 'Acc/Val': 15.649999618530273}\u001b[0m\n",
      "\u001b[2m01:08:43.395439 line        48\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[2m01:08:43.395477 line        59\u001b[0m         if tag == \"tensors\":\n",
      "\u001b[2m01:08:43.395510 line        85\u001b[0m         if tag == \"images\" and save_ims == True:\n",
      "\u001b[2m01:08:43.395559 line        46\u001b[0m     for tag in all_tags.keys():\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtag = 'distributions'\u001b[0m\n",
      "\u001b[2m01:08:43.395593 line        47\u001b[0m         if tag == \"scalars\":\n",
      "\u001b[2m01:08:43.395630 line        59\u001b[0m         if tag == \"tensors\":\n",
      "\u001b[2m01:08:43.395661 line        85\u001b[0m         if tag == \"images\" and save_ims == True:\n",
      "\u001b[2m01:08:43.395693 line        46\u001b[0m     for tag in all_tags.keys():\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtag = 'tensors'\u001b[0m\n",
      "\u001b[2m01:08:43.395724 line        47\u001b[0m         if tag == \"scalars\":\n",
      "\u001b[2m01:08:43.395760 line        59\u001b[0m         if tag == \"tensors\":\n",
      "\u001b[2m01:08:43.395792 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'experiment_name/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.395823 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.395891 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.395974 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.396051 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.396127 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 0.108567044138...9999618530273, 'experiment_name': 'baseline_run'}\u001b[0m\n",
      "\u001b[2m01:08:43.396202 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'image_size/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.396282 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.396345 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.396380 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.396414 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.396446 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 0.108567044138...iment_name': 'baseline_run', 'image_size': '224'}\u001b[0m\n",
      "\u001b[2m01:08:43.396479 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'batch_size/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.396516 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.396561 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.396596 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.396653 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.396704 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 0.108567044138...ne_run', 'image_size': '224', 'batch_size': '32'}\u001b[0m\n",
      "\u001b[2m01:08:43.396737 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'enable_proxy_attention/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.396775 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.396842 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.396877 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.396949 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.396983 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 0.108567044138...ch_size': '32', 'enable_proxy_attention': 'True'}\u001b[0m\n",
      "\u001b[2m01:08:43.397017 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'transfer_imagenet/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.397069 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.397135 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.397170 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.397204 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.397236 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 0.108567044138..._attention': 'True', 'transfer_imagenet': 'True'}\u001b[0m\n",
      "\u001b[2m01:08:43.397275 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'subset_images/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.397337 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.397406 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.397445 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.397479 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.397513 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 0.108567044138...sfer_imagenet': 'True', 'subset_images': '20000'}\u001b[0m\n",
      "\u001b[2m01:08:43.397564 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'pixel_replacement_method/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.397602 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.397646 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.397681 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.397715 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.397748 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 0.108567044138...: '20000', 'pixel_replacement_method': 'blended'}\u001b[0m\n",
      "\u001b[2m01:08:43.397782 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'proxy_steps/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.397820 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.397864 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.397899 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.397932 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.397966 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 0.108567044138...cement_method': 'blended', 'proxy_steps': '[20]'}\u001b[0m\n",
      "\u001b[2m01:08:43.398000 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'load_proxy_data/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.398038 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.398083 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.398118 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.398152 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.398185 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 0.108567044138...proxy_steps': '[20]', 'load_proxy_data': 'False'}\u001b[0m\n",
      "\u001b[2m01:08:43.398219 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'proxy_step/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.398258 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.398302 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.398336 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.398370 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.398403 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.10856704...proxy_steps': '[20]', 'load_proxy_data': 'False'}\u001b[0m\n",
      "\u001b[2m01:08:43.398468 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'log_every/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.398508 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.398553 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.398589 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.398642 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.398676 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.10856704...]', 'load_proxy_data': 'False', 'log_every': '2'}\u001b[0m\n",
      "\u001b[2m01:08:43.398711 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'device/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.398749 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.398793 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.398828 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.398862 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.398895 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.10856704...': 'False', 'log_every': '2', 'device': 'cuda:0'}\u001b[0m\n",
      "\u001b[2m01:08:43.398929 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'dataset_info/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.398967 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.399034 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.399070 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.399106 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.399142 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.10856704...t_name at 0x7f743bfbfa30>, 'num_classes': 101}}\"}\u001b[0m\n",
      "\u001b[2m01:08:43.399195 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'main_run_dir/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.399265 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.399366 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.399440 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.399525 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.399633 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.10856704...DE/Github/improving_robotics_datasets/src/runs/'}\u001b[0m\n",
      "\u001b[2m01:08:43.399702 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'change_subset_attention/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.399779 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.399872 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.399946 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.400015 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.400082 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.10856704...ets/src/runs/', 'change_subset_attention': '0.8'}\u001b[0m\n",
      "\u001b[2m01:08:43.400148 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'model/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.400247 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.400377 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.400463 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.400531 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.400598 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.10856704...hange_subset_attention': '0.8', 'model': 'vgg16'}\u001b[0m\n",
      "\u001b[2m01:08:43.400665 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'proxy_image_weight/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.400738 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.400827 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.400895 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.400964 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.401028 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.10856704...', 'model': 'vgg16', 'proxy_image_weight': '0.1'}\u001b[0m\n",
      "\u001b[2m01:08:43.401093 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'proxy_threshold/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.401166 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.401250 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.401318 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.401412 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.401477 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.10856704..._image_weight': '0.1', 'proxy_threshold': '0.85'}\u001b[0m\n",
      "\u001b[2m01:08:43.401540 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'gradient_method/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.401617 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.401705 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.401777 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.401847 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.401917 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.10856704...d': '0.85', 'gradient_method': 'gradcamplusplus'}\u001b[0m\n",
      "\u001b[2m01:08:43.401986 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'ds_name/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.402064 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.402153 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.402223 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.402289 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.402355 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.10856704...nt_method': 'gradcamplusplus', 'ds_name': 'dogs'}\u001b[0m\n",
      "\u001b[2m01:08:43.402458 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'clear_every_step/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.402532 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.402637 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.402740 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.402847 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.402911 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.10856704...', 'ds_name': 'dogs', 'clear_every_step': 'True'}\u001b[0m\n",
      "\u001b[2m01:08:43.402979 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'fname_start/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.403052 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.403135 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.403204 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.403270 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.403353 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.10856704..._datasets/src/runs/baseline_run_27032023_122730'}\u001b[0m\n",
      "\u001b[2m01:08:43.403437 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'ds_path/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.403511 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.403591 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.403656 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.403731 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.403806 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.10856704...un/media/eragon/HDD/Datasets/dogs/images/Images'}\u001b[0m\n",
      "\u001b[2m01:08:43.403901 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'name_fn/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.403986 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.404080 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.404158 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.404235 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.404308 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.10856704...: '<function get_parent_name at 0x7f743bfbfa30>'}\u001b[0m\n",
      "\u001b[2m01:08:43.404381 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'global_run_count/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.404464 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.404557 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.404637 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.404716 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.404797 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[2m01:08:43.404874 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'writer/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.404949 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.405046 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.405123 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.405198 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.405271 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.10856704....writer.SummaryWriter object at 0x7f7431136e90>'}\u001b[0m\n",
      "\u001b[2m01:08:43.405345 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'label_map/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.405429 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.405525 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.405604 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.405678 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.405753 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.10856704...3-dhole', 119: 'n02116738-African_hunting_dog'}\"}\u001b[0m\n",
      "\u001b[2m01:08:43.405827 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'rev_label_map/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.405987 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.406109 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.406219 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.406339 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.406443 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.10856704...le': 118, 'n02116738-African_hunting_dog': 119}\"}\u001b[0m\n",
      "\u001b[2m01:08:43.406555 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'num_classes/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.406708 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.406875 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.407014 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.407168 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.407305 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.10856704...frican_hunting_dog': 119}\", 'num_classes': '120'}\u001b[0m\n",
      "\u001b[2m01:08:43.407442 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'dataset_sizes/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.407574 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.407718 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.407848 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.407977 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.408105 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.10856704...dataset_sizes': \"{'train': 10000, 'val': 10000}\"}\u001b[0m\n",
      "\u001b[2m01:08:43.408232 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'criterion/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.408372 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.408518 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.408647 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.408775 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.408931 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.10856704...val': 10000}\", 'criterion': 'CrossEntropyLoss()'}\u001b[0m\n",
      "\u001b[2m01:08:43.409074 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'save_path/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.409205 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.409363 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.409491 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.409614 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.409734 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.10856704...rc/runs/baseline_run_27032023_122730/checkpoint'}\u001b[0m\n",
      "\u001b[2m01:08:43.409873 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'final_acc/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.410064 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.410220 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.410371 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.410654 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.410811 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.10856704...7032023_122730/checkpoint', 'final_acc': '15.65'}\u001b[0m\n",
      "\u001b[2m01:08:43.410950 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[2m01:08:43.411124 line        85\u001b[0m         if tag == \"images\" and save_ims == True:\n",
      "\u001b[2m01:08:43.411257 line        46\u001b[0m     for tag in all_tags.keys():\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtag = 'graph'\u001b[0m\n",
      "\u001b[2m01:08:43.411402 line        47\u001b[0m         if tag == \"scalars\":\n",
      "\u001b[2m01:08:43.411499 line        59\u001b[0m         if tag == \"tensors\":\n",
      "\u001b[2m01:08:43.411592 line        85\u001b[0m         if tag == \"images\" and save_ims == True:\n",
      "\u001b[2m01:08:43.411678 line        46\u001b[0m     for tag in all_tags.keys():\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtag = 'meta_graph'\u001b[0m\n",
      "\u001b[2m01:08:43.411777 line        47\u001b[0m         if tag == \"scalars\":\n",
      "\u001b[2m01:08:43.411915 line        59\u001b[0m         if tag == \"tensors\":\n",
      "\u001b[2m01:08:43.412042 line        85\u001b[0m         if tag == \"images\" and save_ims == True:\n",
      "\u001b[2m01:08:43.412125 line        46\u001b[0m     for tag in all_tags.keys():\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtag = 'run_metadata'\u001b[0m\n",
      "\u001b[2m01:08:43.412206 line        47\u001b[0m         if tag == \"scalars\":\n",
      "\u001b[2m01:08:43.412294 line        59\u001b[0m         if tag == \"tensors\":\n",
      "\u001b[2m01:08:43.412374 line        85\u001b[0m         if tag == \"images\" and save_ims == True:\n",
      "\u001b[2m01:08:43.412454 line        46\u001b[0m     for tag in all_tags.keys():\n",
      "\u001b[2m01:08:43.412537 line        96\u001b[0m     return temp_dict\n",
      "\u001b[2m01:08:43.412618 return      96\u001b[0m     return temp_dict\n",
      "\u001b[36m\u001b[2mReturn value:.. \u001b[22m{'proxy_step': 'False', 'Loss/Train': 0.10856704...7032023_122730/checkpoint', 'final_acc': '15.65'}\u001b[0m\n",
      "\u001b[33m\u001b[2mElapsed time: \u001b[22m00:00:00.020890\u001b[0m\n",
      " 69%|█████████████████████████████▋             | 20/29 [00:00<00:00, 39.71it/s]runs/baseline_run_27032023_124745/events.out.tfevents.1679914067.eragon\n",
      "\u001b[32m\u001b[2mStarting var:.. \u001b[22mevent_acc = <tensorboard.backend.event_processing.event_accumulator.EventAccumulator object at 0x7f5b568ed630>\u001b[0m\n",
      "\u001b[32m\u001b[2mStarting var:.. \u001b[22msave_ims = False\u001b[0m\n",
      "\u001b[2m01:08:43.422422 call        42\u001b[0m def process_event_acc(event_acc, save_ims = False):\n",
      "\u001b[2m01:08:43.422503 line        44\u001b[0m     all_tags = event_acc.Tags()\n",
      "\u001b[32m\u001b[2mNew var:....... \u001b[22mall_tags = {'images': [], 'audio': [], 'histograms': [], 's...: False, 'meta_graph': False, 'run_metadata': []}\u001b[0m\n",
      "\u001b[2m01:08:43.422548 line        45\u001b[0m     temp_dict = {}\n",
      "\u001b[32m\u001b[2mNew var:....... \u001b[22mtemp_dict = {}\u001b[0m\n",
      "\u001b[2m01:08:43.422602 line        46\u001b[0m     for tag in all_tags.keys():\n",
      "\u001b[32m\u001b[2mNew var:....... \u001b[22mtag = 'images'\u001b[0m\n",
      "\u001b[2m01:08:43.422648 line        47\u001b[0m         if tag == \"scalars\":\n",
      "\u001b[2m01:08:43.422691 line        59\u001b[0m         if tag == \"tensors\":\n",
      "\u001b[2m01:08:43.422737 line        85\u001b[0m         if tag == \"images\" and save_ims == True:\n",
      "\u001b[2m01:08:43.422772 line        46\u001b[0m     for tag in all_tags.keys():\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtag = 'audio'\u001b[0m\n",
      "\u001b[2m01:08:43.422803 line        47\u001b[0m         if tag == \"scalars\":\n",
      "\u001b[2m01:08:43.422841 line        59\u001b[0m         if tag == \"tensors\":\n",
      "\u001b[2m01:08:43.422871 line        85\u001b[0m         if tag == \"images\" and save_ims == True:\n",
      "\u001b[2m01:08:43.422901 line        46\u001b[0m     for tag in all_tags.keys():\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtag = 'histograms'\u001b[0m\n",
      "\u001b[2m01:08:43.422930 line        47\u001b[0m         if tag == \"scalars\":\n",
      "\u001b[2m01:08:43.422967 line        59\u001b[0m         if tag == \"tensors\":\n",
      "\u001b[2m01:08:43.422998 line        85\u001b[0m         if tag == \"images\" and save_ims == True:\n",
      "\u001b[2m01:08:43.423028 line        46\u001b[0m     for tag in all_tags.keys():\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtag = 'scalars'\u001b[0m\n",
      "\u001b[2m01:08:43.423058 line        47\u001b[0m         if tag == \"scalars\":\n",
      "\u001b[2m01:08:43.423094 line        48\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mNew var:....... \u001b[22msubtag = 'proxy_step'\u001b[0m\n",
      "\u001b[2m01:08:43.423124 line        50\u001b[0m                 try:\n",
      "\u001b[2m01:08:43.423163 line        51\u001b[0m                     temp_dict[subtag] = [tag[-1] for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.423205 exception   51\u001b[0m                     temp_dict[subtag] = [tag[-1] for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[31mException:..... \u001b[1mTypeError: 'ScalarEvent' object is not subscriptable\u001b[0m\n",
      "\u001b[2m01:08:43.423324 line        54\u001b[0m                 except:\n",
      "\u001b[2m01:08:43.423359 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.423401 line        56\u001b[0m                     -1\n",
      "\u001b[2m01:08:43.423441 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.423471 line        57\u001b[0m                 ].value\n",
      "\u001b[2m01:08:43.423500 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0}\u001b[0m\n",
      "\u001b[2m01:08:43.423529 line        48\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'Loss/Train'\u001b[0m\n",
      "\u001b[2m01:08:43.423565 line        50\u001b[0m                 try:\n",
      "\u001b[2m01:08:43.423622 line        51\u001b[0m                     temp_dict[subtag] = [tag[-1] for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.423658 exception   51\u001b[0m                     temp_dict[subtag] = [tag[-1] for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[31mException:..... \u001b[1mTypeError: 'ScalarEvent' object is not subscriptable\u001b[0m\n",
      "\u001b[2m01:08:43.423734 line        54\u001b[0m                 except:\n",
      "\u001b[2m01:08:43.423805 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.423914 line        56\u001b[0m                     -1\n",
      "\u001b[2m01:08:43.423964 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.423994 line        57\u001b[0m                 ].value\n",
      "\u001b[2m01:08:43.424023 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 0.08147948980331421}\u001b[0m\n",
      "\u001b[2m01:08:43.424052 line        48\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'Acc/Train'\u001b[0m\n",
      "\u001b[2m01:08:43.424121 line        50\u001b[0m                 try:\n",
      "\u001b[2m01:08:43.424193 line        51\u001b[0m                     temp_dict[subtag] = [tag[-1] for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.424237 exception   51\u001b[0m                     temp_dict[subtag] = [tag[-1] for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[31mException:..... \u001b[1mTypeError: 'ScalarEvent' object is not subscriptable\u001b[0m\n",
      "\u001b[2m01:08:43.424302 line        54\u001b[0m                 except:\n",
      "\u001b[2m01:08:43.424337 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.424376 line        56\u001b[0m                     -1\n",
      "\u001b[2m01:08:43.424424 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.424474 line        57\u001b[0m                 ].value\n",
      "\u001b[2m01:08:43.424528 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 0.08147948980331421, 'Acc/Train': 41.81062698364258}\u001b[0m\n",
      "\u001b[2m01:08:43.424579 line        48\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'global_run_count'\u001b[0m\n",
      "\u001b[2m01:08:43.424642 line        50\u001b[0m                 try:\n",
      "\u001b[2m01:08:43.424703 line        51\u001b[0m                     temp_dict[subtag] = [tag[-1] for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.424762 exception   51\u001b[0m                     temp_dict[subtag] = [tag[-1] for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[31mException:..... \u001b[1mTypeError: 'ScalarEvent' object is not subscriptable\u001b[0m\n",
      "\u001b[2m01:08:43.424818 line        54\u001b[0m                 except:\n",
      "\u001b[2m01:08:43.424853 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.424894 line        56\u001b[0m                     -1\n",
      "\u001b[2m01:08:43.424926 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.424957 line        57\u001b[0m                 ].value\n",
      "\u001b[2m01:08:43.424986 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 0.081479489803...in': 41.81062698364258, 'global_run_count': 20.0}\u001b[0m\n",
      "\u001b[2m01:08:43.425017 line        48\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'Loss/Val'\u001b[0m\n",
      "\u001b[2m01:08:43.425055 line        50\u001b[0m                 try:\n",
      "\u001b[2m01:08:43.425090 line        51\u001b[0m                     temp_dict[subtag] = [tag[-1] for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.425129 exception   51\u001b[0m                     temp_dict[subtag] = [tag[-1] for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[31mException:..... \u001b[1mTypeError: 'ScalarEvent' object is not subscriptable\u001b[0m\n",
      "\u001b[2m01:08:43.425179 line        54\u001b[0m                 except:\n",
      "\u001b[2m01:08:43.425213 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.425252 line        56\u001b[0m                     -1\n",
      "\u001b[2m01:08:43.425283 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.425315 line        57\u001b[0m                 ].value\n",
      "\u001b[2m01:08:43.425345 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 0.081479489803...run_count': 20.0, 'Loss/Val': 0.0757400393486023}\u001b[0m\n",
      "\u001b[2m01:08:43.425377 line        48\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'Acc/Val'\u001b[0m\n",
      "\u001b[2m01:08:43.425413 line        50\u001b[0m                 try:\n",
      "\u001b[2m01:08:43.425469 line        51\u001b[0m                     temp_dict[subtag] = [tag[-1] for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.425520 exception   51\u001b[0m                     temp_dict[subtag] = [tag[-1] for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[31mException:..... \u001b[1mTypeError: 'ScalarEvent' object is not subscriptable\u001b[0m\n",
      "\u001b[2m01:08:43.425573 line        54\u001b[0m                 except:\n",
      "\u001b[2m01:08:43.425608 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.425647 line        56\u001b[0m                     -1\n",
      "\u001b[2m01:08:43.425679 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.425711 line        57\u001b[0m                 ].value\n",
      "\u001b[2m01:08:43.425742 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 0.081479489803...0.0757400393486023, 'Acc/Val': 45.10061264038086}\u001b[0m\n",
      "\u001b[2m01:08:43.425774 line        48\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[2m01:08:43.425811 line        59\u001b[0m         if tag == \"tensors\":\n",
      "\u001b[2m01:08:43.425843 line        85\u001b[0m         if tag == \"images\" and save_ims == True:\n",
      "\u001b[2m01:08:43.425874 line        46\u001b[0m     for tag in all_tags.keys():\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtag = 'distributions'\u001b[0m\n",
      "\u001b[2m01:08:43.425905 line        47\u001b[0m         if tag == \"scalars\":\n",
      "\u001b[2m01:08:43.425941 line        59\u001b[0m         if tag == \"tensors\":\n",
      "\u001b[2m01:08:43.425971 line        85\u001b[0m         if tag == \"images\" and save_ims == True:\n",
      "\u001b[2m01:08:43.426002 line        46\u001b[0m     for tag in all_tags.keys():\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtag = 'tensors'\u001b[0m\n",
      "\u001b[2m01:08:43.426032 line        47\u001b[0m         if tag == \"scalars\":\n",
      "\u001b[2m01:08:43.426067 line        59\u001b[0m         if tag == \"tensors\":\n",
      "\u001b[2m01:08:43.426098 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'experiment_name/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.426128 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.426172 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.426208 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.426243 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.426275 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 0.081479489803...0061264038086, 'experiment_name': 'baseline_run'}\u001b[0m\n",
      "\u001b[2m01:08:43.426307 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'image_size/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.426345 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.426387 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.426421 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.426455 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.426487 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 0.081479489803...iment_name': 'baseline_run', 'image_size': '224'}\u001b[0m\n",
      "\u001b[2m01:08:43.426519 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'batch_size/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.426560 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.426608 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.426646 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.426679 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.426722 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 0.081479489803...ne_run', 'image_size': '224', 'batch_size': '32'}\u001b[0m\n",
      "\u001b[2m01:08:43.426761 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'enable_proxy_attention/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.426800 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.426844 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.426878 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.426911 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.426943 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 0.081479489803...ch_size': '32', 'enable_proxy_attention': 'True'}\u001b[0m\n",
      "\u001b[2m01:08:43.426976 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'transfer_imagenet/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.427013 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.427116 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.427156 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.427190 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.427223 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 0.081479489803..._attention': 'True', 'transfer_imagenet': 'True'}\u001b[0m\n",
      "\u001b[2m01:08:43.427255 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'subset_images/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.427293 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.427337 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.427371 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.427405 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.427438 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 0.081479489803...sfer_imagenet': 'True', 'subset_images': '20000'}\u001b[0m\n",
      "\u001b[2m01:08:43.427471 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'pixel_replacement_method/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.427508 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.427552 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.427586 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.427628 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.427661 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 0.081479489803...: '20000', 'pixel_replacement_method': 'blended'}\u001b[0m\n",
      "\u001b[2m01:08:43.427716 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'proxy_steps/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.427755 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.427817 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.427868 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.427904 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.427938 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 0.081479489803...cement_method': 'blended', 'proxy_steps': '[20]'}\u001b[0m\n",
      "\u001b[2m01:08:43.427972 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'load_proxy_data/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.428011 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.428056 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.428091 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.428125 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.428165 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 0.081479489803...proxy_steps': '[20]', 'load_proxy_data': 'False'}\u001b[0m\n",
      "\u001b[2m01:08:43.428207 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'proxy_step/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.428246 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.428296 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.428353 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.428412 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.428470 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.08147948...proxy_steps': '[20]', 'load_proxy_data': 'False'}\u001b[0m\n",
      "\u001b[2m01:08:43.428528 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'log_every/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.428597 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.428673 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.428714 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.428790 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.428826 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.08147948...]', 'load_proxy_data': 'False', 'log_every': '2'}\u001b[0m\n",
      "\u001b[2m01:08:43.428861 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'device/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.428900 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.428945 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.428983 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.429017 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.429056 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.08147948...': 'False', 'log_every': '2', 'device': 'cuda:0'}\u001b[0m\n",
      "\u001b[2m01:08:43.429100 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'dataset_info/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.429142 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.429187 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.429222 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.429257 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.429291 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.08147948...t_name at 0x7fd34e5cba30>, 'num_classes': 101}}\"}\u001b[0m\n",
      "\u001b[2m01:08:43.429325 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'main_run_dir/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.429370 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.429420 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.429460 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.429500 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.429540 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.08147948...DE/Github/improving_robotics_datasets/src/runs/'}\u001b[0m\n",
      "\u001b[2m01:08:43.429579 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'change_subset_attention/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.429623 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.429672 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.429713 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.429771 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.429810 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.08147948...ets/src/runs/', 'change_subset_attention': '0.8'}\u001b[0m\n",
      "\u001b[2m01:08:43.429849 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'model/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.429894 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.429945 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.429987 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.430028 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.430067 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.08147948...hange_subset_attention': '0.8', 'model': 'vgg16'}\u001b[0m\n",
      "\u001b[2m01:08:43.430106 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'proxy_image_weight/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.430150 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.430201 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.430242 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.430306 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.430346 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.08147948...', 'model': 'vgg16', 'proxy_image_weight': '0.1'}\u001b[0m\n",
      "\u001b[2m01:08:43.430396 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'proxy_threshold/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.430464 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.430514 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.430556 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.430597 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.430637 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.08147948..._image_weight': '0.1', 'proxy_threshold': '0.85'}\u001b[0m\n",
      "\u001b[2m01:08:43.430676 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'gradient_method/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.430724 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.430799 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.430883 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.430979 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.431041 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.08147948...d': '0.85', 'gradient_method': 'gradcamplusplus'}\u001b[0m\n",
      "\u001b[2m01:08:43.431080 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'ds_name/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.431124 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.431176 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.431217 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.431257 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.431297 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.08147948...hod': 'gradcamplusplus', 'ds_name': 'caltech101'}\u001b[0m\n",
      "\u001b[2m01:08:43.431337 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'clear_every_step/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.431382 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.431433 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.431475 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.431516 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.431555 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.08147948..._name': 'caltech101', 'clear_every_step': 'True'}\u001b[0m\n",
      "\u001b[2m01:08:43.431595 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'fname_start/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.431640 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.431690 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.431731 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.431806 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.431847 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.08147948..._datasets/src/runs/baseline_run_27032023_124745'}\u001b[0m\n",
      "\u001b[2m01:08:43.431889 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'ds_path/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.431936 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.432006 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.432048 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.432089 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.432135 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.08147948...h': '/run/media/eragon/HDD/Datasets/caltech-101'}\u001b[0m\n",
      "\u001b[2m01:08:43.432259 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'name_fn/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.432394 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.432487 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.432569 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.432646 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.432690 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.08147948...: '<function get_parent_name at 0x7fd34e5cba30>'}\u001b[0m\n",
      "\u001b[2m01:08:43.432737 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'global_run_count/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.432791 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.432852 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.432920 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.432994 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.433065 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[2m01:08:43.433138 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'writer/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.433212 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.433276 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.433322 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.433365 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.433408 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.08147948....writer.SummaryWriter object at 0x7fd343702e90>'}\u001b[0m\n",
      "\u001b[2m01:08:43.433450 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'label_map/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.433497 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.433551 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.433594 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.433670 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.433715 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.08147948...windsor_chair', 100: 'wrench', 101: 'yin_yang'}\"}\u001b[0m\n",
      "\u001b[2m01:08:43.433791 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'rev_label_map/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.433849 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.433931 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.433996 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.434047 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.434097 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.08147948...sor_chair': 99, 'wrench': 100, 'yin_yang': 101}\"}\u001b[0m\n",
      "\u001b[2m01:08:43.434147 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'num_classes/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.434210 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.434279 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.434338 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.434401 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.434458 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.08147948...h': 100, 'yin_yang': 101}\", 'num_classes': '102'}\u001b[0m\n",
      "\u001b[2m01:08:43.434515 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'dataset_sizes/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.434578 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.434647 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.434706 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.434765 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.434822 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.08147948... 'dataset_sizes': \"{'train': 4573, 'val': 4572}\"}\u001b[0m\n",
      "\u001b[2m01:08:43.434895 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'criterion/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.434958 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.435027 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.435086 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.435144 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.435200 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.08147948...'val': 4572}\", 'criterion': 'CrossEntropyLoss()'}\u001b[0m\n",
      "\u001b[2m01:08:43.435256 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'save_path/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.435317 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.435387 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.435446 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.435504 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.435562 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.08147948...rc/runs/baseline_run_27032023_124745/checkpoint'}\u001b[0m\n",
      "\u001b[2m01:08:43.435624 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'final_acc/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.435687 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.435756 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.435837 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.435897 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.435964 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.08147948...45/checkpoint', 'final_acc': '45.10061242344707'}\u001b[0m\n",
      "\u001b[2m01:08:43.436023 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[2m01:08:43.436089 line        85\u001b[0m         if tag == \"images\" and save_ims == True:\n",
      "\u001b[2m01:08:43.436150 line        46\u001b[0m     for tag in all_tags.keys():\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtag = 'graph'\u001b[0m\n",
      "\u001b[2m01:08:43.436209 line        47\u001b[0m         if tag == \"scalars\":\n",
      "\u001b[2m01:08:43.436272 line        59\u001b[0m         if tag == \"tensors\":\n",
      "\u001b[2m01:08:43.436375 line        85\u001b[0m         if tag == \"images\" and save_ims == True:\n",
      "\u001b[2m01:08:43.436432 line        46\u001b[0m     for tag in all_tags.keys():\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtag = 'meta_graph'\u001b[0m\n",
      "\u001b[2m01:08:43.436490 line        47\u001b[0m         if tag == \"scalars\":\n",
      "\u001b[2m01:08:43.436552 line        59\u001b[0m         if tag == \"tensors\":\n",
      "\u001b[2m01:08:43.436609 line        85\u001b[0m         if tag == \"images\" and save_ims == True:\n",
      "\u001b[2m01:08:43.436666 line        46\u001b[0m     for tag in all_tags.keys():\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtag = 'run_metadata'\u001b[0m\n",
      "\u001b[2m01:08:43.436736 line        47\u001b[0m         if tag == \"scalars\":\n",
      "\u001b[2m01:08:43.436865 line        59\u001b[0m         if tag == \"tensors\":\n",
      "\u001b[2m01:08:43.436950 line        85\u001b[0m         if tag == \"images\" and save_ims == True:\n",
      "\u001b[2m01:08:43.437018 line        46\u001b[0m     for tag in all_tags.keys():\n",
      "\u001b[2m01:08:43.437124 line        96\u001b[0m     return temp_dict\n",
      "\u001b[2m01:08:43.437184 return      96\u001b[0m     return temp_dict\n",
      "\u001b[36m\u001b[2mReturn value:.. \u001b[22m{'proxy_step': 'False', 'Loss/Train': 0.08147948...45/checkpoint', 'final_acc': '45.10061242344707'}\u001b[0m\n",
      "\u001b[33m\u001b[2mElapsed time: \u001b[22m00:00:00.014914\u001b[0m\n",
      "runs/baseline_run_27032023_125754/events.out.tfevents.1679914675.eragon\n",
      "\u001b[32m\u001b[2mStarting var:.. \u001b[22mevent_acc = <tensorboard.backend.event_processing.event_accumulator.EventAccumulator object at 0x7f5b568ed600>\u001b[0m\n",
      "\u001b[32m\u001b[2mStarting var:.. \u001b[22msave_ims = False\u001b[0m\n",
      "\u001b[2m01:08:43.445414 call        42\u001b[0m def process_event_acc(event_acc, save_ims = False):\n",
      "\u001b[2m01:08:43.445545 line        44\u001b[0m     all_tags = event_acc.Tags()\n",
      "\u001b[32m\u001b[2mNew var:....... \u001b[22mall_tags = {'images': [], 'audio': [], 'histograms': [], 's...: False, 'meta_graph': False, 'run_metadata': []}\u001b[0m\n",
      "\u001b[2m01:08:43.445651 line        45\u001b[0m     temp_dict = {}\n",
      "\u001b[32m\u001b[2mNew var:....... \u001b[22mtemp_dict = {}\u001b[0m\n",
      "\u001b[2m01:08:43.445718 line        46\u001b[0m     for tag in all_tags.keys():\n",
      "\u001b[32m\u001b[2mNew var:....... \u001b[22mtag = 'images'\u001b[0m\n",
      "\u001b[2m01:08:43.445765 line        47\u001b[0m         if tag == \"scalars\":\n",
      "\u001b[2m01:08:43.445802 line        59\u001b[0m         if tag == \"tensors\":\n",
      "\u001b[2m01:08:43.445832 line        85\u001b[0m         if tag == \"images\" and save_ims == True:\n",
      "\u001b[2m01:08:43.445860 line        46\u001b[0m     for tag in all_tags.keys():\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtag = 'audio'\u001b[0m\n",
      "\u001b[2m01:08:43.445886 line        47\u001b[0m         if tag == \"scalars\":\n",
      "\u001b[2m01:08:43.445918 line        59\u001b[0m         if tag == \"tensors\":\n",
      "\u001b[2m01:08:43.445945 line        85\u001b[0m         if tag == \"images\" and save_ims == True:\n",
      "\u001b[2m01:08:43.445972 line        46\u001b[0m     for tag in all_tags.keys():\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtag = 'histograms'\u001b[0m\n",
      "\u001b[2m01:08:43.445998 line        47\u001b[0m         if tag == \"scalars\":\n",
      "\u001b[2m01:08:43.446029 line        59\u001b[0m         if tag == \"tensors\":\n",
      "\u001b[2m01:08:43.446076 line        85\u001b[0m         if tag == \"images\" and save_ims == True:\n",
      "\u001b[2m01:08:43.446103 line        46\u001b[0m     for tag in all_tags.keys():\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtag = 'scalars'\u001b[0m\n",
      "\u001b[2m01:08:43.446160 line        47\u001b[0m         if tag == \"scalars\":\n",
      "\u001b[2m01:08:43.446218 line        48\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mNew var:....... \u001b[22msubtag = 'proxy_step'\u001b[0m\n",
      "\u001b[2m01:08:43.446248 line        50\u001b[0m                 try:\n",
      "\u001b[2m01:08:43.446283 line        51\u001b[0m                     temp_dict[subtag] = [tag[-1] for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.446323 exception   51\u001b[0m                     temp_dict[subtag] = [tag[-1] for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[31mException:..... \u001b[1mTypeError: 'ScalarEvent' object is not subscriptable\u001b[0m\n",
      "\u001b[2m01:08:43.446445 line        54\u001b[0m                 except:\n",
      "\u001b[2m01:08:43.446479 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.446519 line        56\u001b[0m                     -1\n",
      "\u001b[2m01:08:43.446550 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.446579 line        57\u001b[0m                 ].value\n",
      "\u001b[2m01:08:43.446608 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0}\u001b[0m\n",
      "\u001b[2m01:08:43.446637 line        48\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'Loss/Train'\u001b[0m\n",
      "\u001b[2m01:08:43.446674 line        50\u001b[0m                 try:\n",
      "\u001b[2m01:08:43.446708 line        51\u001b[0m                     temp_dict[subtag] = [tag[-1] for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.446744 exception   51\u001b[0m                     temp_dict[subtag] = [tag[-1] for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[31mException:..... \u001b[1mTypeError: 'ScalarEvent' object is not subscriptable\u001b[0m\n",
      "\u001b[2m01:08:43.446797 line        54\u001b[0m                 except:\n",
      "\u001b[2m01:08:43.446830 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.446867 line        56\u001b[0m                     -1\n",
      "\u001b[2m01:08:43.446938 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.446967 line        57\u001b[0m                 ].value\n",
      "\u001b[2m01:08:43.446996 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 0.09378068149089813}\u001b[0m\n",
      "\u001b[2m01:08:43.447026 line        48\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'Acc/Train'\u001b[0m\n",
      "\u001b[2m01:08:43.447110 line        50\u001b[0m                 try:\n",
      "\u001b[2m01:08:43.447150 line        51\u001b[0m                     temp_dict[subtag] = [tag[-1] for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.447188 exception   51\u001b[0m                     temp_dict[subtag] = [tag[-1] for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[31mException:..... \u001b[1mTypeError: 'ScalarEvent' object is not subscriptable\u001b[0m\n",
      "\u001b[2m01:08:43.447240 line        54\u001b[0m                 except:\n",
      "\u001b[2m01:08:43.447297 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.447337 line        56\u001b[0m                     -1\n",
      "\u001b[2m01:08:43.447368 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.447424 line        57\u001b[0m                 ].value\n",
      "\u001b[2m01:08:43.447455 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 0.09378068149089813, 'Acc/Train': 5.079999923706055}\u001b[0m\n",
      "\u001b[2m01:08:43.447489 line        48\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'global_run_count'\u001b[0m\n",
      "\u001b[2m01:08:43.447552 line        50\u001b[0m                 try:\n",
      "\u001b[2m01:08:43.447594 line        51\u001b[0m                     temp_dict[subtag] = [tag[-1] for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.447635 exception   51\u001b[0m                     temp_dict[subtag] = [tag[-1] for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[31mException:..... \u001b[1mTypeError: 'ScalarEvent' object is not subscriptable\u001b[0m\n",
      "\u001b[2m01:08:43.447690 line        54\u001b[0m                 except:\n",
      "\u001b[2m01:08:43.447726 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.447769 line        56\u001b[0m                     -1\n",
      "\u001b[2m01:08:43.447803 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.447838 line        57\u001b[0m                 ].value\n",
      "\u001b[2m01:08:43.447871 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 0.093780681490...in': 5.079999923706055, 'global_run_count': 20.0}\u001b[0m\n",
      "\u001b[2m01:08:43.447905 line        48\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'Loss/Val'\u001b[0m\n",
      "\u001b[2m01:08:43.447948 line        50\u001b[0m                 try:\n",
      "\u001b[2m01:08:43.447989 line        51\u001b[0m                     temp_dict[subtag] = [tag[-1] for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.448031 exception   51\u001b[0m                     temp_dict[subtag] = [tag[-1] for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[31mException:..... \u001b[1mTypeError: 'ScalarEvent' object is not subscriptable\u001b[0m\n",
      "\u001b[2m01:08:43.448087 line        54\u001b[0m                 except:\n",
      "\u001b[2m01:08:43.448124 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.448168 line        56\u001b[0m                     -1\n",
      "\u001b[2m01:08:43.448202 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.448237 line        57\u001b[0m                 ].value\n",
      "\u001b[2m01:08:43.448271 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 0.093780681490...l_run_count': 20.0, 'Loss/Val': 0.09377421438694}\u001b[0m\n",
      "\u001b[2m01:08:43.448305 line        48\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'Acc/Val'\u001b[0m\n",
      "\u001b[2m01:08:43.448347 line        50\u001b[0m                 try:\n",
      "\u001b[2m01:08:43.448388 line        51\u001b[0m                     temp_dict[subtag] = [tag[-1] for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.448463 exception   51\u001b[0m                     temp_dict[subtag] = [tag[-1] for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[31mException:..... \u001b[1mTypeError: 'ScalarEvent' object is not subscriptable\u001b[0m\n",
      "\u001b[2m01:08:43.448521 line        54\u001b[0m                 except:\n",
      "\u001b[2m01:08:43.448560 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.448604 line        56\u001b[0m                     -1\n",
      "\u001b[2m01:08:43.448658 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.448694 line        57\u001b[0m                 ].value\n",
      "\u001b[2m01:08:43.448729 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 0.093780681490...: 0.09377421438694, 'Acc/Val': 5.070000171661377}\u001b[0m\n",
      "\u001b[2m01:08:43.448765 line        48\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[2m01:08:43.448807 line        59\u001b[0m         if tag == \"tensors\":\n",
      "\u001b[2m01:08:43.448842 line        85\u001b[0m         if tag == \"images\" and save_ims == True:\n",
      "\u001b[2m01:08:43.448877 line        46\u001b[0m     for tag in all_tags.keys():\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtag = 'distributions'\u001b[0m\n",
      "\u001b[2m01:08:43.448912 line        47\u001b[0m         if tag == \"scalars\":\n",
      "\u001b[2m01:08:43.448953 line        59\u001b[0m         if tag == \"tensors\":\n",
      "\u001b[2m01:08:43.448987 line        85\u001b[0m         if tag == \"images\" and save_ims == True:\n",
      "\u001b[2m01:08:43.449021 line        46\u001b[0m     for tag in all_tags.keys():\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtag = 'tensors'\u001b[0m\n",
      "\u001b[2m01:08:43.449055 line        47\u001b[0m         if tag == \"scalars\":\n",
      "\u001b[2m01:08:43.449095 line        59\u001b[0m         if tag == \"tensors\":\n",
      "\u001b[2m01:08:43.449129 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'experiment_name/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.449164 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.449223 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.449301 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.449341 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.449379 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 0.093780681490...0000171661377, 'experiment_name': 'baseline_run'}\u001b[0m\n",
      "\u001b[2m01:08:43.449414 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'image_size/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.449453 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.449512 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.449550 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.449585 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.449635 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 0.093780681490...iment_name': 'baseline_run', 'image_size': '224'}\u001b[0m\n",
      "\u001b[2m01:08:43.449705 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'batch_size/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.449795 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.449886 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.449946 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.450028 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.450083 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 0.093780681490...ne_run', 'image_size': '224', 'batch_size': '32'}\u001b[0m\n",
      "\u001b[2m01:08:43.450120 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'enable_proxy_attention/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.450159 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.450206 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.450242 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.450276 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.450310 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 0.093780681490...ch_size': '32', 'enable_proxy_attention': 'True'}\u001b[0m\n",
      "\u001b[2m01:08:43.450368 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'transfer_imagenet/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.450444 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.450495 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.450536 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.450570 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.450604 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 0.093780681490..._attention': 'True', 'transfer_imagenet': 'True'}\u001b[0m\n",
      "\u001b[2m01:08:43.450637 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'subset_images/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.450675 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.450720 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.450755 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.450788 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.450821 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 0.093780681490...sfer_imagenet': 'True', 'subset_images': '20000'}\u001b[0m\n",
      "\u001b[2m01:08:43.450854 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'pixel_replacement_method/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.450892 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.450936 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.450970 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.451004 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.451054 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 0.093780681490...: '20000', 'pixel_replacement_method': 'blended'}\u001b[0m\n",
      "\u001b[2m01:08:43.451088 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'proxy_steps/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.451127 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.451171 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.451205 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.451239 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.451272 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 0.093780681490...cement_method': 'blended', 'proxy_steps': '[20]'}\u001b[0m\n",
      "\u001b[2m01:08:43.451306 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'load_proxy_data/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.451344 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.451388 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.451423 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.451457 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.451490 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 0.093780681490...proxy_steps': '[20]', 'load_proxy_data': 'False'}\u001b[0m\n",
      "\u001b[2m01:08:43.451523 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'proxy_step/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.451561 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.451605 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.451644 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.451678 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.451711 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.09378068...proxy_steps': '[20]', 'load_proxy_data': 'False'}\u001b[0m\n",
      "\u001b[2m01:08:43.451744 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'log_every/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.451783 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.451827 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.451861 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.451920 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.451982 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.09378068...]', 'load_proxy_data': 'False', 'log_every': '2'}\u001b[0m\n",
      "\u001b[2m01:08:43.452048 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'device/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.452127 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.452198 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.452234 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.452269 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.452343 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.09378068...': 'False', 'log_every': '2', 'device': 'cuda:0'}\u001b[0m\n",
      "\u001b[2m01:08:43.452395 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'dataset_info/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.452457 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.452502 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.452540 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.452629 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.452666 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.09378068...t_name at 0x7f547f3afa30>, 'num_classes': 101}}\"}\u001b[0m\n",
      "\u001b[2m01:08:43.452700 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'main_run_dir/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.452745 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.452800 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.452844 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.452902 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.452941 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.09378068...DE/Github/improving_robotics_datasets/src/runs/'}\u001b[0m\n",
      "\u001b[2m01:08:43.452980 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'change_subset_attention/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.453049 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.453118 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.453159 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.453199 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.453238 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.09378068...ets/src/runs/', 'change_subset_attention': '0.8'}\u001b[0m\n",
      "\u001b[2m01:08:43.453277 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'model/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.453321 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.453370 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.453411 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.453451 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.453490 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.09378068...hange_subset_attention': '0.8', 'model': 'vgg16'}\u001b[0m\n",
      "\u001b[2m01:08:43.453549 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'proxy_image_weight/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.453636 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.453691 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.453793 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.453838 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.453879 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.09378068...', 'model': 'vgg16', 'proxy_image_weight': '0.1'}\u001b[0m\n",
      "\u001b[2m01:08:43.453920 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'proxy_threshold/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.454009 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.454113 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.454185 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.454257 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.454329 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.09378068..._image_weight': '0.1', 'proxy_threshold': '0.85'}\u001b[0m\n",
      "\u001b[2m01:08:43.454383 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'gradient_method/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.454432 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.454486 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.454530 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.454571 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.454632 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.09378068...d': '0.85', 'gradient_method': 'gradcamplusplus'}\u001b[0m\n",
      "\u001b[2m01:08:43.454676 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'ds_name/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.454751 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.454831 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.454893 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.454935 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.454999 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.09378068...ent_method': 'gradcamplusplus', 'ds_name': 'asl'}\u001b[0m\n",
      "\u001b[2m01:08:43.455057 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'clear_every_step/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.455102 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.455180 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.455224 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.455266 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.455307 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.09378068...s', 'ds_name': 'asl', 'clear_every_step': 'True'}\u001b[0m\n",
      "\u001b[2m01:08:43.455349 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'fname_start/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.455396 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.455448 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.455491 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.455533 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.455573 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.09378068..._datasets/src/runs/baseline_run_27032023_125754'}\u001b[0m\n",
      "\u001b[2m01:08:43.455615 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'ds_path/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.455663 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.455719 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.455762 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.455805 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.455846 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.09378068...asets/asl/asl_alphabet_train/asl_alphabet_train'}\u001b[0m\n",
      "\u001b[2m01:08:43.455891 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'name_fn/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.455938 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.455994 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.456039 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.456081 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.456123 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.09378068...: '<function get_parent_name at 0x7f547f3afa30>'}\u001b[0m\n",
      "\u001b[2m01:08:43.456165 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'global_run_count/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.456213 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.456266 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.456309 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.456352 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.456394 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[2m01:08:43.456436 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'writer/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.456477 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.456529 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.456572 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.456614 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.456656 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.09378068....writer.SummaryWriter object at 0x7f5474a0d360>'}\u001b[0m\n",
      "\u001b[2m01:08:43.456698 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'label_map/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.456745 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.456809 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.456853 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.456897 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.456939 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.09378068...P', 16: 'Q', 17: 'U', 18: 'del', 19: 'nothing'}\"}\u001b[0m\n",
      "\u001b[2m01:08:43.456980 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'rev_label_map/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.457028 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.457101 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.457147 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.457191 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.457235 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.09378068...15, 'Q': 16, 'U': 17, 'del': 18, 'nothing': 19}\"}\u001b[0m\n",
      "\u001b[2m01:08:43.457282 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'num_classes/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.457331 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.457385 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.457431 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.457475 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.457518 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.09378068... 'del': 18, 'nothing': 19}\", 'num_classes': '20'}\u001b[0m\n",
      "\u001b[2m01:08:43.457562 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'dataset_sizes/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.457611 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.457666 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.457712 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.457765 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.457833 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.09378068...dataset_sizes': \"{'train': 10000, 'val': 10000}\"}\u001b[0m\n",
      "\u001b[2m01:08:43.457882 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'criterion/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.457932 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.457988 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.458035 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.458081 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.458124 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.09378068...val': 10000}\", 'criterion': 'CrossEntropyLoss()'}\u001b[0m\n",
      "\u001b[2m01:08:43.458185 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'save_path/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.458264 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.458361 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.458508 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.458581 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.458635 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.09378068...rc/runs/baseline_run_27032023_125754/checkpoint'}\u001b[0m\n",
      "\u001b[2m01:08:43.458683 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'final_acc/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.458736 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.458796 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.458845 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.458897 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.458943 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.09378068...27032023_125754/checkpoint', 'final_acc': '5.07'}\u001b[0m\n",
      "\u001b[2m01:08:43.459001 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[2m01:08:43.459064 line        85\u001b[0m         if tag == \"images\" and save_ims == True:\n",
      "\u001b[2m01:08:43.459111 line        46\u001b[0m     for tag in all_tags.keys():\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtag = 'graph'\u001b[0m\n",
      "\u001b[2m01:08:43.459158 line        47\u001b[0m         if tag == \"scalars\":\n",
      "\u001b[2m01:08:43.459209 line        59\u001b[0m         if tag == \"tensors\":\n",
      "\u001b[2m01:08:43.459255 line        85\u001b[0m         if tag == \"images\" and save_ims == True:\n",
      "\u001b[2m01:08:43.459300 line        46\u001b[0m     for tag in all_tags.keys():\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtag = 'meta_graph'\u001b[0m\n",
      "\u001b[2m01:08:43.459346 line        47\u001b[0m         if tag == \"scalars\":\n",
      "\u001b[2m01:08:43.459396 line        59\u001b[0m         if tag == \"tensors\":\n",
      "\u001b[2m01:08:43.459440 line        85\u001b[0m         if tag == \"images\" and save_ims == True:\n",
      "\u001b[2m01:08:43.459506 line        46\u001b[0m     for tag in all_tags.keys():\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtag = 'run_metadata'\u001b[0m\n",
      "\u001b[2m01:08:43.459552 line        47\u001b[0m         if tag == \"scalars\":\n",
      "\u001b[2m01:08:43.459603 line        59\u001b[0m         if tag == \"tensors\":\n",
      "\u001b[2m01:08:43.459648 line        85\u001b[0m         if tag == \"images\" and save_ims == True:\n",
      "\u001b[2m01:08:43.459692 line        46\u001b[0m     for tag in all_tags.keys():\n",
      "\u001b[2m01:08:43.459738 line        96\u001b[0m     return temp_dict\n",
      "\u001b[2m01:08:43.459783 return      96\u001b[0m     return temp_dict\n",
      "\u001b[36m\u001b[2mReturn value:.. \u001b[22m{'proxy_step': 'False', 'Loss/Train': 0.09378068...27032023_125754/checkpoint', 'final_acc': '5.07'}\u001b[0m\n",
      "\u001b[33m\u001b[2mElapsed time: \u001b[22m00:00:00.014475\u001b[0m\n",
      "runs/baseline_run_27032023_131945/events.out.tfevents.1679915985.eragon\n",
      "\u001b[32m\u001b[2mStarting var:.. \u001b[22mevent_acc = <tensorboard.backend.event_processing.event_accumulator.EventAccumulator object at 0x7f5b568ed540>\u001b[0m\n",
      "\u001b[32m\u001b[2mStarting var:.. \u001b[22msave_ims = False\u001b[0m\n",
      "\u001b[2m01:08:43.474527 call        42\u001b[0m def process_event_acc(event_acc, save_ims = False):\n",
      "\u001b[2m01:08:43.474659 line        44\u001b[0m     all_tags = event_acc.Tags()\n",
      "\u001b[32m\u001b[2mNew var:....... \u001b[22mall_tags = {'images': [], 'audio': [], 'histograms': [], 's...: False, 'meta_graph': False, 'run_metadata': []}\u001b[0m\n",
      "\u001b[2m01:08:43.474729 line        45\u001b[0m     temp_dict = {}\n",
      "\u001b[32m\u001b[2mNew var:....... \u001b[22mtemp_dict = {}\u001b[0m\n",
      "\u001b[2m01:08:43.474800 line        46\u001b[0m     for tag in all_tags.keys():\n",
      "\u001b[32m\u001b[2mNew var:....... \u001b[22mtag = 'images'\u001b[0m\n",
      "\u001b[2m01:08:43.474939 line        47\u001b[0m         if tag == \"scalars\":\n",
      "\u001b[2m01:08:43.475005 line        59\u001b[0m         if tag == \"tensors\":\n",
      "\u001b[2m01:08:43.475065 line        85\u001b[0m         if tag == \"images\" and save_ims == True:\n",
      "\u001b[2m01:08:43.475116 line        46\u001b[0m     for tag in all_tags.keys():\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtag = 'audio'\u001b[0m\n",
      "\u001b[2m01:08:43.475162 line        47\u001b[0m         if tag == \"scalars\":\n",
      "\u001b[2m01:08:43.475215 line        59\u001b[0m         if tag == \"tensors\":\n",
      "\u001b[2m01:08:43.475289 line        85\u001b[0m         if tag == \"images\" and save_ims == True:\n",
      "\u001b[2m01:08:43.475338 line        46\u001b[0m     for tag in all_tags.keys():\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtag = 'histograms'\u001b[0m\n",
      "\u001b[2m01:08:43.475384 line        47\u001b[0m         if tag == \"scalars\":\n",
      "\u001b[2m01:08:43.475438 line        59\u001b[0m         if tag == \"tensors\":\n",
      "\u001b[2m01:08:43.475483 line        85\u001b[0m         if tag == \"images\" and save_ims == True:\n",
      "\u001b[2m01:08:43.475527 line        46\u001b[0m     for tag in all_tags.keys():\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtag = 'scalars'\u001b[0m\n",
      "\u001b[2m01:08:43.475571 line        47\u001b[0m         if tag == \"scalars\":\n",
      "\u001b[2m01:08:43.475629 line        48\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mNew var:....... \u001b[22msubtag = 'proxy_step'\u001b[0m\n",
      "\u001b[2m01:08:43.475679 line        50\u001b[0m                 try:\n",
      "\u001b[2m01:08:43.475738 line        51\u001b[0m                     temp_dict[subtag] = [tag[-1] for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.475807 exception   51\u001b[0m                     temp_dict[subtag] = [tag[-1] for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[31mException:..... \u001b[1mTypeError: 'ScalarEvent' object is not subscriptable\u001b[0m\n",
      "\u001b[2m01:08:43.475987 line        54\u001b[0m                 except:\n",
      "\u001b[2m01:08:43.476044 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.476108 line        56\u001b[0m                     -1\n",
      "\u001b[2m01:08:43.476143 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.476182 line        57\u001b[0m                 ].value\n",
      "\u001b[2m01:08:43.476231 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0}\u001b[0m\n",
      "\u001b[2m01:08:43.476279 line        48\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'Loss/Train'\u001b[0m\n",
      "\u001b[2m01:08:43.476340 line        50\u001b[0m                 try:\n",
      "\u001b[2m01:08:43.476396 line        51\u001b[0m                     temp_dict[subtag] = [tag[-1] for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.476457 exception   51\u001b[0m                     temp_dict[subtag] = [tag[-1] for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[31mException:..... \u001b[1mTypeError: 'ScalarEvent' object is not subscriptable\u001b[0m\n",
      "\u001b[2m01:08:43.476542 line        54\u001b[0m                 except:\n",
      "\u001b[2m01:08:43.476594 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.476656 line        56\u001b[0m                     -1\n",
      "\u001b[2m01:08:43.476706 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.476760 line        57\u001b[0m                 ].value\n",
      "\u001b[2m01:08:43.476809 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': nan}\u001b[0m\n",
      "\u001b[2m01:08:43.476861 line        48\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'Acc/Train'\u001b[0m\n",
      "\u001b[2m01:08:43.476919 line        50\u001b[0m                 try:\n",
      "\u001b[2m01:08:43.476976 line        51\u001b[0m                     temp_dict[subtag] = [tag[-1] for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.477089 exception   51\u001b[0m                     temp_dict[subtag] = [tag[-1] for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[31mException:..... \u001b[1mTypeError: 'ScalarEvent' object is not subscriptable\u001b[0m\n",
      "\u001b[2m01:08:43.477180 line        54\u001b[0m                 except:\n",
      "\u001b[2m01:08:43.477235 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.477298 line        56\u001b[0m                     -1\n",
      "\u001b[2m01:08:43.477351 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.477402 line        57\u001b[0m                 ].value\n",
      "\u001b[2m01:08:43.477451 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': nan, 'Acc/Train': 10.179513931274414}\u001b[0m\n",
      "\u001b[2m01:08:43.477500 line        48\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'global_run_count'\u001b[0m\n",
      "\u001b[2m01:08:43.477559 line        50\u001b[0m                 try:\n",
      "\u001b[2m01:08:43.477648 line        51\u001b[0m                     temp_dict[subtag] = [tag[-1] for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.477713 exception   51\u001b[0m                     temp_dict[subtag] = [tag[-1] for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[31mException:..... \u001b[1mTypeError: 'ScalarEvent' object is not subscriptable\u001b[0m\n",
      "\u001b[2m01:08:43.477799 line        54\u001b[0m                 except:\n",
      "\u001b[2m01:08:43.477855 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.477923 line        56\u001b[0m                     -1\n",
      "\u001b[2m01:08:43.477976 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.478030 line        57\u001b[0m                 ].value\n",
      "\u001b[2m01:08:43.478082 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': nan, 'Acc/Train': 10.179513931274414, 'global_run_count': 20.0}\u001b[0m\n",
      "\u001b[2m01:08:43.478133 line        48\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'Loss/Val'\u001b[0m\n",
      "\u001b[2m01:08:43.478199 line        50\u001b[0m                 try:\n",
      "\u001b[2m01:08:43.478260 line        51\u001b[0m                     temp_dict[subtag] = [tag[-1] for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.478325 exception   51\u001b[0m                     temp_dict[subtag] = [tag[-1] for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[31mException:..... \u001b[1mTypeError: 'ScalarEvent' object is not subscriptable\u001b[0m\n",
      "\u001b[2m01:08:43.478411 line        54\u001b[0m                 except:\n",
      "\u001b[2m01:08:43.478466 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.478530 line        56\u001b[0m                     -1\n",
      "\u001b[2m01:08:43.478584 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.478635 line        57\u001b[0m                 ].value\n",
      "\u001b[2m01:08:43.478686 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': nan, 'Acc/Trai...74414, 'global_run_count': 20.0, 'Loss/Val': nan}\u001b[0m\n",
      "\u001b[2m01:08:43.478740 line        48\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'Acc/Val'\u001b[0m\n",
      "\u001b[2m01:08:43.478802 line        50\u001b[0m                 try:\n",
      "\u001b[2m01:08:43.478862 line        51\u001b[0m                     temp_dict[subtag] = [tag[-1] for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.478926 exception   51\u001b[0m                     temp_dict[subtag] = [tag[-1] for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[31mException:..... \u001b[1mTypeError: 'ScalarEvent' object is not subscriptable\u001b[0m\n",
      "\u001b[2m01:08:43.479012 line        54\u001b[0m                 except:\n",
      "\u001b[2m01:08:43.479068 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.479135 line        56\u001b[0m                     -1\n",
      "\u001b[2m01:08:43.479194 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.479244 line        57\u001b[0m                 ].value\n",
      "\u001b[2m01:08:43.479296 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': nan, 'Acc/Trai..., 'Loss/Val': nan, 'Acc/Val': 10.160540580749512}\u001b[0m\n",
      "\u001b[2m01:08:43.479351 line        48\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[2m01:08:43.479418 line        59\u001b[0m         if tag == \"tensors\":\n",
      "\u001b[2m01:08:43.479474 line        85\u001b[0m         if tag == \"images\" and save_ims == True:\n",
      "\u001b[2m01:08:43.479529 line        46\u001b[0m     for tag in all_tags.keys():\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtag = 'distributions'\u001b[0m\n",
      "\u001b[2m01:08:43.479582 line        47\u001b[0m         if tag == \"scalars\":\n",
      "\u001b[2m01:08:43.479644 line        59\u001b[0m         if tag == \"tensors\":\n",
      "\u001b[2m01:08:43.479698 line        85\u001b[0m         if tag == \"images\" and save_ims == True:\n",
      "\u001b[2m01:08:43.479753 line        46\u001b[0m     for tag in all_tags.keys():\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtag = 'tensors'\u001b[0m\n",
      "\u001b[2m01:08:43.479835 line        47\u001b[0m         if tag == \"scalars\":\n",
      "\u001b[2m01:08:43.479917 line        59\u001b[0m         if tag == \"tensors\":\n",
      "\u001b[2m01:08:43.479973 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'experiment_name/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.480029 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.480107 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.480170 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.480230 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.480287 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': nan, 'Acc/Trai...0540580749512, 'experiment_name': 'baseline_run'}\u001b[0m\n",
      "\u001b[2m01:08:43.480350 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'image_size/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.480432 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.480510 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.480571 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.480628 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.480681 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': nan, 'Acc/Trai...iment_name': 'baseline_run', 'image_size': '224'}\u001b[0m\n",
      "\u001b[2m01:08:43.480743 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'batch_size/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.480846 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.480938 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.481006 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.481065 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.481121 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': nan, 'Acc/Trai...ne_run', 'image_size': '224', 'batch_size': '32'}\u001b[0m\n",
      "\u001b[2m01:08:43.481177 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'enable_proxy_attention/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.481244 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.481322 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.481382 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.481441 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.481500 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': nan, 'Acc/Trai...ch_size': '32', 'enable_proxy_attention': 'True'}\u001b[0m\n",
      "\u001b[2m01:08:43.481557 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'transfer_imagenet/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.481624 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.481704 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.481799 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.481865 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.481933 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': nan, 'Acc/Trai..._attention': 'True', 'transfer_imagenet': 'True'}\u001b[0m\n",
      "\u001b[2m01:08:43.481997 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'subset_images/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.482075 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.482164 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.482231 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.482297 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.482363 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': nan, 'Acc/Trai...sfer_imagenet': 'True', 'subset_images': '20000'}\u001b[0m\n",
      "\u001b[2m01:08:43.482426 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'pixel_replacement_method/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.482505 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.482594 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.482660 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.482723 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.482779 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': nan, 'Acc/Trai...: '20000', 'pixel_replacement_method': 'blended'}\u001b[0m\n",
      "\u001b[2m01:08:43.482834 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'proxy_steps/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.482952 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.483048 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.483117 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.483185 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.483248 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': nan, 'Acc/Trai...cement_method': 'blended', 'proxy_steps': '[20]'}\u001b[0m\n",
      "\u001b[2m01:08:43.483311 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'load_proxy_data/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.483388 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.483469 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.483538 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.483597 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.483653 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': nan, 'Acc/Trai...proxy_steps': '[20]', 'load_proxy_data': 'False'}\u001b[0m\n",
      "\u001b[2m01:08:43.483707 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'proxy_step/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.483789 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.483892 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.483954 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.484011 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.484084 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': nan, 'Acc/...proxy_steps': '[20]', 'load_proxy_data': 'False'}\u001b[0m\n",
      "\u001b[2m01:08:43.484148 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'log_every/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.484216 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.484294 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.484362 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.484430 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.484495 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': nan, 'Acc/...]', 'load_proxy_data': 'False', 'log_every': '2'}\u001b[0m\n",
      "\u001b[2m01:08:43.484559 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'device/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.484638 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.484726 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.484793 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.484861 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.484928 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': nan, 'Acc/...': 'False', 'log_every': '2', 'device': 'cuda:0'}\u001b[0m\n",
      "\u001b[2m01:08:43.484993 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'dataset_info/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.485075 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.485204 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.485277 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.485345 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.485418 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': nan, 'Acc/...t_name at 0x7f0557797a30>, 'num_classes': 101}}\"}\u001b[0m\n",
      "\u001b[2m01:08:43.485485 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'main_run_dir/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.485577 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.485683 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.485764 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.485843 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.486240 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': nan, 'Acc/...DE/Github/improving_robotics_datasets/src/runs/'}\u001b[0m\n",
      "\u001b[2m01:08:43.486352 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'change_subset_attention/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.486452 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.486563 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.486644 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.486725 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.486802 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': nan, 'Acc/...ets/src/runs/', 'change_subset_attention': '0.8'}\u001b[0m\n",
      "\u001b[2m01:08:43.486878 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'model/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.486973 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.487087 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.487169 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.487251 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.487329 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': nan, 'Acc/...hange_subset_attention': '0.8', 'model': 'vgg16'}\u001b[0m\n",
      "\u001b[2m01:08:43.487409 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'proxy_image_weight/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.487510 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.487612 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.487691 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.487770 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.487848 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': nan, 'Acc/...', 'model': 'vgg16', 'proxy_image_weight': '0.1'}\u001b[0m\n",
      "\u001b[2m01:08:43.487925 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'proxy_threshold/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.488021 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.488150 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.488245 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.488325 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.488619 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': nan, 'Acc/..._image_weight': '0.1', 'proxy_threshold': '0.85'}\u001b[0m\n",
      "\u001b[2m01:08:43.488730 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'gradient_method/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.488835 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.488947 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.489031 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.489110 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.489219 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': nan, 'Acc/...d': '0.85', 'gradient_method': 'gradcamplusplus'}\u001b[0m\n",
      "\u001b[2m01:08:43.489298 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'ds_name/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.489390 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.489495 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.489575 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.489654 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.489735 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': nan, 'Acc/...hod': 'gradcamplusplus', 'ds_name': 'imagenette'}\u001b[0m\n",
      "\u001b[2m01:08:43.489814 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'clear_every_step/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.489910 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.490017 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.490456 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.490560 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.490646 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': nan, 'Acc/..._name': 'imagenette', 'clear_every_step': 'True'}\u001b[0m\n",
      "\u001b[2m01:08:43.490732 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'fname_start/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.490827 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.490938 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.491022 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.491104 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.491183 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': nan, 'Acc/..._datasets/src/runs/baseline_run_27032023_131945'}\u001b[0m\n",
      "\u001b[2m01:08:43.491284 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'ds_path/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.491383 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.491488 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.491571 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.491649 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.491727 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': nan, 'Acc/...media/eragon/HDD/Datasets/imagenette2-320/train'}\u001b[0m\n",
      "\u001b[2m01:08:43.491806 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'name_fn/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.491903 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.492009 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.492091 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.492173 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.492256 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': nan, 'Acc/...: '<function get_parent_name at 0x7f0557797a30>'}\u001b[0m\n",
      "\u001b[2m01:08:43.492335 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'global_run_count/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.492432 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.492536 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.492618 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.492696 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.492772 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[2m01:08:43.492848 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'writer/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.492927 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.493034 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.493115 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.493191 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.493271 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': nan, 'Acc/....writer.SummaryWriter object at 0x7f053ce8d270>'}\u001b[0m\n",
      "\u001b[2m01:08:43.493347 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'label_map/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.493442 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.493549 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.493633 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.493724 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.493806 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': nan, 'Acc/...7: 'n03425413', 8: 'n03445777', 9: 'n03888257'}\"}\u001b[0m\n",
      "\u001b[2m01:08:43.493885 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'rev_label_map/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.493982 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.494089 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.494175 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.494280 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.494357 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': nan, 'Acc/...'n03425413': 7, 'n03445777': 8, 'n03888257': 9}\"}\u001b[0m\n",
      "\u001b[2m01:08:43.494426 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'num_classes/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.494482 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.494564 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.494614 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.494694 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.494777 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': nan, 'Acc/...45777': 8, 'n03888257': 9}\", 'num_classes': '10'}\u001b[0m\n",
      "\u001b[2m01:08:43.494850 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'dataset_sizes/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.494938 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.495036 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.495120 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.495197 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.495273 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': nan, 'Acc/... 'dataset_sizes': \"{'train': 4735, 'val': 4734}\"}\u001b[0m\n",
      "\u001b[2m01:08:43.495345 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'criterion/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.495436 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.495522 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.495579 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.495627 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.495675 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': nan, 'Acc/...'val': 4734}\", 'criterion': 'CrossEntropyLoss()'}\u001b[0m\n",
      "\u001b[2m01:08:43.495755 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'save_path/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.495846 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.495951 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.496036 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.496123 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.496211 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': nan, 'Acc/...rc/runs/baseline_run_27032023_131945/checkpoint'}\u001b[0m\n",
      "\u001b[2m01:08:43.496297 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'final_acc/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.496388 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.496496 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.496579 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.496665 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.496743 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': nan, 'Acc/...5/checkpoint', 'final_acc': '10.160540768905788'}\u001b[0m\n",
      "\u001b[2m01:08:43.496828 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[2m01:08:43.496901 line        85\u001b[0m         if tag == \"images\" and save_ims == True:\n",
      "\u001b[2m01:08:43.496977 line        46\u001b[0m     for tag in all_tags.keys():\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtag = 'graph'\u001b[0m\n",
      "\u001b[2m01:08:43.497031 line        47\u001b[0m         if tag == \"scalars\":\n",
      "\u001b[2m01:08:43.497111 line        59\u001b[0m         if tag == \"tensors\":\n",
      "\u001b[2m01:08:43.497162 line        85\u001b[0m         if tag == \"images\" and save_ims == True:\n",
      "\u001b[2m01:08:43.497208 line        46\u001b[0m     for tag in all_tags.keys():\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtag = 'meta_graph'\u001b[0m\n",
      "\u001b[2m01:08:43.497302 line        47\u001b[0m         if tag == \"scalars\":\n",
      "\u001b[2m01:08:43.497359 line        59\u001b[0m         if tag == \"tensors\":\n",
      "\u001b[2m01:08:43.497404 line        85\u001b[0m         if tag == \"images\" and save_ims == True:\n",
      "\u001b[2m01:08:43.497466 line        46\u001b[0m     for tag in all_tags.keys():\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtag = 'run_metadata'\u001b[0m\n",
      "\u001b[2m01:08:43.497514 line        47\u001b[0m         if tag == \"scalars\":\n",
      "\u001b[2m01:08:43.497564 line        59\u001b[0m         if tag == \"tensors\":\n",
      "\u001b[2m01:08:43.497623 line        85\u001b[0m         if tag == \"images\" and save_ims == True:\n",
      "\u001b[2m01:08:43.497672 line        46\u001b[0m     for tag in all_tags.keys():\n",
      "\u001b[2m01:08:43.497716 line        96\u001b[0m     return temp_dict\n",
      "\u001b[2m01:08:43.497761 return      96\u001b[0m     return temp_dict\n",
      "\u001b[36m\u001b[2mReturn value:.. \u001b[22m{'proxy_step': 'False', 'Loss/Train': nan, 'Acc/...5/checkpoint', 'final_acc': '10.160540768905788'}\u001b[0m\n",
      "\u001b[33m\u001b[2mElapsed time: \u001b[22m00:00:00.023355\u001b[0m\n",
      "runs/baseline_run_27032023_133419/events.out.tfevents.1679916859.eragon\n",
      "\u001b[32m\u001b[2mStarting var:.. \u001b[22mevent_acc = <tensorboard.backend.event_processing.event_accumulator.EventAccumulator object at 0x7f5b568efa00>\u001b[0m\n",
      "\u001b[32m\u001b[2mStarting var:.. \u001b[22msave_ims = False\u001b[0m\n",
      "\u001b[2m01:08:43.506208 call        42\u001b[0m def process_event_acc(event_acc, save_ims = False):\n",
      "\u001b[2m01:08:43.506327 line        44\u001b[0m     all_tags = event_acc.Tags()\n",
      "\u001b[32m\u001b[2mNew var:....... \u001b[22mall_tags = {'images': [], 'audio': [], 'histograms': [], 's...: False, 'meta_graph': False, 'run_metadata': []}\u001b[0m\n",
      "\u001b[2m01:08:43.506397 line        45\u001b[0m     temp_dict = {}\n",
      "\u001b[32m\u001b[2mNew var:....... \u001b[22mtemp_dict = {}\u001b[0m\n",
      "\u001b[2m01:08:43.506462 line        46\u001b[0m     for tag in all_tags.keys():\n",
      "\u001b[32m\u001b[2mNew var:....... \u001b[22mtag = 'images'\u001b[0m\n",
      "\u001b[2m01:08:43.506507 line        47\u001b[0m         if tag == \"scalars\":\n",
      "\u001b[2m01:08:43.506564 line        59\u001b[0m         if tag == \"tensors\":\n",
      "\u001b[2m01:08:43.506600 line        85\u001b[0m         if tag == \"images\" and save_ims == True:\n",
      "\u001b[2m01:08:43.506632 line        46\u001b[0m     for tag in all_tags.keys():\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtag = 'audio'\u001b[0m\n",
      "\u001b[2m01:08:43.506661 line        47\u001b[0m         if tag == \"scalars\":\n",
      "\u001b[2m01:08:43.506696 line        59\u001b[0m         if tag == \"tensors\":\n",
      "\u001b[2m01:08:43.506740 line        85\u001b[0m         if tag == \"images\" and save_ims == True:\n",
      "\u001b[2m01:08:43.506803 line        46\u001b[0m     for tag in all_tags.keys():\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtag = 'histograms'\u001b[0m\n",
      "\u001b[2m01:08:43.506833 line        47\u001b[0m         if tag == \"scalars\":\n",
      "\u001b[2m01:08:43.506868 line        59\u001b[0m         if tag == \"tensors\":\n",
      "\u001b[2m01:08:43.506907 line        85\u001b[0m         if tag == \"images\" and save_ims == True:\n",
      "\u001b[2m01:08:43.506953 line        46\u001b[0m     for tag in all_tags.keys():\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtag = 'scalars'\u001b[0m\n",
      "\u001b[2m01:08:43.506987 line        47\u001b[0m         if tag == \"scalars\":\n",
      "\u001b[2m01:08:43.507032 line        48\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mNew var:....... \u001b[22msubtag = 'proxy_step'\u001b[0m\n",
      "\u001b[2m01:08:43.507091 line        50\u001b[0m                 try:\n",
      "\u001b[2m01:08:43.507147 line        51\u001b[0m                     temp_dict[subtag] = [tag[-1] for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.507216 exception   51\u001b[0m                     temp_dict[subtag] = [tag[-1] for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[31mException:..... \u001b[1mTypeError: 'ScalarEvent' object is not subscriptable\u001b[0m\n",
      "\u001b[2m01:08:43.507448 line        54\u001b[0m                 except:\n",
      "\u001b[2m01:08:43.507504 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.507567 line        56\u001b[0m                     -1\n",
      "\u001b[2m01:08:43.507614 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.507661 line        57\u001b[0m                 ].value\n",
      "\u001b[2m01:08:43.507708 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0}\u001b[0m\n",
      "\u001b[2m01:08:43.507755 line        48\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'Loss/Train'\u001b[0m\n",
      "\u001b[2m01:08:43.507816 line        50\u001b[0m                 try:\n",
      "\u001b[2m01:08:43.507874 line        51\u001b[0m                     temp_dict[subtag] = [tag[-1] for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.507931 exception   51\u001b[0m                     temp_dict[subtag] = [tag[-1] for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[31mException:..... \u001b[1mTypeError: 'ScalarEvent' object is not subscriptable\u001b[0m\n",
      "\u001b[2m01:08:43.508016 line        54\u001b[0m                 except:\n",
      "\u001b[2m01:08:43.508066 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.508126 line        56\u001b[0m                     -1\n",
      "\u001b[2m01:08:43.508176 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.508222 line        57\u001b[0m                 ].value\n",
      "\u001b[2m01:08:43.508270 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 0.0719868466258049}\u001b[0m\n",
      "\u001b[2m01:08:43.508326 line        48\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'Acc/Train'\u001b[0m\n",
      "\u001b[2m01:08:43.508388 line        50\u001b[0m                 try:\n",
      "\u001b[2m01:08:43.508443 line        51\u001b[0m                     temp_dict[subtag] = [tag[-1] for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.508500 exception   51\u001b[0m                     temp_dict[subtag] = [tag[-1] for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[31mException:..... \u001b[1mTypeError: 'ScalarEvent' object is not subscriptable\u001b[0m\n",
      "\u001b[2m01:08:43.508581 line        54\u001b[0m                 except:\n",
      "\u001b[2m01:08:43.508630 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.508690 line        56\u001b[0m                     -1\n",
      "\u001b[2m01:08:43.508739 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.508791 line        57\u001b[0m                 ].value\n",
      "\u001b[2m01:08:43.508842 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 0.0719868466258049, 'Acc/Train': 9.545934677124023}\u001b[0m\n",
      "\u001b[2m01:08:43.508890 line        48\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'global_run_count'\u001b[0m\n",
      "\u001b[2m01:08:43.508949 line        50\u001b[0m                 try:\n",
      "\u001b[2m01:08:43.509042 line        51\u001b[0m                     temp_dict[subtag] = [tag[-1] for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.509120 exception   51\u001b[0m                     temp_dict[subtag] = [tag[-1] for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[31mException:..... \u001b[1mTypeError: 'ScalarEvent' object is not subscriptable\u001b[0m\n",
      "\u001b[2m01:08:43.509203 line        54\u001b[0m                 except:\n",
      "\u001b[2m01:08:43.509257 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.509330 line        56\u001b[0m                     -1\n",
      "\u001b[2m01:08:43.509383 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.509433 line        57\u001b[0m                 ].value\n",
      "\u001b[2m01:08:43.509485 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 0.071986846625...in': 9.545934677124023, 'global_run_count': 20.0}\u001b[0m\n",
      "\u001b[2m01:08:43.509537 line        48\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'Loss/Val'\u001b[0m\n",
      "\u001b[2m01:08:43.509602 line        50\u001b[0m                 try:\n",
      "\u001b[2m01:08:43.509659 line        51\u001b[0m                     temp_dict[subtag] = [tag[-1] for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.509719 exception   51\u001b[0m                     temp_dict[subtag] = [tag[-1] for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[31mException:..... \u001b[1mTypeError: 'ScalarEvent' object is not subscriptable\u001b[0m\n",
      "\u001b[2m01:08:43.509806 line        54\u001b[0m                 except:\n",
      "\u001b[2m01:08:43.509857 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.509916 line        56\u001b[0m                     -1\n",
      "\u001b[2m01:08:43.509964 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.510013 line        57\u001b[0m                 ].value\n",
      "\u001b[2m01:08:43.510060 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 0.071986846625...un_count': 20.0, 'Loss/Val': 0.07197749614715576}\u001b[0m\n",
      "\u001b[2m01:08:43.510109 line        48\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'Acc/Val'\u001b[0m\n",
      "\u001b[2m01:08:43.510202 line        50\u001b[0m                 try:\n",
      "\u001b[2m01:08:43.510264 line        51\u001b[0m                     temp_dict[subtag] = [tag[-1] for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.510327 exception   51\u001b[0m                     temp_dict[subtag] = [tag[-1] for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[31mException:..... \u001b[1mTypeError: 'ScalarEvent' object is not subscriptable\u001b[0m\n",
      "\u001b[2m01:08:43.510428 line        54\u001b[0m                 except:\n",
      "\u001b[2m01:08:43.510486 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.510552 line        56\u001b[0m                     -1\n",
      "\u001b[2m01:08:43.510610 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.510666 line        57\u001b[0m                 ].value\n",
      "\u001b[2m01:08:43.510721 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 0.071986846625...07197749614715576, 'Acc/Val': 10.477397918701172}\u001b[0m\n",
      "\u001b[2m01:08:43.510777 line        48\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[2m01:08:43.510844 line        59\u001b[0m         if tag == \"tensors\":\n",
      "\u001b[2m01:08:43.510900 line        85\u001b[0m         if tag == \"images\" and save_ims == True:\n",
      "\u001b[2m01:08:43.511000 line        46\u001b[0m     for tag in all_tags.keys():\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtag = 'distributions'\u001b[0m\n",
      "\u001b[2m01:08:43.511056 line        47\u001b[0m         if tag == \"scalars\":\n",
      "\u001b[2m01:08:43.511121 line        59\u001b[0m         if tag == \"tensors\":\n",
      "\u001b[2m01:08:43.511180 line        85\u001b[0m         if tag == \"images\" and save_ims == True:\n",
      "\u001b[2m01:08:43.511236 line        46\u001b[0m     for tag in all_tags.keys():\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtag = 'tensors'\u001b[0m\n",
      "\u001b[2m01:08:43.511290 line        47\u001b[0m         if tag == \"scalars\":\n",
      "\u001b[2m01:08:43.511392 line        59\u001b[0m         if tag == \"tensors\":\n",
      "\u001b[2m01:08:43.511451 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'experiment_name/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.511507 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.511593 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.511656 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.511719 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.511776 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 0.071986846625...7397918701172, 'experiment_name': 'baseline_run'}\u001b[0m\n",
      "\u001b[2m01:08:43.511838 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'image_size/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.511907 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.511983 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.512040 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.512098 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.512155 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 0.071986846625...iment_name': 'baseline_run', 'image_size': '224'}\u001b[0m\n",
      "\u001b[2m01:08:43.512210 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'batch_size/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.512271 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.512340 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.512426 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.512481 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.512538 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 0.071986846625...ne_run', 'image_size': '224', 'batch_size': '32'}\u001b[0m\n",
      "\u001b[2m01:08:43.512593 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'enable_proxy_attention/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.512656 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.512731 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.512789 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.512846 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.512903 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 0.071986846625...ch_size': '32', 'enable_proxy_attention': 'True'}\u001b[0m\n",
      "\u001b[2m01:08:43.512967 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'transfer_imagenet/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.513015 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.513070 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.513125 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.513166 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.513204 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 0.071986846625..._attention': 'True', 'transfer_imagenet': 'True'}\u001b[0m\n",
      "\u001b[2m01:08:43.513261 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'subset_images/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.513308 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.513362 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.513413 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.513464 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.513505 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 0.071986846625...sfer_imagenet': 'True', 'subset_images': '20000'}\u001b[0m\n",
      "\u001b[2m01:08:43.513544 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'pixel_replacement_method/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.513597 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.513655 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.513696 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.513757 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.513797 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 0.071986846625...: '20000', 'pixel_replacement_method': 'blended'}\u001b[0m\n",
      "\u001b[2m01:08:43.513835 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'proxy_steps/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.513880 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.513946 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.513988 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.514027 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.514065 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 0.071986846625...cement_method': 'blended', 'proxy_steps': '[20]'}\u001b[0m\n",
      "\u001b[2m01:08:43.514144 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'load_proxy_data/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.514192 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.514244 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.514299 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.514362 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.514415 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 0.071986846625...proxy_steps': '[20]', 'load_proxy_data': 'False'}\u001b[0m\n",
      "\u001b[2m01:08:43.514476 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'proxy_step/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.514525 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.514578 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.514618 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.514657 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.514710 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.07198684...proxy_steps': '[20]', 'load_proxy_data': 'False'}\u001b[0m\n",
      "\u001b[2m01:08:43.514763 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'log_every/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.514826 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.514878 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.514916 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.514952 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.514987 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.07198684...]', 'load_proxy_data': 'False', 'log_every': '2'}\u001b[0m\n",
      "\u001b[2m01:08:43.515022 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'device/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.515062 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.515145 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.515203 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.515261 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.515320 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.07198684...': 'False', 'log_every': '2', 'device': 'cuda:0'}\u001b[0m\n",
      "\u001b[2m01:08:43.515369 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'dataset_info/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.515411 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.515458 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.515495 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.515531 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.515566 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.07198684...t_name at 0x7fbb527d7ac0>, 'num_classes': 101}}\"}\u001b[0m\n",
      "\u001b[2m01:08:43.515602 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'main_run_dir/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.515649 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.515701 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.515742 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.515783 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.515822 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.07198684...DE/Github/improving_robotics_datasets/src/runs/'}\u001b[0m\n",
      "\u001b[2m01:08:43.515862 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'change_subset_attention/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.515907 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.515958 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.516000 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.516041 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.516081 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.07198684...ets/src/runs/', 'change_subset_attention': '0.8'}\u001b[0m\n",
      "\u001b[2m01:08:43.516121 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'model/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.516170 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.516268 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.516342 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.516408 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.516479 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.07198684...hange_subset_attention': '0.8', 'model': 'vgg16'}\u001b[0m\n",
      "\u001b[2m01:08:43.516556 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'proxy_image_weight/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.516626 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.516706 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.516794 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.516858 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.516908 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.07198684...', 'model': 'vgg16', 'proxy_image_weight': '0.1'}\u001b[0m\n",
      "\u001b[2m01:08:43.516956 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'proxy_threshold/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.517025 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.517103 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.517154 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.517212 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.517265 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.07198684..._image_weight': '0.1', 'proxy_threshold': '0.85'}\u001b[0m\n",
      "\u001b[2m01:08:43.517327 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'gradient_method/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.517412 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.517512 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.517584 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.517637 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.517684 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.07198684...d': '0.85', 'gradient_method': 'gradcamplusplus'}\u001b[0m\n",
      "\u001b[2m01:08:43.517730 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'ds_name/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.517782 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.517839 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.517883 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.517926 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.517968 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.07198684...hod': 'gradcamplusplus', 'ds_name': 'imagenette'}\u001b[0m\n",
      "\u001b[2m01:08:43.518009 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'clear_every_step/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.518058 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.518114 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.518157 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.518199 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.518242 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.07198684..._name': 'imagenette', 'clear_every_step': 'True'}\u001b[0m\n",
      "\u001b[2m01:08:43.518284 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'fname_start/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.518345 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.518402 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.518445 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.518488 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.518530 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.07198684..._datasets/src/runs/baseline_run_27032023_133419'}\u001b[0m\n",
      "\u001b[2m01:08:43.518571 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'ds_path/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.518620 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.518673 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.518716 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.518761 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.518804 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.07198684...media/eragon/HDD/Datasets/imagenette2-320/train'}\u001b[0m\n",
      "\u001b[2m01:08:43.518846 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'name_fn/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.518894 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.518951 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.518997 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.519040 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.519082 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.07198684...: '<function get_parent_name at 0x7fbb527d7ac0>'}\u001b[0m\n",
      "\u001b[2m01:08:43.519124 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'global_run_count/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.519171 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.519225 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.519284 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.519349 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.519412 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[2m01:08:43.519477 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'writer/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.519543 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.519638 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.519696 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.519753 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.519821 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.07198684....writer.SummaryWriter object at 0x7fbb43da6dd0>'}\u001b[0m\n",
      "\u001b[2m01:08:43.519891 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'label_map/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.519954 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.520013 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.520060 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.520104 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.520149 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.07198684...7: 'n03425413', 8: 'n03445777', 9: 'n03888257'}\"}\u001b[0m\n",
      "\u001b[2m01:08:43.520197 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'rev_label_map/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.520250 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.520311 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.520360 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.520426 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.520475 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.07198684...'n03425413': 7, 'n03445777': 8, 'n03888257': 9}\"}\u001b[0m\n",
      "\u001b[2m01:08:43.520522 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'num_classes/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.520579 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.520646 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.520696 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.520745 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.520793 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.07198684...45777': 8, 'n03888257': 9}\", 'num_classes': '10'}\u001b[0m\n",
      "\u001b[2m01:08:43.520841 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'dataset_sizes/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.520896 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.520957 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.521007 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.521056 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.521103 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.07198684... 'dataset_sizes': \"{'train': 4735, 'val': 4734}\"}\u001b[0m\n",
      "\u001b[2m01:08:43.521150 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'criterion/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.521212 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.521274 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.521324 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.521373 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.521421 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.07198684...'val': 4734}\", 'criterion': 'CrossEntropyLoss()'}\u001b[0m\n",
      "\u001b[2m01:08:43.521471 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'save_path/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.521528 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.521591 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.521641 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.521690 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.521738 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.07198684...rc/runs/baseline_run_27032023_133419/checkpoint'}\u001b[0m\n",
      "\u001b[2m01:08:43.521787 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'final_acc/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.521864 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.521943 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.521996 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.522053 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.522114 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.07198684...9/checkpoint', 'final_acc': '10.477397549640896'}\u001b[0m\n",
      "\u001b[2m01:08:43.522166 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[2m01:08:43.522227 line        85\u001b[0m         if tag == \"images\" and save_ims == True:\n",
      "\u001b[2m01:08:43.522307 line        46\u001b[0m     for tag in all_tags.keys():\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtag = 'graph'\u001b[0m\n",
      "\u001b[2m01:08:43.522385 line        47\u001b[0m         if tag == \"scalars\":\n",
      "\u001b[2m01:08:43.522473 line        59\u001b[0m         if tag == \"tensors\":\n",
      "\u001b[2m01:08:43.522557 line        85\u001b[0m         if tag == \"images\" and save_ims == True:\n",
      "\u001b[2m01:08:43.522639 line        46\u001b[0m     for tag in all_tags.keys():\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtag = 'meta_graph'\u001b[0m\n",
      "\u001b[2m01:08:43.522725 line        47\u001b[0m         if tag == \"scalars\":\n",
      "\u001b[2m01:08:43.522820 line        59\u001b[0m         if tag == \"tensors\":\n",
      "\u001b[2m01:08:43.522897 line        85\u001b[0m         if tag == \"images\" and save_ims == True:\n",
      "\u001b[2m01:08:43.522967 line        46\u001b[0m     for tag in all_tags.keys():\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtag = 'run_metadata'\u001b[0m\n",
      "\u001b[2m01:08:43.523022 line        47\u001b[0m         if tag == \"scalars\":\n",
      "\u001b[2m01:08:43.523076 line        59\u001b[0m         if tag == \"tensors\":\n",
      "\u001b[2m01:08:43.523132 line        85\u001b[0m         if tag == \"images\" and save_ims == True:\n",
      "\u001b[2m01:08:43.523190 line        46\u001b[0m     for tag in all_tags.keys():\n",
      "\u001b[2m01:08:43.523238 line        96\u001b[0m     return temp_dict\n",
      "\u001b[2m01:08:43.523283 return      96\u001b[0m     return temp_dict\n",
      "\u001b[36m\u001b[2mReturn value:.. \u001b[22m{'proxy_step': 'False', 'Loss/Train': 0.07198684...9/checkpoint', 'final_acc': '10.477397549640896'}\u001b[0m\n",
      "\u001b[33m\u001b[2mElapsed time: \u001b[22m00:00:00.017199\u001b[0m\n",
      " 83%|███████████████████████████████████▌       | 24/29 [00:00<00:00, 38.53it/s]runs/baseline_run_27032023_142831/events.out.tfevents.1679920112.eragon\n",
      "\u001b[32m\u001b[2mStarting var:.. \u001b[22mevent_acc = <tensorboard.backend.event_processing.event_accumulator.EventAccumulator object at 0x7f5b568ee6e0>\u001b[0m\n",
      "\u001b[32m\u001b[2mStarting var:.. \u001b[22msave_ims = False\u001b[0m\n",
      "\u001b[2m01:08:43.534677 call        42\u001b[0m def process_event_acc(event_acc, save_ims = False):\n",
      "\u001b[2m01:08:43.534789 line        44\u001b[0m     all_tags = event_acc.Tags()\n",
      "\u001b[32m\u001b[2mNew var:....... \u001b[22mall_tags = {'images': [], 'audio': [], 'histograms': [], 's...: False, 'meta_graph': False, 'run_metadata': []}\u001b[0m\n",
      "\u001b[2m01:08:43.534850 line        45\u001b[0m     temp_dict = {}\n",
      "\u001b[32m\u001b[2mNew var:....... \u001b[22mtemp_dict = {}\u001b[0m\n",
      "\u001b[2m01:08:43.534899 line        46\u001b[0m     for tag in all_tags.keys():\n",
      "\u001b[32m\u001b[2mNew var:....... \u001b[22mtag = 'images'\u001b[0m\n",
      "\u001b[2m01:08:43.534939 line        47\u001b[0m         if tag == \"scalars\":\n",
      "\u001b[2m01:08:43.534976 line        59\u001b[0m         if tag == \"tensors\":\n",
      "\u001b[2m01:08:43.535007 line        85\u001b[0m         if tag == \"images\" and save_ims == True:\n",
      "\u001b[2m01:08:43.535036 line        46\u001b[0m     for tag in all_tags.keys():\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtag = 'audio'\u001b[0m\n",
      "\u001b[2m01:08:43.535065 line        47\u001b[0m         if tag == \"scalars\":\n",
      "\u001b[2m01:08:43.535117 line        59\u001b[0m         if tag == \"tensors\":\n",
      "\u001b[2m01:08:43.535160 line        85\u001b[0m         if tag == \"images\" and save_ims == True:\n",
      "\u001b[2m01:08:43.535205 line        46\u001b[0m     for tag in all_tags.keys():\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtag = 'histograms'\u001b[0m\n",
      "\u001b[2m01:08:43.535249 line        47\u001b[0m         if tag == \"scalars\":\n",
      "\u001b[2m01:08:43.535308 line        59\u001b[0m         if tag == \"tensors\":\n",
      "\u001b[2m01:08:43.535353 line        85\u001b[0m         if tag == \"images\" and save_ims == True:\n",
      "\u001b[2m01:08:43.535400 line        46\u001b[0m     for tag in all_tags.keys():\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtag = 'scalars'\u001b[0m\n",
      "\u001b[2m01:08:43.535449 line        47\u001b[0m         if tag == \"scalars\":\n",
      "\u001b[2m01:08:43.535503 line        48\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mNew var:....... \u001b[22msubtag = 'proxy_step'\u001b[0m\n",
      "\u001b[2m01:08:43.535553 line        50\u001b[0m                 try:\n",
      "\u001b[2m01:08:43.535612 line        51\u001b[0m                     temp_dict[subtag] = [tag[-1] for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.535675 exception   51\u001b[0m                     temp_dict[subtag] = [tag[-1] for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[31mException:..... \u001b[1mTypeError: 'ScalarEvent' object is not subscriptable\u001b[0m\n",
      "\u001b[2m01:08:43.535814 line        54\u001b[0m                 except:\n",
      "\u001b[2m01:08:43.535852 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.535914 line        56\u001b[0m                     -1\n",
      "\u001b[2m01:08:43.535964 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.536010 line        57\u001b[0m                 ].value\n",
      "\u001b[2m01:08:43.536055 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0}\u001b[0m\n",
      "\u001b[2m01:08:43.536101 line        48\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'Loss/Train'\u001b[0m\n",
      "\u001b[2m01:08:43.536157 line        50\u001b[0m                 try:\n",
      "\u001b[2m01:08:43.536210 line        51\u001b[0m                     temp_dict[subtag] = [tag[-1] for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.536278 exception   51\u001b[0m                     temp_dict[subtag] = [tag[-1] for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[31mException:..... \u001b[1mTypeError: 'ScalarEvent' object is not subscriptable\u001b[0m\n",
      "\u001b[2m01:08:43.536375 line        54\u001b[0m                 except:\n",
      "\u001b[2m01:08:43.536434 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.536488 line        56\u001b[0m                     -1\n",
      "\u001b[2m01:08:43.536539 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.536577 line        57\u001b[0m                 ].value\n",
      "\u001b[2m01:08:43.536613 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 4.991223249817267e-05}\u001b[0m\n",
      "\u001b[2m01:08:43.536663 line        48\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'Acc/Train'\u001b[0m\n",
      "\u001b[2m01:08:43.536726 line        50\u001b[0m                 try:\n",
      "\u001b[2m01:08:43.536789 line        51\u001b[0m                     temp_dict[subtag] = [tag[-1] for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.536856 exception   51\u001b[0m                     temp_dict[subtag] = [tag[-1] for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[31mException:..... \u001b[1mTypeError: 'ScalarEvent' object is not subscriptable\u001b[0m\n",
      "\u001b[2m01:08:43.536949 line        54\u001b[0m                 except:\n",
      "\u001b[2m01:08:43.537003 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.537096 line        56\u001b[0m                     -1\n",
      "\u001b[2m01:08:43.537152 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.537206 line        57\u001b[0m                 ].value\n",
      "\u001b[2m01:08:43.537263 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 4.991223249817267e-05, 'Acc/Train': 99.94999694824219}\u001b[0m\n",
      "\u001b[2m01:08:43.537321 line        48\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'global_run_count'\u001b[0m\n",
      "\u001b[2m01:08:43.537378 line        50\u001b[0m                 try:\n",
      "\u001b[2m01:08:43.537420 line        51\u001b[0m                     temp_dict[subtag] = [tag[-1] for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.537465 exception   51\u001b[0m                     temp_dict[subtag] = [tag[-1] for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[31mException:..... \u001b[1mTypeError: 'ScalarEvent' object is not subscriptable\u001b[0m\n",
      "\u001b[2m01:08:43.537533 line        54\u001b[0m                 except:\n",
      "\u001b[2m01:08:43.537569 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.537613 line        56\u001b[0m                     -1\n",
      "\u001b[2m01:08:43.537648 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.537682 line        57\u001b[0m                 ].value\n",
      "\u001b[2m01:08:43.537716 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 4.991223249817...in': 99.94999694824219, 'global_run_count': 20.0}\u001b[0m\n",
      "\u001b[2m01:08:43.537750 line        48\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'Loss/Val'\u001b[0m\n",
      "\u001b[2m01:08:43.537791 line        50\u001b[0m                 try:\n",
      "\u001b[2m01:08:43.537831 line        51\u001b[0m                     temp_dict[subtag] = [tag[-1] for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.537872 exception   51\u001b[0m                     temp_dict[subtag] = [tag[-1] for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[31mException:..... \u001b[1mTypeError: 'ScalarEvent' object is not subscriptable\u001b[0m\n",
      "\u001b[2m01:08:43.537930 line        54\u001b[0m                 except:\n",
      "\u001b[2m01:08:43.537966 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.538009 line        56\u001b[0m                     -1\n",
      "\u001b[2m01:08:43.538044 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.538079 line        57\u001b[0m                 ].value\n",
      "\u001b[2m01:08:43.538113 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 4.991223249817..._count': 20.0, 'Loss/Val': 0.0006338467937894166}\u001b[0m\n",
      "\u001b[2m01:08:43.538146 line        48\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'Acc/Val'\u001b[0m\n",
      "\u001b[2m01:08:43.538186 line        50\u001b[0m                 try:\n",
      "\u001b[2m01:08:43.538223 line        51\u001b[0m                     temp_dict[subtag] = [tag[-1] for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.538269 exception   51\u001b[0m                     temp_dict[subtag] = [tag[-1] for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[31mException:..... \u001b[1mTypeError: 'ScalarEvent' object is not subscriptable\u001b[0m\n",
      "\u001b[2m01:08:43.538330 line        54\u001b[0m                 except:\n",
      "\u001b[2m01:08:43.538369 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.538414 line        56\u001b[0m                     -1\n",
      "\u001b[2m01:08:43.538450 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.538486 line        57\u001b[0m                 ].value\n",
      "\u001b[2m01:08:43.538523 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 4.991223249817...006338467937894166, 'Acc/Val': 98.93000030517578}\u001b[0m\n",
      "\u001b[2m01:08:43.538560 line        48\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[2m01:08:43.538605 line        59\u001b[0m         if tag == \"tensors\":\n",
      "\u001b[2m01:08:43.538642 line        85\u001b[0m         if tag == \"images\" and save_ims == True:\n",
      "\u001b[2m01:08:43.538676 line        46\u001b[0m     for tag in all_tags.keys():\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtag = 'distributions'\u001b[0m\n",
      "\u001b[2m01:08:43.538711 line        47\u001b[0m         if tag == \"scalars\":\n",
      "\u001b[2m01:08:43.538752 line        59\u001b[0m         if tag == \"tensors\":\n",
      "\u001b[2m01:08:43.538786 line        85\u001b[0m         if tag == \"images\" and save_ims == True:\n",
      "\u001b[2m01:08:43.538823 line        46\u001b[0m     for tag in all_tags.keys():\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtag = 'tensors'\u001b[0m\n",
      "\u001b[2m01:08:43.538856 line        47\u001b[0m         if tag == \"scalars\":\n",
      "\u001b[2m01:08:43.538904 line        59\u001b[0m         if tag == \"tensors\":\n",
      "\u001b[2m01:08:43.538938 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'experiment_name/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.538972 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.539020 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.539059 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.539097 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.539132 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 4.991223249817...3000030517578, 'experiment_name': 'baseline_run'}\u001b[0m\n",
      "\u001b[2m01:08:43.539166 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'image_size/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.539206 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.539252 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.539289 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.539327 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.539362 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 4.991223249817...iment_name': 'baseline_run', 'image_size': '224'}\u001b[0m\n",
      "\u001b[2m01:08:43.539397 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'batch_size/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.539436 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.539482 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.539518 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.539552 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.539587 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 4.991223249817...ne_run', 'image_size': '224', 'batch_size': '64'}\u001b[0m\n",
      "\u001b[2m01:08:43.539621 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'enable_proxy_attention/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.539661 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.539707 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.539742 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.539778 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.539812 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 4.991223249817...ch_size': '64', 'enable_proxy_attention': 'True'}\u001b[0m\n",
      "\u001b[2m01:08:43.539846 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'transfer_imagenet/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.539886 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.539931 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.539970 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.540007 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.540043 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 4.991223249817..._attention': 'True', 'transfer_imagenet': 'True'}\u001b[0m\n",
      "\u001b[2m01:08:43.540078 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'subset_images/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.540139 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.540186 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.540223 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.540258 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.540293 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 4.991223249817...sfer_imagenet': 'True', 'subset_images': '20000'}\u001b[0m\n",
      "\u001b[2m01:08:43.540328 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'pixel_replacement_method/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.540369 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.540435 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.540473 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.540509 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.540544 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 4.991223249817...: '20000', 'pixel_replacement_method': 'blended'}\u001b[0m\n",
      "\u001b[2m01:08:43.540589 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'proxy_steps/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.540639 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.540688 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.540727 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.540764 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.540800 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 4.991223249817...cement_method': 'blended', 'proxy_steps': '[20]'}\u001b[0m\n",
      "\u001b[2m01:08:43.540837 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'load_proxy_data/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.540881 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.540934 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.540973 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.541009 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.541045 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 4.991223249817...proxy_steps': '[20]', 'load_proxy_data': 'False'}\u001b[0m\n",
      "\u001b[2m01:08:43.541080 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'proxy_step/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.541129 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.541184 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.541222 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.541259 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.541293 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 4.99122324...proxy_steps': '[20]', 'load_proxy_data': 'False'}\u001b[0m\n",
      "\u001b[2m01:08:43.541328 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'log_every/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.541369 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.541415 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.541452 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.541488 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.541523 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 4.99122324...]', 'load_proxy_data': 'False', 'log_every': '2'}\u001b[0m\n",
      "\u001b[2m01:08:43.541558 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'device/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.541598 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.541644 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.541680 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.541716 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.541751 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 4.99122324...': 'False', 'log_every': '2', 'device': 'cuda:0'}\u001b[0m\n",
      "\u001b[2m01:08:43.541786 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'dataset_info/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.541826 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.541872 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.541909 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.541945 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.541980 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 4.99122324...nt_name at 0x7f51e93bbac0>, 'num_classes': 39}}\"}\u001b[0m\n",
      "\u001b[2m01:08:43.542015 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'main_run_dir/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.542062 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.542114 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.542158 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.542201 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.542243 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 4.99122324...DE/Github/improving_robotics_datasets/src/runs/'}\u001b[0m\n",
      "\u001b[2m01:08:43.542284 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'change_subset_attention/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.542331 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.542384 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.542430 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.542475 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.542517 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 4.99122324...ets/src/runs/', 'change_subset_attention': '0.8'}\u001b[0m\n",
      "\u001b[2m01:08:43.542559 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'model/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.542609 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.542665 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.542710 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.542766 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.542820 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 4.99122324...ge_subset_attention': '0.8', 'model': 'resnet18'}\u001b[0m\n",
      "\u001b[2m01:08:43.542868 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'proxy_image_weight/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.542918 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.542974 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.543019 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.543064 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.543107 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 4.99122324...'model': 'resnet18', 'proxy_image_weight': '0.1'}\u001b[0m\n",
      "\u001b[2m01:08:43.543152 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'proxy_threshold/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.543203 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.543259 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.543305 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.543353 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.543398 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 4.99122324..._image_weight': '0.1', 'proxy_threshold': '0.85'}\u001b[0m\n",
      "\u001b[2m01:08:43.543442 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'gradient_method/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.543489 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.543544 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.543587 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.543630 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.543673 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 4.99122324...d': '0.85', 'gradient_method': 'gradcamplusplus'}\u001b[0m\n",
      "\u001b[2m01:08:43.543715 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'ds_name/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.543787 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.543843 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.543888 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.543942 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.543986 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 4.99122324...d': 'gradcamplusplus', 'ds_name': 'plantdisease'}\u001b[0m\n",
      "\u001b[2m01:08:43.544029 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'clear_every_step/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.544077 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.544131 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.544175 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.544219 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.544265 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 4.99122324...ame': 'plantdisease', 'clear_every_step': 'True'}\u001b[0m\n",
      "\u001b[2m01:08:43.544320 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'fname_start/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.544370 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.544429 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.544475 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.544520 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.544564 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 4.99122324..._datasets/src/runs/baseline_run_27032023_142831'}\u001b[0m\n",
      "\u001b[2m01:08:43.544607 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'ds_path/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.544656 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.544711 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.544756 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.544800 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.544844 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 4.99122324...ant_leave_diseases_dataset_without_augmentation'}\u001b[0m\n",
      "\u001b[2m01:08:43.544888 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'name_fn/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.544942 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.545015 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.545072 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.545123 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.545169 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 4.99122324...: '<function get_parent_name at 0x7f51e93bbac0>'}\u001b[0m\n",
      "\u001b[2m01:08:43.545214 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'global_run_count/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.545263 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.545328 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.545380 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.545440 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.545488 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[2m01:08:43.545533 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'writer/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.545578 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.545636 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.545683 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.545728 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.545774 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 4.99122324....writer.SummaryWriter object at 0x7f51cea20e50>'}\u001b[0m\n",
      "\u001b[2m01:08:43.545819 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'label_map/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.545868 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.545925 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.545971 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.546020 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.546065 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 4.99122324...__Tomato_mosaic_virus', 38: 'Tomato___healthy'}\"}\u001b[0m\n",
      "\u001b[2m01:08:43.546118 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'rev_label_map/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.546176 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.546239 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.546293 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.546345 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.546396 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 4.99122324...mato_mosaic_virus': 37, 'Tomato___healthy': 38}\"}\u001b[0m\n",
      "\u001b[2m01:08:43.546447 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'num_classes/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.546509 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.546577 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.546635 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.546692 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.546750 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 4.99122324...7, 'Tomato___healthy': 38}\", 'num_classes': '39'}\u001b[0m\n",
      "\u001b[2m01:08:43.546806 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'dataset_sizes/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.546868 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.546937 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.546995 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.547065 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.547125 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 4.99122324...dataset_sizes': \"{'train': 10000, 'val': 10000}\"}\u001b[0m\n",
      "\u001b[2m01:08:43.547191 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'criterion/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.547258 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.547331 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.547391 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.547450 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.547507 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 4.99122324...val': 10000}\", 'criterion': 'CrossEntropyLoss()'}\u001b[0m\n",
      "\u001b[2m01:08:43.547563 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'save_path/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.547626 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.547694 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.547752 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.547810 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.547867 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 4.99122324...rc/runs/baseline_run_27032023_142831/checkpoint'}\u001b[0m\n",
      "\u001b[2m01:08:43.547924 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'final_acc/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.547987 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.548056 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.548114 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.548171 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.548229 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 4.99122324...7032023_142831/checkpoint', 'final_acc': '98.93'}\u001b[0m\n",
      "\u001b[2m01:08:43.548286 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[2m01:08:43.548349 line        85\u001b[0m         if tag == \"images\" and save_ims == True:\n",
      "\u001b[2m01:08:43.548407 line        46\u001b[0m     for tag in all_tags.keys():\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtag = 'graph'\u001b[0m\n",
      "\u001b[2m01:08:43.548473 line        47\u001b[0m         if tag == \"scalars\":\n",
      "\u001b[2m01:08:43.548536 line        59\u001b[0m         if tag == \"tensors\":\n",
      "\u001b[2m01:08:43.548593 line        85\u001b[0m         if tag == \"images\" and save_ims == True:\n",
      "\u001b[2m01:08:43.548649 line        46\u001b[0m     for tag in all_tags.keys():\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtag = 'meta_graph'\u001b[0m\n",
      "\u001b[2m01:08:43.548705 line        47\u001b[0m         if tag == \"scalars\":\n",
      "\u001b[2m01:08:43.548766 line        59\u001b[0m         if tag == \"tensors\":\n",
      "\u001b[2m01:08:43.548822 line        85\u001b[0m         if tag == \"images\" and save_ims == True:\n",
      "\u001b[2m01:08:43.548879 line        46\u001b[0m     for tag in all_tags.keys():\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtag = 'run_metadata'\u001b[0m\n",
      "\u001b[2m01:08:43.548935 line        47\u001b[0m         if tag == \"scalars\":\n",
      "\u001b[2m01:08:43.548995 line        59\u001b[0m         if tag == \"tensors\":\n",
      "\u001b[2m01:08:43.549050 line        85\u001b[0m         if tag == \"images\" and save_ims == True:\n",
      "\u001b[2m01:08:43.549105 line        46\u001b[0m     for tag in all_tags.keys():\n",
      "\u001b[2m01:08:43.549160 line        96\u001b[0m     return temp_dict\n",
      "\u001b[2m01:08:43.549235 return      96\u001b[0m     return temp_dict\n",
      "\u001b[36m\u001b[2mReturn value:.. \u001b[22m{'proxy_step': 'False', 'Loss/Train': 4.99122324...7032023_142831/checkpoint', 'final_acc': '98.93'}\u001b[0m\n",
      "\u001b[33m\u001b[2mElapsed time: \u001b[22m00:00:00.014692\u001b[0m\n",
      "runs/baseline_run_27032023_143750/events.out.tfevents.1679920670.eragon\n",
      "\u001b[32m\u001b[2mStarting var:.. \u001b[22mevent_acc = <tensorboard.backend.event_processing.event_accumulator.EventAccumulator object at 0x7f5b568efdf0>\u001b[0m\n",
      "\u001b[32m\u001b[2mStarting var:.. \u001b[22msave_ims = False\u001b[0m\n",
      "\u001b[2m01:08:43.557543 call        42\u001b[0m def process_event_acc(event_acc, save_ims = False):\n",
      "\u001b[2m01:08:43.557672 line        44\u001b[0m     all_tags = event_acc.Tags()\n",
      "\u001b[32m\u001b[2mNew var:....... \u001b[22mall_tags = {'images': [], 'audio': [], 'histograms': [], 's...: False, 'meta_graph': False, 'run_metadata': []}\u001b[0m\n",
      "\u001b[2m01:08:43.557761 line        45\u001b[0m     temp_dict = {}\n",
      "\u001b[32m\u001b[2mNew var:....... \u001b[22mtemp_dict = {}\u001b[0m\n",
      "\u001b[2m01:08:43.557848 line        46\u001b[0m     for tag in all_tags.keys():\n",
      "\u001b[32m\u001b[2mNew var:....... \u001b[22mtag = 'images'\u001b[0m\n",
      "\u001b[2m01:08:43.557920 line        47\u001b[0m         if tag == \"scalars\":\n",
      "\u001b[2m01:08:43.557993 line        59\u001b[0m         if tag == \"tensors\":\n",
      "\u001b[2m01:08:43.558027 line        85\u001b[0m         if tag == \"images\" and save_ims == True:\n",
      "\u001b[2m01:08:43.558057 line        46\u001b[0m     for tag in all_tags.keys():\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtag = 'audio'\u001b[0m\n",
      "\u001b[2m01:08:43.558085 line        47\u001b[0m         if tag == \"scalars\":\n",
      "\u001b[2m01:08:43.558132 line        59\u001b[0m         if tag == \"tensors\":\n",
      "\u001b[2m01:08:43.558171 line        85\u001b[0m         if tag == \"images\" and save_ims == True:\n",
      "\u001b[2m01:08:43.558243 line        46\u001b[0m     for tag in all_tags.keys():\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtag = 'histograms'\u001b[0m\n",
      "\u001b[2m01:08:43.558274 line        47\u001b[0m         if tag == \"scalars\":\n",
      "\u001b[2m01:08:43.558321 line        59\u001b[0m         if tag == \"tensors\":\n",
      "\u001b[2m01:08:43.558351 line        85\u001b[0m         if tag == \"images\" and save_ims == True:\n",
      "\u001b[2m01:08:43.558379 line        46\u001b[0m     for tag in all_tags.keys():\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtag = 'scalars'\u001b[0m\n",
      "\u001b[2m01:08:43.558406 line        47\u001b[0m         if tag == \"scalars\":\n",
      "\u001b[2m01:08:43.558439 line        48\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mNew var:....... \u001b[22msubtag = 'proxy_step'\u001b[0m\n",
      "\u001b[2m01:08:43.558467 line        50\u001b[0m                 try:\n",
      "\u001b[2m01:08:43.558504 line        51\u001b[0m                     temp_dict[subtag] = [tag[-1] for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.558549 exception   51\u001b[0m                     temp_dict[subtag] = [tag[-1] for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[31mException:..... \u001b[1mTypeError: 'ScalarEvent' object is not subscriptable\u001b[0m\n",
      "\u001b[2m01:08:43.558688 line        54\u001b[0m                 except:\n",
      "\u001b[2m01:08:43.558723 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.558765 line        56\u001b[0m                     -1\n",
      "\u001b[2m01:08:43.558796 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.558825 line        57\u001b[0m                 ].value\n",
      "\u001b[2m01:08:43.558854 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0}\u001b[0m\n",
      "\u001b[2m01:08:43.558884 line        48\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'Loss/Train'\u001b[0m\n",
      "\u001b[2m01:08:43.558922 line        50\u001b[0m                 try:\n",
      "\u001b[2m01:08:43.558967 line        51\u001b[0m                     temp_dict[subtag] = [tag[-1] for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.559011 exception   51\u001b[0m                     temp_dict[subtag] = [tag[-1] for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[31mException:..... \u001b[1mTypeError: 'ScalarEvent' object is not subscriptable\u001b[0m\n",
      "\u001b[2m01:08:43.559077 line        54\u001b[0m                 except:\n",
      "\u001b[2m01:08:43.559111 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.559149 line        56\u001b[0m                     -1\n",
      "\u001b[2m01:08:43.559180 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.559210 line        57\u001b[0m                 ].value\n",
      "\u001b[2m01:08:43.559239 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 1.352688832412241e-05}\u001b[0m\n",
      "\u001b[2m01:08:43.559270 line        48\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'Acc/Train'\u001b[0m\n",
      "\u001b[2m01:08:43.559309 line        50\u001b[0m                 try:\n",
      "\u001b[2m01:08:43.559346 line        51\u001b[0m                     temp_dict[subtag] = [tag[-1] for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.559384 exception   51\u001b[0m                     temp_dict[subtag] = [tag[-1] for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[31mException:..... \u001b[1mTypeError: 'ScalarEvent' object is not subscriptable\u001b[0m\n",
      "\u001b[2m01:08:43.559436 line        54\u001b[0m                 except:\n",
      "\u001b[2m01:08:43.559470 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.559513 line        56\u001b[0m                     -1\n",
      "\u001b[2m01:08:43.559546 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.559577 line        57\u001b[0m                 ].value\n",
      "\u001b[2m01:08:43.559608 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 1.352688832412241e-05, 'Acc/Train': 99.98999786376953}\u001b[0m\n",
      "\u001b[2m01:08:43.559639 line        48\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'global_run_count'\u001b[0m\n",
      "\u001b[2m01:08:43.559677 line        50\u001b[0m                 try:\n",
      "\u001b[2m01:08:43.559714 line        51\u001b[0m                     temp_dict[subtag] = [tag[-1] for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.559754 exception   51\u001b[0m                     temp_dict[subtag] = [tag[-1] for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[31mException:..... \u001b[1mTypeError: 'ScalarEvent' object is not subscriptable\u001b[0m\n",
      "\u001b[2m01:08:43.559805 line        54\u001b[0m                 except:\n",
      "\u001b[2m01:08:43.559840 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.559882 line        56\u001b[0m                     -1\n",
      "\u001b[2m01:08:43.559914 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.559946 line        57\u001b[0m                 ].value\n",
      "\u001b[2m01:08:43.559977 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 1.352688832412...in': 99.98999786376953, 'global_run_count': 20.0}\u001b[0m\n",
      "\u001b[2m01:08:43.560009 line        48\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'Loss/Val'\u001b[0m\n",
      "\u001b[2m01:08:43.560055 line        50\u001b[0m                 try:\n",
      "\u001b[2m01:08:43.560097 line        51\u001b[0m                     temp_dict[subtag] = [tag[-1] for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.560137 exception   51\u001b[0m                     temp_dict[subtag] = [tag[-1] for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[31mException:..... \u001b[1mTypeError: 'ScalarEvent' object is not subscriptable\u001b[0m\n",
      "\u001b[2m01:08:43.560191 line        54\u001b[0m                 except:\n",
      "\u001b[2m01:08:43.560227 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.560268 line        56\u001b[0m                     -1\n",
      "\u001b[2m01:08:43.560301 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.560335 line        57\u001b[0m                 ].value\n",
      "\u001b[2m01:08:43.560367 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 1.352688832412...n_count': 20.0, 'Loss/Val': 0.000413578178267926}\u001b[0m\n",
      "\u001b[2m01:08:43.560428 line        48\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'Acc/Val'\u001b[0m\n",
      "\u001b[2m01:08:43.560471 line        50\u001b[0m                 try:\n",
      "\u001b[2m01:08:43.560510 line        51\u001b[0m                     temp_dict[subtag] = [tag[-1] for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.560552 exception   51\u001b[0m                     temp_dict[subtag] = [tag[-1] for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[31mException:..... \u001b[1mTypeError: 'ScalarEvent' object is not subscriptable\u001b[0m\n",
      "\u001b[2m01:08:43.560606 line        54\u001b[0m                 except:\n",
      "\u001b[2m01:08:43.560643 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.560685 line        56\u001b[0m                     -1\n",
      "\u001b[2m01:08:43.560719 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.560753 line        57\u001b[0m                 ].value\n",
      "\u001b[2m01:08:43.560785 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 1.352688832412....000413578178267926, 'Acc/Val': 99.3499984741211}\u001b[0m\n",
      "\u001b[2m01:08:43.560819 line        48\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[2m01:08:43.560860 line        59\u001b[0m         if tag == \"tensors\":\n",
      "\u001b[2m01:08:43.560894 line        85\u001b[0m         if tag == \"images\" and save_ims == True:\n",
      "\u001b[2m01:08:43.560933 line        46\u001b[0m     for tag in all_tags.keys():\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtag = 'distributions'\u001b[0m\n",
      "\u001b[2m01:08:43.560976 line        47\u001b[0m         if tag == \"scalars\":\n",
      "\u001b[2m01:08:43.561015 line        59\u001b[0m         if tag == \"tensors\":\n",
      "\u001b[2m01:08:43.561048 line        85\u001b[0m         if tag == \"images\" and save_ims == True:\n",
      "\u001b[2m01:08:43.561084 line        46\u001b[0m     for tag in all_tags.keys():\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtag = 'tensors'\u001b[0m\n",
      "\u001b[2m01:08:43.561119 line        47\u001b[0m         if tag == \"scalars\":\n",
      "\u001b[2m01:08:43.561158 line        59\u001b[0m         if tag == \"tensors\":\n",
      "\u001b[2m01:08:43.561191 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'experiment_name/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.561234 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.561315 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.561365 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.561405 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.561458 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 1.352688832412...3499984741211, 'experiment_name': 'baseline_run'}\u001b[0m\n",
      "\u001b[2m01:08:43.561498 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'image_size/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.561539 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.561588 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.561625 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.561662 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.561695 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 1.352688832412...iment_name': 'baseline_run', 'image_size': '224'}\u001b[0m\n",
      "\u001b[2m01:08:43.561729 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'batch_size/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.561769 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.561819 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.561861 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.561896 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.561944 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 1.352688832412...ne_run', 'image_size': '224', 'batch_size': '64'}\u001b[0m\n",
      "\u001b[2m01:08:43.561981 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'enable_proxy_attention/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.562022 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.562069 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.562106 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.562142 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.562176 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 1.352688832412...ch_size': '64', 'enable_proxy_attention': 'True'}\u001b[0m\n",
      "\u001b[2m01:08:43.562219 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'transfer_imagenet/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.562262 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.562308 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.562345 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.562382 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.562415 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 1.352688832412..._attention': 'True', 'transfer_imagenet': 'True'}\u001b[0m\n",
      "\u001b[2m01:08:43.562450 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'subset_images/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.562490 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.562547 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.562603 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.562663 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.562709 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 1.352688832412...sfer_imagenet': 'True', 'subset_images': '20000'}\u001b[0m\n",
      "\u001b[2m01:08:43.562746 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'pixel_replacement_method/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.562787 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.562834 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.562871 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.562907 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.562942 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 1.352688832412...: '20000', 'pixel_replacement_method': 'blended'}\u001b[0m\n",
      "\u001b[2m01:08:43.562985 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'proxy_steps/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.563025 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.563071 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.563108 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.563144 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.563178 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 1.352688832412...cement_method': 'blended', 'proxy_steps': '[20]'}\u001b[0m\n",
      "\u001b[2m01:08:43.563213 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'load_proxy_data/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.563253 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.563299 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.563343 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.563387 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.563422 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 1.352688832412...proxy_steps': '[20]', 'load_proxy_data': 'False'}\u001b[0m\n",
      "\u001b[2m01:08:43.563458 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'proxy_step/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.563498 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.563556 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.563596 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.563633 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.563678 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 1.35268883...proxy_steps': '[20]', 'load_proxy_data': 'False'}\u001b[0m\n",
      "\u001b[2m01:08:43.563716 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'log_every/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.563771 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.563818 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.563855 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.563892 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.563927 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 1.35268883...]', 'load_proxy_data': 'False', 'log_every': '2'}\u001b[0m\n",
      "\u001b[2m01:08:43.563962 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'device/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.564002 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.564053 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.564110 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.564168 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.564210 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 1.35268883...': 'False', 'log_every': '2', 'device': 'cuda:0'}\u001b[0m\n",
      "\u001b[2m01:08:43.564247 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'dataset_info/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.564288 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.564335 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.564372 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.564409 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.564444 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 1.35268883...nt_name at 0x7f48d3fcbac0>, 'num_classes': 39}}\"}\u001b[0m\n",
      "\u001b[2m01:08:43.564480 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'main_run_dir/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.564528 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.564582 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.564625 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.564668 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.564710 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 1.35268883...DE/Github/improving_robotics_datasets/src/runs/'}\u001b[0m\n",
      "\u001b[2m01:08:43.564752 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'change_subset_attention/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.564799 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.564852 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.564896 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.564939 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.564980 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 1.35268883...ets/src/runs/', 'change_subset_attention': '0.8'}\u001b[0m\n",
      "\u001b[2m01:08:43.565022 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'model/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.565071 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.565149 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.565222 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.565297 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.565355 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 1.35268883...et_attention': '0.8', 'model': 'efficientnet_b0'}\u001b[0m\n",
      "\u001b[2m01:08:43.565400 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'proxy_image_weight/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.565450 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.565507 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.565553 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.565598 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.565640 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 1.35268883...: 'efficientnet_b0', 'proxy_image_weight': '0.1'}\u001b[0m\n",
      "\u001b[2m01:08:43.565685 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'proxy_threshold/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.565748 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.565817 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.565885 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.565933 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.565976 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 1.35268883..._image_weight': '0.1', 'proxy_threshold': '0.85'}\u001b[0m\n",
      "\u001b[2m01:08:43.566019 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'gradient_method/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.566067 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.566134 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.566183 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.566228 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.566272 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 1.35268883...d': '0.85', 'gradient_method': 'gradcamplusplus'}\u001b[0m\n",
      "\u001b[2m01:08:43.566318 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'ds_name/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.566366 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.566421 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.566466 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.566510 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.566553 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 1.35268883...d': 'gradcamplusplus', 'ds_name': 'plantdisease'}\u001b[0m\n",
      "\u001b[2m01:08:43.566596 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'clear_every_step/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.566645 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.566722 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.566798 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.566847 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.566890 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 1.35268883...ame': 'plantdisease', 'clear_every_step': 'True'}\u001b[0m\n",
      "\u001b[2m01:08:43.566942 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'fname_start/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.566999 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.567068 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.567116 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.567162 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.567206 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 1.35268883..._datasets/src/runs/baseline_run_27032023_143750'}\u001b[0m\n",
      "\u001b[2m01:08:43.567250 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'ds_path/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.567299 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.567354 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.567400 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.567444 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.567492 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 1.35268883...ant_leave_diseases_dataset_without_augmentation'}\u001b[0m\n",
      "\u001b[2m01:08:43.567535 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'name_fn/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.567585 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.567640 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.567685 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.567730 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.567773 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 1.35268883...: '<function get_parent_name at 0x7f48d3fcbac0>'}\u001b[0m\n",
      "\u001b[2m01:08:43.567818 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'global_run_count/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.567867 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.567922 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.567967 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.568012 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.568064 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[2m01:08:43.568109 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'writer/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.568152 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.568207 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.568252 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.568296 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.568339 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 1.35268883....writer.SummaryWriter object at 0x7f48c56454b0>'}\u001b[0m\n",
      "\u001b[2m01:08:43.568383 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'label_map/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.568432 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.568486 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.568531 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.568576 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.568620 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 1.35268883...__Tomato_mosaic_virus', 38: 'Tomato___healthy'}\"}\u001b[0m\n",
      "\u001b[2m01:08:43.568664 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'rev_label_map/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.568720 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.568781 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.568832 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.568883 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.568934 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 1.35268883...mato_mosaic_virus': 37, 'Tomato___healthy': 38}\"}\u001b[0m\n",
      "\u001b[2m01:08:43.568984 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'num_classes/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.569045 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.569115 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.569179 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.569236 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.569307 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 1.35268883...7, 'Tomato___healthy': 38}\", 'num_classes': '39'}\u001b[0m\n",
      "\u001b[2m01:08:43.569393 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'dataset_sizes/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.569493 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.569583 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.569645 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.569704 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.569761 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 1.35268883...dataset_sizes': \"{'train': 10000, 'val': 10000}\"}\u001b[0m\n",
      "\u001b[2m01:08:43.569824 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'criterion/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.569908 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.570007 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.570071 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.570131 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.570198 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 1.35268883...val': 10000}\", 'criterion': 'CrossEntropyLoss()'}\u001b[0m\n",
      "\u001b[2m01:08:43.570261 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'save_path/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.570334 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.570437 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.570539 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.570634 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.570693 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 1.35268883...rc/runs/baseline_run_27032023_143750/checkpoint'}\u001b[0m\n",
      "\u001b[2m01:08:43.570750 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'final_acc/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.570823 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.570911 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.570974 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.571033 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.571090 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 1.35268883...7032023_143750/checkpoint', 'final_acc': '99.35'}\u001b[0m\n",
      "\u001b[2m01:08:43.571148 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[2m01:08:43.571211 line        85\u001b[0m         if tag == \"images\" and save_ims == True:\n",
      "\u001b[2m01:08:43.571269 line        46\u001b[0m     for tag in all_tags.keys():\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtag = 'graph'\u001b[0m\n",
      "\u001b[2m01:08:43.571359 line        47\u001b[0m         if tag == \"scalars\":\n",
      "\u001b[2m01:08:43.571445 line        59\u001b[0m         if tag == \"tensors\":\n",
      "\u001b[2m01:08:43.571504 line        85\u001b[0m         if tag == \"images\" and save_ims == True:\n",
      "\u001b[2m01:08:43.571561 line        46\u001b[0m     for tag in all_tags.keys():\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtag = 'meta_graph'\u001b[0m\n",
      "\u001b[2m01:08:43.571623 line        47\u001b[0m         if tag == \"scalars\":\n",
      "\u001b[2m01:08:43.571697 line        59\u001b[0m         if tag == \"tensors\":\n",
      "\u001b[2m01:08:43.571755 line        85\u001b[0m         if tag == \"images\" and save_ims == True:\n",
      "\u001b[2m01:08:43.571823 line        46\u001b[0m     for tag in all_tags.keys():\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtag = 'run_metadata'\u001b[0m\n",
      "\u001b[2m01:08:43.571883 line        47\u001b[0m         if tag == \"scalars\":\n",
      "\u001b[2m01:08:43.571956 line        59\u001b[0m         if tag == \"tensors\":\n",
      "\u001b[2m01:08:43.572013 line        85\u001b[0m         if tag == \"images\" and save_ims == True:\n",
      "\u001b[2m01:08:43.572069 line        46\u001b[0m     for tag in all_tags.keys():\n",
      "\u001b[2m01:08:43.572126 line        96\u001b[0m     return temp_dict\n",
      "\u001b[2m01:08:43.572184 return      96\u001b[0m     return temp_dict\n",
      "\u001b[36m\u001b[2mReturn value:.. \u001b[22m{'proxy_step': 'False', 'Loss/Train': 1.35268883...7032023_143750/checkpoint', 'final_acc': '99.35'}\u001b[0m\n",
      "\u001b[33m\u001b[2mElapsed time: \u001b[22m00:00:00.014793\u001b[0m\n",
      "runs/baseline_run_27032023_144800/events.out.tfevents.1679921281.eragon\n",
      "\u001b[32m\u001b[2mStarting var:.. \u001b[22mevent_acc = <tensorboard.backend.event_processing.event_accumulator.EventAccumulator object at 0x7f5b568ef5b0>\u001b[0m\n",
      "\u001b[32m\u001b[2mStarting var:.. \u001b[22msave_ims = False\u001b[0m\n",
      "\u001b[2m01:08:43.581276 call        42\u001b[0m def process_event_acc(event_acc, save_ims = False):\n",
      "\u001b[2m01:08:43.581368 line        44\u001b[0m     all_tags = event_acc.Tags()\n",
      "\u001b[32m\u001b[2mNew var:....... \u001b[22mall_tags = {'images': [], 'audio': [], 'histograms': [], 's...: False, 'meta_graph': False, 'run_metadata': []}\u001b[0m\n",
      "\u001b[2m01:08:43.581416 line        45\u001b[0m     temp_dict = {}\n",
      "\u001b[32m\u001b[2mNew var:....... \u001b[22mtemp_dict = {}\u001b[0m\n",
      "\u001b[2m01:08:43.581462 line        46\u001b[0m     for tag in all_tags.keys():\n",
      "\u001b[32m\u001b[2mNew var:....... \u001b[22mtag = 'images'\u001b[0m\n",
      "\u001b[2m01:08:43.581501 line        47\u001b[0m         if tag == \"scalars\":\n",
      "\u001b[2m01:08:43.581539 line        59\u001b[0m         if tag == \"tensors\":\n",
      "\u001b[2m01:08:43.581569 line        85\u001b[0m         if tag == \"images\" and save_ims == True:\n",
      "\u001b[2m01:08:43.581598 line        46\u001b[0m     for tag in all_tags.keys():\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtag = 'audio'\u001b[0m\n",
      "\u001b[2m01:08:43.581627 line        47\u001b[0m         if tag == \"scalars\":\n",
      "\u001b[2m01:08:43.581659 line        59\u001b[0m         if tag == \"tensors\":\n",
      "\u001b[2m01:08:43.581687 line        85\u001b[0m         if tag == \"images\" and save_ims == True:\n",
      "\u001b[2m01:08:43.581714 line        46\u001b[0m     for tag in all_tags.keys():\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtag = 'histograms'\u001b[0m\n",
      "\u001b[2m01:08:43.581742 line        47\u001b[0m         if tag == \"scalars\":\n",
      "\u001b[2m01:08:43.581799 line        59\u001b[0m         if tag == \"tensors\":\n",
      "\u001b[2m01:08:43.581843 line        85\u001b[0m         if tag == \"images\" and save_ims == True:\n",
      "\u001b[2m01:08:43.581887 line        46\u001b[0m     for tag in all_tags.keys():\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtag = 'scalars'\u001b[0m\n",
      "\u001b[2m01:08:43.581933 line        47\u001b[0m         if tag == \"scalars\":\n",
      "\u001b[2m01:08:43.581988 line        48\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mNew var:....... \u001b[22msubtag = 'proxy_step'\u001b[0m\n",
      "\u001b[2m01:08:43.582033 line        50\u001b[0m                 try:\n",
      "\u001b[2m01:08:43.582070 line        51\u001b[0m                     temp_dict[subtag] = [tag[-1] for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.582113 exception   51\u001b[0m                     temp_dict[subtag] = [tag[-1] for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[31mException:..... \u001b[1mTypeError: 'ScalarEvent' object is not subscriptable\u001b[0m\n",
      "\u001b[2m01:08:43.582245 line        54\u001b[0m                 except:\n",
      "\u001b[2m01:08:43.582280 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.582321 line        56\u001b[0m                     -1\n",
      "\u001b[2m01:08:43.582352 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.582381 line        57\u001b[0m                 ].value\n",
      "\u001b[2m01:08:43.582411 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0}\u001b[0m\n",
      "\u001b[2m01:08:43.582441 line        48\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'Loss/Train'\u001b[0m\n",
      "\u001b[2m01:08:43.582477 line        50\u001b[0m                 try:\n",
      "\u001b[2m01:08:43.582527 line        51\u001b[0m                     temp_dict[subtag] = [tag[-1] for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.582579 exception   51\u001b[0m                     temp_dict[subtag] = [tag[-1] for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[31mException:..... \u001b[1mTypeError: 'ScalarEvent' object is not subscriptable\u001b[0m\n",
      "\u001b[2m01:08:43.582681 line        54\u001b[0m                 except:\n",
      "\u001b[2m01:08:43.582734 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.582847 line        56\u001b[0m                     -1\n",
      "\u001b[2m01:08:43.582899 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.582973 line        57\u001b[0m                 ].value\n",
      "\u001b[2m01:08:43.583082 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 4.357923535280861e-05}\u001b[0m\n",
      "\u001b[2m01:08:43.583131 line        48\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'Acc/Train'\u001b[0m\n",
      "\u001b[2m01:08:43.583197 line        50\u001b[0m                 try:\n",
      "\u001b[2m01:08:43.583274 line        51\u001b[0m                     temp_dict[subtag] = [tag[-1] for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.583337 exception   51\u001b[0m                     temp_dict[subtag] = [tag[-1] for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[31mException:..... \u001b[1mTypeError: 'ScalarEvent' object is not subscriptable\u001b[0m\n",
      "\u001b[2m01:08:43.583402 line        54\u001b[0m                 except:\n",
      "\u001b[2m01:08:43.583440 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.583480 line        56\u001b[0m                     -1\n",
      "\u001b[2m01:08:43.583514 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.583579 line        57\u001b[0m                 ].value\n",
      "\u001b[2m01:08:43.583623 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 4.357923535280861e-05, 'Acc/Train': 99.95999908447266}\u001b[0m\n",
      "\u001b[2m01:08:43.583658 line        48\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'global_run_count'\u001b[0m\n",
      "\u001b[2m01:08:43.583701 line        50\u001b[0m                 try:\n",
      "\u001b[2m01:08:43.583797 line        51\u001b[0m                     temp_dict[subtag] = [tag[-1] for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.583842 exception   51\u001b[0m                     temp_dict[subtag] = [tag[-1] for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[31mException:..... \u001b[1mTypeError: 'ScalarEvent' object is not subscriptable\u001b[0m\n",
      "\u001b[2m01:08:43.583903 line        54\u001b[0m                 except:\n",
      "\u001b[2m01:08:43.583954 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.584024 line        56\u001b[0m                     -1\n",
      "\u001b[2m01:08:43.584114 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.584162 line        57\u001b[0m                 ].value\n",
      "\u001b[2m01:08:43.584200 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 4.357923535280...in': 99.95999908447266, 'global_run_count': 20.0}\u001b[0m\n",
      "\u001b[2m01:08:43.584240 line        48\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'Loss/Val'\u001b[0m\n",
      "\u001b[2m01:08:43.584288 line        50\u001b[0m                 try:\n",
      "\u001b[2m01:08:43.584336 line        51\u001b[0m                     temp_dict[subtag] = [tag[-1] for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.584379 exception   51\u001b[0m                     temp_dict[subtag] = [tag[-1] for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[31mException:..... \u001b[1mTypeError: 'ScalarEvent' object is not subscriptable\u001b[0m\n",
      "\u001b[2m01:08:43.584434 line        54\u001b[0m                 except:\n",
      "\u001b[2m01:08:43.584484 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.584530 line        56\u001b[0m                     -1\n",
      "\u001b[2m01:08:43.584564 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.584597 line        57\u001b[0m                 ].value\n",
      "\u001b[2m01:08:43.584632 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 4.357923535280..._count': 20.0, 'Loss/Val': 0.0008813623571768403}\u001b[0m\n",
      "\u001b[2m01:08:43.584678 line        48\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'Acc/Val'\u001b[0m\n",
      "\u001b[2m01:08:43.584724 line        50\u001b[0m                 try:\n",
      "\u001b[2m01:08:43.584762 line        51\u001b[0m                     temp_dict[subtag] = [tag[-1] for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.584806 exception   51\u001b[0m                     temp_dict[subtag] = [tag[-1] for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[31mException:..... \u001b[1mTypeError: 'ScalarEvent' object is not subscriptable\u001b[0m\n",
      "\u001b[2m01:08:43.584875 line        54\u001b[0m                 except:\n",
      "\u001b[2m01:08:43.584912 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.584955 line        56\u001b[0m                     -1\n",
      "\u001b[2m01:08:43.584998 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.585043 line        57\u001b[0m                 ].value\n",
      "\u001b[2m01:08:43.585078 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 4.357923535280...008813623571768403, 'Acc/Val': 99.22000122070312}\u001b[0m\n",
      "\u001b[2m01:08:43.585112 line        48\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[2m01:08:43.585153 line        59\u001b[0m         if tag == \"tensors\":\n",
      "\u001b[2m01:08:43.585204 line        85\u001b[0m         if tag == \"images\" and save_ims == True:\n",
      "\u001b[2m01:08:43.585241 line        46\u001b[0m     for tag in all_tags.keys():\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtag = 'distributions'\u001b[0m\n",
      "\u001b[2m01:08:43.585284 line        47\u001b[0m         if tag == \"scalars\":\n",
      "\u001b[2m01:08:43.585324 line        59\u001b[0m         if tag == \"tensors\":\n",
      "\u001b[2m01:08:43.585373 line        85\u001b[0m         if tag == \"images\" and save_ims == True:\n",
      "\u001b[2m01:08:43.585410 line        46\u001b[0m     for tag in all_tags.keys():\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtag = 'tensors'\u001b[0m\n",
      "\u001b[2m01:08:43.585445 line        47\u001b[0m         if tag == \"scalars\":\n",
      "\u001b[2m01:08:43.585484 line        59\u001b[0m         if tag == \"tensors\":\n",
      "\u001b[2m01:08:43.585524 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'experiment_name/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.585566 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.585616 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.585656 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.585700 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.585742 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 4.357923535280...2000122070312, 'experiment_name': 'baseline_run'}\u001b[0m\n",
      "\u001b[2m01:08:43.585778 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'image_size/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.585817 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.585866 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.585928 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.585984 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.586041 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 4.357923535280...iment_name': 'baseline_run', 'image_size': '224'}\u001b[0m\n",
      "\u001b[2m01:08:43.586082 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'batch_size/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.586123 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.586170 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.586215 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.586295 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.586332 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 4.357923535280...ne_run', 'image_size': '224', 'batch_size': '32'}\u001b[0m\n",
      "\u001b[2m01:08:43.586404 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'enable_proxy_attention/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.586444 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.586499 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.586543 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.586579 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.586620 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 4.357923535280...ch_size': '32', 'enable_proxy_attention': 'True'}\u001b[0m\n",
      "\u001b[2m01:08:43.586668 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'transfer_imagenet/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.586710 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.586761 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.586806 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.586842 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.586877 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 4.357923535280..._attention': 'True', 'transfer_imagenet': 'True'}\u001b[0m\n",
      "\u001b[2m01:08:43.586911 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'subset_images/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.586951 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.586996 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.587031 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.587094 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.587150 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 4.357923535280...sfer_imagenet': 'True', 'subset_images': '20000'}\u001b[0m\n",
      "\u001b[2m01:08:43.587209 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'pixel_replacement_method/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.587290 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.587403 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.587516 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.587573 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.587631 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 4.357923535280...: '20000', 'pixel_replacement_method': 'blended'}\u001b[0m\n",
      "\u001b[2m01:08:43.587670 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'proxy_steps/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.587718 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.587768 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.587804 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.587840 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.587874 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 4.357923535280...cement_method': 'blended', 'proxy_steps': '[20]'}\u001b[0m\n",
      "\u001b[2m01:08:43.587909 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'load_proxy_data/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.587949 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.587995 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.588031 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.588066 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.588101 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 4.357923535280...proxy_steps': '[20]', 'load_proxy_data': 'False'}\u001b[0m\n",
      "\u001b[2m01:08:43.588135 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'proxy_step/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.588176 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.588222 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.588258 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.588293 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.588328 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 4.35792353...proxy_steps': '[20]', 'load_proxy_data': 'False'}\u001b[0m\n",
      "\u001b[2m01:08:43.588364 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'log_every/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.588405 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.588451 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.588489 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.588525 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.588561 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 4.35792353...]', 'load_proxy_data': 'False', 'log_every': '2'}\u001b[0m\n",
      "\u001b[2m01:08:43.588596 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'device/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.588636 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.588683 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.588719 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.588754 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.588789 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 4.35792353...': 'False', 'log_every': '2', 'device': 'cuda:0'}\u001b[0m\n",
      "\u001b[2m01:08:43.588836 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'dataset_info/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.588876 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.588923 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.588959 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.588996 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.589033 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 4.35792353...nt_name at 0x7f1f31f9bac0>, 'num_classes': 39}}\"}\u001b[0m\n",
      "\u001b[2m01:08:43.589068 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'main_run_dir/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.589116 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.589169 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.589212 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.589254 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.589295 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 4.35792353...DE/Github/improving_robotics_datasets/src/runs/'}\u001b[0m\n",
      "\u001b[2m01:08:43.589337 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'change_subset_attention/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.589383 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.589436 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.589479 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.589521 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.589563 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 4.35792353...ets/src/runs/', 'change_subset_attention': '0.8'}\u001b[0m\n",
      "\u001b[2m01:08:43.589610 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'model/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.589659 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.589712 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.589756 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.589798 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.589839 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 4.35792353...ge_subset_attention': '0.8', 'model': 'resnet50'}\u001b[0m\n",
      "\u001b[2m01:08:43.589881 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'proxy_image_weight/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.589928 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.589979 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.590023 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.590066 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.590127 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 4.35792353...'model': 'resnet50', 'proxy_image_weight': '0.1'}\u001b[0m\n",
      "\u001b[2m01:08:43.590170 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'proxy_threshold/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.590219 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.590271 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.590319 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.590378 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.590446 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 4.35792353..._image_weight': '0.1', 'proxy_threshold': '0.85'}\u001b[0m\n",
      "\u001b[2m01:08:43.590501 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'gradient_method/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.590551 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.590619 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.590665 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.590708 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.590758 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 4.35792353...d': '0.85', 'gradient_method': 'gradcamplusplus'}\u001b[0m\n",
      "\u001b[2m01:08:43.590822 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'ds_name/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.590890 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.590961 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.591018 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.591067 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.591110 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 4.35792353...d': 'gradcamplusplus', 'ds_name': 'plantdisease'}\u001b[0m\n",
      "\u001b[2m01:08:43.591156 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'clear_every_step/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.591204 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.591259 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.591303 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.591346 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.591389 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 4.35792353...ame': 'plantdisease', 'clear_every_step': 'True'}\u001b[0m\n",
      "\u001b[2m01:08:43.591431 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'fname_start/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.591480 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.591533 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.591578 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.591622 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.591664 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 4.35792353..._datasets/src/runs/baseline_run_27032023_144800'}\u001b[0m\n",
      "\u001b[2m01:08:43.591707 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'ds_path/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.591755 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.591819 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.591872 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.591917 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.591960 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 4.35792353...ant_leave_diseases_dataset_without_augmentation'}\u001b[0m\n",
      "\u001b[2m01:08:43.592003 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'name_fn/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.592053 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.592108 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.592154 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.592198 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.592242 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 4.35792353...: '<function get_parent_name at 0x7f1f31f9bac0>'}\u001b[0m\n",
      "\u001b[2m01:08:43.592286 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'global_run_count/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.592338 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.592394 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.592443 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.592487 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.592568 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[2m01:08:43.592649 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'writer/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.592692 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.592746 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.592791 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.592835 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.592878 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 4.35792353....writer.SummaryWriter object at 0x7f1f231711b0>'}\u001b[0m\n",
      "\u001b[2m01:08:43.592922 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'label_map/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.592979 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.593035 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.593080 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.593125 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.593169 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 4.35792353...__Tomato_mosaic_virus', 38: 'Tomato___healthy'}\"}\u001b[0m\n",
      "\u001b[2m01:08:43.593213 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'rev_label_map/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.593268 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.593329 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.593380 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.593431 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.593481 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 4.35792353...mato_mosaic_virus': 37, 'Tomato___healthy': 38}\"}\u001b[0m\n",
      "\u001b[2m01:08:43.593530 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'num_classes/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.593590 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.593657 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.593713 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.593816 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.593872 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 4.35792353...7, 'Tomato___healthy': 38}\", 'num_classes': '39'}\u001b[0m\n",
      "\u001b[2m01:08:43.593926 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'dataset_sizes/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.593986 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.594052 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.594108 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.594163 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.594218 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 4.35792353...dataset_sizes': \"{'train': 10000, 'val': 10000}\"}\u001b[0m\n",
      "\u001b[2m01:08:43.594288 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'criterion/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.594351 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.594422 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.594483 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.594540 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.594596 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 4.35792353...val': 10000}\", 'criterion': 'CrossEntropyLoss()'}\u001b[0m\n",
      "\u001b[2m01:08:43.594666 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'save_path/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.594747 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.594844 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.594946 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.595046 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.595121 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 4.35792353...rc/runs/baseline_run_27032023_144800/checkpoint'}\u001b[0m\n",
      "\u001b[2m01:08:43.595175 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'final_acc/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.595236 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.595303 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.595360 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.595415 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.595470 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 4.35792353...7032023_144800/checkpoint', 'final_acc': '99.22'}\u001b[0m\n",
      "\u001b[2m01:08:43.595525 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[2m01:08:43.595593 line        85\u001b[0m         if tag == \"images\" and save_ims == True:\n",
      "\u001b[2m01:08:43.595652 line        46\u001b[0m     for tag in all_tags.keys():\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtag = 'graph'\u001b[0m\n",
      "\u001b[2m01:08:43.595707 line        47\u001b[0m         if tag == \"scalars\":\n",
      "\u001b[2m01:08:43.595767 line        59\u001b[0m         if tag == \"tensors\":\n",
      "\u001b[2m01:08:43.595821 line        85\u001b[0m         if tag == \"images\" and save_ims == True:\n",
      "\u001b[2m01:08:43.595875 line        46\u001b[0m     for tag in all_tags.keys():\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtag = 'meta_graph'\u001b[0m\n",
      "\u001b[2m01:08:43.595929 line        47\u001b[0m         if tag == \"scalars\":\n",
      "\u001b[2m01:08:43.595989 line        59\u001b[0m         if tag == \"tensors\":\n",
      "\u001b[2m01:08:43.596043 line        85\u001b[0m         if tag == \"images\" and save_ims == True:\n",
      "\u001b[2m01:08:43.596097 line        46\u001b[0m     for tag in all_tags.keys():\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtag = 'run_metadata'\u001b[0m\n",
      "\u001b[2m01:08:43.596150 line        47\u001b[0m         if tag == \"scalars\":\n",
      "\u001b[2m01:08:43.596209 line        59\u001b[0m         if tag == \"tensors\":\n",
      "\u001b[2m01:08:43.596263 line        85\u001b[0m         if tag == \"images\" and save_ims == True:\n",
      "\u001b[2m01:08:43.596317 line        46\u001b[0m     for tag in all_tags.keys():\n",
      "\u001b[2m01:08:43.596371 line        96\u001b[0m     return temp_dict\n",
      "\u001b[2m01:08:43.596434 return      96\u001b[0m     return temp_dict\n",
      "\u001b[36m\u001b[2mReturn value:.. \u001b[22m{'proxy_step': 'False', 'Loss/Train': 4.35792353...7032023_144800/checkpoint', 'final_acc': '99.22'}\u001b[0m\n",
      "\u001b[33m\u001b[2mElapsed time: \u001b[22m00:00:00.015304\u001b[0m\n",
      "runs/baseline_run_26032023_201014/events.out.tfevents.1679854215.eragon\n",
      "\u001b[32m\u001b[2mStarting var:.. \u001b[22mevent_acc = <tensorboard.backend.event_processing.event_accumulator.EventAccumulator object at 0x7f5b568ee860>\u001b[0m\n",
      "\u001b[32m\u001b[2mStarting var:.. \u001b[22msave_ims = False\u001b[0m\n",
      "\u001b[2m01:08:43.605285 call        42\u001b[0m def process_event_acc(event_acc, save_ims = False):\n",
      "\u001b[2m01:08:43.605357 line        44\u001b[0m     all_tags = event_acc.Tags()\n",
      "\u001b[32m\u001b[2mNew var:....... \u001b[22mall_tags = {'images': [], 'audio': [], 'histograms': [], 's...: False, 'meta_graph': False, 'run_metadata': []}\u001b[0m\n",
      "\u001b[2m01:08:43.605398 line        45\u001b[0m     temp_dict = {}\n",
      "\u001b[32m\u001b[2mNew var:....... \u001b[22mtemp_dict = {}\u001b[0m\n",
      "\u001b[2m01:08:43.605484 line        46\u001b[0m     for tag in all_tags.keys():\n",
      "\u001b[32m\u001b[2mNew var:....... \u001b[22mtag = 'images'\u001b[0m\n",
      "\u001b[2m01:08:43.605523 line        47\u001b[0m         if tag == \"scalars\":\n",
      "\u001b[2m01:08:43.605560 line        59\u001b[0m         if tag == \"tensors\":\n",
      "\u001b[2m01:08:43.605589 line        85\u001b[0m         if tag == \"images\" and save_ims == True:\n",
      "\u001b[2m01:08:43.605618 line        46\u001b[0m     for tag in all_tags.keys():\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtag = 'audio'\u001b[0m\n",
      "\u001b[2m01:08:43.605645 line        47\u001b[0m         if tag == \"scalars\":\n",
      "\u001b[2m01:08:43.605677 line        59\u001b[0m         if tag == \"tensors\":\n",
      "\u001b[2m01:08:43.605704 line        85\u001b[0m         if tag == \"images\" and save_ims == True:\n",
      "\u001b[2m01:08:43.605731 line        46\u001b[0m     for tag in all_tags.keys():\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtag = 'histograms'\u001b[0m\n",
      "\u001b[2m01:08:43.605757 line        47\u001b[0m         if tag == \"scalars\":\n",
      "\u001b[2m01:08:43.605788 line        59\u001b[0m         if tag == \"tensors\":\n",
      "\u001b[2m01:08:43.605814 line        85\u001b[0m         if tag == \"images\" and save_ims == True:\n",
      "\u001b[2m01:08:43.605842 line        46\u001b[0m     for tag in all_tags.keys():\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtag = 'scalars'\u001b[0m\n",
      "\u001b[2m01:08:43.605872 line        47\u001b[0m         if tag == \"scalars\":\n",
      "\u001b[2m01:08:43.605904 line        48\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mNew var:....... \u001b[22msubtag = 'proxy_step'\u001b[0m\n",
      "\u001b[2m01:08:43.605932 line        50\u001b[0m                 try:\n",
      "\u001b[2m01:08:43.605966 line        51\u001b[0m                     temp_dict[subtag] = [tag[-1] for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.606009 exception   51\u001b[0m                     temp_dict[subtag] = [tag[-1] for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[31mException:..... \u001b[1mTypeError: 'ScalarEvent' object is not subscriptable\u001b[0m\n",
      "\u001b[2m01:08:43.606086 line        54\u001b[0m                 except:\n",
      "\u001b[2m01:08:43.606119 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.606158 line        56\u001b[0m                     -1\n",
      "\u001b[2m01:08:43.606187 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.606216 line        57\u001b[0m                 ].value\n",
      "\u001b[2m01:08:43.606245 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0}\u001b[0m\n",
      "\u001b[2m01:08:43.606274 line        48\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'Loss/Train'\u001b[0m\n",
      "\u001b[2m01:08:43.606310 line        50\u001b[0m                 try:\n",
      "\u001b[2m01:08:43.606343 line        51\u001b[0m                     temp_dict[subtag] = [tag[-1] for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.606379 exception   51\u001b[0m                     temp_dict[subtag] = [tag[-1] for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[31mException:..... \u001b[1mTypeError: 'ScalarEvent' object is not subscriptable\u001b[0m\n",
      "\u001b[2m01:08:43.606435 line        54\u001b[0m                 except:\n",
      "\u001b[2m01:08:43.606467 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.606503 line        56\u001b[0m                     -1\n",
      "\u001b[2m01:08:43.606534 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.606563 line        57\u001b[0m                 ].value\n",
      "\u001b[2m01:08:43.606592 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 3.0047511245356873e-05}\u001b[0m\n",
      "\u001b[2m01:08:43.606620 line        48\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'Acc/Train'\u001b[0m\n",
      "\u001b[2m01:08:43.606657 line        50\u001b[0m                 try:\n",
      "\u001b[2m01:08:43.606691 line        51\u001b[0m                     temp_dict[subtag] = [tag[-1] for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.606727 exception   51\u001b[0m                     temp_dict[subtag] = [tag[-1] for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[31mException:..... \u001b[1mTypeError: 'ScalarEvent' object is not subscriptable\u001b[0m\n",
      "\u001b[2m01:08:43.606786 line        54\u001b[0m                 except:\n",
      "\u001b[2m01:08:43.606821 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.606859 line        56\u001b[0m                     -1\n",
      "\u001b[2m01:08:43.606891 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.606922 line        57\u001b[0m                 ].value\n",
      "\u001b[2m01:08:43.606953 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 3.0047511245356873e-05, 'Acc/Train': 99.93439483642578}\u001b[0m\n",
      "\u001b[2m01:08:43.606985 line        48\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'global_run_count'\u001b[0m\n",
      "\u001b[2m01:08:43.607046 line        50\u001b[0m                 try:\n",
      "\u001b[2m01:08:43.607140 line        51\u001b[0m                     temp_dict[subtag] = [tag[-1] for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.607202 exception   51\u001b[0m                     temp_dict[subtag] = [tag[-1] for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[31mException:..... \u001b[1mTypeError: 'ScalarEvent' object is not subscriptable\u001b[0m\n",
      "\u001b[2m01:08:43.607273 line        54\u001b[0m                 except:\n",
      "\u001b[2m01:08:43.607328 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.607376 line        56\u001b[0m                     -1\n",
      "\u001b[2m01:08:43.607416 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.607452 line        57\u001b[0m                 ].value\n",
      "\u001b[2m01:08:43.607495 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 3.004751124535...in': 99.93439483642578, 'global_run_count': 20.0}\u001b[0m\n",
      "\u001b[2m01:08:43.607535 line        48\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'Loss/Val'\u001b[0m\n",
      "\u001b[2m01:08:43.607577 line        50\u001b[0m                 try:\n",
      "\u001b[2m01:08:43.607621 line        51\u001b[0m                     temp_dict[subtag] = [tag[-1] for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.607673 exception   51\u001b[0m                     temp_dict[subtag] = [tag[-1] for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[31mException:..... \u001b[1mTypeError: 'ScalarEvent' object is not subscriptable\u001b[0m\n",
      "\u001b[2m01:08:43.607728 line        54\u001b[0m                 except:\n",
      "\u001b[2m01:08:43.607775 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.607816 line        56\u001b[0m                     -1\n",
      "\u001b[2m01:08:43.607850 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.607882 line        57\u001b[0m                 ].value\n",
      "\u001b[2m01:08:43.607915 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 3.004751124535...n_count': 20.0, 'Loss/Val': 0.004748863633722067}\u001b[0m\n",
      "\u001b[2m01:08:43.607947 line        48\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'Acc/Val'\u001b[0m\n",
      "\u001b[2m01:08:43.607986 line        50\u001b[0m                 try:\n",
      "\u001b[2m01:08:43.608023 line        51\u001b[0m                     temp_dict[subtag] = [tag[-1] for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.608061 exception   51\u001b[0m                     temp_dict[subtag] = [tag[-1] for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[31mException:..... \u001b[1mTypeError: 'ScalarEvent' object is not subscriptable\u001b[0m\n",
      "\u001b[2m01:08:43.608113 line        54\u001b[0m                 except:\n",
      "\u001b[2m01:08:43.608148 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.608202 line        56\u001b[0m                     -1\n",
      "\u001b[2m01:08:43.608246 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.608303 line        57\u001b[0m                 ].value\n",
      "\u001b[2m01:08:43.608344 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 3.004751124535...004748863633722067, 'Acc/Val': 92.45407104492188}\u001b[0m\n",
      "\u001b[2m01:08:43.608378 line        48\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[2m01:08:43.608418 line        59\u001b[0m         if tag == \"tensors\":\n",
      "\u001b[2m01:08:43.608451 line        85\u001b[0m         if tag == \"images\" and save_ims == True:\n",
      "\u001b[2m01:08:43.608484 line        46\u001b[0m     for tag in all_tags.keys():\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtag = 'distributions'\u001b[0m\n",
      "\u001b[2m01:08:43.608517 line        47\u001b[0m         if tag == \"scalars\":\n",
      "\u001b[2m01:08:43.608555 line        59\u001b[0m         if tag == \"tensors\":\n",
      "\u001b[2m01:08:43.608587 line        85\u001b[0m         if tag == \"images\" and save_ims == True:\n",
      "\u001b[2m01:08:43.608619 line        46\u001b[0m     for tag in all_tags.keys():\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtag = 'tensors'\u001b[0m\n",
      "\u001b[2m01:08:43.608660 line        47\u001b[0m         if tag == \"scalars\":\n",
      "\u001b[2m01:08:43.608698 line        59\u001b[0m         if tag == \"tensors\":\n",
      "\u001b[2m01:08:43.608730 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'experiment_name/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.608762 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.608807 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.608844 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.608880 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.608913 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 3.004751124535...5407104492188, 'experiment_name': 'baseline_run'}\u001b[0m\n",
      "\u001b[2m01:08:43.608947 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'image_size/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.608984 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.609027 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.609061 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.609095 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.609128 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 3.004751124535...iment_name': 'baseline_run', 'image_size': '224'}\u001b[0m\n",
      "\u001b[2m01:08:43.609161 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'batch_size/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.609198 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.609241 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.609275 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.609308 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.609341 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 3.004751124535...ne_run', 'image_size': '224', 'batch_size': '64'}\u001b[0m\n",
      "\u001b[2m01:08:43.609377 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'enable_proxy_attention/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.609414 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.609458 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.609493 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.609527 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.609560 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 3.004751124535...ch_size': '64', 'enable_proxy_attention': 'True'}\u001b[0m\n",
      "\u001b[2m01:08:43.609593 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'transfer_imagenet/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.609631 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.609675 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.609710 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.609745 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.609778 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 3.004751124535..._attention': 'True', 'transfer_imagenet': 'True'}\u001b[0m\n",
      "\u001b[2m01:08:43.609812 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'subset_images/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.609850 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.609894 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.609929 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.609963 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.609996 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 3.004751124535...sfer_imagenet': 'True', 'subset_images': '20000'}\u001b[0m\n",
      "\u001b[2m01:08:43.610051 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'pixel_replacement_method/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.610090 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.610136 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.610172 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.610207 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.610241 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 3.004751124535...: '20000', 'pixel_replacement_method': 'blended'}\u001b[0m\n",
      "\u001b[2m01:08:43.610276 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'proxy_steps/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.610316 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.610361 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.610424 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.610475 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.610510 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 3.004751124535...cement_method': 'blended', 'proxy_steps': '[20]'}\u001b[0m\n",
      "\u001b[2m01:08:43.610544 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'load_proxy_data/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.610584 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.610630 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.610665 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.610700 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.610734 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 3.004751124535...proxy_steps': '[20]', 'load_proxy_data': 'False'}\u001b[0m\n",
      "\u001b[2m01:08:43.610768 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'proxy_step/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.610807 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.610852 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.610887 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.610922 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.610971 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 3.00475112...proxy_steps': '[20]', 'load_proxy_data': 'False'}\u001b[0m\n",
      "\u001b[2m01:08:43.611026 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'log_every/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.611091 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.611169 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.611211 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.611247 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.611283 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 3.00475112...]', 'load_proxy_data': 'False', 'log_every': '2'}\u001b[0m\n",
      "\u001b[2m01:08:43.611321 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'device/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.611377 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.611426 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.611464 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.611517 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.611557 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 3.00475112...': 'False', 'log_every': '2', 'device': 'cuda:0'}\u001b[0m\n",
      "\u001b[2m01:08:43.611611 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'dataset_info/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.611673 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.611738 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.611820 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.611877 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.611914 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 3.00475112...t_name at 0x7f9ee61c3a30>, 'num_classes': 101}}\"}\u001b[0m\n",
      "\u001b[2m01:08:43.611959 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'main_run_dir/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.612009 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.612061 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.612104 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.612145 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.612185 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 3.00475112...DE/Github/improving_robotics_datasets/src/runs/'}\u001b[0m\n",
      "\u001b[2m01:08:43.612226 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'change_subset_attention/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.612271 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.612323 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.612365 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.612408 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.612448 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 3.00475112...ets/src/runs/', 'change_subset_attention': '0.8'}\u001b[0m\n",
      "\u001b[2m01:08:43.612504 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'model/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.612596 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.612684 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.612752 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.612800 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.612843 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 3.00475112...et_attention': '0.8', 'model': 'efficientnet_b0'}\u001b[0m\n",
      "\u001b[2m01:08:43.612885 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'proxy_image_weight/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.612932 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.612986 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.613030 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.613073 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.613114 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 3.00475112...: 'efficientnet_b0', 'proxy_image_weight': '0.1'}\u001b[0m\n",
      "\u001b[2m01:08:43.613157 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'proxy_threshold/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.613210 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.613265 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.613323 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.613367 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.613408 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 3.00475112..._image_weight': '0.1', 'proxy_threshold': '0.85'}\u001b[0m\n",
      "\u001b[2m01:08:43.613461 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'gradient_method/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.613509 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.613561 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.613624 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.613667 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.613709 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 3.00475112...d': '0.85', 'gradient_method': 'gradcamplusplus'}\u001b[0m\n",
      "\u001b[2m01:08:43.613789 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'ds_name/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.613836 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.613889 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.613949 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.614047 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.614119 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 3.00475112...hod': 'gradcamplusplus', 'ds_name': 'caltech101'}\u001b[0m\n",
      "\u001b[2m01:08:43.614163 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'clear_every_step/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.614211 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.614267 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.614311 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.614354 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.614395 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 3.00475112..._name': 'caltech101', 'clear_every_step': 'True'}\u001b[0m\n",
      "\u001b[2m01:08:43.614436 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'fname_start/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.614484 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.614537 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.614582 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.614624 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.614666 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 3.00475112..._datasets/src/runs/baseline_run_26032023_201014'}\u001b[0m\n",
      "\u001b[2m01:08:43.614709 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'ds_path/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.614757 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.614811 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.614854 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.614896 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.614937 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 3.00475112...h': '/run/media/eragon/HDD/Datasets/caltech-101'}\u001b[0m\n",
      "\u001b[2m01:08:43.614978 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'name_fn/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.615025 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.615079 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.615142 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.615209 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.615282 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 3.00475112...: '<function get_parent_name at 0x7f9ee61c3a30>'}\u001b[0m\n",
      "\u001b[2m01:08:43.615350 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'global_run_count/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.615461 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.615521 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.615567 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.615612 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.615662 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[2m01:08:43.615711 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'writer/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.615772 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.615851 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.615906 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.615971 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.616076 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 3.00475112....writer.SummaryWriter object at 0x7f9ed77dee90>'}\u001b[0m\n",
      "\u001b[2m01:08:43.616190 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'label_map/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.616289 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.616411 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.616485 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.616553 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.616625 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 3.00475112...windsor_chair', 100: 'wrench', 101: 'yin_yang'}\"}\u001b[0m\n",
      "\u001b[2m01:08:43.616690 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'rev_label_map/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.616784 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.616877 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.616936 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.617033 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.617139 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 3.00475112...sor_chair': 99, 'wrench': 100, 'yin_yang': 101}\"}\u001b[0m\n",
      "\u001b[2m01:08:43.617197 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'num_classes/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.617266 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.617340 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.617403 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.617465 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.617525 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 3.00475112...h': 100, 'yin_yang': 101}\", 'num_classes': '102'}\u001b[0m\n",
      "\u001b[2m01:08:43.617585 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'dataset_sizes/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.617660 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.617733 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.617795 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.617854 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.617913 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 3.00475112... 'dataset_sizes': \"{'train': 4573, 'val': 4572}\"}\u001b[0m\n",
      "\u001b[2m01:08:43.617972 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'criterion/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.618036 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.618106 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.618167 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.618228 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.618287 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 3.00475112...'val': 4572}\", 'criterion': 'CrossEntropyLoss()'}\u001b[0m\n",
      "\u001b[2m01:08:43.618347 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'cam/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.618411 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.618481 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.618542 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.618600 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.618660 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 3.00475112...splus.GradCAMPlusPlus object at 0x7f9ed6c35750>'}\u001b[0m\n",
      "\u001b[2m01:08:43.618719 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'save_path/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.618783 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.618852 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.618913 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.618974 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.619033 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 3.00475112...rc/runs/baseline_run_26032023_201014/checkpoint'}\u001b[0m\n",
      "\u001b[2m01:08:43.619091 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'final_acc/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.619156 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.619226 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.619303 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.619421 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.619527 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 3.00475112...14/checkpoint', 'final_acc': '92.45406824146981'}\u001b[0m\n",
      "\u001b[2m01:08:43.619592 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[2m01:08:43.619665 line        85\u001b[0m         if tag == \"images\" and save_ims == True:\n",
      "\u001b[2m01:08:43.619728 line        46\u001b[0m     for tag in all_tags.keys():\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtag = 'graph'\u001b[0m\n",
      "\u001b[2m01:08:43.619788 line        47\u001b[0m         if tag == \"scalars\":\n",
      "\u001b[2m01:08:43.619856 line        59\u001b[0m         if tag == \"tensors\":\n",
      "\u001b[2m01:08:43.619917 line        85\u001b[0m         if tag == \"images\" and save_ims == True:\n",
      "\u001b[2m01:08:43.619981 line        46\u001b[0m     for tag in all_tags.keys():\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtag = 'meta_graph'\u001b[0m\n",
      "\u001b[2m01:08:43.620044 line        47\u001b[0m         if tag == \"scalars\":\n",
      "\u001b[2m01:08:43.620109 line        59\u001b[0m         if tag == \"tensors\":\n",
      "\u001b[2m01:08:43.620192 line        85\u001b[0m         if tag == \"images\" and save_ims == True:\n",
      "\u001b[2m01:08:43.620316 line        46\u001b[0m     for tag in all_tags.keys():\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtag = 'run_metadata'\u001b[0m\n",
      "\u001b[2m01:08:43.620395 line        47\u001b[0m         if tag == \"scalars\":\n",
      "\u001b[2m01:08:43.620485 line        59\u001b[0m         if tag == \"tensors\":\n",
      "\u001b[2m01:08:43.620583 line        85\u001b[0m         if tag == \"images\" and save_ims == True:\n",
      "\u001b[2m01:08:43.620662 line        46\u001b[0m     for tag in all_tags.keys():\n",
      "\u001b[2m01:08:43.620760 line        96\u001b[0m     return temp_dict\n",
      "\u001b[2m01:08:43.620820 return      96\u001b[0m     return temp_dict\n",
      "\u001b[36m\u001b[2mReturn value:.. \u001b[22m{'proxy_step': 'False', 'Loss/Train': 3.00475112...14/checkpoint', 'final_acc': '92.45406824146981'}\u001b[0m\n",
      "\u001b[33m\u001b[2mElapsed time: \u001b[22m00:00:00.015697\u001b[0m\n",
      "runs/baseline_run_27032023_120416/events.out.tfevents.1679911460.eragon\n",
      "\u001b[32m\u001b[2mStarting var:.. \u001b[22mevent_acc = <tensorboard.backend.event_processing.event_accumulator.EventAccumulator object at 0x7f5b568edd80>\u001b[0m\n",
      "\u001b[32m\u001b[2mStarting var:.. \u001b[22msave_ims = False\u001b[0m\n",
      "\u001b[2m01:08:43.633608 call        42\u001b[0m def process_event_acc(event_acc, save_ims = False):\n",
      "\u001b[2m01:08:43.633736 line        44\u001b[0m     all_tags = event_acc.Tags()\n",
      "\u001b[32m\u001b[2mNew var:....... \u001b[22mall_tags = {'images': [], 'audio': [], 'histograms': [], 's...: False, 'meta_graph': False, 'run_metadata': []}\u001b[0m\n",
      "\u001b[2m01:08:43.633808 line        45\u001b[0m     temp_dict = {}\n",
      "\u001b[32m\u001b[2mNew var:....... \u001b[22mtemp_dict = {}\u001b[0m\n",
      "\u001b[2m01:08:43.633878 line        46\u001b[0m     for tag in all_tags.keys():\n",
      "\u001b[32m\u001b[2mNew var:....... \u001b[22mtag = 'images'\u001b[0m\n",
      "\u001b[2m01:08:43.633943 line        47\u001b[0m         if tag == \"scalars\":\n",
      "\u001b[2m01:08:43.634007 line        59\u001b[0m         if tag == \"tensors\":\n",
      "\u001b[2m01:08:43.634059 line        85\u001b[0m         if tag == \"images\" and save_ims == True:\n",
      "\u001b[2m01:08:43.634110 line        46\u001b[0m     for tag in all_tags.keys():\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtag = 'audio'\u001b[0m\n",
      "\u001b[2m01:08:43.634161 line        47\u001b[0m         if tag == \"scalars\":\n",
      "\u001b[2m01:08:43.634221 line        59\u001b[0m         if tag == \"tensors\":\n",
      "\u001b[2m01:08:43.634271 line        85\u001b[0m         if tag == \"images\" and save_ims == True:\n",
      "\u001b[2m01:08:43.634319 line        46\u001b[0m     for tag in all_tags.keys():\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtag = 'histograms'\u001b[0m\n",
      "\u001b[2m01:08:43.634368 line        47\u001b[0m         if tag == \"scalars\":\n",
      "\u001b[2m01:08:43.634426 line        59\u001b[0m         if tag == \"tensors\":\n",
      "\u001b[2m01:08:43.634471 line        85\u001b[0m         if tag == \"images\" and save_ims == True:\n",
      "\u001b[2m01:08:43.634517 line        46\u001b[0m     for tag in all_tags.keys():\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtag = 'scalars'\u001b[0m\n",
      "\u001b[2m01:08:43.634562 line        47\u001b[0m         if tag == \"scalars\":\n",
      "\u001b[2m01:08:43.634616 line        48\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mNew var:....... \u001b[22msubtag = 'proxy_step'\u001b[0m\n",
      "\u001b[2m01:08:43.634662 line        50\u001b[0m                 try:\n",
      "\u001b[2m01:08:43.634720 line        51\u001b[0m                     temp_dict[subtag] = [tag[-1] for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.634788 exception   51\u001b[0m                     temp_dict[subtag] = [tag[-1] for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[31mException:..... \u001b[1mTypeError: 'ScalarEvent' object is not subscriptable\u001b[0m\n",
      "\u001b[2m01:08:43.634991 line        54\u001b[0m                 except:\n",
      "\u001b[2m01:08:43.635050 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.635119 line        56\u001b[0m                     -1\n",
      "\u001b[2m01:08:43.635174 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.635225 line        57\u001b[0m                 ].value\n",
      "\u001b[2m01:08:43.635275 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0}\u001b[0m\n",
      "\u001b[2m01:08:43.635327 line        48\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'Loss/Train'\u001b[0m\n",
      "\u001b[2m01:08:43.635390 line        50\u001b[0m                 try:\n",
      "\u001b[2m01:08:43.635450 line        51\u001b[0m                     temp_dict[subtag] = [tag[-1] for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.635512 exception   51\u001b[0m                     temp_dict[subtag] = [tag[-1] for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[31mException:..... \u001b[1mTypeError: 'ScalarEvent' object is not subscriptable\u001b[0m\n",
      "\u001b[2m01:08:43.635658 line        54\u001b[0m                 except:\n",
      "\u001b[2m01:08:43.635734 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.635818 line        56\u001b[0m                     -1\n",
      "\u001b[2m01:08:43.635889 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.635938 line        57\u001b[0m                 ].value\n",
      "\u001b[2m01:08:43.636019 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 0.1441509872674942}\u001b[0m\n",
      "\u001b[2m01:08:43.636092 line        48\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'Acc/Train'\u001b[0m\n",
      "\u001b[2m01:08:43.636162 line        50\u001b[0m                 try:\n",
      "\u001b[2m01:08:43.636228 line        51\u001b[0m                     temp_dict[subtag] = [tag[-1] for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.636293 exception   51\u001b[0m                     temp_dict[subtag] = [tag[-1] for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[31mException:..... \u001b[1mTypeError: 'ScalarEvent' object is not subscriptable\u001b[0m\n",
      "\u001b[2m01:08:43.636382 line        54\u001b[0m                 except:\n",
      "\u001b[2m01:08:43.636439 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.636505 line        56\u001b[0m                     -1\n",
      "\u001b[2m01:08:43.636560 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.636611 line        57\u001b[0m                 ].value\n",
      "\u001b[2m01:08:43.636662 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 0.1441509872674942, 'Acc/Train': 1.2100000381469727}\u001b[0m\n",
      "\u001b[2m01:08:43.636710 line        48\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'global_run_count'\u001b[0m\n",
      "\u001b[2m01:08:43.636772 line        50\u001b[0m                 try:\n",
      "\u001b[2m01:08:43.636833 line        51\u001b[0m                     temp_dict[subtag] = [tag[-1] for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.636896 exception   51\u001b[0m                     temp_dict[subtag] = [tag[-1] for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[31mException:..... \u001b[1mTypeError: 'ScalarEvent' object is not subscriptable\u001b[0m\n",
      "\u001b[2m01:08:43.636987 line        54\u001b[0m                 except:\n",
      "\u001b[2m01:08:43.637044 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.637124 line        56\u001b[0m                     -1\n",
      "\u001b[2m01:08:43.637179 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.637232 line        57\u001b[0m                 ].value\n",
      "\u001b[2m01:08:43.637283 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 0.144150987267...n': 1.2100000381469727, 'global_run_count': 20.0}\u001b[0m\n",
      "\u001b[2m01:08:43.637336 line        48\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'Loss/Val'\u001b[0m\n",
      "\u001b[2m01:08:43.637402 line        50\u001b[0m                 try:\n",
      "\u001b[2m01:08:43.637464 line        51\u001b[0m                     temp_dict[subtag] = [tag[-1] for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.637528 exception   51\u001b[0m                     temp_dict[subtag] = [tag[-1] for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[31mException:..... \u001b[1mTypeError: 'ScalarEvent' object is not subscriptable\u001b[0m\n",
      "\u001b[2m01:08:43.637620 line        54\u001b[0m                 except:\n",
      "\u001b[2m01:08:43.637681 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.637749 line        56\u001b[0m                     -1\n",
      "\u001b[2m01:08:43.637805 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.637863 line        57\u001b[0m                 ].value\n",
      "\u001b[2m01:08:43.637918 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 0.144150987267...un_count': 20.0, 'Loss/Val': 0.14413389563560486}\u001b[0m\n",
      "\u001b[2m01:08:43.637975 line        48\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'Acc/Val'\u001b[0m\n",
      "\u001b[2m01:08:43.638045 line        50\u001b[0m                 try:\n",
      "\u001b[2m01:08:43.638111 line        51\u001b[0m                     temp_dict[subtag] = [tag[-1] for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.638180 exception   51\u001b[0m                     temp_dict[subtag] = [tag[-1] for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[31mException:..... \u001b[1mTypeError: 'ScalarEvent' object is not subscriptable\u001b[0m\n",
      "\u001b[2m01:08:43.638270 line        54\u001b[0m                 except:\n",
      "\u001b[2m01:08:43.638330 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.638403 line        56\u001b[0m                     -1\n",
      "\u001b[2m01:08:43.638462 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[2m01:08:43.638516 line        57\u001b[0m                 ].value\n",
      "\u001b[2m01:08:43.638569 line        55\u001b[0m                     temp_dict[subtag] = [tag for tag in event_acc.Scalars(tag=subtag)][\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 0.144150987267...14413389563560486, 'Acc/Val': 1.0399999618530273}\u001b[0m\n",
      "\u001b[2m01:08:43.638622 line        48\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[2m01:08:43.638685 line        59\u001b[0m         if tag == \"tensors\":\n",
      "\u001b[2m01:08:43.638741 line        85\u001b[0m         if tag == \"images\" and save_ims == True:\n",
      "\u001b[2m01:08:43.638797 line        46\u001b[0m     for tag in all_tags.keys():\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtag = 'distributions'\u001b[0m\n",
      "\u001b[2m01:08:43.638854 line        47\u001b[0m         if tag == \"scalars\":\n",
      "\u001b[2m01:08:43.638921 line        59\u001b[0m         if tag == \"tensors\":\n",
      "\u001b[2m01:08:43.638977 line        85\u001b[0m         if tag == \"images\" and save_ims == True:\n",
      "\u001b[2m01:08:43.639032 line        46\u001b[0m     for tag in all_tags.keys():\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtag = 'tensors'\u001b[0m\n",
      "\u001b[2m01:08:43.639087 line        47\u001b[0m         if tag == \"scalars\":\n",
      "\u001b[2m01:08:43.639149 line        59\u001b[0m         if tag == \"tensors\":\n",
      "\u001b[2m01:08:43.639204 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'experiment_name/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.639259 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.639336 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.639400 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.639462 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.639521 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 0.144150987267...9999618530273, 'experiment_name': 'baseline_run'}\u001b[0m\n",
      "\u001b[2m01:08:43.639581 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'image_size/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.639650 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.639730 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.639792 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.639851 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.639908 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 0.144150987267...iment_name': 'baseline_run', 'image_size': '224'}\u001b[0m\n",
      "\u001b[2m01:08:43.639967 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'batch_size/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.640037 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.640123 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.640184 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.640243 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.640303 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 0.144150987267...ne_run', 'image_size': '224', 'batch_size': '32'}\u001b[0m\n",
      "\u001b[2m01:08:43.640363 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'enable_proxy_attention/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.640458 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.640538 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.640603 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.640662 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.640722 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 0.144150987267...ch_size': '32', 'enable_proxy_attention': 'True'}\u001b[0m\n",
      "\u001b[2m01:08:43.640781 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'transfer_imagenet/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.640849 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.640926 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.640988 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.641047 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.641108 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 0.144150987267..._attention': 'True', 'transfer_imagenet': 'True'}\u001b[0m\n",
      "\u001b[2m01:08:43.641168 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'subset_images/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.641240 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.641319 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.641380 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.641438 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.641496 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 0.144150987267...sfer_imagenet': 'True', 'subset_images': '20000'}\u001b[0m\n",
      "\u001b[2m01:08:43.641553 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'pixel_replacement_method/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.641623 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.641703 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.641765 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.641826 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.641885 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 0.144150987267...: '20000', 'pixel_replacement_method': 'blended'}\u001b[0m\n",
      "\u001b[2m01:08:43.641946 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'proxy_steps/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.642017 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.642098 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.642160 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.642223 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.642283 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 0.144150987267...cement_method': 'blended', 'proxy_steps': '[20]'}\u001b[0m\n",
      "\u001b[2m01:08:43.642342 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'load_proxy_data/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.642411 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.642513 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.642630 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.642720 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.642797 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 0.0, 'Loss/Train': 0.144150987267...proxy_steps': '[20]', 'load_proxy_data': 'False'}\u001b[0m\n",
      "\u001b[2m01:08:43.642878 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'proxy_step/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.642971 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.643085 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.643146 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.643210 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.643272 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.14415098...proxy_steps': '[20]', 'load_proxy_data': 'False'}\u001b[0m\n",
      "\u001b[2m01:08:43.643329 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'log_every/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.643399 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.643480 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.643543 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.643604 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.643665 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.14415098...]', 'load_proxy_data': 'False', 'log_every': '2'}\u001b[0m\n",
      "\u001b[2m01:08:43.643731 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'device/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.643803 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.643882 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.643945 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.644006 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.644065 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.14415098...': 'False', 'log_every': '2', 'device': 'cuda:0'}\u001b[0m\n",
      "\u001b[2m01:08:43.644128 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'dataset_info/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.644198 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.644301 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.644364 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.644423 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.644483 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.14415098...t_name at 0x7f333bd9ba30>, 'num_classes': 101}}\"}\u001b[0m\n",
      "\u001b[2m01:08:43.644542 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'main_run_dir/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.644624 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.644724 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.644800 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.644874 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.644943 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.14415098...DE/Github/improving_robotics_datasets/src/runs/'}\u001b[0m\n",
      "\u001b[2m01:08:43.645015 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'change_subset_attention/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.645096 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.645190 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.645264 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.645336 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.645408 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.14415098...ets/src/runs/', 'change_subset_attention': '0.8'}\u001b[0m\n",
      "\u001b[2m01:08:43.645479 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'model/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.645561 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.645657 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.645731 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.645803 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.645873 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.14415098...hange_subset_attention': '0.8', 'model': 'vgg16'}\u001b[0m\n",
      "\u001b[2m01:08:43.645944 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'proxy_image_weight/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.646027 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.646123 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.646197 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.646268 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.646339 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.14415098...', 'model': 'vgg16', 'proxy_image_weight': '0.1'}\u001b[0m\n",
      "\u001b[2m01:08:43.646410 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'proxy_threshold/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.646495 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.646591 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.646667 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.646739 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.646810 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.14415098..._image_weight': '0.1', 'proxy_threshold': '0.85'}\u001b[0m\n",
      "\u001b[2m01:08:43.646881 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'gradient_method/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.646962 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.647061 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.647150 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.647223 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.647294 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.14415098...d': '0.85', 'gradient_method': 'gradcamplusplus'}\u001b[0m\n",
      "\u001b[2m01:08:43.647366 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'ds_name/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.647449 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.647548 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.647625 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.647698 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.647773 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.14415098...ethod': 'gradcamplusplus', 'ds_name': 'cifar100'}\u001b[0m\n",
      "\u001b[2m01:08:43.647847 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'clear_every_step/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.647931 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.648024 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.648101 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.648172 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.648242 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.14415098...ds_name': 'cifar100', 'clear_every_step': 'True'}\u001b[0m\n",
      "\u001b[2m01:08:43.648315 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'fname_start/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.648396 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.648497 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.648574 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.648650 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.648722 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.14415098..._datasets/src/runs/baseline_run_27032023_120416'}\u001b[0m\n",
      "\u001b[2m01:08:43.648794 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'ds_path/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.648874 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.648969 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.649045 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.649122 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.649195 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.14415098...'/run/media/eragon/HDD/Datasets/CIFAR-100/train'}\u001b[0m\n",
      "\u001b[2m01:08:43.649268 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'name_fn/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.649349 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.649468 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.649602 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.649695 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.649797 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.14415098...: '<function get_parent_name at 0x7f333bd9ba30>'}\u001b[0m\n",
      "\u001b[2m01:08:43.649890 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'global_run_count/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.650003 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.650145 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.650234 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.650337 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.650445 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[2m01:08:43.650551 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'writer/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.650650 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.650751 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.650832 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.650905 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.650977 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.14415098....writer.SummaryWriter object at 0x7f3330f90fa0>'}\u001b[0m\n",
      "\u001b[2m01:08:43.651051 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'label_map/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.651136 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.651236 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.651313 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.651386 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.651460 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.14415098...low_tree', 97: 'wolf', 98: 'woman', 99: 'worm'}\"}\u001b[0m\n",
      "\u001b[2m01:08:43.651533 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'rev_label_map/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.651626 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.651732 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.651831 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.651921 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.652008 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.14415098...tree': 96, 'wolf': 97, 'woman': 98, 'worm': 99}\"}\u001b[0m\n",
      "\u001b[2m01:08:43.652096 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'num_classes/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.652207 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.652333 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.652437 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.652540 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.652637 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.14415098... 'woman': 98, 'worm': 99}\", 'num_classes': '100'}\u001b[0m\n",
      "\u001b[2m01:08:43.652737 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'dataset_sizes/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.652847 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.652967 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.653069 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.653170 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.653266 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.14415098...dataset_sizes': \"{'train': 10000, 'val': 10000}\"}\u001b[0m\n",
      "\u001b[2m01:08:43.653366 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'criterion/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.653483 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.653611 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.653730 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.653835 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.653940 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.14415098...val': 10000}\", 'criterion': 'CrossEntropyLoss()'}\u001b[0m\n",
      "\u001b[2m01:08:43.654043 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'save_path/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.654156 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.654280 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.654384 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.654492 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.654595 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.14415098...rc/runs/baseline_run_27032023_120416/checkpoint'}\u001b[0m\n",
      "\u001b[2m01:08:43.654698 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22msubtag = 'final_acc/text_summary'\u001b[0m\n",
      "\u001b[2m01:08:43.654811 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.654938 line        75\u001b[0m                     .string_val[0]\n",
      "\u001b[2m01:08:43.655047 line        74\u001b[0m                     [tag.tensor_proto for tag in event_acc.Tensors(tag=subtag)][0]\n",
      "\u001b[2m01:08:43.655153 line        76\u001b[0m                     .decode(\"ascii\")\n",
      "\u001b[2m01:08:43.655256 line        73\u001b[0m                 temp_dict[subtag.replace(\"/text_summary\", \"\")] = (\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtemp_dict = {'proxy_step': 'False', 'Loss/Train': 0.14415098...27032023_120416/checkpoint', 'final_acc': '1.04'}\u001b[0m\n",
      "\u001b[2m01:08:43.655357 line        60\u001b[0m             for subtag in all_tags[tag]:\n",
      "\u001b[2m01:08:43.655471 line        85\u001b[0m         if tag == \"images\" and save_ims == True:\n",
      "\u001b[2m01:08:43.655568 line        46\u001b[0m     for tag in all_tags.keys():\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtag = 'graph'\u001b[0m\n",
      "\u001b[2m01:08:43.655669 line        47\u001b[0m         if tag == \"scalars\":\n",
      "\u001b[2m01:08:43.655780 line        59\u001b[0m         if tag == \"tensors\":\n",
      "\u001b[2m01:08:43.655881 line        85\u001b[0m         if tag == \"images\" and save_ims == True:\n",
      "\u001b[2m01:08:43.655983 line        46\u001b[0m     for tag in all_tags.keys():\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtag = 'meta_graph'\u001b[0m\n",
      "\u001b[2m01:08:43.656086 line        47\u001b[0m         if tag == \"scalars\":\n",
      "\u001b[2m01:08:43.656194 line        59\u001b[0m         if tag == \"tensors\":\n",
      "\u001b[2m01:08:43.656298 line        85\u001b[0m         if tag == \"images\" and save_ims == True:\n",
      "\u001b[2m01:08:43.656422 line        46\u001b[0m     for tag in all_tags.keys():\n",
      "\u001b[32m\u001b[2mModified var:.. \u001b[22mtag = 'run_metadata'\u001b[0m\n",
      "\u001b[2m01:08:43.656571 line        47\u001b[0m         if tag == \"scalars\":\n",
      "\u001b[2m01:08:43.656706 line        59\u001b[0m         if tag == \"tensors\":\n",
      "\u001b[2m01:08:43.656844 line        85\u001b[0m         if tag == \"images\" and save_ims == True:\n",
      "\u001b[2m01:08:43.656965 line        46\u001b[0m     for tag in all_tags.keys():\n",
      "\u001b[2m01:08:43.657127 line        96\u001b[0m     return temp_dict\n",
      "\u001b[2m01:08:43.657242 return      96\u001b[0m     return temp_dict\n",
      "\u001b[36m\u001b[2mReturn value:.. \u001b[22m{'proxy_step': 'False', 'Loss/Train': 0.14415098...27032023_120416/checkpoint', 'final_acc': '1.04'}\u001b[0m\n",
      "\u001b[33m\u001b[2mElapsed time: \u001b[22m00:00:00.023884\u001b[0m\n",
      "100%|███████████████████████████████████████████| 29/29 [00:00<00:00, 39.20it/s]\n"
     ]
    }
   ],
   "source": [
    "!python result_aggregator.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df = read_pickle(fname = \"./results/aggregated_runs.csv\")[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['20', '10', '11', '21', nan, 11.0, 1.0], dtype=object)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df[\"global_run_count\"].unique()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean if required"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29      10\n",
       "30      11\n",
       "32      10\n",
       "33      11\n",
       "35      10\n",
       "      ... \n",
       "234    NaN\n",
       "235     10\n",
       "236     11\n",
       "238     10\n",
       "239     11\n",
       "Name: global_run_count, Length: 145, dtype: object"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "145"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# broken_runs = combined_df.query('global_run_count != \"21\" and global_run_count != \"20\"')[\"index\"].values\n",
    "# len(broken_runs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['runs/proxy_run_28032023_090406/events.out.tfevents.1679987046.eragon',\n",
       "       'runs/proxy_run_28032023_090406/events.out.tfevents.1679987233.eragon',\n",
       "       'runs/proxy_run_28032023_091102/events.out.tfevents.1679987462.eragon',\n",
       "       'runs/proxy_run_28032023_091102/events.out.tfevents.1679987655.eragon',\n",
       "       'runs/proxy_run_28032023_091810/events.out.tfevents.1679987891.eragon',\n",
       "       'runs/proxy_run_28032023_091810/events.out.tfevents.1679988089.eragon',\n",
       "       'runs/proxy_run_28032023_092528/events.out.tfevents.1679988329.eragon',\n",
       "       'runs/proxy_run_28032023_092528/events.out.tfevents.1679988530.eragon',\n",
       "       'runs/proxy_run_28032023_093255/events.out.tfevents.1679988775.eragon',\n",
       "       'runs/proxy_run_28032023_093255/events.out.tfevents.1679989067.eragon',\n",
       "       'runs/proxy_run_28032023_094334/events.out.tfevents.1679989414.eragon',\n",
       "       'runs/proxy_run_28032023_094334/events.out.tfevents.1679989710.eragon',\n",
       "       'runs/proxy_run_28032023_095419/events.out.tfevents.1679990059.eragon',\n",
       "       'runs/proxy_run_28032023_095419/events.out.tfevents.1679990359.eragon',\n",
       "       'runs/proxy_run_28032023_100510/events.out.tfevents.1679990711.eragon',\n",
       "       'runs/proxy_run_28032023_100510/events.out.tfevents.1679991013.eragon',\n",
       "       'runs/proxy_run_28032023_101609/events.out.tfevents.1679991369.eragon',\n",
       "       'runs/proxy_run_28032023_101609/events.out.tfevents.1679991854.eragon',\n",
       "       'runs/proxy_run_28032023_103346/events.out.tfevents.1679992426.eragon',\n",
       "       'runs/proxy_run_28032023_103346/events.out.tfevents.1679992907.eragon',\n",
       "       'runs/proxy_run_28032023_105120/events.out.tfevents.1679993480.eragon',\n",
       "       'runs/proxy_run_28032023_105120/events.out.tfevents.1679993961.eragon',\n",
       "       'runs/proxy_run_28032023_110851/events.out.tfevents.1679994531.eragon',\n",
       "       'runs/proxy_run_28032023_110851/events.out.tfevents.1679995013.eragon',\n",
       "       'runs/proxy_run_28032023_112625/events.out.tfevents.1679995585.eragon',\n",
       "       'runs/proxy_run_28032023_112625/events.out.tfevents.1679995798.eragon',\n",
       "       'runs/proxy_run_28032023_113403/events.out.tfevents.1679996044.eragon',\n",
       "       'runs/proxy_run_28032023_113403/events.out.tfevents.1679996256.eragon',\n",
       "       'runs/proxy_run_28032023_114142/events.out.tfevents.1679996502.eragon',\n",
       "       'runs/proxy_run_28032023_114142/events.out.tfevents.1679996714.eragon',\n",
       "       'runs/proxy_run_28032023_120940/events.out.tfevents.1679998180.eragon',\n",
       "       'runs/proxy_run_28032023_120940/events.out.tfevents.1679998419.eragon',\n",
       "       'runs/proxy_run_28032023_121818/events.out.tfevents.1679998698.eragon',\n",
       "       'runs/proxy_run_28032023_121818/events.out.tfevents.1679998933.eragon',\n",
       "       'runs/proxy_run_28032023_122706/events.out.tfevents.1679999226.eragon',\n",
       "       'runs/proxy_run_28032023_122706/events.out.tfevents.1679999476.eragon',\n",
       "       'runs/proxy_run_28032023_123623/events.out.tfevents.1679999783.eragon',\n",
       "       'runs/proxy_run_28032023_123623/events.out.tfevents.1680000171.eragon',\n",
       "       'runs/proxy_run_28032023_125024/events.out.tfevents.1680000624.eragon',\n",
       "       'runs/proxy_run_28032023_125024/events.out.tfevents.1680000990.eragon',\n",
       "       'runs/proxy_run_28032023_130314/events.out.tfevents.1680001394.eragon',\n",
       "       'runs/proxy_run_28032023_130314/events.out.tfevents.1680001748.eragon',\n",
       "       'runs/proxy_run_28032023_131558/events.out.tfevents.1680002158.eragon',\n",
       "       'runs/proxy_run_28032023_131558/events.out.tfevents.1680002508.eragon',\n",
       "       'runs/proxy_run_28032023_132833/events.out.tfevents.1680002913.eragon',\n",
       "       'runs/proxy_run_28032023_132833/events.out.tfevents.1680003425.eragon',\n",
       "       'runs/proxy_run_28032023_134705/events.out.tfevents.1680004025.eragon',\n",
       "       'runs/proxy_run_28032023_134705/events.out.tfevents.1680004548.eragon',\n",
       "       'runs/proxy_run_28032023_140557/events.out.tfevents.1680005158.eragon',\n",
       "       'runs/proxy_run_28032023_140557/events.out.tfevents.1680005682.eragon',\n",
       "       'runs/proxy_run_28032023_142452/events.out.tfevents.1680006293.eragon',\n",
       "       'runs/proxy_run_28032023_142452/events.out.tfevents.1680006821.eragon',\n",
       "       'runs/proxy_run_28032023_150603/events.out.tfevents.1680008763.eragon',\n",
       "       'runs/proxy_run_28032023_150603/events.out.tfevents.1680009032.eragon',\n",
       "       'runs/proxy_run_28032023_151603/events.out.tfevents.1680009363.eragon',\n",
       "       'runs/proxy_run_28032023_151603/events.out.tfevents.1680009473.eragon',\n",
       "       'runs/proxy_run_28032023_152002/events.out.tfevents.1680009602.eragon',\n",
       "       'runs/proxy_run_28032023_152002/events.out.tfevents.1680009896.eragon',\n",
       "       'runs/proxy_run_28032023_153027/events.out.tfevents.1680010227.eragon',\n",
       "       'runs/proxy_run_28032023_153027/events.out.tfevents.1680010353.eragon',\n",
       "       'runs/proxy_run_28032023_153501/events.out.tfevents.1680010501.eragon',\n",
       "       'runs/proxy_run_28032023_153501/events.out.tfevents.1680011128.eragon',\n",
       "       'runs/proxy_run_28032023_155739/events.out.tfevents.1680011859.eragon',\n",
       "       'runs/proxy_run_28032023_155739/events.out.tfevents.1680012150.eragon',\n",
       "       'runs/proxy_run_28032023_160809/events.out.tfevents.1680012489.eragon',\n",
       "       'runs/proxy_run_28032023_160809/events.out.tfevents.1680012598.eragon',\n",
       "       'runs/proxy_run_28032023_161209/events.out.tfevents.1680012729.eragon',\n",
       "       'runs/proxy_run_28032023_161209/events.out.tfevents.1680012968.eragon',\n",
       "       'runs/proxy_run_28032023_162040/events.out.tfevents.1680013240.eragon',\n",
       "       'runs/proxy_run_28032023_162040/events.out.tfevents.1680013366.eragon',\n",
       "       'runs/proxy_run_28032023_162514/events.out.tfevents.1680013514.eragon',\n",
       "       'runs/proxy_run_28032023_162514/events.out.tfevents.1680013878.eragon',\n",
       "       'runs/proxy_run_28032023_163804/events.out.tfevents.1680014284.eragon',\n",
       "       'runs/proxy_run_28032023_163804/events.out.tfevents.1680014574.eragon',\n",
       "       'runs/proxy_run_28032023_164831/events.out.tfevents.1680014912.eragon',\n",
       "       'runs/proxy_run_28032023_164831/events.out.tfevents.1680015021.eragon',\n",
       "       'runs/proxy_run_28032023_165232/events.out.tfevents.1680015152.eragon',\n",
       "       'runs/proxy_run_28032023_165232/events.out.tfevents.1680015377.eragon',\n",
       "       'runs/proxy_run_28032023_170036/events.out.tfevents.1680015636.eragon',\n",
       "       'runs/proxy_run_28032023_170036/events.out.tfevents.1680015764.eragon',\n",
       "       'runs/proxy_run_28032023_170511/events.out.tfevents.1680015912.eragon',\n",
       "       'runs/proxy_run_28032023_170511/events.out.tfevents.1680016172.eragon',\n",
       "       'runs/proxy_run_28032023_171430/events.out.tfevents.1680016470.eragon',\n",
       "       'runs/proxy_run_28032023_171430/events.out.tfevents.1680016763.eragon',\n",
       "       'runs/proxy_run_28032023_172500/events.out.tfevents.1680017100.eragon',\n",
       "       'runs/proxy_run_28032023_172500/events.out.tfevents.1680017210.eragon',\n",
       "       'runs/proxy_run_28032023_172900/events.out.tfevents.1680017340.eragon',\n",
       "       'runs/proxy_run_28032023_172900/events.out.tfevents.1680017566.eragon',\n",
       "       'runs/proxy_run_28032023_173711/events.out.tfevents.1680017831.eragon',\n",
       "       'runs/proxy_run_28032023_173711/events.out.tfevents.1680017957.eragon',\n",
       "       'runs/proxy_run_28032023_174145/events.out.tfevents.1680018105.eragon',\n",
       "       'runs/proxy_run_28032023_174145/events.out.tfevents.1680018343.eragon',\n",
       "       'runs/proxy_run_28032023_175021/events.out.tfevents.1680018621.eragon',\n",
       "       'runs/proxy_run_28032023_175021/events.out.tfevents.1680018983.eragon',\n",
       "       'runs/proxy_run_28032023_180321/events.out.tfevents.1680019401.eragon',\n",
       "       'runs/proxy_run_28032023_180321/events.out.tfevents.1680019552.eragon',\n",
       "       'runs/proxy_run_28032023_180846/events.out.tfevents.1680019726.eragon',\n",
       "       'runs/proxy_run_28032023_180846/events.out.tfevents.1680020036.eragon',\n",
       "       'runs/proxy_run_28032023_181950/events.out.tfevents.1680020390.eragon',\n",
       "       'runs/proxy_run_28032023_181950/events.out.tfevents.1680020558.eragon',\n",
       "       'runs/proxy_run_28032023_182546/events.out.tfevents.1680020747.eragon',\n",
       "       'runs/proxy_run_28032023_182546/events.out.tfevents.1680021060.eragon',\n",
       "       'runs/proxy_run_28032023_183701/events.out.tfevents.1680021421.eragon',\n",
       "       'runs/proxy_run_28032023_183701/events.out.tfevents.1680021782.eragon',\n",
       "       'runs/proxy_run_28032023_185000/events.out.tfevents.1680022200.eragon',\n",
       "       'runs/proxy_run_28032023_185000/events.out.tfevents.1680022351.eragon',\n",
       "       'runs/proxy_run_29032023_095618/events.out.tfevents.1680076585.eragon',\n",
       "       'runs/proxy_run_29032023_095618/events.out.tfevents.1680076833.eragon',\n",
       "       'runs/proxy_run_29032023_100319/events.out.tfevents.1680077001.eragon',\n",
       "       'runs/proxy_run_29032023_100457/events.out.tfevents.1680077106.eragon',\n",
       "       'runs/proxy_run_29032023_100933/events.out.tfevents.1680077373.eragon',\n",
       "       'runs/proxy_run_29032023_100933/events.out.tfevents.1680077944.eragon',\n",
       "       'runs/proxy_run_29032023_104220/events.out.tfevents.1680079340.eragon',\n",
       "       'runs/proxy_run_29032023_104220/events.out.tfevents.1680079774.eragon',\n",
       "       'runs/proxy_run_29032023_105817/events.out.tfevents.1680080297.eragon',\n",
       "       'runs/proxy_run_29032023_105817/events.out.tfevents.1680080785.eragon',\n",
       "       'runs/proxy_run_29032023_111528/events.out.tfevents.1680081328.eragon',\n",
       "       'runs/proxy_run_29032023_111528/events.out.tfevents.1680081819.eragon',\n",
       "       'runs/proxy_run_29032023_113309/events.out.tfevents.1680082389.eragon',\n",
       "       'runs/proxy_run_29032023_113309/events.out.tfevents.1680082883.eragon',\n",
       "       'runs/proxy_run_29032023_115029/events.out.tfevents.1680083429.eragon',\n",
       "       'runs/proxy_run_29032023_115029/events.out.tfevents.1680083914.eragon',\n",
       "       'runs/proxy_run_29032023_120722/events.out.tfevents.1680084442.eragon',\n",
       "       'runs/proxy_run_29032023_120722/events.out.tfevents.1680084915.eragon',\n",
       "       'runs/proxy_run_29032023_122425/events.out.tfevents.1680085465.eragon',\n",
       "       'runs/proxy_run_29032023_122425/events.out.tfevents.1680085959.eragon',\n",
       "       'runs/proxy_run_29032023_124214/events.out.tfevents.1680086534.eragon',\n",
       "       'runs/proxy_run_29032023_124214/events.out.tfevents.1680087026.eragon',\n",
       "       'runs/proxy_run_29032023_125931/events.out.tfevents.1680087571.eragon',\n",
       "       'runs/proxy_run_29032023_125931/events.out.tfevents.1680088063.eragon',\n",
       "       'runs/proxy_run_29032023_131705/events.out.tfevents.1680088626.eragon',\n",
       "       'runs/proxy_run_29032023_131705/events.out.tfevents.1680089120.eragon',\n",
       "       'runs/proxy_run_29032023_133445/events.out.tfevents.1680089685.eragon',\n",
       "       'runs/proxy_run_29032023_133445/events.out.tfevents.1680090169.eragon',\n",
       "       'runs/proxy_run_29032023_135133/events.out.tfevents.1680090693.eragon',\n",
       "       'runs/proxy_run_29032023_135133/events.out.tfevents.1680091178.eragon',\n",
       "       'runs/proxy_run_29032023_140908/events.out.tfevents.1680091748.eragon',\n",
       "       'runs/proxy_run_29032023_140908/events.out.tfevents.1680092253.eragon',\n",
       "       'runs/proxy_run_29032023_142709/events.out.tfevents.1680092829.eragon',\n",
       "       'runs/proxy_run_29032023_142709/events.out.tfevents.1680093332.eragon',\n",
       "       'runs/proxy_run_29032023_144502/events.out.tfevents.1680093902.eragon',\n",
       "       'runs/proxy_run_29032023_154223/events.out.tfevents.1680097343.eragon',\n",
       "       'runs/proxy_run_29032023_154223/events.out.tfevents.1680097782.eragon',\n",
       "       'runs/proxy_run_29032023_155820/events.out.tfevents.1680098300.eragon',\n",
       "       'runs/proxy_run_29032023_155820/events.out.tfevents.1680098791.eragon'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# broken_runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Delete broken runs\n",
    "# [Path.unlink(Path(x)) for x in broken_runs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def dir_empty(path):\n",
    "    empty = True\n",
    "    for item in path.glob('*'):\n",
    "        if item.is_file():\n",
    "            empty = False\n",
    "        if item.is_dir() and not dir_empty(item):\n",
    "            empty = False\n",
    "    # if empty:\n",
    "        # path.rmdir()  # Remove if you just want to have the result\n",
    "    return empty\n",
    "\n",
    "# dir_empty([x for x in Path(\"./results\").glob(\"*\") if x.is_dir()])\n",
    "# [Path.rmdir(x) for x in Path(\"./results\").glob(\"*\") if x.is_dir() and dir_empty(x)]\n",
    "[Path.rmdir(x) for x in Path(\"./runs\").glob(\"*\") if x.is_dir() and dir_empty(x)]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Continue here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df = combined_df.query('global_run_count == \"21\" or global_run_count == \"20\"')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>proxy_step</th>\n",
       "      <th>Loss/Train</th>\n",
       "      <th>Acc/Train</th>\n",
       "      <th>global_run_count</th>\n",
       "      <th>Loss/Val</th>\n",
       "      <th>Acc/Val</th>\n",
       "      <th>experiment_name</th>\n",
       "      <th>image_size</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>...</th>\n",
       "      <th>writer</th>\n",
       "      <th>label_map</th>\n",
       "      <th>rev_label_map</th>\n",
       "      <th>num_classes</th>\n",
       "      <th>dataset_sizes</th>\n",
       "      <th>criterion</th>\n",
       "      <th>cam</th>\n",
       "      <th>save_path</th>\n",
       "      <th>final_acc</th>\n",
       "      <th>Number_Chosen</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>runs/baseline_run_26032023_124800/events.out.t...</td>\n",
       "      <td>False</td>\n",
       "      <td>0.00103</td>\n",
       "      <td>99.43</td>\n",
       "      <td>20</td>\n",
       "      <td>0.046147</td>\n",
       "      <td>65.949997</td>\n",
       "      <td>baseline_run</td>\n",
       "      <td>224</td>\n",
       "      <td>32</td>\n",
       "      <td>...</td>\n",
       "      <td>&lt;tensorboardX.writer.SummaryWriter object at 0...</td>\n",
       "      <td>{0: 'apple', 1: 'aquarium_fish', 2: 'baby', 3:...</td>\n",
       "      <td>{'apple': 0, 'aquarium_fish': 1, 'baby': 2, 'b...</td>\n",
       "      <td>100</td>\n",
       "      <td>{'train': 10000, 'val': 10000}</td>\n",
       "      <td>CrossEntropyLoss()</td>\n",
       "      <td>&lt;pytorch_grad_cam.grad_cam_plusplus.GradCAMPlu...</td>\n",
       "      <td>/run/media/eragon/HDD/CODE/Github/improving_ro...</td>\n",
       "      <td>65.95</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>runs/baseline_run_26032023_132227/events.out.t...</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000502</td>\n",
       "      <td>99.459999</td>\n",
       "      <td>20</td>\n",
       "      <td>0.024097</td>\n",
       "      <td>63.66</td>\n",
       "      <td>baseline_run</td>\n",
       "      <td>224</td>\n",
       "      <td>64</td>\n",
       "      <td>...</td>\n",
       "      <td>&lt;tensorboardX.writer.SummaryWriter object at 0...</td>\n",
       "      <td>{0: 'n02085620-Chihuahua', 1: 'n02085782-Japan...</td>\n",
       "      <td>{'n02085620-Chihuahua': 0, 'n02085782-Japanese...</td>\n",
       "      <td>120</td>\n",
       "      <td>{'train': 10000, 'val': 10000}</td>\n",
       "      <td>CrossEntropyLoss()</td>\n",
       "      <td>&lt;pytorch_grad_cam.grad_cam_plusplus.GradCAMPlu...</td>\n",
       "      <td>/run/media/eragon/HDD/CODE/Github/improving_ro...</td>\n",
       "      <td>63.66</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>runs/baseline_run_26032023_133425/events.out.t...</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000079</td>\n",
       "      <td>99.912529</td>\n",
       "      <td>20</td>\n",
       "      <td>0.007058</td>\n",
       "      <td>88.954506</td>\n",
       "      <td>baseline_run</td>\n",
       "      <td>224</td>\n",
       "      <td>64</td>\n",
       "      <td>...</td>\n",
       "      <td>&lt;tensorboardX.writer.SummaryWriter object at 0...</td>\n",
       "      <td>{0: 'BACKGROUND_Google', 1: 'Faces', 2: 'Faces...</td>\n",
       "      <td>{'BACKGROUND_Google': 0, 'Faces': 1, 'Faces_ea...</td>\n",
       "      <td>102</td>\n",
       "      <td>{'train': 4573, 'val': 4572}</td>\n",
       "      <td>CrossEntropyLoss()</td>\n",
       "      <td>&lt;pytorch_grad_cam.grad_cam_plusplus.GradCAMPlu...</td>\n",
       "      <td>/run/media/eragon/HDD/CODE/Github/improving_ro...</td>\n",
       "      <td>88.95450568678915</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>runs/baseline_run_26032023_134035/events.out.t...</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>100.0</td>\n",
       "      <td>20</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>100.0</td>\n",
       "      <td>baseline_run</td>\n",
       "      <td>224</td>\n",
       "      <td>64</td>\n",
       "      <td>...</td>\n",
       "      <td>&lt;tensorboardX.writer.SummaryWriter object at 0...</td>\n",
       "      <td>{0: 'A', 1: 'B', 2: 'C', 3: 'D', 4: 'E', 5: 'F...</td>\n",
       "      <td>{'A': 0, 'B': 1, 'C': 2, 'D': 3, 'E': 4, 'F': ...</td>\n",
       "      <td>20</td>\n",
       "      <td>{'train': 10000, 'val': 10000}</td>\n",
       "      <td>CrossEntropyLoss()</td>\n",
       "      <td>&lt;pytorch_grad_cam.grad_cam_plusplus.GradCAMPlu...</td>\n",
       "      <td>/run/media/eragon/HDD/CODE/Github/improving_ro...</td>\n",
       "      <td>100.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>runs/baseline_run_26032023_135310/events.out.t...</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000112</td>\n",
       "      <td>99.873283</td>\n",
       "      <td>20</td>\n",
       "      <td>0.003803</td>\n",
       "      <td>93.409378</td>\n",
       "      <td>baseline_run</td>\n",
       "      <td>224</td>\n",
       "      <td>64</td>\n",
       "      <td>...</td>\n",
       "      <td>&lt;tensorboardX.writer.SummaryWriter object at 0...</td>\n",
       "      <td>{0: 'n01440764', 1: 'n02102040', 2: 'n02979186...</td>\n",
       "      <td>{'n01440764': 0, 'n02102040': 1, 'n02979186': ...</td>\n",
       "      <td>10</td>\n",
       "      <td>{'train': 4735, 'val': 4734}</td>\n",
       "      <td>CrossEntropyLoss()</td>\n",
       "      <td>&lt;pytorch_grad_cam.grad_cam_plusplus.GradCAMPlu...</td>\n",
       "      <td>/run/media/eragon/HDD/CODE/Github/improving_ro...</td>\n",
       "      <td>93.40937896070976</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               index proxy_step Loss/Train  \\\n",
       "0  runs/baseline_run_26032023_124800/events.out.t...      False    0.00103   \n",
       "1  runs/baseline_run_26032023_132227/events.out.t...      False   0.000502   \n",
       "2  runs/baseline_run_26032023_133425/events.out.t...      False   0.000079   \n",
       "3  runs/baseline_run_26032023_134035/events.out.t...      False   0.000007   \n",
       "4  runs/baseline_run_26032023_135310/events.out.t...      False   0.000112   \n",
       "\n",
       "   Acc/Train global_run_count  Loss/Val    Acc/Val experiment_name image_size  \\\n",
       "0      99.43               20  0.046147  65.949997    baseline_run        224   \n",
       "1  99.459999               20  0.024097      63.66    baseline_run        224   \n",
       "2  99.912529               20  0.007058  88.954506    baseline_run        224   \n",
       "3      100.0               20  0.000001      100.0    baseline_run        224   \n",
       "4  99.873283               20  0.003803  93.409378    baseline_run        224   \n",
       "\n",
       "  batch_size  ...                                             writer  \\\n",
       "0         32  ...  <tensorboardX.writer.SummaryWriter object at 0...   \n",
       "1         64  ...  <tensorboardX.writer.SummaryWriter object at 0...   \n",
       "2         64  ...  <tensorboardX.writer.SummaryWriter object at 0...   \n",
       "3         64  ...  <tensorboardX.writer.SummaryWriter object at 0...   \n",
       "4         64  ...  <tensorboardX.writer.SummaryWriter object at 0...   \n",
       "\n",
       "                                           label_map  \\\n",
       "0  {0: 'apple', 1: 'aquarium_fish', 2: 'baby', 3:...   \n",
       "1  {0: 'n02085620-Chihuahua', 1: 'n02085782-Japan...   \n",
       "2  {0: 'BACKGROUND_Google', 1: 'Faces', 2: 'Faces...   \n",
       "3  {0: 'A', 1: 'B', 2: 'C', 3: 'D', 4: 'E', 5: 'F...   \n",
       "4  {0: 'n01440764', 1: 'n02102040', 2: 'n02979186...   \n",
       "\n",
       "                                       rev_label_map num_classes  \\\n",
       "0  {'apple': 0, 'aquarium_fish': 1, 'baby': 2, 'b...         100   \n",
       "1  {'n02085620-Chihuahua': 0, 'n02085782-Japanese...         120   \n",
       "2  {'BACKGROUND_Google': 0, 'Faces': 1, 'Faces_ea...         102   \n",
       "3  {'A': 0, 'B': 1, 'C': 2, 'D': 3, 'E': 4, 'F': ...          20   \n",
       "4  {'n01440764': 0, 'n02102040': 1, 'n02979186': ...          10   \n",
       "\n",
       "                    dataset_sizes           criterion  \\\n",
       "0  {'train': 10000, 'val': 10000}  CrossEntropyLoss()   \n",
       "1  {'train': 10000, 'val': 10000}  CrossEntropyLoss()   \n",
       "2    {'train': 4573, 'val': 4572}  CrossEntropyLoss()   \n",
       "3  {'train': 10000, 'val': 10000}  CrossEntropyLoss()   \n",
       "4    {'train': 4735, 'val': 4734}  CrossEntropyLoss()   \n",
       "\n",
       "                                                 cam  \\\n",
       "0  <pytorch_grad_cam.grad_cam_plusplus.GradCAMPlu...   \n",
       "1  <pytorch_grad_cam.grad_cam_plusplus.GradCAMPlu...   \n",
       "2  <pytorch_grad_cam.grad_cam_plusplus.GradCAMPlu...   \n",
       "3  <pytorch_grad_cam.grad_cam_plusplus.GradCAMPlu...   \n",
       "4  <pytorch_grad_cam.grad_cam_plusplus.GradCAMPlu...   \n",
       "\n",
       "                                           save_path          final_acc  \\\n",
       "0  /run/media/eragon/HDD/CODE/Github/improving_ro...              65.95   \n",
       "1  /run/media/eragon/HDD/CODE/Github/improving_ro...              63.66   \n",
       "2  /run/media/eragon/HDD/CODE/Github/improving_ro...  88.95450568678915   \n",
       "3  /run/media/eragon/HDD/CODE/Github/improving_ro...              100.0   \n",
       "4  /run/media/eragon/HDD/CODE/Github/improving_ro...  93.40937896070976   \n",
       "\n",
       "  Number_Chosen  \n",
       "0           NaN  \n",
       "1           NaN  \n",
       "2           NaN  \n",
       "3           NaN  \n",
       "4           NaN  \n",
       "\n",
       "[5 rows x 40 columns]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(96, 40)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[10, 'p', 10]    67\n",
       "[20]             29\n",
       "Name: proxy_steps, dtype: int64"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df[combined_df[\"global_run_count\"]!= \"0\"][\"proxy_steps\"].value_counts()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filtered_df.iloc[1].original_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filtered_df.iloc[1].converted_proxy"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_proxy(string): return \"p\" in string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_stats(values):\n",
    "    return f\"min: {values.min()} \\nmax: {values.max()} \\navg: {values.mean()}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_float(df, cols, totype= float):\n",
    "    for col in cols:\n",
    "        df[col] = df[col].astype(totype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df = combined_df.fillna(0)\n",
    "# col to check for proxy\n",
    "# combined_df[\"has_proxy\"] = combined_df[\"proxy_steps\"].apply(check_proxy)\n",
    "# Fix naming\n",
    "combined_df = combined_df.rename(columns={\"Acc/Val\":\"accuracy\", \"proxy_steps\":\"step_schedule\"})\n",
    "# Fix types\n",
    "convert_float(combined_df, [\"change_subset_attention\", \"proxy_threshold\", \"accuracy\"], float)\n",
    "convert_float(combined_df, [\"global_run_count\"], int)\n",
    "convert_float(combined_df, [\"transfer_imagenet\"], bool)\n",
    "\n",
    "# ignore failed runs\n",
    "# combined_df = combined_df[combined_df[\"global_run_count\"]!=0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df[\"has_proxy\"] = combined_df[\"step_schedule\"].apply(check_proxy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df.loc[combined_df[\"has_proxy\"] == False, [\"pixel_replacement_method\", \"transfer_imagenet\", \"gradient_method\"]] = \"baseline\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grouped Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_grouped_results(df, group_cols ,filter = None, index_cols = ([\"ds_name\", (\"accuracy\")]), print_latex = False):\n",
    "    if filter != None:\n",
    "        df = df.reset_index()\n",
    "        for key in filter.keys():\n",
    "            df = df[df[key] == filter[key]]\n",
    "    final_df = pd.DataFrame(df.groupby(group_cols, as_index=True).mean(numeric_only = True)[\"accuracy\"]).sort_values(index_cols, ascending=False)\n",
    "    if print_latex == True:\n",
    "        clipboard.copy(final_df.to_latex())\n",
    "\n",
    "    return final_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ds_name</th>\n",
       "      <th>model</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">plantdisease</th>\n",
       "      <th>resnet50</th>\n",
       "      <td>99.220001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>efficientnet_b0</th>\n",
       "      <td>99.130001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>resnet18</th>\n",
       "      <td>99.089999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">imagenette</th>\n",
       "      <th>resnet18</th>\n",
       "      <td>97.558090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>resnet50</th>\n",
       "      <td>94.190956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>efficientnet_b0</th>\n",
       "      <td>93.800167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vit_base_patch16_224</th>\n",
       "      <td>39.543728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vgg16</th>\n",
       "      <td>10.318969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">dogs</th>\n",
       "      <th>efficientnet_b0</th>\n",
       "      <td>88.589139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>resnet18</th>\n",
       "      <td>80.130001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>resnet50</th>\n",
       "      <td>66.629997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vgg16</th>\n",
       "      <td>15.650000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vit_base_patch16_224</th>\n",
       "      <td>10.950000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">cifar100</th>\n",
       "      <th>efficientnet_b0</th>\n",
       "      <td>82.301112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>resnet50</th>\n",
       "      <td>81.273334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>resnet18</th>\n",
       "      <td>77.486667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vit_base_patch16_224</th>\n",
       "      <td>13.120000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vgg16</th>\n",
       "      <td>1.040000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">caltech101</th>\n",
       "      <th>efficientnet_b0</th>\n",
       "      <td>96.252551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>resnet18</th>\n",
       "      <td>96.146106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>resnet50</th>\n",
       "      <td>85.454941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vgg16</th>\n",
       "      <td>45.100613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vit_base_patch16_224</th>\n",
       "      <td>32.874016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">asl</th>\n",
       "      <th>resnet18</th>\n",
       "      <td>99.980000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>efficientnet_b0</th>\n",
       "      <td>99.755001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>resnet50</th>\n",
       "      <td>98.589996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vit_base_patch16_224</th>\n",
       "      <td>14.090000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vgg16</th>\n",
       "      <td>5.070000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    accuracy\n",
       "ds_name      model                          \n",
       "plantdisease resnet50              99.220001\n",
       "             efficientnet_b0       99.130001\n",
       "             resnet18              99.089999\n",
       "imagenette   resnet18              97.558090\n",
       "             resnet50              94.190956\n",
       "             efficientnet_b0       93.800167\n",
       "             vit_base_patch16_224  39.543728\n",
       "             vgg16                 10.318969\n",
       "dogs         efficientnet_b0       88.589139\n",
       "             resnet18              80.130001\n",
       "             resnet50              66.629997\n",
       "             vgg16                 15.650000\n",
       "             vit_base_patch16_224  10.950000\n",
       "cifar100     efficientnet_b0       82.301112\n",
       "             resnet50              81.273334\n",
       "             resnet18              77.486667\n",
       "             vit_base_patch16_224  13.120000\n",
       "             vgg16                  1.040000\n",
       "caltech101   efficientnet_b0       96.252551\n",
       "             resnet18              96.146106\n",
       "             resnet50              85.454941\n",
       "             vgg16                 45.100613\n",
       "             vit_base_patch16_224  32.874016\n",
       "asl          resnet18              99.980000\n",
       "             efficientnet_b0       99.755001\n",
       "             resnet50              98.589996\n",
       "             vit_base_patch16_224  14.090000\n",
       "             vgg16                  5.070000"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "return_grouped_results(combined_df, [\"ds_name\",\"model\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ds_name</th>\n",
       "      <th>pixel_replacement_method</th>\n",
       "      <th>transfer_imagenet</th>\n",
       "      <th>gradient_method</th>\n",
       "      <th>step_schedule</th>\n",
       "      <th>change_subset_attention</th>\n",
       "      <th>proxy_threshold</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">dogs</th>\n",
       "      <th rowspan=\"4\" valign=\"top\">blended</th>\n",
       "      <th rowspan=\"4\" valign=\"top\">True</th>\n",
       "      <th rowspan=\"4\" valign=\"top\">gradcamplusplus</th>\n",
       "      <th rowspan=\"4\" valign=\"top\">[10, 'p', 10]</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">0.2</th>\n",
       "      <th>0.10</th>\n",
       "      <td>89.702185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.85</th>\n",
       "      <td>89.465372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">0.8</th>\n",
       "      <th>0.10</th>\n",
       "      <td>88.106315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.85</th>\n",
       "      <td>87.892746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>baseline</th>\n",
       "      <th>baseline</th>\n",
       "      <th>baseline</th>\n",
       "      <th>[20]</th>\n",
       "      <th>0.8</th>\n",
       "      <th>0.85</th>\n",
       "      <td>45.681999</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                           accuracy\n",
       "ds_name pixel_replacement_method transfer_imagenet gradient_method step_schedule change_subset_attention proxy_threshold           \n",
       "dogs    blended                  True              gradcamplusplus [10, 'p', 10] 0.2                     0.10             89.702185\n",
       "                                                                                                         0.85             89.465372\n",
       "                                                                                 0.8                     0.10             88.106315\n",
       "                                                                                                         0.85             87.892746\n",
       "        baseline                 baseline          baseline        [20]          0.8                     0.85             45.681999"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "return_grouped_results(combined_df, [\"ds_name\", \"pixel_replacement_method\", \"transfer_imagenet\", \"gradient_method\", \"step_schedule\", \"change_subset_attention\", \"proxy_threshold\"], filter = { \"ds_name\":\"dogs\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ds_name</th>\n",
       "      <th>pixel_replacement_method</th>\n",
       "      <th>transfer_imagenet</th>\n",
       "      <th>gradient_method</th>\n",
       "      <th>step_schedule</th>\n",
       "      <th>change_subset_attention</th>\n",
       "      <th>proxy_threshold</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>plantdisease</th>\n",
       "      <th>blended</th>\n",
       "      <th>True</th>\n",
       "      <th>gradcamplusplus</th>\n",
       "      <th>[10, 'p', 10]</th>\n",
       "      <th>0.8</th>\n",
       "      <th>0.10</th>\n",
       "      <td>98.910004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>imagenette</th>\n",
       "      <th>blended</th>\n",
       "      <th>True</th>\n",
       "      <th>gradcamplusplus</th>\n",
       "      <th>[10, 'p', 10]</th>\n",
       "      <th>0.8</th>\n",
       "      <th>0.10</th>\n",
       "      <td>99.598648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">dogs</th>\n",
       "      <th rowspan=\"4\" valign=\"top\">blended</th>\n",
       "      <th rowspan=\"4\" valign=\"top\">True</th>\n",
       "      <th rowspan=\"4\" valign=\"top\">gradcamplusplus</th>\n",
       "      <th rowspan=\"4\" valign=\"top\">[10, 'p', 10]</th>\n",
       "      <th>0.2</th>\n",
       "      <th>0.10</th>\n",
       "      <td>89.702185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">0.8</th>\n",
       "      <th>0.85</th>\n",
       "      <td>89.509843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.10</th>\n",
       "      <td>89.490840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.2</th>\n",
       "      <th>0.85</th>\n",
       "      <td>89.465372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">cifar100</th>\n",
       "      <th rowspan=\"4\" valign=\"top\">blended</th>\n",
       "      <th rowspan=\"4\" valign=\"top\">True</th>\n",
       "      <th rowspan=\"4\" valign=\"top\">gradcamplusplus</th>\n",
       "      <th rowspan=\"4\" valign=\"top\">[10, 'p', 10]</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">0.2</th>\n",
       "      <th>0.10</th>\n",
       "      <td>83.820000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.85</th>\n",
       "      <td>83.530003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">0.8</th>\n",
       "      <th>0.10</th>\n",
       "      <td>83.345001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.85</th>\n",
       "      <td>83.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">caltech101</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">blended</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">True</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">gradcamplusplus</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">[10, 'p', 10]</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">0.8</th>\n",
       "      <th>0.10</th>\n",
       "      <td>98.162727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.85</th>\n",
       "      <td>98.140854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>asl</th>\n",
       "      <th>blended</th>\n",
       "      <th>True</th>\n",
       "      <th>gradcamplusplus</th>\n",
       "      <th>[10, 'p', 10]</th>\n",
       "      <th>0.8</th>\n",
       "      <th>0.10</th>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                 accuracy\n",
       "ds_name      pixel_replacement_method transfer_imagenet gradient_method step_schedule change_subset_attention proxy_threshold            \n",
       "plantdisease blended                  True              gradcamplusplus [10, 'p', 10] 0.8                     0.10              98.910004\n",
       "imagenette   blended                  True              gradcamplusplus [10, 'p', 10] 0.8                     0.10              99.598648\n",
       "dogs         blended                  True              gradcamplusplus [10, 'p', 10] 0.2                     0.10              89.702185\n",
       "                                                                                      0.8                     0.85              89.509843\n",
       "                                                                                                              0.10              89.490840\n",
       "                                                                                      0.2                     0.85              89.465372\n",
       "cifar100     blended                  True              gradcamplusplus [10, 'p', 10] 0.2                     0.10              83.820000\n",
       "                                                                                                              0.85              83.530003\n",
       "                                                                                      0.8                     0.10              83.345001\n",
       "                                                                                                              0.85              83.000000\n",
       "caltech101   blended                  True              gradcamplusplus [10, 'p', 10] 0.8                     0.10              98.162727\n",
       "                                                                                                              0.85              98.140854\n",
       "asl          blended                  True              gradcamplusplus [10, 'p', 10] 0.8                     0.10             100.000000"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "return_grouped_results(combined_df, [\"ds_name\", \"pixel_replacement_method\", \"transfer_imagenet\", \"gradient_method\", \"step_schedule\", \"change_subset_attention\", \"proxy_threshold\"], filter = { \"model\":\"efficientnet_b0\", \"has_proxy\":True,})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ds_name</th>\n",
       "      <th>pixel_replacement_method</th>\n",
       "      <th>transfer_imagenet</th>\n",
       "      <th>gradient_method</th>\n",
       "      <th>step_schedule</th>\n",
       "      <th>model</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">plantdisease</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">baseline</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">baseline</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">baseline</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">[20]</th>\n",
       "      <th>efficientnet_b0</th>\n",
       "      <td>99.349998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>resnet50</th>\n",
       "      <td>99.220001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>blended</th>\n",
       "      <th>True</th>\n",
       "      <th>gradcamplusplus</th>\n",
       "      <th>[10, 'p', 10]</th>\n",
       "      <th>resnet18</th>\n",
       "      <td>99.129999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>baseline</th>\n",
       "      <th>baseline</th>\n",
       "      <th>baseline</th>\n",
       "      <th>[20]</th>\n",
       "      <th>resnet18</th>\n",
       "      <td>98.930000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>blended</th>\n",
       "      <th>True</th>\n",
       "      <th>gradcamplusplus</th>\n",
       "      <th>[10, 'p', 10]</th>\n",
       "      <th>efficientnet_b0</th>\n",
       "      <td>98.910004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"7\" valign=\"top\">imagenette</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">blended</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">True</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">gradcamplusplus</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">[10, 'p', 10]</th>\n",
       "      <th>efficientnet_b0</th>\n",
       "      <td>99.598648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>resnet18</th>\n",
       "      <td>98.595268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">baseline</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">baseline</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">baseline</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">[20]</th>\n",
       "      <th>resnet50</th>\n",
       "      <td>94.190956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>resnet18</th>\n",
       "      <td>93.409378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>efficientnet_b0</th>\n",
       "      <td>88.001686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vit_base_patch16_224</th>\n",
       "      <td>39.543728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vgg16</th>\n",
       "      <td>10.318969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"7\" valign=\"top\">dogs</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">blended</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">True</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">gradcamplusplus</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">[10, 'p', 10]</th>\n",
       "      <th>efficientnet_b0</th>\n",
       "      <td>89.537425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>resnet18</th>\n",
       "      <td>84.247501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">baseline</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">baseline</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">baseline</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">[20]</th>\n",
       "      <th>efficientnet_b0</th>\n",
       "      <td>71.519997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>resnet50</th>\n",
       "      <td>66.629997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>resnet18</th>\n",
       "      <td>63.660000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vgg16</th>\n",
       "      <td>15.650000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vit_base_patch16_224</th>\n",
       "      <td>10.950000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"8\" valign=\"top\">cifar100</th>\n",
       "      <th rowspan=\"3\" valign=\"top\">blended</th>\n",
       "      <th rowspan=\"3\" valign=\"top\">True</th>\n",
       "      <th rowspan=\"3\" valign=\"top\">gradcamplusplus</th>\n",
       "      <th rowspan=\"3\" valign=\"top\">[10, 'p', 10]</th>\n",
       "      <th>resnet50</th>\n",
       "      <td>83.475000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>efficientnet_b0</th>\n",
       "      <td>83.423751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>resnet18</th>\n",
       "      <td>78.928751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">baseline</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">baseline</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">baseline</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">[20]</th>\n",
       "      <th>efficientnet_b0</th>\n",
       "      <td>73.320000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>resnet18</th>\n",
       "      <td>65.949997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>resnet50</th>\n",
       "      <td>63.660000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vit_base_patch16_224</th>\n",
       "      <td>13.120000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vgg16</th>\n",
       "      <td>1.040000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"7\" valign=\"top\">caltech101</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">blended</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">True</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">gradcamplusplus</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">[10, 'p', 10]</th>\n",
       "      <th>efficientnet_b0</th>\n",
       "      <td>98.151791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>resnet18</th>\n",
       "      <td>97.944006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">baseline</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">baseline</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">baseline</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">[20]</th>\n",
       "      <th>efficientnet_b0</th>\n",
       "      <td>92.454071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>resnet18</th>\n",
       "      <td>88.954506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>resnet50</th>\n",
       "      <td>85.454941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vgg16</th>\n",
       "      <td>45.100613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vit_base_patch16_224</th>\n",
       "      <td>32.874016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"7\" valign=\"top\">asl</th>\n",
       "      <th>baseline</th>\n",
       "      <th>baseline</th>\n",
       "      <th>baseline</th>\n",
       "      <th>[20]</th>\n",
       "      <th>resnet18</th>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">blended</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">True</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">gradcamplusplus</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">[10, 'p', 10]</th>\n",
       "      <th>efficientnet_b0</th>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>resnet18</th>\n",
       "      <td>99.975000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">baseline</th>\n",
       "      <th rowspan=\"4\" valign=\"top\">baseline</th>\n",
       "      <th rowspan=\"4\" valign=\"top\">baseline</th>\n",
       "      <th rowspan=\"4\" valign=\"top\">[20]</th>\n",
       "      <th>efficientnet_b0</th>\n",
       "      <td>99.510002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>resnet50</th>\n",
       "      <td>98.589996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vit_base_patch16_224</th>\n",
       "      <td>14.090000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vgg16</th>\n",
       "      <td>5.070000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                              accuracy\n",
       "ds_name      pixel_replacement_method transfer_imagenet gradient_method step_schedule model                           \n",
       "plantdisease baseline                 baseline          baseline        [20]          efficientnet_b0        99.349998\n",
       "                                                                                      resnet50               99.220001\n",
       "             blended                  True              gradcamplusplus [10, 'p', 10] resnet18               99.129999\n",
       "             baseline                 baseline          baseline        [20]          resnet18               98.930000\n",
       "             blended                  True              gradcamplusplus [10, 'p', 10] efficientnet_b0        98.910004\n",
       "imagenette   blended                  True              gradcamplusplus [10, 'p', 10] efficientnet_b0        99.598648\n",
       "                                                                                      resnet18               98.595268\n",
       "             baseline                 baseline          baseline        [20]          resnet50               94.190956\n",
       "                                                                                      resnet18               93.409378\n",
       "                                                                                      efficientnet_b0        88.001686\n",
       "                                                                                      vit_base_patch16_224   39.543728\n",
       "                                                                                      vgg16                  10.318969\n",
       "dogs         blended                  True              gradcamplusplus [10, 'p', 10] efficientnet_b0        89.537425\n",
       "                                                                                      resnet18               84.247501\n",
       "             baseline                 baseline          baseline        [20]          efficientnet_b0        71.519997\n",
       "                                                                                      resnet50               66.629997\n",
       "                                                                                      resnet18               63.660000\n",
       "                                                                                      vgg16                  15.650000\n",
       "                                                                                      vit_base_patch16_224   10.950000\n",
       "cifar100     blended                  True              gradcamplusplus [10, 'p', 10] resnet50               83.475000\n",
       "                                                                                      efficientnet_b0        83.423751\n",
       "                                                                                      resnet18               78.928751\n",
       "             baseline                 baseline          baseline        [20]          efficientnet_b0        73.320000\n",
       "                                                                                      resnet18               65.949997\n",
       "                                                                                      resnet50               63.660000\n",
       "                                                                                      vit_base_patch16_224   13.120000\n",
       "                                                                                      vgg16                   1.040000\n",
       "caltech101   blended                  True              gradcamplusplus [10, 'p', 10] efficientnet_b0        98.151791\n",
       "                                                                                      resnet18               97.944006\n",
       "             baseline                 baseline          baseline        [20]          efficientnet_b0        92.454071\n",
       "                                                                                      resnet18               88.954506\n",
       "                                                                                      resnet50               85.454941\n",
       "                                                                                      vgg16                  45.100613\n",
       "                                                                                      vit_base_patch16_224   32.874016\n",
       "asl          baseline                 baseline          baseline        [20]          resnet18              100.000000\n",
       "             blended                  True              gradcamplusplus [10, 'p', 10] efficientnet_b0       100.000000\n",
       "                                                                                      resnet18               99.975000\n",
       "             baseline                 baseline          baseline        [20]          efficientnet_b0        99.510002\n",
       "                                                                                      resnet50               98.589996\n",
       "                                                                                      vit_base_patch16_224   14.090000\n",
       "                                                                                      vgg16                   5.070000"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "return_grouped_results(combined_df, [\"ds_name\", \"pixel_replacement_method\", \"transfer_imagenet\", \"gradient_method\", \"step_schedule\", \"model\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ds_name</th>\n",
       "      <th>pixel_replacement_method</th>\n",
       "      <th>transfer_imagenet</th>\n",
       "      <th>gradient_method</th>\n",
       "      <th>change_subset_attention</th>\n",
       "      <th>step_schedule</th>\n",
       "      <th>proxy_image_weight</th>\n",
       "      <th>model</th>\n",
       "      <th>global_run_count</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">plantdisease</th>\n",
       "      <th rowspan=\"3\" valign=\"top\">baseline</th>\n",
       "      <th rowspan=\"3\" valign=\"top\">baseline</th>\n",
       "      <th rowspan=\"3\" valign=\"top\">baseline</th>\n",
       "      <th rowspan=\"3\" valign=\"top\">0.8</th>\n",
       "      <th rowspan=\"3\" valign=\"top\">[20]</th>\n",
       "      <th rowspan=\"3\" valign=\"top\">0.1</th>\n",
       "      <th>efficientnet_b0</th>\n",
       "      <th>20</th>\n",
       "      <td>99.349998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>resnet50</th>\n",
       "      <th>20</th>\n",
       "      <td>99.220001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>resnet18</th>\n",
       "      <th>20</th>\n",
       "      <td>98.930000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">imagenette</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">baseline</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">baseline</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">baseline</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">0.8</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">[20]</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">0.1</th>\n",
       "      <th>resnet50</th>\n",
       "      <th>20</th>\n",
       "      <td>94.190956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>resnet18</th>\n",
       "      <th>20</th>\n",
       "      <td>93.409378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>efficientnet_b0</th>\n",
       "      <th>20</th>\n",
       "      <td>88.001686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vit_base_patch16_224</th>\n",
       "      <th>20</th>\n",
       "      <td>39.543728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vgg16</th>\n",
       "      <th>20</th>\n",
       "      <td>10.318969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">dogs</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">baseline</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">baseline</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">baseline</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">0.8</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">[20]</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">0.1</th>\n",
       "      <th>efficientnet_b0</th>\n",
       "      <th>20</th>\n",
       "      <td>71.519997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>resnet50</th>\n",
       "      <th>20</th>\n",
       "      <td>66.629997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>resnet18</th>\n",
       "      <th>20</th>\n",
       "      <td>63.660000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vgg16</th>\n",
       "      <th>20</th>\n",
       "      <td>15.650000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vit_base_patch16_224</th>\n",
       "      <th>20</th>\n",
       "      <td>10.950000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">cifar100</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">baseline</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">baseline</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">baseline</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">0.8</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">[20]</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">0.1</th>\n",
       "      <th>efficientnet_b0</th>\n",
       "      <th>20</th>\n",
       "      <td>73.320000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>resnet18</th>\n",
       "      <th>20</th>\n",
       "      <td>65.949997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>resnet50</th>\n",
       "      <th>20</th>\n",
       "      <td>63.660000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vit_base_patch16_224</th>\n",
       "      <th>20</th>\n",
       "      <td>13.120000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vgg16</th>\n",
       "      <th>20</th>\n",
       "      <td>1.040000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">caltech101</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">baseline</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">baseline</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">baseline</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">0.8</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">[20]</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">0.1</th>\n",
       "      <th>efficientnet_b0</th>\n",
       "      <th>20</th>\n",
       "      <td>92.454071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>resnet18</th>\n",
       "      <th>20</th>\n",
       "      <td>88.954506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>resnet50</th>\n",
       "      <th>20</th>\n",
       "      <td>85.454941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vgg16</th>\n",
       "      <th>20</th>\n",
       "      <td>45.100613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vit_base_patch16_224</th>\n",
       "      <th>20</th>\n",
       "      <td>32.874016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">asl</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">baseline</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">baseline</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">baseline</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">0.8</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">[20]</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">0.1</th>\n",
       "      <th>resnet18</th>\n",
       "      <th>20</th>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>efficientnet_b0</th>\n",
       "      <th>20</th>\n",
       "      <td>99.510002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>resnet50</th>\n",
       "      <th>20</th>\n",
       "      <td>98.589996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vit_base_patch16_224</th>\n",
       "      <th>20</th>\n",
       "      <td>14.090000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vgg16</th>\n",
       "      <th>20</th>\n",
       "      <td>5.070000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                          accuracy\n",
       "ds_name      pixel_replacement_method transfer_imagenet gradient_method change_subset_attention step_schedule proxy_image_weight model                global_run_count            \n",
       "plantdisease baseline                 baseline          baseline        0.8                     [20]          0.1                efficientnet_b0      20                 99.349998\n",
       "                                                                                                                                 resnet50             20                 99.220001\n",
       "                                                                                                                                 resnet18             20                 98.930000\n",
       "imagenette   baseline                 baseline          baseline        0.8                     [20]          0.1                resnet50             20                 94.190956\n",
       "                                                                                                                                 resnet18             20                 93.409378\n",
       "                                                                                                                                 efficientnet_b0      20                 88.001686\n",
       "                                                                                                                                 vit_base_patch16_224 20                 39.543728\n",
       "                                                                                                                                 vgg16                20                 10.318969\n",
       "dogs         baseline                 baseline          baseline        0.8                     [20]          0.1                efficientnet_b0      20                 71.519997\n",
       "                                                                                                                                 resnet50             20                 66.629997\n",
       "                                                                                                                                 resnet18             20                 63.660000\n",
       "                                                                                                                                 vgg16                20                 15.650000\n",
       "                                                                                                                                 vit_base_patch16_224 20                 10.950000\n",
       "cifar100     baseline                 baseline          baseline        0.8                     [20]          0.1                efficientnet_b0      20                 73.320000\n",
       "                                                                                                                                 resnet18             20                 65.949997\n",
       "                                                                                                                                 resnet50             20                 63.660000\n",
       "                                                                                                                                 vit_base_patch16_224 20                 13.120000\n",
       "                                                                                                                                 vgg16                20                  1.040000\n",
       "caltech101   baseline                 baseline          baseline        0.8                     [20]          0.1                efficientnet_b0      20                 92.454071\n",
       "                                                                                                                                 resnet18             20                 88.954506\n",
       "                                                                                                                                 resnet50             20                 85.454941\n",
       "                                                                                                                                 vgg16                20                 45.100613\n",
       "                                                                                                                                 vit_base_patch16_224 20                 32.874016\n",
       "asl          baseline                 baseline          baseline        0.8                     [20]          0.1                resnet18             20                100.000000\n",
       "                                                                                                                                 efficientnet_b0      20                 99.510002\n",
       "                                                                                                                                 resnet50             20                 98.589996\n",
       "                                                                                                                                 vit_base_patch16_224 20                 14.090000\n",
       "                                                                                                                                 vgg16                20                  5.070000"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "return_grouped_results(combined_df, [\"ds_name\", \"pixel_replacement_method\", \"transfer_imagenet\", \"gradient_method\", \"change_subset_attention\", \"step_schedule\", \"proxy_image_weight\",  \"model\", \"global_run_count\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare CAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_models = return_grouped_results(combined_df, [\"index\",\"ds_name\", \"pixel_replacement_method\", \"transfer_imagenet\", \"gradient_method\", \"step_schedule\", \"model\", \"num_classes\"])\n",
    "\n",
    "test_models = test_models.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>ds_name</th>\n",
       "      <th>pixel_replacement_method</th>\n",
       "      <th>transfer_imagenet</th>\n",
       "      <th>gradient_method</th>\n",
       "      <th>step_schedule</th>\n",
       "      <th>model</th>\n",
       "      <th>num_classes</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>runs/baseline_run_27032023_143750/events.out.t...</td>\n",
       "      <td>plantdisease</td>\n",
       "      <td>baseline</td>\n",
       "      <td>baseline</td>\n",
       "      <td>baseline</td>\n",
       "      <td>[20]</td>\n",
       "      <td>efficientnet_b0</td>\n",
       "      <td>39</td>\n",
       "      <td>99.349998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>runs/baseline_run_27032023_144800/events.out.t...</td>\n",
       "      <td>plantdisease</td>\n",
       "      <td>baseline</td>\n",
       "      <td>baseline</td>\n",
       "      <td>baseline</td>\n",
       "      <td>[20]</td>\n",
       "      <td>resnet50</td>\n",
       "      <td>39</td>\n",
       "      <td>99.220001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>runs/baseline_run_27032023_142831/events.out.t...</td>\n",
       "      <td>plantdisease</td>\n",
       "      <td>baseline</td>\n",
       "      <td>baseline</td>\n",
       "      <td>baseline</td>\n",
       "      <td>[20]</td>\n",
       "      <td>resnet18</td>\n",
       "      <td>39</td>\n",
       "      <td>98.930000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>runs/baseline_run_26032023_215855/events.out.t...</td>\n",
       "      <td>imagenette</td>\n",
       "      <td>baseline</td>\n",
       "      <td>baseline</td>\n",
       "      <td>baseline</td>\n",
       "      <td>[20]</td>\n",
       "      <td>resnet50</td>\n",
       "      <td>10</td>\n",
       "      <td>94.190956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>runs/baseline_run_26032023_135310/events.out.t...</td>\n",
       "      <td>imagenette</td>\n",
       "      <td>baseline</td>\n",
       "      <td>baseline</td>\n",
       "      <td>baseline</td>\n",
       "      <td>[20]</td>\n",
       "      <td>resnet18</td>\n",
       "      <td>10</td>\n",
       "      <td>93.409378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>runs/baseline_run_26032023_205454/events.out.t...</td>\n",
       "      <td>imagenette</td>\n",
       "      <td>baseline</td>\n",
       "      <td>baseline</td>\n",
       "      <td>baseline</td>\n",
       "      <td>[20]</td>\n",
       "      <td>efficientnet_b0</td>\n",
       "      <td>10</td>\n",
       "      <td>88.001686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>runs/baseline_run_27032023_114723/events.out.t...</td>\n",
       "      <td>imagenette</td>\n",
       "      <td>baseline</td>\n",
       "      <td>baseline</td>\n",
       "      <td>baseline</td>\n",
       "      <td>[20]</td>\n",
       "      <td>vit_base_patch16_224</td>\n",
       "      <td>10</td>\n",
       "      <td>39.543728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>runs/baseline_run_27032023_133419/events.out.t...</td>\n",
       "      <td>imagenette</td>\n",
       "      <td>baseline</td>\n",
       "      <td>baseline</td>\n",
       "      <td>baseline</td>\n",
       "      <td>[20]</td>\n",
       "      <td>vgg16</td>\n",
       "      <td>10</td>\n",
       "      <td>10.477398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>runs/baseline_run_27032023_131945/events.out.t...</td>\n",
       "      <td>imagenette</td>\n",
       "      <td>baseline</td>\n",
       "      <td>baseline</td>\n",
       "      <td>baseline</td>\n",
       "      <td>[20]</td>\n",
       "      <td>vgg16</td>\n",
       "      <td>10</td>\n",
       "      <td>10.160541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>runs/baseline_run_26032023_193957/events.out.t...</td>\n",
       "      <td>dogs</td>\n",
       "      <td>baseline</td>\n",
       "      <td>baseline</td>\n",
       "      <td>baseline</td>\n",
       "      <td>[20]</td>\n",
       "      <td>efficientnet_b0</td>\n",
       "      <td>120</td>\n",
       "      <td>71.519997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>runs/baseline_run_26032023_211712/events.out.t...</td>\n",
       "      <td>dogs</td>\n",
       "      <td>baseline</td>\n",
       "      <td>baseline</td>\n",
       "      <td>baseline</td>\n",
       "      <td>[20]</td>\n",
       "      <td>resnet50</td>\n",
       "      <td>120</td>\n",
       "      <td>66.629997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>runs/baseline_run_26032023_132227/events.out.t...</td>\n",
       "      <td>dogs</td>\n",
       "      <td>baseline</td>\n",
       "      <td>baseline</td>\n",
       "      <td>baseline</td>\n",
       "      <td>[20]</td>\n",
       "      <td>resnet18</td>\n",
       "      <td>120</td>\n",
       "      <td>63.660000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>runs/baseline_run_27032023_122730/events.out.t...</td>\n",
       "      <td>dogs</td>\n",
       "      <td>baseline</td>\n",
       "      <td>baseline</td>\n",
       "      <td>baseline</td>\n",
       "      <td>[20]</td>\n",
       "      <td>vgg16</td>\n",
       "      <td>120</td>\n",
       "      <td>15.650000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>runs/baseline_run_27032023_102541/events.out.t...</td>\n",
       "      <td>dogs</td>\n",
       "      <td>baseline</td>\n",
       "      <td>baseline</td>\n",
       "      <td>baseline</td>\n",
       "      <td>[20]</td>\n",
       "      <td>vit_base_patch16_224</td>\n",
       "      <td>120</td>\n",
       "      <td>10.950000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>runs/baseline_run_26032023_190957/events.out.t...</td>\n",
       "      <td>cifar100</td>\n",
       "      <td>baseline</td>\n",
       "      <td>baseline</td>\n",
       "      <td>baseline</td>\n",
       "      <td>[20]</td>\n",
       "      <td>efficientnet_b0</td>\n",
       "      <td>100</td>\n",
       "      <td>73.320000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>runs/baseline_run_26032023_124800/events.out.t...</td>\n",
       "      <td>cifar100</td>\n",
       "      <td>baseline</td>\n",
       "      <td>baseline</td>\n",
       "      <td>baseline</td>\n",
       "      <td>[20]</td>\n",
       "      <td>resnet18</td>\n",
       "      <td>100</td>\n",
       "      <td>65.949997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>runs/baseline_run_26032023_210253/events.out.t...</td>\n",
       "      <td>cifar100</td>\n",
       "      <td>baseline</td>\n",
       "      <td>baseline</td>\n",
       "      <td>baseline</td>\n",
       "      <td>[20]</td>\n",
       "      <td>resnet50</td>\n",
       "      <td>100</td>\n",
       "      <td>63.660000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>runs/baseline_run_26032023_232253/events.out.t...</td>\n",
       "      <td>cifar100</td>\n",
       "      <td>baseline</td>\n",
       "      <td>baseline</td>\n",
       "      <td>baseline</td>\n",
       "      <td>[20]</td>\n",
       "      <td>vit_base_patch16_224</td>\n",
       "      <td>100</td>\n",
       "      <td>13.120000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>runs/baseline_run_27032023_120416/events.out.t...</td>\n",
       "      <td>cifar100</td>\n",
       "      <td>baseline</td>\n",
       "      <td>baseline</td>\n",
       "      <td>baseline</td>\n",
       "      <td>[20]</td>\n",
       "      <td>vgg16</td>\n",
       "      <td>100</td>\n",
       "      <td>1.040000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>runs/baseline_run_26032023_201014/events.out.t...</td>\n",
       "      <td>caltech101</td>\n",
       "      <td>baseline</td>\n",
       "      <td>baseline</td>\n",
       "      <td>baseline</td>\n",
       "      <td>[20]</td>\n",
       "      <td>efficientnet_b0</td>\n",
       "      <td>102</td>\n",
       "      <td>92.454071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>runs/baseline_run_26032023_133425/events.out.t...</td>\n",
       "      <td>caltech101</td>\n",
       "      <td>baseline</td>\n",
       "      <td>baseline</td>\n",
       "      <td>baseline</td>\n",
       "      <td>[20]</td>\n",
       "      <td>resnet18</td>\n",
       "      <td>102</td>\n",
       "      <td>88.954506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>runs/baseline_run_26032023_213720/events.out.t...</td>\n",
       "      <td>caltech101</td>\n",
       "      <td>baseline</td>\n",
       "      <td>baseline</td>\n",
       "      <td>baseline</td>\n",
       "      <td>[20]</td>\n",
       "      <td>resnet50</td>\n",
       "      <td>102</td>\n",
       "      <td>85.454941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>runs/baseline_run_27032023_124745/events.out.t...</td>\n",
       "      <td>caltech101</td>\n",
       "      <td>baseline</td>\n",
       "      <td>baseline</td>\n",
       "      <td>baseline</td>\n",
       "      <td>[20]</td>\n",
       "      <td>vgg16</td>\n",
       "      <td>102</td>\n",
       "      <td>45.100613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>runs/baseline_run_27032023_105652/events.out.t...</td>\n",
       "      <td>caltech101</td>\n",
       "      <td>baseline</td>\n",
       "      <td>baseline</td>\n",
       "      <td>baseline</td>\n",
       "      <td>[20]</td>\n",
       "      <td>vit_base_patch16_224</td>\n",
       "      <td>102</td>\n",
       "      <td>32.874016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>runs/baseline_run_26032023_134035/events.out.t...</td>\n",
       "      <td>asl</td>\n",
       "      <td>baseline</td>\n",
       "      <td>baseline</td>\n",
       "      <td>baseline</td>\n",
       "      <td>[20]</td>\n",
       "      <td>resnet18</td>\n",
       "      <td>20</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>runs/baseline_run_26032023_203613/events.out.t...</td>\n",
       "      <td>asl</td>\n",
       "      <td>baseline</td>\n",
       "      <td>baseline</td>\n",
       "      <td>baseline</td>\n",
       "      <td>[20]</td>\n",
       "      <td>efficientnet_b0</td>\n",
       "      <td>20</td>\n",
       "      <td>99.510002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>runs/baseline_run_26032023_214436/events.out.t...</td>\n",
       "      <td>asl</td>\n",
       "      <td>baseline</td>\n",
       "      <td>baseline</td>\n",
       "      <td>baseline</td>\n",
       "      <td>[20]</td>\n",
       "      <td>resnet50</td>\n",
       "      <td>20</td>\n",
       "      <td>98.589996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>runs/baseline_run_27032023_111325/events.out.t...</td>\n",
       "      <td>asl</td>\n",
       "      <td>baseline</td>\n",
       "      <td>baseline</td>\n",
       "      <td>baseline</td>\n",
       "      <td>[20]</td>\n",
       "      <td>vit_base_patch16_224</td>\n",
       "      <td>20</td>\n",
       "      <td>14.090000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>runs/baseline_run_27032023_125754/events.out.t...</td>\n",
       "      <td>asl</td>\n",
       "      <td>baseline</td>\n",
       "      <td>baseline</td>\n",
       "      <td>baseline</td>\n",
       "      <td>[20]</td>\n",
       "      <td>vgg16</td>\n",
       "      <td>20</td>\n",
       "      <td>5.070000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                index       ds_name  \\\n",
       "0   runs/baseline_run_27032023_143750/events.out.t...  plantdisease   \n",
       "1   runs/baseline_run_27032023_144800/events.out.t...  plantdisease   \n",
       "2   runs/baseline_run_27032023_142831/events.out.t...  plantdisease   \n",
       "3   runs/baseline_run_26032023_215855/events.out.t...    imagenette   \n",
       "4   runs/baseline_run_26032023_135310/events.out.t...    imagenette   \n",
       "5   runs/baseline_run_26032023_205454/events.out.t...    imagenette   \n",
       "6   runs/baseline_run_27032023_114723/events.out.t...    imagenette   \n",
       "7   runs/baseline_run_27032023_133419/events.out.t...    imagenette   \n",
       "8   runs/baseline_run_27032023_131945/events.out.t...    imagenette   \n",
       "9   runs/baseline_run_26032023_193957/events.out.t...          dogs   \n",
       "10  runs/baseline_run_26032023_211712/events.out.t...          dogs   \n",
       "11  runs/baseline_run_26032023_132227/events.out.t...          dogs   \n",
       "12  runs/baseline_run_27032023_122730/events.out.t...          dogs   \n",
       "13  runs/baseline_run_27032023_102541/events.out.t...          dogs   \n",
       "14  runs/baseline_run_26032023_190957/events.out.t...      cifar100   \n",
       "15  runs/baseline_run_26032023_124800/events.out.t...      cifar100   \n",
       "16  runs/baseline_run_26032023_210253/events.out.t...      cifar100   \n",
       "17  runs/baseline_run_26032023_232253/events.out.t...      cifar100   \n",
       "18  runs/baseline_run_27032023_120416/events.out.t...      cifar100   \n",
       "19  runs/baseline_run_26032023_201014/events.out.t...    caltech101   \n",
       "20  runs/baseline_run_26032023_133425/events.out.t...    caltech101   \n",
       "21  runs/baseline_run_26032023_213720/events.out.t...    caltech101   \n",
       "22  runs/baseline_run_27032023_124745/events.out.t...    caltech101   \n",
       "23  runs/baseline_run_27032023_105652/events.out.t...    caltech101   \n",
       "24  runs/baseline_run_26032023_134035/events.out.t...           asl   \n",
       "25  runs/baseline_run_26032023_203613/events.out.t...           asl   \n",
       "26  runs/baseline_run_26032023_214436/events.out.t...           asl   \n",
       "27  runs/baseline_run_27032023_111325/events.out.t...           asl   \n",
       "28  runs/baseline_run_27032023_125754/events.out.t...           asl   \n",
       "\n",
       "   pixel_replacement_method transfer_imagenet gradient_method step_schedule  \\\n",
       "0                  baseline          baseline        baseline          [20]   \n",
       "1                  baseline          baseline        baseline          [20]   \n",
       "2                  baseline          baseline        baseline          [20]   \n",
       "3                  baseline          baseline        baseline          [20]   \n",
       "4                  baseline          baseline        baseline          [20]   \n",
       "5                  baseline          baseline        baseline          [20]   \n",
       "6                  baseline          baseline        baseline          [20]   \n",
       "7                  baseline          baseline        baseline          [20]   \n",
       "8                  baseline          baseline        baseline          [20]   \n",
       "9                  baseline          baseline        baseline          [20]   \n",
       "10                 baseline          baseline        baseline          [20]   \n",
       "11                 baseline          baseline        baseline          [20]   \n",
       "12                 baseline          baseline        baseline          [20]   \n",
       "13                 baseline          baseline        baseline          [20]   \n",
       "14                 baseline          baseline        baseline          [20]   \n",
       "15                 baseline          baseline        baseline          [20]   \n",
       "16                 baseline          baseline        baseline          [20]   \n",
       "17                 baseline          baseline        baseline          [20]   \n",
       "18                 baseline          baseline        baseline          [20]   \n",
       "19                 baseline          baseline        baseline          [20]   \n",
       "20                 baseline          baseline        baseline          [20]   \n",
       "21                 baseline          baseline        baseline          [20]   \n",
       "22                 baseline          baseline        baseline          [20]   \n",
       "23                 baseline          baseline        baseline          [20]   \n",
       "24                 baseline          baseline        baseline          [20]   \n",
       "25                 baseline          baseline        baseline          [20]   \n",
       "26                 baseline          baseline        baseline          [20]   \n",
       "27                 baseline          baseline        baseline          [20]   \n",
       "28                 baseline          baseline        baseline          [20]   \n",
       "\n",
       "                   model num_classes    accuracy  \n",
       "0        efficientnet_b0          39   99.349998  \n",
       "1               resnet50          39   99.220001  \n",
       "2               resnet18          39   98.930000  \n",
       "3               resnet50          10   94.190956  \n",
       "4               resnet18          10   93.409378  \n",
       "5        efficientnet_b0          10   88.001686  \n",
       "6   vit_base_patch16_224          10   39.543728  \n",
       "7                  vgg16          10   10.477398  \n",
       "8                  vgg16          10   10.160541  \n",
       "9        efficientnet_b0         120   71.519997  \n",
       "10              resnet50         120   66.629997  \n",
       "11              resnet18         120   63.660000  \n",
       "12                 vgg16         120   15.650000  \n",
       "13  vit_base_patch16_224         120   10.950000  \n",
       "14       efficientnet_b0         100   73.320000  \n",
       "15              resnet18         100   65.949997  \n",
       "16              resnet50         100   63.660000  \n",
       "17  vit_base_patch16_224         100   13.120000  \n",
       "18                 vgg16         100    1.040000  \n",
       "19       efficientnet_b0         102   92.454071  \n",
       "20              resnet18         102   88.954506  \n",
       "21              resnet50         102   85.454941  \n",
       "22                 vgg16         102   45.100613  \n",
       "23  vit_base_patch16_224         102   32.874016  \n",
       "24              resnet18          20  100.000000  \n",
       "25       efficientnet_b0          20   99.510002  \n",
       "26              resnet50          20   98.589996  \n",
       "27  vit_base_patch16_224          20   14.090000  \n",
       "28                 vgg16          20    5.070000  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "test_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1, model_2 = test_models.loc[:1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['runs/baseline_run_27032023_143750/events.out.tfevents.1679920670.eragon',\n",
       "       'plantdisease', 'baseline', 'baseline', 'baseline', '[20]',\n",
       "       'efficientnet_b0', '39', 99.3499984741211], dtype=object)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/eragon/mambaforge/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from proxyattention.training import choose_network\n",
    "\n",
    "import albumentations as A\n",
    "\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from proxyattention.data_utils import ImageClassDs, create_folds, get_parent_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for ResNet:\n\tMissing key(s) in state_dict: \"conv1.weight\", \"bn1.weight\", \"bn1.bias\", \"bn1.running_mean\", \"bn1.running_var\", \"layer1.0.conv1.weight\", \"layer1.0.bn1.weight\", \"layer1.0.bn1.bias\", \"layer1.0.bn1.running_mean\", \"layer1.0.bn1.running_var\", \"layer1.0.conv2.weight\", \"layer1.0.bn2.weight\", \"layer1.0.bn2.bias\", \"layer1.0.bn2.running_mean\", \"layer1.0.bn2.running_var\", \"layer1.0.conv3.weight\", \"layer1.0.bn3.weight\", \"layer1.0.bn3.bias\", \"layer1.0.bn3.running_mean\", \"layer1.0.bn3.running_var\", \"layer1.0.downsample.0.weight\", \"layer1.0.downsample.1.weight\", \"layer1.0.downsample.1.bias\", \"layer1.0.downsample.1.running_mean\", \"layer1.0.downsample.1.running_var\", \"layer1.1.conv1.weight\", \"layer1.1.bn1.weight\", \"layer1.1.bn1.bias\", \"layer1.1.bn1.running_mean\", \"layer1.1.bn1.running_var\", \"layer1.1.conv2.weight\", \"layer1.1.bn2.weight\", \"layer1.1.bn2.bias\", \"layer1.1.bn2.running_mean\", \"layer1.1.bn2.running_var\", \"layer1.1.conv3.weight\", \"layer1.1.bn3.weight\", \"layer1.1.bn3.bias\", \"layer1.1.bn3.running_mean\", \"layer1.1.bn3.running_var\", \"layer1.2.conv1.weight\", \"layer1.2.bn1.weight\", \"layer1.2.bn1.bias\", \"layer1.2.bn1.running_mean\", \"layer1.2.bn1.running_var\", \"layer1.2.conv2.weight\", \"layer1.2.bn2.weight\", \"layer1.2.bn2.bias\", \"layer1.2.bn2.running_mean\", \"layer1.2.bn2.running_var\", \"layer1.2.conv3.weight\", \"layer1.2.bn3.weight\", \"layer1.2.bn3.bias\", \"layer1.2.bn3.running_mean\", \"layer1.2.bn3.running_var\", \"layer2.0.conv1.weight\", \"layer2.0.bn1.weight\", \"layer2.0.bn1.bias\", \"layer2.0.bn1.running_mean\", \"layer2.0.bn1.running_var\", \"layer2.0.conv2.weight\", \"layer2.0.bn2.weight\", \"layer2.0.bn2.bias\", \"layer2.0.bn2.running_mean\", \"layer2.0.bn2.running_var\", \"layer2.0.conv3.weight\", \"layer2.0.bn3.weight\", \"layer2.0.bn3.bias\", \"layer2.0.bn3.running_mean\", \"layer2.0.bn3.running_var\", \"layer2.0.downsample.0.weight\", \"layer2.0.downsample.1.weight\", \"layer2.0.downsample.1.bias\", \"layer2.0.downsample.1.running_mean\", \"layer2.0.downsample.1.running_var\", \"layer2.1.conv1.weight\", \"layer2.1.bn1.weight\", \"layer2.1.bn1.bias\", \"layer2.1.bn1.running_mean\", \"layer2.1.bn1.running_var\", \"layer2.1.conv2.weight\", \"layer2.1.bn2.weight\", \"layer2.1.bn2.bias\", \"layer2.1.bn2.running_mean\", \"layer2.1.bn2.running_var\", \"layer2.1.conv3.weight\", \"layer2.1.bn3.weight\", \"layer2.1.bn3.bias\", \"layer2.1.bn3.running_mean\", \"layer2.1.bn3.running_var\", \"layer2.2.conv1.weight\", \"layer2.2.bn1.weight\", \"layer2.2.bn1.bias\", \"layer2.2.bn1.running_mean\", \"layer2.2.bn1.running_var\", \"layer2.2.conv2.weight\", \"layer2.2.bn2.weight\", \"layer2.2.bn2.bias\", \"layer2.2.bn2.running_mean\", \"layer2.2.bn2.running_var\", \"layer2.2.conv3.weight\", \"layer2.2.bn3.weight\", \"layer2.2.bn3.bias\", \"layer2.2.bn3.running_mean\", \"layer2.2.bn3.running_var\", \"layer2.3.conv1.weight\", \"layer2.3.bn1.weight\", \"layer2.3.bn1.bias\", \"layer2.3.bn1.running_mean\", \"layer2.3.bn1.running_var\", \"layer2.3.conv2.weight\", \"layer2.3.bn2.weight\", \"layer2.3.bn2.bias\", \"layer2.3.bn2.running_mean\", \"layer2.3.bn2.running_var\", \"layer2.3.conv3.weight\", \"layer2.3.bn3.weight\", \"layer2.3.bn3.bias\", \"layer2.3.bn3.running_mean\", \"layer2.3.bn3.running_var\", \"layer3.0.conv1.weight\", \"layer3.0.bn1.weight\", \"layer3.0.bn1.bias\", \"layer3.0.bn1.running_mean\", \"layer3.0.bn1.running_var\", \"layer3.0.conv2.weight\", \"layer3.0.bn2.weight\", \"layer3.0.bn2.bias\", \"layer3.0.bn2.running_mean\", \"layer3.0.bn2.running_var\", \"layer3.0.conv3.weight\", \"layer3.0.bn3.weight\", \"layer3.0.bn3.bias\", \"layer3.0.bn3.running_mean\", \"layer3.0.bn3.running_var\", \"layer3.0.downsample.0.weight\", \"layer3.0.downsample.1.weight\", \"layer3.0.downsample.1.bias\", \"layer3.0.downsample.1.running_mean\", \"layer3.0.downsample.1.running_var\", \"layer3.1.conv1.weight\", \"layer3.1.bn1.weight\", \"layer3.1.bn1.bias\", \"layer3.1.bn1.running_mean\", \"layer3.1.bn1.running_var\", \"layer3.1.conv2.weight\", \"layer3.1.bn2.weight\", \"layer3.1.bn2.bias\", \"layer3.1.bn2.running_mean\", \"layer3.1.bn2.running_var\", \"layer3.1.conv3.weight\", \"layer3.1.bn3.weight\", \"layer3.1.bn3.bias\", \"layer3.1.bn3.running_mean\", \"layer3.1.bn3.running_var\", \"layer3.2.conv1.weight\", \"layer3.2.bn1.weight\", \"layer3.2.bn1.bias\", \"layer3.2.bn1.running_mean\", \"layer3.2.bn1.running_var\", \"layer3.2.conv2.weight\", \"layer3.2.bn2.weight\", \"layer3.2.bn2.bias\", \"layer3.2.bn2.running_mean\", \"layer3.2.bn2.running_var\", \"layer3.2.conv3.weight\", \"layer3.2.bn3.weight\", \"layer3.2.bn3.bias\", \"layer3.2.bn3.running_mean\", \"layer3.2.bn3.running_var\", \"layer3.3.conv1.weight\", \"layer3.3.bn1.weight\", \"layer3.3.bn1.bias\", \"layer3.3.bn1.running_mean\", \"layer3.3.bn1.running_var\", \"layer3.3.conv2.weight\", \"layer3.3.bn2.weight\", \"layer3.3.bn2.bias\", \"layer3.3.bn2.running_mean\", \"layer3.3.bn2.running_var\", \"layer3.3.conv3.weight\", \"layer3.3.bn3.weight\", \"layer3.3.bn3.bias\", \"layer3.3.bn3.running_mean\", \"layer3.3.bn3.running_var\", \"layer3.4.conv1.weight\", \"layer3.4.bn1.weight\", \"layer3.4.bn1.bias\", \"layer3.4.bn1.running_mean\", \"layer3.4.bn1.running_var\", \"layer3.4.conv2.weight\", \"layer3.4.bn2.weight\", \"layer3.4.bn2.bias\", \"layer3.4.bn2.running_mean\", \"layer3.4.bn2.running_var\", \"layer3.4.conv3.weight\", \"layer3.4.bn3.weight\", \"layer3.4.bn3.bias\", \"layer3.4.bn3.running_mean\", \"layer3.4.bn3.running_var\", \"layer3.5.conv1.weight\", \"layer3.5.bn1.weight\", \"layer3.5.bn1.bias\", \"layer3.5.bn1.running_mean\", \"layer3.5.bn1.running_var\", \"layer3.5.conv2.weight\", \"layer3.5.bn2.weight\", \"layer3.5.bn2.bias\", \"layer3.5.bn2.running_mean\", \"layer3.5.bn2.running_var\", \"layer3.5.conv3.weight\", \"layer3.5.bn3.weight\", \"layer3.5.bn3.bias\", \"layer3.5.bn3.running_mean\", \"layer3.5.bn3.running_var\", \"layer4.0.conv1.weight\", \"layer4.0.bn1.weight\", \"layer4.0.bn1.bias\", \"layer4.0.bn1.running_mean\", \"layer4.0.bn1.running_var\", \"layer4.0.conv2.weight\", \"layer4.0.bn2.weight\", \"layer4.0.bn2.bias\", \"layer4.0.bn2.running_mean\", \"layer4.0.bn2.running_var\", \"layer4.0.conv3.weight\", \"layer4.0.bn3.weight\", \"layer4.0.bn3.bias\", \"layer4.0.bn3.running_mean\", \"layer4.0.bn3.running_var\", \"layer4.0.downsample.0.weight\", \"layer4.0.downsample.1.weight\", \"layer4.0.downsample.1.bias\", \"layer4.0.downsample.1.running_mean\", \"layer4.0.downsample.1.running_var\", \"layer4.1.conv1.weight\", \"layer4.1.bn1.weight\", \"layer4.1.bn1.bias\", \"layer4.1.bn1.running_mean\", \"layer4.1.bn1.running_var\", \"layer4.1.conv2.weight\", \"layer4.1.bn2.weight\", \"layer4.1.bn2.bias\", \"layer4.1.bn2.running_mean\", \"layer4.1.bn2.running_var\", \"layer4.1.conv3.weight\", \"layer4.1.bn3.weight\", \"layer4.1.bn3.bias\", \"layer4.1.bn3.running_mean\", \"layer4.1.bn3.running_var\", \"layer4.2.conv1.weight\", \"layer4.2.bn1.weight\", \"layer4.2.bn1.bias\", \"layer4.2.bn1.running_mean\", \"layer4.2.bn1.running_var\", \"layer4.2.conv2.weight\", \"layer4.2.bn2.weight\", \"layer4.2.bn2.bias\", \"layer4.2.bn2.running_mean\", \"layer4.2.bn2.running_var\", \"layer4.2.conv3.weight\", \"layer4.2.bn3.weight\", \"layer4.2.bn3.bias\", \"layer4.2.bn3.running_mean\", \"layer4.2.bn3.running_var\", \"fc.weight\", \"fc.bias\". \n\tUnexpected key(s) in state_dict: \"_orig_mod.conv1.weight\", \"_orig_mod.bn1.weight\", \"_orig_mod.bn1.bias\", \"_orig_mod.bn1.running_mean\", \"_orig_mod.bn1.running_var\", \"_orig_mod.bn1.num_batches_tracked\", \"_orig_mod.layer1.0.conv1.weight\", \"_orig_mod.layer1.0.bn1.weight\", \"_orig_mod.layer1.0.bn1.bias\", \"_orig_mod.layer1.0.bn1.running_mean\", \"_orig_mod.layer1.0.bn1.running_var\", \"_orig_mod.layer1.0.bn1.num_batches_tracked\", \"_orig_mod.layer1.0.conv2.weight\", \"_orig_mod.layer1.0.bn2.weight\", \"_orig_mod.layer1.0.bn2.bias\", \"_orig_mod.layer1.0.bn2.running_mean\", \"_orig_mod.layer1.0.bn2.running_var\", \"_orig_mod.layer1.0.bn2.num_batches_tracked\", \"_orig_mod.layer1.0.conv3.weight\", \"_orig_mod.layer1.0.bn3.weight\", \"_orig_mod.layer1.0.bn3.bias\", \"_orig_mod.layer1.0.bn3.running_mean\", \"_orig_mod.layer1.0.bn3.running_var\", \"_orig_mod.layer1.0.bn3.num_batches_tracked\", \"_orig_mod.layer1.0.downsample.0.weight\", \"_orig_mod.layer1.0.downsample.1.weight\", \"_orig_mod.layer1.0.downsample.1.bias\", \"_orig_mod.layer1.0.downsample.1.running_mean\", \"_orig_mod.layer1.0.downsample.1.running_var\", \"_orig_mod.layer1.0.downsample.1.num_batches_tracked\", \"_orig_mod.layer1.1.conv1.weight\", \"_orig_mod.layer1.1.bn1.weight\", \"_orig_mod.layer1.1.bn1.bias\", \"_orig_mod.layer1.1.bn1.running_mean\", \"_orig_mod.layer1.1.bn1.running_var\", \"_orig_mod.layer1.1.bn1.num_batches_tracked\", \"_orig_mod.layer1.1.conv2.weight\", \"_orig_mod.layer1.1.bn2.weight\", \"_orig_mod.layer1.1.bn2.bias\", \"_orig_mod.layer1.1.bn2.running_mean\", \"_orig_mod.layer1.1.bn2.running_var\", \"_orig_mod.layer1.1.bn2.num_batches_tracked\", \"_orig_mod.layer1.1.conv3.weight\", \"_orig_mod.layer1.1.bn3.weight\", \"_orig_mod.layer1.1.bn3.bias\", \"_orig_mod.layer1.1.bn3.running_mean\", \"_orig_mod.layer1.1.bn3.running_var\", \"_orig_mod.layer1.1.bn3.num_batches_tracked\", \"_orig_mod.layer1.2.conv1.weight\", \"_orig_mod.layer1.2.bn1.weight\", \"_orig_mod.layer1.2.bn1.bias\", \"_orig_mod.layer1.2.bn1.running_mean\", \"_orig_mod.layer1.2.bn1.running_var\", \"_orig_mod.layer1.2.bn1.num_batches_tracked\", \"_orig_mod.layer1.2.conv2.weight\", \"_orig_mod.layer1.2.bn2.weight\", \"_orig_mod.layer1.2.bn2.bias\", \"_orig_mod.layer1.2.bn2.running_mean\", \"_orig_mod.layer1.2.bn2.running_var\", \"_orig_mod.layer1.2.bn2.num_batches_tracked\", \"_orig_mod.layer1.2.conv3.weight\", \"_orig_mod.layer1.2.bn3.weight\", \"_orig_mod.layer1.2.bn3.bias\", \"_orig_mod.layer1.2.bn3.running_mean\", \"_orig_mod.layer1.2.bn3.running_var\", \"_orig_mod.layer1.2.bn3.num_batches_tracked\", \"_orig_mod.layer2.0.conv1.weight\", \"_orig_mod.layer2.0.bn1.weight\", \"_orig_mod.layer2.0.bn1.bias\", \"_orig_mod.layer2.0.bn1.running_mean\", \"_orig_mod.layer2.0.bn1.running_var\", \"_orig_mod.layer2.0.bn1.num_batches_tracked\", \"_orig_mod.layer2.0.conv2.weight\", \"_orig_mod.layer2.0.bn2.weight\", \"_orig_mod.layer2.0.bn2.bias\", \"_orig_mod.layer2.0.bn2.running_mean\", \"_orig_mod.layer2.0.bn2.running_var\", \"_orig_mod.layer2.0.bn2.num_batches_tracked\", \"_orig_mod.layer2.0.conv3.weight\", \"_orig_mod.layer2.0.bn3.weight\", \"_orig_mod.layer2.0.bn3.bias\", \"_orig_mod.layer2.0.bn3.running_mean\", \"_orig_mod.layer2.0.bn3.running_var\", \"_orig_mod.layer2.0.bn3.num_batches_tracked\", \"_orig_mod.layer2.0.downsample.0.weight\", \"_orig_mod.layer2.0.downsample.1.weight\", \"_orig_mod.layer2.0.downsample.1.bias\", \"_orig_mod.layer2.0.downsample.1.running_mean\", \"_orig_mod.layer2.0.downsample.1.running_var\", \"_orig_mod.layer2.0.downsample.1.num_batches_tracked\", \"_orig_mod.layer2.1.conv1.weight\", \"_orig_mod.layer2.1.bn1.weight\", \"_orig_mod.layer2.1.bn1.bias\", \"_orig_mod.layer2.1.bn1.running_mean\", \"_orig_mod.layer2.1.bn1.running_var\", \"_orig_mod.layer2.1.bn1.num_batches_tracked\", \"_orig_mod.layer2.1.conv2.weight\", \"_orig_mod.layer2.1.bn2.weight\", \"_orig_mod.layer2.1.bn2.bias\", \"_orig_mod.layer2.1.bn2.running_mean\", \"_orig_mod.layer2.1.bn2.running_var\", \"_orig_mod.layer2.1.bn2.num_batches_tracked\", \"_orig_mod.layer2.1.conv3.weight\", \"_orig_mod.layer2.1.bn3.weight\", \"_orig_mod.layer2.1.bn3.bias\", \"_orig_mod.layer2.1.bn3.running_mean\", \"_orig_mod.layer2.1.bn3.running_var\", \"_orig_mod.layer2.1.bn3.num_batches_tracked\", \"_orig_mod.layer2.2.conv1.weight\", \"_orig_mod.layer2.2.bn1.weight\", \"_orig_mod.layer2.2.bn1.bias\", \"_orig_mod.layer2.2.bn1.running_mean\", \"_orig_mod.layer2.2.bn1.running_var\", \"_orig_mod.layer2.2.bn1.num_batches_tracked\", \"_orig_mod.layer2.2.conv2.weight\", \"_orig_mod.layer2.2.bn2.weight\", \"_orig_mod.layer2.2.bn2.bias\", \"_orig_mod.layer2.2.bn2.running_mean\", \"_orig_mod.layer2.2.bn2.running_var\", \"_orig_mod.layer2.2.bn2.num_batches_tracked\", \"_orig_mod.layer2.2.conv3.weight\", \"_orig_mod.layer2.2.bn3.weight\", \"_orig_mod.layer2.2.bn3.bias\", \"_orig_mod.layer2.2.bn3.running_mean\", \"_orig_mod.layer2.2.bn3.running_var\", \"_orig_mod.layer2.2.bn3.num_batches_tracked\", \"_orig_mod.layer2.3.conv1.weight\", \"_orig_mod.layer2.3.bn1.weight\", \"_orig_mod.layer2.3.bn1.bias\", \"_orig_mod.layer2.3.bn1.running_mean\", \"_orig_mod.layer2.3.bn1.running_var\", \"_orig_mod.layer2.3.bn1.num_batches_tracked\", \"_orig_mod.layer2.3.conv2.weight\", \"_orig_mod.layer2.3.bn2.weight\", \"_orig_mod.layer2.3.bn2.bias\", \"_orig_mod.layer2.3.bn2.running_mean\", \"_orig_mod.layer2.3.bn2.running_var\", \"_orig_mod.layer2.3.bn2.num_batches_tracked\", \"_orig_mod.layer2.3.conv3.weight\", \"_orig_mod.layer2.3.bn3.weight\", \"_orig_mod.layer2.3.bn3.bias\", \"_orig_mod.layer2.3.bn3.running_mean\", \"_orig_mod.layer2.3.bn3.running_var\", \"_orig_mod.layer2.3.bn3.num_batches_tracked\", \"_orig_mod.layer3.0.conv1.weight\", \"_orig_mod.layer3.0.bn1.weight\", \"_orig_mod.layer3.0.bn1.bias\", \"_orig_mod.layer3.0.bn1.running_mean\", \"_orig_mod.layer3.0.bn1.running_var\", \"_orig_mod.layer3.0.bn1.num_batches_tracked\", \"_orig_mod.layer3.0.conv2.weight\", \"_orig_mod.layer3.0.bn2.weight\", \"_orig_mod.layer3.0.bn2.bias\", \"_orig_mod.layer3.0.bn2.running_mean\", \"_orig_mod.layer3.0.bn2.running_var\", \"_orig_mod.layer3.0.bn2.num_batches_tracked\", \"_orig_mod.layer3.0.conv3.weight\", \"_orig_mod.layer3.0.bn3.weight\", \"_orig_mod.layer3.0.bn3.bias\", \"_orig_mod.layer3.0.bn3.running_mean\", \"_orig_mod.layer3.0.bn3.running_var\", \"_orig_mod.layer3.0.bn3.num_batches_tracked\", \"_orig_mod.layer3.0.downsample.0.weight\", \"_orig_mod.layer3.0.downsample.1.weight\", \"_orig_mod.layer3.0.downsample.1.bias\", \"_orig_mod.layer3.0.downsample.1.running_mean\", \"_orig_mod.layer3.0.downsample.1.running_var\", \"_orig_mod.layer3.0.downsample.1.num_batches_tracked\", \"_orig_mod.layer3.1.conv1.weight\", \"_orig_mod.layer3.1.bn1.weight\", \"_orig_mod.layer3.1.bn1.bias\", \"_orig_mod.layer3.1.bn1.running_mean\", \"_orig_mod.layer3.1.bn1.running_var\", \"_orig_mod.layer3.1.bn1.num_batches_tracked\", \"_orig_mod.layer3.1.conv2.weight\", \"_orig_mod.layer3.1.bn2.weight\", \"_orig_mod.layer3.1.bn2.bias\", \"_orig_mod.layer3.1.bn2.running_mean\", \"_orig_mod.layer3.1.bn2.running_var\", \"_orig_mod.layer3.1.bn2.num_batches_tracked\", \"_orig_mod.layer3.1.conv3.weight\", \"_orig_mod.layer3.1.bn3.weight\", \"_orig_mod.layer3.1.bn3.bias\", \"_orig_mod.layer3.1.bn3.running_mean\", \"_orig_mod.layer3.1.bn3.running_var\", \"_orig_mod.layer3.1.bn3.num_batches_tracked\", \"_orig_mod.layer3.2.conv1.weight\", \"_orig_mod.layer3.2.bn1.weight\", \"_orig_mod.layer3.2.bn1.bias\", \"_orig_mod.layer3.2.bn1.running_mean\", \"_orig_mod.layer3.2.bn1.running_var\", \"_orig_mod.layer3.2.bn1.num_batches_tracked\", \"_orig_mod.layer3.2.conv2.weight\", \"_orig_mod.layer3.2.bn2.weight\", \"_orig_mod.layer3.2.bn2.bias\", \"_orig_mod.layer3.2.bn2.running_mean\", \"_orig_mod.layer3.2.bn2.running_var\", \"_orig_mod.layer3.2.bn2.num_batches_tracked\", \"_orig_mod.layer3.2.conv3.weight\", \"_orig_mod.layer3.2.bn3.weight\", \"_orig_mod.layer3.2.bn3.bias\", \"_orig_mod.layer3.2.bn3.running_mean\", \"_orig_mod.layer3.2.bn3.running_var\", \"_orig_mod.layer3.2.bn3.num_batches_tracked\", \"_orig_mod.layer3.3.conv1.weight\", \"_orig_mod.layer3.3.bn1.weight\", \"_orig_mod.layer3.3.bn1.bias\", \"_orig_mod.layer3.3.bn1.running_mean\", \"_orig_mod.layer3.3.bn1.running_var\", \"_orig_mod.layer3.3.bn1.num_batches_tracked\", \"_orig_mod.layer3.3.conv2.weight\", \"_orig_mod.layer3.3.bn2.weight\", \"_orig_mod.layer3.3.bn2.bias\", \"_orig_mod.layer3.3.bn2.running_mean\", \"_orig_mod.layer3.3.bn2.running_var\", \"_orig_mod.layer3.3.bn2.num_batches_tracked\", \"_orig_mod.layer3.3.conv3.weight\", \"_orig_mod.layer3.3.bn3.weight\", \"_orig_mod.layer3.3.bn3.bias\", \"_orig_mod.layer3.3.bn3.running_mean\", \"_orig_mod.layer3.3.bn3.running_var\", \"_orig_mod.layer3.3.bn3.num_batches_tracked\", \"_orig_mod.layer3.4.conv1.weight\", \"_orig_mod.layer3.4.bn1.weight\", \"_orig_mod.layer3.4.bn1.bias\", \"_orig_mod.layer3.4.bn1.running_mean\", \"_orig_mod.layer3.4.bn1.running_var\", \"_orig_mod.layer3.4.bn1.num_batches_tracked\", \"_orig_mod.layer3.4.conv2.weight\", \"_orig_mod.layer3.4.bn2.weight\", \"_orig_mod.layer3.4.bn2.bias\", \"_orig_mod.layer3.4.bn2.running_mean\", \"_orig_mod.layer3.4.bn2.running_var\", \"_orig_mod.layer3.4.bn2.num_batches_tracked\", \"_orig_mod.layer3.4.conv3.weight\", \"_orig_mod.layer3.4.bn3.weight\", \"_orig_mod.layer3.4.bn3.bias\", \"_orig_mod.layer3.4.bn3.running_mean\", \"_orig_mod.layer3.4.bn3.running_var\", \"_orig_mod.layer3.4.bn3.num_batches_tracked\", \"_orig_mod.layer3.5.conv1.weight\", \"_orig_mod.layer3.5.bn1.weight\", \"_orig_mod.layer3.5.bn1.bias\", \"_orig_mod.layer3.5.bn1.running_mean\", \"_orig_mod.layer3.5.bn1.running_var\", \"_orig_mod.layer3.5.bn1.num_batches_tracked\", \"_orig_mod.layer3.5.conv2.weight\", \"_orig_mod.layer3.5.bn2.weight\", \"_orig_mod.layer3.5.bn2.bias\", \"_orig_mod.layer3.5.bn2.running_mean\", \"_orig_mod.layer3.5.bn2.running_var\", \"_orig_mod.layer3.5.bn2.num_batches_tracked\", \"_orig_mod.layer3.5.conv3.weight\", \"_orig_mod.layer3.5.bn3.weight\", \"_orig_mod.layer3.5.bn3.bias\", \"_orig_mod.layer3.5.bn3.running_mean\", \"_orig_mod.layer3.5.bn3.running_var\", \"_orig_mod.layer3.5.bn3.num_batches_tracked\", \"_orig_mod.layer4.0.conv1.weight\", \"_orig_mod.layer4.0.bn1.weight\", \"_orig_mod.layer4.0.bn1.bias\", \"_orig_mod.layer4.0.bn1.running_mean\", \"_orig_mod.layer4.0.bn1.running_var\", \"_orig_mod.layer4.0.bn1.num_batches_tracked\", \"_orig_mod.layer4.0.conv2.weight\", \"_orig_mod.layer4.0.bn2.weight\", \"_orig_mod.layer4.0.bn2.bias\", \"_orig_mod.layer4.0.bn2.running_mean\", \"_orig_mod.layer4.0.bn2.running_var\", \"_orig_mod.layer4.0.bn2.num_batches_tracked\", \"_orig_mod.layer4.0.conv3.weight\", \"_orig_mod.layer4.0.bn3.weight\", \"_orig_mod.layer4.0.bn3.bias\", \"_orig_mod.layer4.0.bn3.running_mean\", \"_orig_mod.layer4.0.bn3.running_var\", \"_orig_mod.layer4.0.bn3.num_batches_tracked\", \"_orig_mod.layer4.0.downsample.0.weight\", \"_orig_mod.layer4.0.downsample.1.weight\", \"_orig_mod.layer4.0.downsample.1.bias\", \"_orig_mod.layer4.0.downsample.1.running_mean\", \"_orig_mod.layer4.0.downsample.1.running_var\", \"_orig_mod.layer4.0.downsample.1.num_batches_tracked\", \"_orig_mod.layer4.1.conv1.weight\", \"_orig_mod.layer4.1.bn1.weight\", \"_orig_mod.layer4.1.bn1.bias\", \"_orig_mod.layer4.1.bn1.running_mean\", \"_orig_mod.layer4.1.bn1.running_var\", \"_orig_mod.layer4.1.bn1.num_batches_tracked\", \"_orig_mod.layer4.1.conv2.weight\", \"_orig_mod.layer4.1.bn2.weight\", \"_orig_mod.layer4.1.bn2.bias\", \"_orig_mod.layer4.1.bn2.running_mean\", \"_orig_mod.layer4.1.bn2.running_var\", \"_orig_mod.layer4.1.bn2.num_batches_tracked\", \"_orig_mod.layer4.1.conv3.weight\", \"_orig_mod.layer4.1.bn3.weight\", \"_orig_mod.layer4.1.bn3.bias\", \"_orig_mod.layer4.1.bn3.running_mean\", \"_orig_mod.layer4.1.bn3.running_var\", \"_orig_mod.layer4.1.bn3.num_batches_tracked\", \"_orig_mod.layer4.2.conv1.weight\", \"_orig_mod.layer4.2.bn1.weight\", \"_orig_mod.layer4.2.bn1.bias\", \"_orig_mod.layer4.2.bn1.running_mean\", \"_orig_mod.layer4.2.bn1.running_var\", \"_orig_mod.layer4.2.bn1.num_batches_tracked\", \"_orig_mod.layer4.2.conv2.weight\", \"_orig_mod.layer4.2.bn2.weight\", \"_orig_mod.layer4.2.bn2.bias\", \"_orig_mod.layer4.2.bn2.running_mean\", \"_orig_mod.layer4.2.bn2.running_var\", \"_orig_mod.layer4.2.bn2.num_batches_tracked\", \"_orig_mod.layer4.2.conv3.weight\", \"_orig_mod.layer4.2.bn3.weight\", \"_orig_mod.layer4.2.bn3.bias\", \"_orig_mod.layer4.2.bn3.running_mean\", \"_orig_mod.layer4.2.bn3.running_var\", \"_orig_mod.layer4.2.bn3.num_batches_tracked\", \"_orig_mod.fc.weight\", \"_orig_mod.fc.bias\". ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[38], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m arch_1 \u001b[39m=\u001b[39m choose_network({\u001b[39m\"\u001b[39m\u001b[39mmodel\u001b[39m\u001b[39m\"\u001b[39m:model_2[\u001b[39m-\u001b[39m\u001b[39m3\u001b[39m] , \u001b[39m\"\u001b[39m\u001b[39mtransfer_imagenet\u001b[39m\u001b[39m\"\u001b[39m:\u001b[39mFalse\u001b[39;00m, \u001b[39m\"\u001b[39m\u001b[39mnum_classes\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mint\u001b[39m(model_2[\u001b[39m-\u001b[39m\u001b[39m2\u001b[39m]), \u001b[39m\"\u001b[39m\u001b[39mdevice\u001b[39m\u001b[39m\"\u001b[39m:\u001b[39m\"\u001b[39m\u001b[39mcuda:0\u001b[39m\u001b[39m\"\u001b[39m})\n\u001b[1;32m      2\u001b[0m model_weights \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mload(Path(model_2[\u001b[39m0\u001b[39m])\u001b[39m.\u001b[39mparent\u001b[39m/\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mcheckpoint\u001b[39m\u001b[39m\"\u001b[39m, map_location\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mcuda:0\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m arch_1\u001b[39m.\u001b[39;49mload_state_dict(model_weights[\u001b[39m'\u001b[39;49m\u001b[39mmodel_state_dict\u001b[39;49m\u001b[39m'\u001b[39;49m])\n\u001b[1;32m      4\u001b[0m arch_1\u001b[39m.\u001b[39meval();\n",
      "File \u001b[0;32m~/mambaforge/lib/python3.10/site-packages/torch/nn/modules/module.py:2041\u001b[0m, in \u001b[0;36mModule.load_state_dict\u001b[0;34m(self, state_dict, strict)\u001b[0m\n\u001b[1;32m   2036\u001b[0m         error_msgs\u001b[39m.\u001b[39minsert(\n\u001b[1;32m   2037\u001b[0m             \u001b[39m0\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mMissing key(s) in state_dict: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m. \u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[1;32m   2038\u001b[0m                 \u001b[39m'\u001b[39m\u001b[39m, \u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mjoin(\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(k) \u001b[39mfor\u001b[39;00m k \u001b[39min\u001b[39;00m missing_keys)))\n\u001b[1;32m   2040\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(error_msgs) \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m-> 2041\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mError(s) in loading state_dict for \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\t\u001b[39;00m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[1;32m   2042\u001b[0m                        \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\t\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mjoin(error_msgs)))\n\u001b[1;32m   2043\u001b[0m \u001b[39mreturn\u001b[39;00m _IncompatibleKeys(missing_keys, unexpected_keys)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for ResNet:\n\tMissing key(s) in state_dict: \"conv1.weight\", \"bn1.weight\", \"bn1.bias\", \"bn1.running_mean\", \"bn1.running_var\", \"layer1.0.conv1.weight\", \"layer1.0.bn1.weight\", \"layer1.0.bn1.bias\", \"layer1.0.bn1.running_mean\", \"layer1.0.bn1.running_var\", \"layer1.0.conv2.weight\", \"layer1.0.bn2.weight\", \"layer1.0.bn2.bias\", \"layer1.0.bn2.running_mean\", \"layer1.0.bn2.running_var\", \"layer1.0.conv3.weight\", \"layer1.0.bn3.weight\", \"layer1.0.bn3.bias\", \"layer1.0.bn3.running_mean\", \"layer1.0.bn3.running_var\", \"layer1.0.downsample.0.weight\", \"layer1.0.downsample.1.weight\", \"layer1.0.downsample.1.bias\", \"layer1.0.downsample.1.running_mean\", \"layer1.0.downsample.1.running_var\", \"layer1.1.conv1.weight\", \"layer1.1.bn1.weight\", \"layer1.1.bn1.bias\", \"layer1.1.bn1.running_mean\", \"layer1.1.bn1.running_var\", \"layer1.1.conv2.weight\", \"layer1.1.bn2.weight\", \"layer1.1.bn2.bias\", \"layer1.1.bn2.running_mean\", \"layer1.1.bn2.running_var\", \"layer1.1.conv3.weight\", \"layer1.1.bn3.weight\", \"layer1.1.bn3.bias\", \"layer1.1.bn3.running_mean\", \"layer1.1.bn3.running_var\", \"layer1.2.conv1.weight\", \"layer1.2.bn1.weight\", \"layer1.2.bn1.bias\", \"layer1.2.bn1.running_mean\", \"layer1.2.bn1.running_var\", \"layer1.2.conv2.weight\", \"layer1.2.bn2.weight\", \"layer1.2.bn2.bias\", \"layer1.2.bn2.running_mean\", \"layer1.2.bn2.running_var\", \"layer1.2.conv3.weight\", \"layer1.2.bn3.weight\", \"layer1.2.bn3.bias\", \"layer1.2.bn3.running_mean\", \"layer1.2.bn3.running_var\", \"layer2.0.conv1.weight\", \"layer2.0.bn1.weight\", \"layer2.0.bn1.bias\", \"layer2.0.bn1.running_mean\", \"layer2.0.bn1.running_var\", \"layer2.0.conv2.weight\", \"layer2.0.bn2.weight\", \"layer2.0.bn2.bias\", \"layer2.0.bn2.running_mean\", \"layer2.0.bn2.running_var\", \"layer2.0.conv3.weight\", \"layer2.0.bn3.weight\", \"layer2.0.bn3.bias\", \"layer2.0.bn3.running_mean\", \"layer2.0.bn3.running_var\", \"layer2.0.downsample.0.weight\", \"layer2.0.downsample.1.weight\", \"layer2.0.downsample.1.bias\", \"layer2.0.downsample.1.running_mean\", \"layer2.0.downsample.1.running_var\", \"layer2.1.conv1.weight\", \"layer2.1.bn1.weight\", \"layer2.1.bn1.bias\", \"layer2.1.bn1.running_mean\", \"layer2.1.bn1.running_var\", \"layer2.1.conv2.weight\", \"layer2.1.bn2.weight\", \"layer2.1.bn2.bias\", \"layer2.1.bn2.running_mean\", \"layer2.1.bn2.running_var\", \"layer2.1.conv3.weight\", \"layer2.1.bn3.weight\", \"layer2.1.bn3.bias\", \"layer2.1.bn3.running_mean\", \"layer2.1.bn3.running_var\", \"layer2.2.conv1.weight\", \"layer2.2.bn1.weight\", \"layer2.2.bn1.bias\", \"layer2.2.bn1.running_mean\", \"layer2.2.bn1.running_var\", \"layer2.2.conv2.weight\", \"layer2.2.bn2.weight\", \"layer2.2.bn2.bias\", \"layer2.2.bn2.running_mean\", \"layer2.2.bn2.running_var\", \"layer2.2.conv3.weight\", \"layer2.2.bn3.weight\", \"layer2.2.bn3.bias\", \"layer2.2.bn3.running_mean\", \"layer2.2.bn3.running_var\", \"layer2.3.conv1.weight\", \"layer2.3.bn1.weight\", \"layer2.3.bn1.bias\", \"layer2.3.bn1.running_mean\", \"layer2.3.bn1.running_var\", \"layer2.3.conv2.weight\", \"layer2.3.bn2.weight\", \"layer2.3.bn2.bias\", \"layer2.3.bn2.running_mean\", \"layer2.3.bn2.running_var\", \"layer2.3.conv3.weight\", \"layer2.3.bn3.weight\", \"layer2.3.bn3.bias\", \"layer2.3.bn3.running_mean\", \"layer2.3.bn3.running_var\", \"layer3.0.conv1.weight\", \"layer3.0.bn1.weight\", \"layer3.0.bn1.bias\", \"layer3.0.bn1.running_mean\", \"layer3.0.bn1.running_var\", \"layer3.0.conv2.weight\", \"layer3.0.bn2.weight\", \"layer3.0.bn2.bias\", \"layer3.0.bn2.running_mean\", \"layer3.0.bn2.running_var\", \"layer3.0.conv3.weight\", \"layer3.0.bn3.weight\", \"layer3.0.bn3.bias\", \"layer3.0.bn3.running_mean\", \"layer3.0.bn3.running_var\", \"layer3.0.downsample.0.weight\", \"layer3.0.downsample.1.weight\", \"layer3.0.downsample.1.bias\", \"layer3.0.downsample.1.running_mean\", \"layer3.0.downsample.1.running_var\", \"layer3.1.conv1.weight\", \"layer3.1.bn1.weight\", \"layer3.1.bn1.bias\", \"layer3.1.bn1.running_mean\", \"layer3.1.bn1.running_var\", \"layer3.1.conv2.weight\", \"layer3.1.bn2.weight\", \"layer3.1.bn2.bias\", \"layer3.1.bn2.running_mean\", \"layer3.1.bn2.running_var\", \"layer3.1.conv3.weight\", \"layer3.1.bn3.weight\", \"layer3.1.bn3.bias\", \"layer3.1.bn3.running_mean\", \"layer3.1.bn3.running_var\", \"layer3.2.conv1.weight\", \"layer3.2.bn1.weight\", \"layer3.2.bn1.bias\", \"layer3.2.bn1.running_mean\", \"layer3.2.bn1.running_var\", \"layer3.2.conv2.weight\", \"layer3.2.bn2.weight\", \"layer3.2.bn2.bias\", \"layer3.2.bn2.running_mean\", \"layer3.2.bn2.running_var\", \"layer3.2.conv3.weight\", \"layer3.2.bn3.weight\", \"layer3.2.bn3.bias\", \"layer3.2.bn3.running_mean\", \"layer3.2.bn3.running_var\", \"layer3.3.conv1.weight\", \"layer3.3.bn1.weight\", \"layer3.3.bn1.bias\", \"layer3.3.bn1.running_mean\", \"layer3.3.bn1.running_var\", \"layer3.3.conv2.weight\", \"layer3.3.bn2.weight\", \"layer3.3.bn2.bias\", \"layer3.3.bn2.running_mean\", \"layer3.3.bn2.running_var\", \"layer3.3.conv3.weight\", \"layer3.3.bn3.weight\", \"layer3.3.bn3.bias\", \"layer3.3.bn3.running_mean\", \"layer3.3.bn3.running_var\", \"layer3.4.conv1.weight\", \"layer3.4.bn1.weight\", \"layer3.4.bn1.bias\", \"layer3.4.bn1.running_mean\", \"layer3.4.bn1.running_var\", \"layer3.4.conv2.weight\", \"layer3.4.bn2.weight\", \"layer3.4.bn2.bias\", \"layer3.4.bn2.running_mean\", \"layer3.4.bn2.running_var\", \"layer3.4.conv3.weight\", \"layer3.4.bn3.weight\", \"layer3.4.bn3.bias\", \"layer3.4.bn3.running_mean\", \"layer3.4.bn3.running_var\", \"layer3.5.conv1.weight\", \"layer3.5.bn1.weight\", \"layer3.5.bn1.bias\", \"layer3.5.bn1.running_mean\", \"layer3.5.bn1.running_var\", \"layer3.5.conv2.weight\", \"layer3.5.bn2.weight\", \"layer3.5.bn2.bias\", \"layer3.5.bn2.running_mean\", \"layer3.5.bn2.running_var\", \"layer3.5.conv3.weight\", \"layer3.5.bn3.weight\", \"layer3.5.bn3.bias\", \"layer3.5.bn3.running_mean\", \"layer3.5.bn3.running_var\", \"layer4.0.conv1.weight\", \"layer4.0.bn1.weight\", \"layer4.0.bn1.bias\", \"layer4.0.bn1.running_mean\", \"layer4.0.bn1.running_var\", \"layer4.0.conv2.weight\", \"layer4.0.bn2.weight\", \"layer4.0.bn2.bias\", \"layer4.0.bn2.running_mean\", \"layer4.0.bn2.running_var\", \"layer4.0.conv3.weight\", \"layer4.0.bn3.weight\", \"layer4.0.bn3.bias\", \"layer4.0.bn3.running_mean\", \"layer4.0.bn3.running_var\", \"layer4.0.downsample.0.weight\", \"layer4.0.downsample.1.weight\", \"layer4.0.downsample.1.bias\", \"layer4.0.downsample.1.running_mean\", \"layer4.0.downsample.1.running_var\", \"layer4.1.conv1.weight\", \"layer4.1.bn1.weight\", \"layer4.1.bn1.bias\", \"layer4.1.bn1.running_mean\", \"layer4.1.bn1.running_var\", \"layer4.1.conv2.weight\", \"layer4.1.bn2.weight\", \"layer4.1.bn2.bias\", \"layer4.1.bn2.running_mean\", \"layer4.1.bn2.running_var\", \"layer4.1.conv3.weight\", \"layer4.1.bn3.weight\", \"layer4.1.bn3.bias\", \"layer4.1.bn3.running_mean\", \"layer4.1.bn3.running_var\", \"layer4.2.conv1.weight\", \"layer4.2.bn1.weight\", \"layer4.2.bn1.bias\", \"layer4.2.bn1.running_mean\", \"layer4.2.bn1.running_var\", \"layer4.2.conv2.weight\", \"layer4.2.bn2.weight\", \"layer4.2.bn2.bias\", \"layer4.2.bn2.running_mean\", \"layer4.2.bn2.running_var\", \"layer4.2.conv3.weight\", \"layer4.2.bn3.weight\", \"layer4.2.bn3.bias\", \"layer4.2.bn3.running_mean\", \"layer4.2.bn3.running_var\", \"fc.weight\", \"fc.bias\". \n\tUnexpected key(s) in state_dict: \"_orig_mod.conv1.weight\", \"_orig_mod.bn1.weight\", \"_orig_mod.bn1.bias\", \"_orig_mod.bn1.running_mean\", \"_orig_mod.bn1.running_var\", \"_orig_mod.bn1.num_batches_tracked\", \"_orig_mod.layer1.0.conv1.weight\", \"_orig_mod.layer1.0.bn1.weight\", \"_orig_mod.layer1.0.bn1.bias\", \"_orig_mod.layer1.0.bn1.running_mean\", \"_orig_mod.layer1.0.bn1.running_var\", \"_orig_mod.layer1.0.bn1.num_batches_tracked\", \"_orig_mod.layer1.0.conv2.weight\", \"_orig_mod.layer1.0.bn2.weight\", \"_orig_mod.layer1.0.bn2.bias\", \"_orig_mod.layer1.0.bn2.running_mean\", \"_orig_mod.layer1.0.bn2.running_var\", \"_orig_mod.layer1.0.bn2.num_batches_tracked\", \"_orig_mod.layer1.0.conv3.weight\", \"_orig_mod.layer1.0.bn3.weight\", \"_orig_mod.layer1.0.bn3.bias\", \"_orig_mod.layer1.0.bn3.running_mean\", \"_orig_mod.layer1.0.bn3.running_var\", \"_orig_mod.layer1.0.bn3.num_batches_tracked\", \"_orig_mod.layer1.0.downsample.0.weight\", \"_orig_mod.layer1.0.downsample.1.weight\", \"_orig_mod.layer1.0.downsample.1.bias\", \"_orig_mod.layer1.0.downsample.1.running_mean\", \"_orig_mod.layer1.0.downsample.1.running_var\", \"_orig_mod.layer1.0.downsample.1.num_batches_tracked\", \"_orig_mod.layer1.1.conv1.weight\", \"_orig_mod.layer1.1.bn1.weight\", \"_orig_mod.layer1.1.bn1.bias\", \"_orig_mod.layer1.1.bn1.running_mean\", \"_orig_mod.layer1.1.bn1.running_var\", \"_orig_mod.layer1.1.bn1.num_batches_tracked\", \"_orig_mod.layer1.1.conv2.weight\", \"_orig_mod.layer1.1.bn2.weight\", \"_orig_mod.layer1.1.bn2.bias\", \"_orig_mod.layer1.1.bn2.running_mean\", \"_orig_mod.layer1.1.bn2.running_var\", \"_orig_mod.layer1.1.bn2.num_batches_tracked\", \"_orig_mod.layer1.1.conv3.weight\", \"_orig_mod.layer1.1.bn3.weight\", \"_orig_mod.layer1.1.bn3.bias\", \"_orig_mod.layer1.1.bn3.running_mean\", \"_orig_mod.layer1.1.bn3.running_var\", \"_orig_mod.layer1.1.bn3.num_batches_tracked\", \"_orig_mod.layer1.2.conv1.weight\", \"_orig_mod.layer1.2.bn1.weight\", \"_orig_mod.layer1.2.bn1.bias\", \"_orig_mod.layer1.2.bn1.running_mean\", \"_orig_mod.layer1.2.bn1.running_var\", \"_orig_mod.layer1.2.bn1.num_batches_tracked\", \"_orig_mod.layer1.2.conv2.weight\", \"_orig_mod.layer1.2.bn2.weight\", \"_orig_mod.layer1.2.bn2.bias\", \"_orig_mod.layer1.2.bn2.running_mean\", \"_orig_mod.layer1.2.bn2.running_var\", \"_orig_mod.layer1.2.bn2.num_batches_tracked\", \"_orig_mod.layer1.2.conv3.weight\", \"_orig_mod.layer1.2.bn3.weight\", \"_orig_mod.layer1.2.bn3.bias\", \"_orig_mod.layer1.2.bn3.running_mean\", \"_orig_mod.layer1.2.bn3.running_var\", \"_orig_mod.layer1.2.bn3.num_batches_tracked\", \"_orig_mod.layer2.0.conv1.weight\", \"_orig_mod.layer2.0.bn1.weight\", \"_orig_mod.layer2.0.bn1.bias\", \"_orig_mod.layer2.0.bn1.running_mean\", \"_orig_mod.layer2.0.bn1.running_var\", \"_orig_mod.layer2.0.bn1.num_batches_tracked\", \"_orig_mod.layer2.0.conv2.weight\", \"_orig_mod.layer2.0.bn2.weight\", \"_orig_mod.layer2.0.bn2.bias\", \"_orig_mod.layer2.0.bn2.running_mean\", \"_orig_mod.layer2.0.bn2.running_var\", \"_orig_mod.layer2.0.bn2.num_batches_tracked\", \"_orig_mod.layer2.0.conv3.weight\", \"_orig_mod.layer2.0.bn3.weight\", \"_orig_mod.layer2.0.bn3.bias\", \"_orig_mod.layer2.0.bn3.running_mean\", \"_orig_mod.layer2.0.bn3.running_var\", \"_orig_mod.layer2.0.bn3.num_batches_tracked\", \"_orig_mod.layer2.0.downsample.0.weight\", \"_orig_mod.layer2.0.downsample.1.weight\", \"_orig_mod.layer2.0.downsample.1.bias\", \"_orig_mod.layer2.0.downsample.1.running_mean\", \"_orig_mod.layer2.0.downsample.1.running_var\", \"_orig_mod.layer2.0.downsample.1.num_batches_tracked\", \"_orig_mod.layer2.1.conv1.weight\", \"_orig_mod.layer2.1.bn1.weight\", \"_orig_mod.layer2.1.bn1.bias\", \"_orig_mod.layer2.1.bn1.running_mean\", \"_orig_mod.layer2.1.bn1.running_var\", \"_orig_mod.layer2.1.bn1.num_batches_tracked\", \"_orig_mod.layer2.1.conv2.weight\", \"_orig_mod.layer2.1.bn2.weight\", \"_orig_mod.layer2.1.bn2.bias\", \"_orig_mod.layer2.1.bn2.running_mean\", \"_orig_mod.layer2.1.bn2.running_var\", \"_orig_mod.layer2.1.bn2.num_batches_tracked\", \"_orig_mod.layer2.1.conv3.weight\", \"_orig_mod.layer2.1.bn3.weight\", \"_orig_mod.layer2.1.bn3.bias\", \"_orig_mod.layer2.1.bn3.running_mean\", \"_orig_mod.layer2.1.bn3.running_var\", \"_orig_mod.layer2.1.bn3.num_batches_tracked\", \"_orig_mod.layer2.2.conv1.weight\", \"_orig_mod.layer2.2.bn1.weight\", \"_orig_mod.layer2.2.bn1.bias\", \"_orig_mod.layer2.2.bn1.running_mean\", \"_orig_mod.layer2.2.bn1.running_var\", \"_orig_mod.layer2.2.bn1.num_batches_tracked\", \"_orig_mod.layer2.2.conv2.weight\", \"_orig_mod.layer2.2.bn2.weight\", \"_orig_mod.layer2.2.bn2.bias\", \"_orig_mod.layer2.2.bn2.running_mean\", \"_orig_mod.layer2.2.bn2.running_var\", \"_orig_mod.layer2.2.bn2.num_batches_tracked\", \"_orig_mod.layer2.2.conv3.weight\", \"_orig_mod.layer2.2.bn3.weight\", \"_orig_mod.layer2.2.bn3.bias\", \"_orig_mod.layer2.2.bn3.running_mean\", \"_orig_mod.layer2.2.bn3.running_var\", \"_orig_mod.layer2.2.bn3.num_batches_tracked\", \"_orig_mod.layer2.3.conv1.weight\", \"_orig_mod.layer2.3.bn1.weight\", \"_orig_mod.layer2.3.bn1.bias\", \"_orig_mod.layer2.3.bn1.running_mean\", \"_orig_mod.layer2.3.bn1.running_var\", \"_orig_mod.layer2.3.bn1.num_batches_tracked\", \"_orig_mod.layer2.3.conv2.weight\", \"_orig_mod.layer2.3.bn2.weight\", \"_orig_mod.layer2.3.bn2.bias\", \"_orig_mod.layer2.3.bn2.running_mean\", \"_orig_mod.layer2.3.bn2.running_var\", \"_orig_mod.layer2.3.bn2.num_batches_tracked\", \"_orig_mod.layer2.3.conv3.weight\", \"_orig_mod.layer2.3.bn3.weight\", \"_orig_mod.layer2.3.bn3.bias\", \"_orig_mod.layer2.3.bn3.running_mean\", \"_orig_mod.layer2.3.bn3.running_var\", \"_orig_mod.layer2.3.bn3.num_batches_tracked\", \"_orig_mod.layer3.0.conv1.weight\", \"_orig_mod.layer3.0.bn1.weight\", \"_orig_mod.layer3.0.bn1.bias\", \"_orig_mod.layer3.0.bn1.running_mean\", \"_orig_mod.layer3.0.bn1.running_var\", \"_orig_mod.layer3.0.bn1.num_batches_tracked\", \"_orig_mod.layer3.0.conv2.weight\", \"_orig_mod.layer3.0.bn2.weight\", \"_orig_mod.layer3.0.bn2.bias\", \"_orig_mod.layer3.0.bn2.running_mean\", \"_orig_mod.layer3.0.bn2.running_var\", \"_orig_mod.layer3.0.bn2.num_batches_tracked\", \"_orig_mod.layer3.0.conv3.weight\", \"_orig_mod.layer3.0.bn3.weight\", \"_orig_mod.layer3.0.bn3.bias\", \"_orig_mod.layer3.0.bn3.running_mean\", \"_orig_mod.layer3.0.bn3.running_var\", \"_orig_mod.layer3.0.bn3.num_batches_tracked\", \"_orig_mod.layer3.0.downsample.0.weight\", \"_orig_mod.layer3.0.downsample.1.weight\", \"_orig_mod.layer3.0.downsample.1.bias\", \"_orig_mod.layer3.0.downsample.1.running_mean\", \"_orig_mod.layer3.0.downsample.1.running_var\", \"_orig_mod.layer3.0.downsample.1.num_batches_tracked\", \"_orig_mod.layer3.1.conv1.weight\", \"_orig_mod.layer3.1.bn1.weight\", \"_orig_mod.layer3.1.bn1.bias\", \"_orig_mod.layer3.1.bn1.running_mean\", \"_orig_mod.layer3.1.bn1.running_var\", \"_orig_mod.layer3.1.bn1.num_batches_tracked\", \"_orig_mod.layer3.1.conv2.weight\", \"_orig_mod.layer3.1.bn2.weight\", \"_orig_mod.layer3.1.bn2.bias\", \"_orig_mod.layer3.1.bn2.running_mean\", \"_orig_mod.layer3.1.bn2.running_var\", \"_orig_mod.layer3.1.bn2.num_batches_tracked\", \"_orig_mod.layer3.1.conv3.weight\", \"_orig_mod.layer3.1.bn3.weight\", \"_orig_mod.layer3.1.bn3.bias\", \"_orig_mod.layer3.1.bn3.running_mean\", \"_orig_mod.layer3.1.bn3.running_var\", \"_orig_mod.layer3.1.bn3.num_batches_tracked\", \"_orig_mod.layer3.2.conv1.weight\", \"_orig_mod.layer3.2.bn1.weight\", \"_orig_mod.layer3.2.bn1.bias\", \"_orig_mod.layer3.2.bn1.running_mean\", \"_orig_mod.layer3.2.bn1.running_var\", \"_orig_mod.layer3.2.bn1.num_batches_tracked\", \"_orig_mod.layer3.2.conv2.weight\", \"_orig_mod.layer3.2.bn2.weight\", \"_orig_mod.layer3.2.bn2.bias\", \"_orig_mod.layer3.2.bn2.running_mean\", \"_orig_mod.layer3.2.bn2.running_var\", \"_orig_mod.layer3.2.bn2.num_batches_tracked\", \"_orig_mod.layer3.2.conv3.weight\", \"_orig_mod.layer3.2.bn3.weight\", \"_orig_mod.layer3.2.bn3.bias\", \"_orig_mod.layer3.2.bn3.running_mean\", \"_orig_mod.layer3.2.bn3.running_var\", \"_orig_mod.layer3.2.bn3.num_batches_tracked\", \"_orig_mod.layer3.3.conv1.weight\", \"_orig_mod.layer3.3.bn1.weight\", \"_orig_mod.layer3.3.bn1.bias\", \"_orig_mod.layer3.3.bn1.running_mean\", \"_orig_mod.layer3.3.bn1.running_var\", \"_orig_mod.layer3.3.bn1.num_batches_tracked\", \"_orig_mod.layer3.3.conv2.weight\", \"_orig_mod.layer3.3.bn2.weight\", \"_orig_mod.layer3.3.bn2.bias\", \"_orig_mod.layer3.3.bn2.running_mean\", \"_orig_mod.layer3.3.bn2.running_var\", \"_orig_mod.layer3.3.bn2.num_batches_tracked\", \"_orig_mod.layer3.3.conv3.weight\", \"_orig_mod.layer3.3.bn3.weight\", \"_orig_mod.layer3.3.bn3.bias\", \"_orig_mod.layer3.3.bn3.running_mean\", \"_orig_mod.layer3.3.bn3.running_var\", \"_orig_mod.layer3.3.bn3.num_batches_tracked\", \"_orig_mod.layer3.4.conv1.weight\", \"_orig_mod.layer3.4.bn1.weight\", \"_orig_mod.layer3.4.bn1.bias\", \"_orig_mod.layer3.4.bn1.running_mean\", \"_orig_mod.layer3.4.bn1.running_var\", \"_orig_mod.layer3.4.bn1.num_batches_tracked\", \"_orig_mod.layer3.4.conv2.weight\", \"_orig_mod.layer3.4.bn2.weight\", \"_orig_mod.layer3.4.bn2.bias\", \"_orig_mod.layer3.4.bn2.running_mean\", \"_orig_mod.layer3.4.bn2.running_var\", \"_orig_mod.layer3.4.bn2.num_batches_tracked\", \"_orig_mod.layer3.4.conv3.weight\", \"_orig_mod.layer3.4.bn3.weight\", \"_orig_mod.layer3.4.bn3.bias\", \"_orig_mod.layer3.4.bn3.running_mean\", \"_orig_mod.layer3.4.bn3.running_var\", \"_orig_mod.layer3.4.bn3.num_batches_tracked\", \"_orig_mod.layer3.5.conv1.weight\", \"_orig_mod.layer3.5.bn1.weight\", \"_orig_mod.layer3.5.bn1.bias\", \"_orig_mod.layer3.5.bn1.running_mean\", \"_orig_mod.layer3.5.bn1.running_var\", \"_orig_mod.layer3.5.bn1.num_batches_tracked\", \"_orig_mod.layer3.5.conv2.weight\", \"_orig_mod.layer3.5.bn2.weight\", \"_orig_mod.layer3.5.bn2.bias\", \"_orig_mod.layer3.5.bn2.running_mean\", \"_orig_mod.layer3.5.bn2.running_var\", \"_orig_mod.layer3.5.bn2.num_batches_tracked\", \"_orig_mod.layer3.5.conv3.weight\", \"_orig_mod.layer3.5.bn3.weight\", \"_orig_mod.layer3.5.bn3.bias\", \"_orig_mod.layer3.5.bn3.running_mean\", \"_orig_mod.layer3.5.bn3.running_var\", \"_orig_mod.layer3.5.bn3.num_batches_tracked\", \"_orig_mod.layer4.0.conv1.weight\", \"_orig_mod.layer4.0.bn1.weight\", \"_orig_mod.layer4.0.bn1.bias\", \"_orig_mod.layer4.0.bn1.running_mean\", \"_orig_mod.layer4.0.bn1.running_var\", \"_orig_mod.layer4.0.bn1.num_batches_tracked\", \"_orig_mod.layer4.0.conv2.weight\", \"_orig_mod.layer4.0.bn2.weight\", \"_orig_mod.layer4.0.bn2.bias\", \"_orig_mod.layer4.0.bn2.running_mean\", \"_orig_mod.layer4.0.bn2.running_var\", \"_orig_mod.layer4.0.bn2.num_batches_tracked\", \"_orig_mod.layer4.0.conv3.weight\", \"_orig_mod.layer4.0.bn3.weight\", \"_orig_mod.layer4.0.bn3.bias\", \"_orig_mod.layer4.0.bn3.running_mean\", \"_orig_mod.layer4.0.bn3.running_var\", \"_orig_mod.layer4.0.bn3.num_batches_tracked\", \"_orig_mod.layer4.0.downsample.0.weight\", \"_orig_mod.layer4.0.downsample.1.weight\", \"_orig_mod.layer4.0.downsample.1.bias\", \"_orig_mod.layer4.0.downsample.1.running_mean\", \"_orig_mod.layer4.0.downsample.1.running_var\", \"_orig_mod.layer4.0.downsample.1.num_batches_tracked\", \"_orig_mod.layer4.1.conv1.weight\", \"_orig_mod.layer4.1.bn1.weight\", \"_orig_mod.layer4.1.bn1.bias\", \"_orig_mod.layer4.1.bn1.running_mean\", \"_orig_mod.layer4.1.bn1.running_var\", \"_orig_mod.layer4.1.bn1.num_batches_tracked\", \"_orig_mod.layer4.1.conv2.weight\", \"_orig_mod.layer4.1.bn2.weight\", \"_orig_mod.layer4.1.bn2.bias\", \"_orig_mod.layer4.1.bn2.running_mean\", \"_orig_mod.layer4.1.bn2.running_var\", \"_orig_mod.layer4.1.bn2.num_batches_tracked\", \"_orig_mod.layer4.1.conv3.weight\", \"_orig_mod.layer4.1.bn3.weight\", \"_orig_mod.layer4.1.bn3.bias\", \"_orig_mod.layer4.1.bn3.running_mean\", \"_orig_mod.layer4.1.bn3.running_var\", \"_orig_mod.layer4.1.bn3.num_batches_tracked\", \"_orig_mod.layer4.2.conv1.weight\", \"_orig_mod.layer4.2.bn1.weight\", \"_orig_mod.layer4.2.bn1.bias\", \"_orig_mod.layer4.2.bn1.running_mean\", \"_orig_mod.layer4.2.bn1.running_var\", \"_orig_mod.layer4.2.bn1.num_batches_tracked\", \"_orig_mod.layer4.2.conv2.weight\", \"_orig_mod.layer4.2.bn2.weight\", \"_orig_mod.layer4.2.bn2.bias\", \"_orig_mod.layer4.2.bn2.running_mean\", \"_orig_mod.layer4.2.bn2.running_var\", \"_orig_mod.layer4.2.bn2.num_batches_tracked\", \"_orig_mod.layer4.2.conv3.weight\", \"_orig_mod.layer4.2.bn3.weight\", \"_orig_mod.layer4.2.bn3.bias\", \"_orig_mod.layer4.2.bn3.running_mean\", \"_orig_mod.layer4.2.bn3.running_var\", \"_orig_mod.layer4.2.bn3.num_batches_tracked\", \"_orig_mod.fc.weight\", \"_orig_mod.fc.bias\". "
     ]
    }
   ],
   "source": [
    "arch_1 = choose_network({\"model\":model_2[-3] , \"transfer_imagenet\":False, \"num_classes\": int(model_2[-2]), \"device\":\"cuda:0\"})\n",
    "model_weights = torch.load(Path(model_2[0]).parent/\"checkpoint\", map_location='cuda:0')\n",
    "arch_1.load_state_dict(model_weights['model_state_dict'])\n",
    "arch_1.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\"image_size\": 224, \"subset_images\":100, \"load_proxy_data\":False, \"name_fn\":get_parent_name, \"ds_path\": \"/Users/eragon/Documents/CODE/Datasets/imagenette2-320/val\", \"batch_size\":10}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transforms = A.Compose(\n",
    "            [\n",
    "                A.Resize(config[\"image_size\"], config[\"image_size\"]),\n",
    "                A.CenterCrop(config[\"image_size\"], config[\"image_size\"], p=1.0),\n",
    "                A.Normalize(\n",
    "                    mean=[0.485, 0.456, 0.406],\n",
    "                    std=[0.229, 0.224, 0.225],\n",
    "                    max_pixel_value=255.0,\n",
    "                    p=1.0,\n",
    "                ),\n",
    "                ToTensorV2(p=1.0),\n",
    "            ],\n",
    "            p=1.0,\n",
    "        ),\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "val = create_folds(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_datasets = ImageClassDs(\n",
    "            val[0], config[\"ds_path\"], train=False, transforms=data_transforms\n",
    "        ),\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dls = torch.utils.data.DataLoader(\n",
    "        image_datasets,\n",
    "        batch_size=config[\"batch_size\"],\n",
    "        shuffle=False,\n",
    "        num_workers=8,\n",
    "    ),\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'arch_1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m arch_1(val_dls)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'arch_1' is not defined"
     ]
    }
   ],
   "source": [
    "arch_1(val_dls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
