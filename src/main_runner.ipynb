{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d8c751fa",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "from config import ds_config\n",
    "from fastai.vision.all import *\n",
    "from fastai.callback.tensorboard import TensorBoardCallback\n",
    "import torchvision.transforms.functional as transformF\n",
    "\n",
    "# from fastai.callback.tracker import\n",
    "from fastai.vision.widgets import *\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import Image\n",
    "import argparse as ap\n",
    "import datetime\n",
    "import gc\n",
    "from tqdm import tqdm\n",
    "from multiprocessing import set_start_method\n",
    "\n",
    "from utils import *  # import utils at the end after fastai because the Hook function is a monkey-patch\n",
    "\n",
    "os.environ[\"TORCH_HOME\"] = \"/media/hdd/Datasets/\"\n",
    "os.environ[\"FASTAI_HOME\"] = \"/media/hdd/Datasets/\"\n",
    "\n",
    "# set_start_method('spawn')\n",
    "# Monkey patch batch prediction (fastai does not have this by default)\n",
    "Learner.predict_batch = predict_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "888680ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ags = ap.ArgumentParser(\"Additional Arguments for CLI\")\n",
    "# ags.add_argument(\n",
    "#     \"--config\", help=\"Name of config from dictionary\", default=\"fish_test_proxy\"\n",
    "# )\n",
    "# ags.add_argument(\"--name\", help=\"Name of the experiment\", required=True)\n",
    "# args = ags.parse_args()\n",
    "args = {\n",
    "    \"config\": \"fish_test_proxy\",\n",
    "    \"name\" : \"testing_ugh\"\n",
    "}\n",
    "from types import SimpleNamespace\n",
    "args = SimpleNamespace(**args)\n",
    "ds_meta = ds_config[args.config]  # get info about dataset from the config file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e0f60a10",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] : File name = fish_testing_ugh_10102022_00:38:33\n",
      "[INFO] : Removed Old augmented files\n"
     ]
    }
   ],
   "source": [
    "# Training Part 1\n",
    "path = Path(ds_meta[\"ds_path\"])\n",
    "fname_start = f'{ds_meta[\"ds_name\"]}_{args.name}_{datetime.now().strftime(\"%d%m%Y_%H:%M:%S\")}'  # unique_name\n",
    "print(f\"[INFO] : File name = {fname_start}\")\n",
    "\n",
    "# Check if directories all present\n",
    "create_if_not_exists(f\"tb_runs/{fname_start}\")\n",
    "create_if_not_exists(f\"csv_logs/{fname_start}\")\n",
    "# Remove previous files\n",
    "\n",
    "all_files = get_image_files(path)\n",
    "[Path.unlink(file) for file in all_files if \"augmented_\" in file.name]\n",
    "print(\"[INFO] : Removed Old augmented files\")\n",
    "\n",
    "# TODO : Add reset folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7c085a3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_tfms = aug_transforms() if ds_meta[\"enable_default_augments\"] == True else None\n",
    "fields = DataBlock(\n",
    "    blocks=(ImageBlock, CategoryBlock),\n",
    "    get_items=get_image_files,\n",
    "    get_y=ds_meta[\"name_fn\"],\n",
    "    splitter=RandomSplitter(valid_pct=0.2, seed=42),\n",
    "    item_tfms=RandomResizedCrop(ds_meta[\"image_size\"], min_scale=0.5),\n",
    "    batch_tfms=batch_tfms,\n",
    ")\n",
    "# Metrics\n",
    "metrics = [accuracy, error_rate]\n",
    "# Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4a0fc50d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LOG] Training rounds scheme : [1, 'aug', 2]\n"
     ]
    }
   ],
   "source": [
    "# MAIN LOOP\n",
    "training_rounds = ds_meta[\"epoch_steps\"]\n",
    "total_epochs = sum(training_rounds)  # total no of epochs\n",
    "\n",
    "# Convert [1,2,3] -> [1,'aug', 2, 'aug', 3, 'aug']\n",
    "[training_rounds.insert(2 * x, \"aug\") for x in range(len(training_rounds))]\n",
    "training_rounds.pop(0)\n",
    "print(f\"[LOG] Training rounds scheme : {training_rounds}\")\n",
    "\n",
    "# Start the loop\n",
    "total_epochs_passed = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f347fbec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3 [00:00<?, ?it/s]/home/eragon/micromamba/envs/pytorcher/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/eragon/micromamba/envs/pytorcher/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>error_rate</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2.207286</td>\n",
       "      <td>1.329824</td>\n",
       "      <td>0.503056</td>\n",
       "      <td>0.496944</td>\n",
       "      <td>00:27</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>error_rate</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.350487</td>\n",
       "      <td>0.895732</td>\n",
       "      <td>0.658333</td>\n",
       "      <td>0.341667</td>\n",
       "      <td>00:39</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 1/3 [01:15<02:30, 75.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LOG] : Cleared learner\n",
      "[INFO]: Running Proxy Attention\n",
      "[INFO] : Starting Attention Loop\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] : Pct wrong for step 1 = 0.3472222222222222\n",
      "[INFO] : Creating maps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/eragon/micromamba/envs/pytorcher/lib/python3.10/site-packages/torch/nn/modules/module.py:1053: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n",
      " 14%|█▍        | 90/625 [02:25<14:27,  1.62s/it]\n",
      " 33%|███▎      | 1/3 [03:46<07:32, 226.35s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/media/hdd/github/improving_robotics_datasets/src/main_runner.ipynb Cell 6'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    <a href='vscode-notebook-cell:/media/hdd/github/improving_robotics_datasets/src/main_runner.ipynb#ch0000005?line=186'>187</a>\u001b[0m     plt\u001b[39m.\u001b[39maxis(\u001b[39m\"\u001b[39m\u001b[39moff\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    <a href='vscode-notebook-cell:/media/hdd/github/improving_robotics_datasets/src/main_runner.ipynb#ch0000005?line=187'>188</a>\u001b[0m     plt\u001b[39m.\u001b[39mbox(\u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m--> <a href='vscode-notebook-cell:/media/hdd/github/improving_robotics_datasets/src/main_runner.ipynb#ch0000005?line=188'>189</a>\u001b[0m     plt\u001b[39m.\u001b[39;49msavefig(rename_for_aug(items[im]), transparent \u001b[39m=\u001b[39;49m \u001b[39mTrue\u001b[39;49;00m)\n\u001b[1;32m    <a href='vscode-notebook-cell:/media/hdd/github/improving_robotics_datasets/src/main_runner.ipynb#ch0000005?line=191'>192</a>\u001b[0m clear_learner(learn, dls)\n\u001b[1;32m    <a href='vscode-notebook-cell:/media/hdd/github/improving_robotics_datasets/src/main_runner.ipynb#ch0000005?line=192'>193</a>\u001b[0m \u001b[39mdel\u001b[39;00m bspred\n",
      "File \u001b[0;32m~/micromamba/envs/pytorcher/lib/python3.10/site-packages/matplotlib/pyplot.py:978\u001b[0m, in \u001b[0;36msavefig\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    <a href='file:///home/eragon/micromamba/envs/pytorcher/lib/python3.10/site-packages/matplotlib/pyplot.py?line=975'>976</a>\u001b[0m fig \u001b[39m=\u001b[39m gcf()\n\u001b[1;32m    <a href='file:///home/eragon/micromamba/envs/pytorcher/lib/python3.10/site-packages/matplotlib/pyplot.py?line=976'>977</a>\u001b[0m res \u001b[39m=\u001b[39m fig\u001b[39m.\u001b[39msavefig(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m--> <a href='file:///home/eragon/micromamba/envs/pytorcher/lib/python3.10/site-packages/matplotlib/pyplot.py?line=977'>978</a>\u001b[0m fig\u001b[39m.\u001b[39;49mcanvas\u001b[39m.\u001b[39;49mdraw_idle()   \u001b[39m# need this if 'transparent=True' to reset colors\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/eragon/micromamba/envs/pytorcher/lib/python3.10/site-packages/matplotlib/pyplot.py?line=978'>979</a>\u001b[0m \u001b[39mreturn\u001b[39;00m res\n",
      "File \u001b[0;32m~/micromamba/envs/pytorcher/lib/python3.10/site-packages/matplotlib/backend_bases.py:2060\u001b[0m, in \u001b[0;36mFigureCanvasBase.draw_idle\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///home/eragon/micromamba/envs/pytorcher/lib/python3.10/site-packages/matplotlib/backend_bases.py?line=2057'>2058</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_is_idle_drawing:\n\u001b[1;32m   <a href='file:///home/eragon/micromamba/envs/pytorcher/lib/python3.10/site-packages/matplotlib/backend_bases.py?line=2058'>2059</a>\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_idle_draw_cntx():\n\u001b[0;32m-> <a href='file:///home/eragon/micromamba/envs/pytorcher/lib/python3.10/site-packages/matplotlib/backend_bases.py?line=2059'>2060</a>\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdraw(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/micromamba/envs/pytorcher/lib/python3.10/site-packages/matplotlib/backends/backend_agg.py:436\u001b[0m, in \u001b[0;36mFigureCanvasAgg.draw\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    <a href='file:///home/eragon/micromamba/envs/pytorcher/lib/python3.10/site-packages/matplotlib/backends/backend_agg.py?line=431'>432</a>\u001b[0m \u001b[39m# Acquire a lock on the shared font cache.\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/eragon/micromamba/envs/pytorcher/lib/python3.10/site-packages/matplotlib/backends/backend_agg.py?line=432'>433</a>\u001b[0m \u001b[39mwith\u001b[39;00m RendererAgg\u001b[39m.\u001b[39mlock, \\\n\u001b[1;32m    <a href='file:///home/eragon/micromamba/envs/pytorcher/lib/python3.10/site-packages/matplotlib/backends/backend_agg.py?line=433'>434</a>\u001b[0m      (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtoolbar\u001b[39m.\u001b[39m_wait_cursor_for_draw_cm() \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtoolbar\n\u001b[1;32m    <a href='file:///home/eragon/micromamba/envs/pytorcher/lib/python3.10/site-packages/matplotlib/backends/backend_agg.py?line=434'>435</a>\u001b[0m       \u001b[39melse\u001b[39;00m nullcontext()):\n\u001b[0;32m--> <a href='file:///home/eragon/micromamba/envs/pytorcher/lib/python3.10/site-packages/matplotlib/backends/backend_agg.py?line=435'>436</a>\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfigure\u001b[39m.\u001b[39;49mdraw(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrenderer)\n\u001b[1;32m    <a href='file:///home/eragon/micromamba/envs/pytorcher/lib/python3.10/site-packages/matplotlib/backends/backend_agg.py?line=436'>437</a>\u001b[0m     \u001b[39m# A GUI class may be need to update a window using this draw, so\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/eragon/micromamba/envs/pytorcher/lib/python3.10/site-packages/matplotlib/backends/backend_agg.py?line=437'>438</a>\u001b[0m     \u001b[39m# don't forget to call the superclass.\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/eragon/micromamba/envs/pytorcher/lib/python3.10/site-packages/matplotlib/backends/backend_agg.py?line=438'>439</a>\u001b[0m     \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39mdraw()\n",
      "File \u001b[0;32m~/micromamba/envs/pytorcher/lib/python3.10/site-packages/matplotlib/artist.py:74\u001b[0m, in \u001b[0;36m_finalize_rasterization.<locals>.draw_wrapper\u001b[0;34m(artist, renderer, *args, **kwargs)\u001b[0m\n\u001b[1;32m     <a href='file:///home/eragon/micromamba/envs/pytorcher/lib/python3.10/site-packages/matplotlib/artist.py?line=71'>72</a>\u001b[0m \u001b[39m@wraps\u001b[39m(draw)\n\u001b[1;32m     <a href='file:///home/eragon/micromamba/envs/pytorcher/lib/python3.10/site-packages/matplotlib/artist.py?line=72'>73</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdraw_wrapper\u001b[39m(artist, renderer, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m---> <a href='file:///home/eragon/micromamba/envs/pytorcher/lib/python3.10/site-packages/matplotlib/artist.py?line=73'>74</a>\u001b[0m     result \u001b[39m=\u001b[39m draw(artist, renderer, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     <a href='file:///home/eragon/micromamba/envs/pytorcher/lib/python3.10/site-packages/matplotlib/artist.py?line=74'>75</a>\u001b[0m     \u001b[39mif\u001b[39;00m renderer\u001b[39m.\u001b[39m_rasterizing:\n\u001b[1;32m     <a href='file:///home/eragon/micromamba/envs/pytorcher/lib/python3.10/site-packages/matplotlib/artist.py?line=75'>76</a>\u001b[0m         renderer\u001b[39m.\u001b[39mstop_rasterizing()\n",
      "File \u001b[0;32m~/micromamba/envs/pytorcher/lib/python3.10/site-packages/matplotlib/artist.py:51\u001b[0m, in \u001b[0;36mallow_rasterization.<locals>.draw_wrapper\u001b[0;34m(artist, renderer)\u001b[0m\n\u001b[1;32m     <a href='file:///home/eragon/micromamba/envs/pytorcher/lib/python3.10/site-packages/matplotlib/artist.py?line=47'>48</a>\u001b[0m     \u001b[39mif\u001b[39;00m artist\u001b[39m.\u001b[39mget_agg_filter() \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m     <a href='file:///home/eragon/micromamba/envs/pytorcher/lib/python3.10/site-packages/matplotlib/artist.py?line=48'>49</a>\u001b[0m         renderer\u001b[39m.\u001b[39mstart_filter()\n\u001b[0;32m---> <a href='file:///home/eragon/micromamba/envs/pytorcher/lib/python3.10/site-packages/matplotlib/artist.py?line=50'>51</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m draw(artist, renderer)\n\u001b[1;32m     <a href='file:///home/eragon/micromamba/envs/pytorcher/lib/python3.10/site-packages/matplotlib/artist.py?line=51'>52</a>\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     <a href='file:///home/eragon/micromamba/envs/pytorcher/lib/python3.10/site-packages/matplotlib/artist.py?line=52'>53</a>\u001b[0m     \u001b[39mif\u001b[39;00m artist\u001b[39m.\u001b[39mget_agg_filter() \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/micromamba/envs/pytorcher/lib/python3.10/site-packages/matplotlib/figure.py:2845\u001b[0m, in \u001b[0;36mFigure.draw\u001b[0;34m(self, renderer)\u001b[0m\n\u001b[1;32m   <a href='file:///home/eragon/micromamba/envs/pytorcher/lib/python3.10/site-packages/matplotlib/figure.py?line=2841'>2842</a>\u001b[0m         \u001b[39m# ValueError can occur when resizing a window.\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/eragon/micromamba/envs/pytorcher/lib/python3.10/site-packages/matplotlib/figure.py?line=2843'>2844</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpatch\u001b[39m.\u001b[39mdraw(renderer)\n\u001b[0;32m-> <a href='file:///home/eragon/micromamba/envs/pytorcher/lib/python3.10/site-packages/matplotlib/figure.py?line=2844'>2845</a>\u001b[0m mimage\u001b[39m.\u001b[39;49m_draw_list_compositing_images(\n\u001b[1;32m   <a href='file:///home/eragon/micromamba/envs/pytorcher/lib/python3.10/site-packages/matplotlib/figure.py?line=2845'>2846</a>\u001b[0m     renderer, \u001b[39mself\u001b[39;49m, artists, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msuppressComposite)\n\u001b[1;32m   <a href='file:///home/eragon/micromamba/envs/pytorcher/lib/python3.10/site-packages/matplotlib/figure.py?line=2847'>2848</a>\u001b[0m \u001b[39mfor\u001b[39;00m sfig \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msubfigs:\n\u001b[1;32m   <a href='file:///home/eragon/micromamba/envs/pytorcher/lib/python3.10/site-packages/matplotlib/figure.py?line=2848'>2849</a>\u001b[0m     sfig\u001b[39m.\u001b[39mdraw(renderer)\n",
      "File \u001b[0;32m~/micromamba/envs/pytorcher/lib/python3.10/site-packages/matplotlib/image.py:132\u001b[0m, in \u001b[0;36m_draw_list_compositing_images\u001b[0;34m(renderer, parent, artists, suppress_composite)\u001b[0m\n\u001b[1;32m    <a href='file:///home/eragon/micromamba/envs/pytorcher/lib/python3.10/site-packages/matplotlib/image.py?line=129'>130</a>\u001b[0m \u001b[39mif\u001b[39;00m not_composite \u001b[39mor\u001b[39;00m \u001b[39mnot\u001b[39;00m has_images:\n\u001b[1;32m    <a href='file:///home/eragon/micromamba/envs/pytorcher/lib/python3.10/site-packages/matplotlib/image.py?line=130'>131</a>\u001b[0m     \u001b[39mfor\u001b[39;00m a \u001b[39min\u001b[39;00m artists:\n\u001b[0;32m--> <a href='file:///home/eragon/micromamba/envs/pytorcher/lib/python3.10/site-packages/matplotlib/image.py?line=131'>132</a>\u001b[0m         a\u001b[39m.\u001b[39;49mdraw(renderer)\n\u001b[1;32m    <a href='file:///home/eragon/micromamba/envs/pytorcher/lib/python3.10/site-packages/matplotlib/image.py?line=132'>133</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    <a href='file:///home/eragon/micromamba/envs/pytorcher/lib/python3.10/site-packages/matplotlib/image.py?line=133'>134</a>\u001b[0m     \u001b[39m# Composite any adjacent images together\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/eragon/micromamba/envs/pytorcher/lib/python3.10/site-packages/matplotlib/image.py?line=134'>135</a>\u001b[0m     image_group \u001b[39m=\u001b[39m []\n",
      "File \u001b[0;32m~/micromamba/envs/pytorcher/lib/python3.10/site-packages/matplotlib/artist.py:51\u001b[0m, in \u001b[0;36mallow_rasterization.<locals>.draw_wrapper\u001b[0;34m(artist, renderer)\u001b[0m\n\u001b[1;32m     <a href='file:///home/eragon/micromamba/envs/pytorcher/lib/python3.10/site-packages/matplotlib/artist.py?line=47'>48</a>\u001b[0m     \u001b[39mif\u001b[39;00m artist\u001b[39m.\u001b[39mget_agg_filter() \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m     <a href='file:///home/eragon/micromamba/envs/pytorcher/lib/python3.10/site-packages/matplotlib/artist.py?line=48'>49</a>\u001b[0m         renderer\u001b[39m.\u001b[39mstart_filter()\n\u001b[0;32m---> <a href='file:///home/eragon/micromamba/envs/pytorcher/lib/python3.10/site-packages/matplotlib/artist.py?line=50'>51</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m draw(artist, renderer)\n\u001b[1;32m     <a href='file:///home/eragon/micromamba/envs/pytorcher/lib/python3.10/site-packages/matplotlib/artist.py?line=51'>52</a>\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     <a href='file:///home/eragon/micromamba/envs/pytorcher/lib/python3.10/site-packages/matplotlib/artist.py?line=52'>53</a>\u001b[0m     \u001b[39mif\u001b[39;00m artist\u001b[39m.\u001b[39mget_agg_filter() \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/micromamba/envs/pytorcher/lib/python3.10/site-packages/matplotlib/axes/_base.py:3091\u001b[0m, in \u001b[0;36m_AxesBase.draw\u001b[0;34m(self, renderer)\u001b[0m\n\u001b[1;32m   <a href='file:///home/eragon/micromamba/envs/pytorcher/lib/python3.10/site-packages/matplotlib/axes/_base.py?line=3087'>3088</a>\u001b[0m         a\u001b[39m.\u001b[39mdraw(renderer)\n\u001b[1;32m   <a href='file:///home/eragon/micromamba/envs/pytorcher/lib/python3.10/site-packages/matplotlib/axes/_base.py?line=3088'>3089</a>\u001b[0m     renderer\u001b[39m.\u001b[39mstop_rasterizing()\n\u001b[0;32m-> <a href='file:///home/eragon/micromamba/envs/pytorcher/lib/python3.10/site-packages/matplotlib/axes/_base.py?line=3090'>3091</a>\u001b[0m mimage\u001b[39m.\u001b[39;49m_draw_list_compositing_images(\n\u001b[1;32m   <a href='file:///home/eragon/micromamba/envs/pytorcher/lib/python3.10/site-packages/matplotlib/axes/_base.py?line=3091'>3092</a>\u001b[0m     renderer, \u001b[39mself\u001b[39;49m, artists, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfigure\u001b[39m.\u001b[39;49msuppressComposite)\n\u001b[1;32m   <a href='file:///home/eragon/micromamba/envs/pytorcher/lib/python3.10/site-packages/matplotlib/axes/_base.py?line=3093'>3094</a>\u001b[0m renderer\u001b[39m.\u001b[39mclose_group(\u001b[39m'\u001b[39m\u001b[39maxes\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m   <a href='file:///home/eragon/micromamba/envs/pytorcher/lib/python3.10/site-packages/matplotlib/axes/_base.py?line=3094'>3095</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstale \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/micromamba/envs/pytorcher/lib/python3.10/site-packages/matplotlib/image.py:132\u001b[0m, in \u001b[0;36m_draw_list_compositing_images\u001b[0;34m(renderer, parent, artists, suppress_composite)\u001b[0m\n\u001b[1;32m    <a href='file:///home/eragon/micromamba/envs/pytorcher/lib/python3.10/site-packages/matplotlib/image.py?line=129'>130</a>\u001b[0m \u001b[39mif\u001b[39;00m not_composite \u001b[39mor\u001b[39;00m \u001b[39mnot\u001b[39;00m has_images:\n\u001b[1;32m    <a href='file:///home/eragon/micromamba/envs/pytorcher/lib/python3.10/site-packages/matplotlib/image.py?line=130'>131</a>\u001b[0m     \u001b[39mfor\u001b[39;00m a \u001b[39min\u001b[39;00m artists:\n\u001b[0;32m--> <a href='file:///home/eragon/micromamba/envs/pytorcher/lib/python3.10/site-packages/matplotlib/image.py?line=131'>132</a>\u001b[0m         a\u001b[39m.\u001b[39;49mdraw(renderer)\n\u001b[1;32m    <a href='file:///home/eragon/micromamba/envs/pytorcher/lib/python3.10/site-packages/matplotlib/image.py?line=132'>133</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    <a href='file:///home/eragon/micromamba/envs/pytorcher/lib/python3.10/site-packages/matplotlib/image.py?line=133'>134</a>\u001b[0m     \u001b[39m# Composite any adjacent images together\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/eragon/micromamba/envs/pytorcher/lib/python3.10/site-packages/matplotlib/image.py?line=134'>135</a>\u001b[0m     image_group \u001b[39m=\u001b[39m []\n",
      "File \u001b[0;32m~/micromamba/envs/pytorcher/lib/python3.10/site-packages/matplotlib/artist.py:51\u001b[0m, in \u001b[0;36mallow_rasterization.<locals>.draw_wrapper\u001b[0;34m(artist, renderer)\u001b[0m\n\u001b[1;32m     <a href='file:///home/eragon/micromamba/envs/pytorcher/lib/python3.10/site-packages/matplotlib/artist.py?line=47'>48</a>\u001b[0m     \u001b[39mif\u001b[39;00m artist\u001b[39m.\u001b[39mget_agg_filter() \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m     <a href='file:///home/eragon/micromamba/envs/pytorcher/lib/python3.10/site-packages/matplotlib/artist.py?line=48'>49</a>\u001b[0m         renderer\u001b[39m.\u001b[39mstart_filter()\n\u001b[0;32m---> <a href='file:///home/eragon/micromamba/envs/pytorcher/lib/python3.10/site-packages/matplotlib/artist.py?line=50'>51</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m draw(artist, renderer)\n\u001b[1;32m     <a href='file:///home/eragon/micromamba/envs/pytorcher/lib/python3.10/site-packages/matplotlib/artist.py?line=51'>52</a>\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     <a href='file:///home/eragon/micromamba/envs/pytorcher/lib/python3.10/site-packages/matplotlib/artist.py?line=52'>53</a>\u001b[0m     \u001b[39mif\u001b[39;00m artist\u001b[39m.\u001b[39mget_agg_filter() \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/micromamba/envs/pytorcher/lib/python3.10/site-packages/matplotlib/image.py:646\u001b[0m, in \u001b[0;36m_ImageBase.draw\u001b[0;34m(self, renderer, *args, **kwargs)\u001b[0m\n\u001b[1;32m    <a href='file:///home/eragon/micromamba/envs/pytorcher/lib/python3.10/site-packages/matplotlib/image.py?line=643'>644</a>\u001b[0m         renderer\u001b[39m.\u001b[39mdraw_image(gc, l, b, im, trans)\n\u001b[1;32m    <a href='file:///home/eragon/micromamba/envs/pytorcher/lib/python3.10/site-packages/matplotlib/image.py?line=644'>645</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> <a href='file:///home/eragon/micromamba/envs/pytorcher/lib/python3.10/site-packages/matplotlib/image.py?line=645'>646</a>\u001b[0m     im, l, b, trans \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmake_image(\n\u001b[1;32m    <a href='file:///home/eragon/micromamba/envs/pytorcher/lib/python3.10/site-packages/matplotlib/image.py?line=646'>647</a>\u001b[0m         renderer, renderer\u001b[39m.\u001b[39;49mget_image_magnification())\n\u001b[1;32m    <a href='file:///home/eragon/micromamba/envs/pytorcher/lib/python3.10/site-packages/matplotlib/image.py?line=647'>648</a>\u001b[0m     \u001b[39mif\u001b[39;00m im \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    <a href='file:///home/eragon/micromamba/envs/pytorcher/lib/python3.10/site-packages/matplotlib/image.py?line=648'>649</a>\u001b[0m         renderer\u001b[39m.\u001b[39mdraw_image(gc, l, b, im)\n",
      "File \u001b[0;32m~/micromamba/envs/pytorcher/lib/python3.10/site-packages/matplotlib/image.py:956\u001b[0m, in \u001b[0;36mAxesImage.make_image\u001b[0;34m(self, renderer, magnification, unsampled)\u001b[0m\n\u001b[1;32m    <a href='file:///home/eragon/micromamba/envs/pytorcher/lib/python3.10/site-packages/matplotlib/image.py?line=952'>953</a>\u001b[0m transformed_bbox \u001b[39m=\u001b[39m TransformedBbox(bbox, trans)\n\u001b[1;32m    <a href='file:///home/eragon/micromamba/envs/pytorcher/lib/python3.10/site-packages/matplotlib/image.py?line=953'>954</a>\u001b[0m clip \u001b[39m=\u001b[39m ((\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_clip_box() \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maxes\u001b[39m.\u001b[39mbbox) \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_clip_on()\n\u001b[1;32m    <a href='file:///home/eragon/micromamba/envs/pytorcher/lib/python3.10/site-packages/matplotlib/image.py?line=954'>955</a>\u001b[0m         \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfigure\u001b[39m.\u001b[39mbbox)\n\u001b[0;32m--> <a href='file:///home/eragon/micromamba/envs/pytorcher/lib/python3.10/site-packages/matplotlib/image.py?line=955'>956</a>\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_image(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_A, bbox, transformed_bbox, clip,\n\u001b[1;32m    <a href='file:///home/eragon/micromamba/envs/pytorcher/lib/python3.10/site-packages/matplotlib/image.py?line=956'>957</a>\u001b[0m                         magnification, unsampled\u001b[39m=\u001b[39;49munsampled)\n",
      "File \u001b[0;32m~/micromamba/envs/pytorcher/lib/python3.10/site-packages/matplotlib/image.py:557\u001b[0m, in \u001b[0;36m_ImageBase._make_image\u001b[0;34m(self, A, in_bbox, out_bbox, clip_bbox, magnification, unsampled, round_to_pixel_border)\u001b[0m\n\u001b[1;32m    <a href='file:///home/eragon/micromamba/envs/pytorcher/lib/python3.10/site-packages/matplotlib/image.py?line=553'>554</a>\u001b[0m     alpha \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_scalar_alpha()\n\u001b[1;32m    <a href='file:///home/eragon/micromamba/envs/pytorcher/lib/python3.10/site-packages/matplotlib/image.py?line=554'>555</a>\u001b[0m     output_alpha \u001b[39m=\u001b[39m _resample(  \u001b[39m# resample alpha channel\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/eragon/micromamba/envs/pytorcher/lib/python3.10/site-packages/matplotlib/image.py?line=555'>556</a>\u001b[0m         \u001b[39mself\u001b[39m, A[\u001b[39m.\u001b[39m\u001b[39m.\u001b[39m\u001b[39m.\u001b[39m, \u001b[39m3\u001b[39m], out_shape, t, alpha\u001b[39m=\u001b[39malpha)\n\u001b[0;32m--> <a href='file:///home/eragon/micromamba/envs/pytorcher/lib/python3.10/site-packages/matplotlib/image.py?line=556'>557</a>\u001b[0m     output \u001b[39m=\u001b[39m _resample(  \u001b[39m# resample rgb channels\u001b[39;49;00m\n\u001b[1;32m    <a href='file:///home/eragon/micromamba/envs/pytorcher/lib/python3.10/site-packages/matplotlib/image.py?line=557'>558</a>\u001b[0m         \u001b[39mself\u001b[39;49m, _rgb_to_rgba(A[\u001b[39m.\u001b[39;49m\u001b[39m.\u001b[39;49m\u001b[39m.\u001b[39;49m, :\u001b[39m3\u001b[39;49m]), out_shape, t, alpha\u001b[39m=\u001b[39;49malpha)\n\u001b[1;32m    <a href='file:///home/eragon/micromamba/envs/pytorcher/lib/python3.10/site-packages/matplotlib/image.py?line=558'>559</a>\u001b[0m     output[\u001b[39m.\u001b[39m\u001b[39m.\u001b[39m\u001b[39m.\u001b[39m, \u001b[39m3\u001b[39m] \u001b[39m=\u001b[39m output_alpha  \u001b[39m# recombine rgb and alpha\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/eragon/micromamba/envs/pytorcher/lib/python3.10/site-packages/matplotlib/image.py?line=560'>561</a>\u001b[0m \u001b[39m# at this point output is either a 2D array of normed data\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/eragon/micromamba/envs/pytorcher/lib/python3.10/site-packages/matplotlib/image.py?line=561'>562</a>\u001b[0m \u001b[39m# (of int or float)\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/eragon/micromamba/envs/pytorcher/lib/python3.10/site-packages/matplotlib/image.py?line=562'>563</a>\u001b[0m \u001b[39m# or an RGBA array of re-sampled input\u001b[39;00m\n",
      "File \u001b[0;32m~/micromamba/envs/pytorcher/lib/python3.10/site-packages/matplotlib/image.py:193\u001b[0m, in \u001b[0;36m_resample\u001b[0;34m(image_obj, data, out_shape, transform, resample, alpha)\u001b[0m\n\u001b[1;32m    <a href='file:///home/eragon/micromamba/envs/pytorcher/lib/python3.10/site-packages/matplotlib/image.py?line=190'>191</a>\u001b[0m \u001b[39mif\u001b[39;00m resample \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    <a href='file:///home/eragon/micromamba/envs/pytorcher/lib/python3.10/site-packages/matplotlib/image.py?line=191'>192</a>\u001b[0m     resample \u001b[39m=\u001b[39m image_obj\u001b[39m.\u001b[39mget_resample()\n\u001b[0;32m--> <a href='file:///home/eragon/micromamba/envs/pytorcher/lib/python3.10/site-packages/matplotlib/image.py?line=192'>193</a>\u001b[0m _image\u001b[39m.\u001b[39;49mresample(data, out, transform,\n\u001b[1;32m    <a href='file:///home/eragon/micromamba/envs/pytorcher/lib/python3.10/site-packages/matplotlib/image.py?line=193'>194</a>\u001b[0m                 _interpd_[interpolation],\n\u001b[1;32m    <a href='file:///home/eragon/micromamba/envs/pytorcher/lib/python3.10/site-packages/matplotlib/image.py?line=194'>195</a>\u001b[0m                 resample,\n\u001b[1;32m    <a href='file:///home/eragon/micromamba/envs/pytorcher/lib/python3.10/site-packages/matplotlib/image.py?line=195'>196</a>\u001b[0m                 alpha,\n\u001b[1;32m    <a href='file:///home/eragon/micromamba/envs/pytorcher/lib/python3.10/site-packages/matplotlib/image.py?line=196'>197</a>\u001b[0m                 image_obj\u001b[39m.\u001b[39;49mget_filternorm(),\n\u001b[1;32m    <a href='file:///home/eragon/micromamba/envs/pytorcher/lib/python3.10/site-packages/matplotlib/image.py?line=197'>198</a>\u001b[0m                 image_obj\u001b[39m.\u001b[39;49mget_filterrad())\n\u001b[1;32m    <a href='file:///home/eragon/micromamba/envs/pytorcher/lib/python3.10/site-packages/matplotlib/image.py?line=198'>199</a>\u001b[0m \u001b[39mreturn\u001b[39;00m out\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "for i, step in tqdm(enumerate(training_rounds), total=len(training_rounds)):\n",
    "    if i == 0:\n",
    "        # Initialize everything with new or old data\n",
    "        dls = fields.dataloaders(path, bs=ds_meta[\"batch_size\"])\n",
    "        cbs = [\n",
    "            TensorBoardCallback(\n",
    "                log_dir=f\"tb_runs/{fname_start}\", projector=False, trace_model=False\n",
    "            ),\n",
    "            CSVLogger(fname=f\"csv_logs/{fname_start}.csv\"),\n",
    "        ]\n",
    "\n",
    "        learn = vision_learner(\n",
    "            dls, ds_meta[\"network\"], cbs=cbs, metrics=metrics, pretrained=ds_meta[\"pretrained\"]\n",
    "        ).to_fp16()\n",
    "        fname_training = f'{ds_meta[\"ds_name\"]}_{args.name}_{datetime.now().strftime(\"%d%m%Y_%H:%M:%S\")}'  # unique_name\n",
    "        learn.fine_tune(step)\n",
    "        learn.save(\"temp_model\")  # saving so can be reloaded\n",
    "        clear_learner(learn, dls)\n",
    "        print(\"[LOG] : Cleared learner\")\n",
    "        # Since training is in batches, keep track of total no of epochs trained for\n",
    "        total_epochs_passed += step\n",
    "\n",
    "    if step != \"aug\" and i > 0:\n",
    "        # Initialize everything with new or old data\n",
    "        dls = fields.dataloaders(path, bs=ds_meta[\"batch_size\"])\n",
    "        cbs = [\n",
    "            TensorBoardCallback(\n",
    "                log_dir=f\"tb_runs/{fname_start}\", projector=False, trace_model=False\n",
    "            ),\n",
    "            CSVLogger(fname=f\"csv_logs/{fname_start}.csv\"),\n",
    "        ]\n",
    "\n",
    "        learn = vision_learner(\n",
    "            dls, ds_meta[\"network\"], cbs=cbs, metrics=metrics, pretrained=ds_meta[\"pretrained\"]\n",
    "        ).to_fp16()\n",
    "\n",
    "        learn.load(\"temp_model\")  # load model since augment has been done already\n",
    "        # Continue training\n",
    "        fname_training = f'{ds_meta[\"ds_name\"]}_{args.name}_{datetime.now().strftime(\"%d%m%Y_%H:%M:%S\")}'  # unique_name\n",
    "        learn.fine_tune(step)\n",
    "        learn.save(\"temp_model\")\n",
    "        clear_learner(learn, dls)\n",
    "\n",
    "        print(\"[LOG] : Cleared learner\")\n",
    "        # Since training is in batches, keep track of total no of epochs trained for\n",
    "        total_epochs_passed += step\n",
    "    if step == \"aug\":\n",
    "        if ds_meta[\"enable_proxy_attention\"] == True:\n",
    "            print(\"[INFO]: Running Proxy Attention\")\n",
    "\n",
    "            # PROXY ATTENTION LOOP\n",
    "\n",
    "            dls = fields.dataloaders(path, bs=ds_meta[\"batch_size\"])\n",
    "            cbs = [\n",
    "                TensorBoardCallback(\n",
    "                    log_dir=f\"tb_runs/{fname_start}\", projector=False, trace_model=False\n",
    "                ),\n",
    "                CSVLogger(fname=f\"csv_logs/{fname_start}.csv\"),\n",
    "            ]\n",
    "\n",
    "            learn = vision_learner(\n",
    "                dls, ds_meta[\"network\"], cbs=cbs, metrics=metrics, pretrained=ds_meta[\"pretrained\"]\n",
    "            ).to_fp16()\n",
    "\n",
    "            learn.load(\"temp_model\")  # load model since augment has been done already\n",
    "            learn.to('cpu')\n",
    "\n",
    "            # Get the classes\n",
    "            print(\"[INFO] : Starting Attention Loop\")\n",
    "            vocab_dict = {\n",
    "                learn.dls.vocab[x]: x for x in range(len(learn.dls.vocab))\n",
    "            }  # Get class names\n",
    "            # Get images, shuffle, pick a subset\n",
    "            items = get_image_files_exclude_augment(ds_meta[\"ds_path\"])\n",
    "            # items = items.shuffle()\n",
    "            subset = int(ds_meta[\"change_subset_attention\"] * len(items))\n",
    "            items = items[:subset]\n",
    "            # Get preds from the network for all the chosen images with \"num_workers\" threads\n",
    "            bspred = learn.predict_batch(items, num_workers=10)\n",
    "            # Get all the class names for the subset of images and convert them into the One hot encoded version that the network knows already\n",
    "            item_names = list(\n",
    "                map(lambda x: vocab_dict[x], list(map(ds_meta[\"name_fn\"], items)))\n",
    "            )\n",
    "\n",
    "            # Get the index of all the images that the network predicted wrong\n",
    "            # TODO : Check for confidence\n",
    "            index_wrongs = [\n",
    "                x for x in range(subset) if bspred[2][x] != TensorBase(item_names)[x]\n",
    "            ]\n",
    "            print(\n",
    "                f\"[INFO] : Pct wrong for step {total_epochs_passed} = {len(index_wrongs)/len(bspred[2])}\"\n",
    "            )\n",
    "\n",
    "            # RUN PROXY ATTENTION\n",
    "            print(f\"[INFO] : Creating maps\")\n",
    "            # def create_im(im):\n",
    "            #     img = PILImage.create(items[im])\n",
    "\n",
    "            #     (x,) = first(dls.test_dl([img]))\n",
    "\n",
    "            #     x_dec = TensorImage(dls.train.decode((x,))[0][0])\n",
    "\n",
    "            #     # Get attention maps\n",
    "\n",
    "            #     # -----\n",
    "            #     # Grad CAM Attention map\n",
    "            #     cls = 1\n",
    "            #     try:\n",
    "            #         with HookBwd(learn.model[-2][4][-1]) as hookg:  # for other layers\n",
    "            #             with Hook(learn.model[-2][4][-1]) as hook:\n",
    "            #                 output = learn.model.eval()(x.cuda())\n",
    "            #                 act = hook.stored\n",
    "            #             output[0, cls].backward()\n",
    "            #             grad = hookg.stored\n",
    "            #         w = grad[0].mean(dim=[1, 2], keepdim=True)\n",
    "            #         cam_map = (w * act[0]).sum(0)\n",
    "            #         # print(x.shape,x_dec.shape, w.shape, cam_map.shape)\n",
    "\n",
    "            #     except Exception as e:\n",
    "            #         print(e)\n",
    "            #     # -----\n",
    "\n",
    "            #     # test_cam_map = cam_map.detach().cpu()\n",
    "            #     # Resize cam map so it's the same size as the image, as the output is much smaller\n",
    "            #     t_resized = transformF.resize(\n",
    "            #         torch.unsqueeze(cam_map, 0), ds_meta[\"image_size\"]\n",
    "            #     )\n",
    "            #     t_resized = (\n",
    "            #         torch.cat([t_resized, t_resized, t_resized], dim=0).detach().cpu()\n",
    "            #     )\n",
    "\n",
    "            #     # IMPORTANT : Change the pixels that are of higher intensity to 0 because they did not help the network get the right answer\n",
    "            #     x_dec[t_resized >= 0.009] = 0.0\n",
    "\n",
    "            #     x_dec = torch.einsum(\"ijk->jki\", x_dec)\n",
    "            #     plt.imshow(x_dec)\n",
    "            #     plt.axis(\"off\")\n",
    "            #     plt.spines['top'].set_visible(False)\n",
    "            #     plt.spines['right'].set_visible(False)\n",
    "            #     plt.spines['bottom'].set_visible(False)\n",
    "            #     plt.spines['left'].set_visible(False)\n",
    "            #     plt.box(False)\n",
    "            #     plt.savefig(rename_for_aug(items[im]), transparent = True)\n",
    "\n",
    "            # parallel(create_im, index_wrongs, progress=True, n_workers=8)\n",
    "            for im in tqdm(index_wrongs, total = len(index_wrongs)):\n",
    "                img = PILImage.create(items[im])\n",
    "\n",
    "                (x,) = first(dls.test_dl([img]))\n",
    "\n",
    "                x_dec = TensorImage(dls.train.decode((x,))[0][0])\n",
    "\n",
    "                # Get attention maps\n",
    "\n",
    "                # -----\n",
    "                # Grad CAM Attention map\n",
    "                cls = 1\n",
    "                try:\n",
    "                    with HookBwd(learn.model[-2][4][-1]) as hookg:  # for other layers\n",
    "                        with Hook(learn.model[-2][4][-1]) as hook:\n",
    "                            output = learn.model.eval()(x.cuda())\n",
    "                            act = hook.stored\n",
    "                        output[0, cls].backward()\n",
    "                        grad = hookg.stored\n",
    "                    w = grad[0].mean(dim=[1, 2], keepdim=True)\n",
    "                    cam_map = (w * act[0]).sum(0)\n",
    "                    # print(x.shape,x_dec.shape, w.shape, cam_map.shape)\n",
    "\n",
    "                except Exception as e:\n",
    "                    print(e)\n",
    "                # -----\n",
    "\n",
    "                # test_cam_map = cam_map.detach().cpu()\n",
    "                # Resize cam map so it's the same size as the image, as the output is much smaller\n",
    "                t_resized = transformF.resize(\n",
    "                    torch.unsqueeze(cam_map, 0), ds_meta[\"image_size\"]\n",
    "                )\n",
    "                t_resized = (\n",
    "                    torch.cat([t_resized, t_resized, t_resized], dim=0).detach().cpu()\n",
    "                )\n",
    "\n",
    "                # IMPORTANT : Change the pixels that are of higher intensity to 0 because they did not help the network get the right answer\n",
    "                x_dec[t_resized >= 0.008] = 0.0\n",
    "\n",
    "                x_dec = torch.einsum(\"ijk->jki\", x_dec)\n",
    "                plt.imshow(x_dec)\n",
    "                plt.axis(\"off\")\n",
    "                plt.box(False)\n",
    "                plt.savefig(rename_for_aug(items[im]), transparent = True)\n",
    "\n",
    "\n",
    "            clear_learner(learn, dls)\n",
    "            del bspred\n",
    "            del items\n",
    "            # del t_resized\n",
    "            gc.collect()\n",
    "\n",
    "    # Save model every n epochs\n",
    "    if total_epochs_passed % ds_meta[\"save_model_every_n_epoch\"] == 0:\n",
    "        learn.save(fname_training)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "db63ec5837ed7153ffcff7a5d42bf80536894c2cc03a9bb032bbe91b2078875e"
  },
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit ('pytorcher')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
